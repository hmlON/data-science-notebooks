АРРЫЕВ
ЫОЫЬШЕАВ
РВО ОВАММШО

Вачід М. Нітше1Ь1аи

ТЬе Нпічетзіъу
оі Техаз. Апзііп. Техаз

МсОгшн-НШ Воск Сошргшу
1972
 pagebreak 
АРРЫЕВ
ЫОЫЬШЕАВ
РВО ОВАММШО

Вачід М. Нітше1Ь1аи

ТЬе Нпічетзіъу
оі Техаз. Апзъіп. Техаз

МсОгшн-НШ Воск Сошргшу
1972
 pagebreak 
Д . Х иммельблау

ПРИНЛАДНОЕ
НЕЛИНЕЙНОЕ
ПРОГРАММИРОВАНИЕ

Перевод с английского
-И. М. БЫХОВСКОИ и Е. Т. ВАВИЛОВА

Под редакцией
М. Л. БЫХОВСКОГО

ИЗДАТЕЛЬСТВО «МИР»
МОСКВА 1975
 pagebreak 
УДК Б|.880.115

Книга посвященв методам оптимального управления системами
‹: нелинейными цыевыми функциями. Описаны методы нелинейного
программирования как при отсутствии ограничений на управляю-
щие переменные. так и при наличии ограничений. Рассматриваются
такие вопросы, как изможиость получения решения, время оптими-
зации, точность решения и т, д. Для наиболее важных методов при-
водятся программы решения на язык`е ФОРТРАН. Каждая глава
содержит много примеров. не только поясняющих теорию. но и иллю-
сгрируюших неОБХОДИМЫе вычислительные процедуры и используе—
мые програимщ

Книга представляет интерес для специалистов по автоматическф
му управдению, вычислительной технике и прикладной математике.

Редакция литературы по новой техники

@ Перевод на русский язык, «Мир», 1974

х 3314429
“041 ‹о1›-15 ’ "“‘
 pagebreak 
ПРЕДИСЛОВИЕ

Цель этой книги состоит в том, чтобы в доступной форме изложить некото-
рые из наиболее эффективных методов нелинейного программирования и дать
сравнитыьную оценку этих методов Для решения общей задачи нелинейного про‹
граммирования было предложено довольно много алгоритмов, однако лишь не-
многие из них оказались эффективными для задач большой размерности. Ни один
из этих алгоритмов не имеет по отношению к другим таких преимуществ, чтобы
его МОЖНО бЫЛО считать универсальным средством решения любых задач Не-
линейного программирования.

В данной книге описанию используемых мет0дов уделяется больше внима-
ния, чем математическим доказательствам сходимости адгоритмов нелинейного
програМмирования для определенных типов задач. Такие доказательств, разу-
иееюя, важны, однако они применимы только к весьма узким категориям задач
иімогут служить лишь как дополнительная информациядля исследователя, при—
меняющего тот или иной алгоритм. В отличие от линейного программирования
при решении задачи нелинейного программирования выбранный алгоритм может
оказаться эффективным, даже если не удается доказать его сходимость Справщ
лина и обратное утверждение, а именно: наличие доказательства сходимости алт`
рита в частных случаях может не означать, что он окажется удовлетворить…»-
инм для более сложных задач. '

В книге подробно описаны те алгоритмы нелинейного программирования.
которые оказались достаточно эффективными на практике. При сравнении алго-
ритмов были использованы следующие критерии:

]; надежность;

2 скорость решения;

3) время подготовки задачи для решения;

4) 'ючиость решения;

5) степень выполнения ограничивающих условий.

Рассматриваемые меюды предназначены для оптимизации значения некоторой
нелинейной функции при ограничениях в виде равенств и (или) неравенств,
содержащих функции большого числа переменных. Все э‘іи переменные являются
детерминированными (в отличие от случайных, или стохастических, переменных).
Описанные методы могут быть практически реализованы лишь при помощи совре—
менных цифровых или гибридных ЭВМ. Использование аналоговых вычислитель-
ных машин не рассматривается. Не раесматриваюгся также ни целочисленное (или
дискретное) программирование, ни методы поиска оптимального решения динами-
ческих задач, т. е. задач, в которых время является одним из параметров.

В этой книге мы не стремимся раскрыть отдельные тонкости методов оптишх-
зации, однако здесь приведены все необходимые подробности, позволяющие чи-
тателю проследить СУЩС’ГВЕННЫО этапы К82КД0Г0 ИЗ рассматримемых МЁЮДОВ.
Нередко оказывается, ЧТО детали программирования некоторого алгоритма,
особенно в часто повторяемых процедурах. заметно влияют на качество работы ал-
горитма в целом. Подробно рассмотренные примеры в конце каждого раздели пояс—
няют вычислительные аспекты алгоритмов; для иллюстрации логической струк—
туры алгоритмов приведено болЬШое количество блоксхем. Приложение 5 содер-
жит несколько машинных программ для наиболее удачных алгоритмов. Благодя ря
 pagebreak 
6 Предисловие

 

кому что для всех алгоритмов используются Одни и те же обозначения, можно глуб-
же понять их структурные связи друг с другом и общие свойства.

Книга состоит из трех частей Первая часть содержит две главы. Глава 1 пред-
ставили— собой краткое введение; в гл. ? формулируется общая задача нелинейного
программирования, рассиатрнвается связь нелинейного программирования с дру-
ГИМИ видами МаТеМЗТИЧеСКОГО программирования И, наконец. устанавливаются
необходимые И ДОСТЗТОЧНЫЕ УСЛОВИЯ существования оптимального решения.

Во второй части рассматриваются алгоритмы нелинейного программирования
при отсутствии ограничений. В гл. 3 описывается градиентный метод. метод вто—
рых производных и другие связанные с ними стратегии, в которых используются
производные. Глава 4 посвящена рассмотрению стратегий поиска. В гл. 5 дается
оценка различных алгоритмов оптимизации при отсутствии ограничений.

В Т етьей части описываются МГОРИТМЫ оптимизации при наличии ограни-
чений. лава 6 посвящена рассмотрению методов линеаризации. В гл. 7 изло-
жены методы штрафных функций, а в гл. 8 описан метод скользящего допуска.
Оценки алгоритмов оптимизации при наличии ограииіюний приводятся в гл. 9.

Приложение А содержит ряд упражнений с соответствующими решениями.
Кроме того, в каждой главе (за исключением первой] приводятся дополнительные
задачи, предлагаемые читателю для решения.

Для понимания описанных в книге алгоритмов необходимо знание основ ма—
тематического анализа, некоторое умение обращаться с матрицами и векторами.
а также знакомство (: ме'юдами решения задач линейного программирования.
В приложении В приводятся основные сведения из матричной алгебры. Для чтения
машинных программ необходимо знание основ программирования на ФОРТРАНе.
Однако эти программы снабжены необходимыми инструкциями, так что их можно
использовать, владея лишь методикой перфорирования. Такого рода «механичз-
ский» ПОДХОД К использованию программ иногда оказывается ВПОЛНе приеМЛемым.
однако при отсутствии должной осторожности он может привести :( ошибкам.

Д . М. Химмельблау
 pagebreak 
Часть |

ПРЕДВАРИТЕЛЬНЫЕ СВЕДЕНИЯ

В первой части книги сформулирована задача нелинейного
программирования. показана ее связь с реальными физическими
задачами, а также приведена терминология, связанная ‹: нелиней-
ным программированием. Кроме того, здесь описаны методы с по-
мощью которых можно определить, действительно ли предполага-
емое оптимальное решеНИе является оптимальным.
 pagebreak 
Глава 1
ВВЕДЕНИЕ

На протяжении всей своей истории люди при необходимости
принимать решения прибегали к сложным ритуалам. Они устраивали
торжественные церемонии,_ приносили в жертву животных, гадали
по звездам и следили за полетом птиц. Они полагались на народные
приметы и старались следовать примитивным правилам, облегчаю-
щим им трудную задачу принятия решений. В настоящее время
для принятия решения используют новый и, по-видимому, более
научный «ритуал», основанный на применении электронно—вычжли-
тельной машины. Без современных технических средств человече—
ский ум, вероятно, не может учесть многочисленные и разно—
образные факторы, с которыми сталкиваются при управлении пред‹
приятием, конструировании ракеты или регулировании движения
транспорта. Существующие в настоящее время многочисленные мате-
матические методы оптимизации уже достаточно развиты, что по-
зволяет эффективно использовать возможности цифровых и гиб—
ридных вычислительных машин. Одним из этих методов является
матемаТИческое программирование… включающее в себя как частный
случай нелинейное программирование.

Термин «математическое программирование» предложен Робер—
том дорфманом приблизительно в 1950 г.; теперь он объединяет
линейное программирование, целочисленное программирование, вы—
пуклое программирование, нелинейное программирование и програм-
мирование при наличии неопределенности. Нелинейное програм-
мирование имеет дело с оптимизацией нелинейных фуниций при
линейных и (или) нелинейных ограничениях. Типичными областями
его применения являются прогнозирование, планирование промыш-
ЛеНного производства, управление товарными ресурсами, контроль
качества выпускаемой продукции, планирование обслуживания
и ремонта, проектирование технологических линий (процессов),
учет и планирование капиталовложений. Пока еще не существует
общего метода решения Нелинейных задач оптимизации, такого, как,
например, симплексный алгоритм, разработанный для задач линей-
ного программироъзания. Нелинейное программирохзание при реше-
нии задач включает в себя элементы экспериментирования. Его
развитие до сих пор сводилось к предложениям частных адгоритмов,
 pagebreak 
Введение 9

 

программированию их, проверке результатов применения этих алгорит-
мов в конкретных задачах, представляющих практический интерес,
и построению лучших алгоритмов на основе приобретенного опыта.

Последние двадцать лет в области математического програм—
мирования значительные усилия были сконцентрированы на линей-
ном программировании. Полученные результаты столь значительны,
что достигнутый здесь уровень позволяет решать большинство
практических задач. Что же касается нелинейного программи-
рования, то, хотя здесь и было предложено большое число различных
стратегий поиска решений, успешное применение нашли лишь не-
многие алгоритмы. Область применения разработанных алгорИтмов
нелинейного программирования весЬМа ограничена. В связи с даль-
нейшим развитием ЭВМ и растущей необходимостью более точно
решать задачи, представляющие практический интерес, возникает
необходимость в методах решения задач нелинейного программи-
рования с более широкой областью применим0сти.

Большинство практических задач имеет несколько (а некоторые.
возможно, даже бесконечное число) решений. Целью оптимизации
является нахожление наилучшего решения среди многих потенци-
ально возможных в соответствии с некоторым критерием эффектив-
ности или качества. Задача, допускающая лишь одно решение,
не требует оптимизации. Оптимизация может быть осуществлена
при помощи многих стратегий, начиная с Весьма сложных анали-
тических й численных математических процедур и кончая разумным
применением простой арифметики. Предполагая, что подлежащая
оптимизации задача некоторым образом определена (не обязательно
математически), можно классифицировать общие методы оптими-
зации следующим образом:

1. Аналитические методы, использующие классические методы
дифференциального и вариационного исчислений. Эти методы заклю-
чаются в определении экстремума функции } (х) путем нахождения
тех значений х, которые обращают в нуль производные [(х) по х.
В случае поиска экстремума [ (х) при налИчии ограничений приме—
няются такие методы, как метод множителей Лагранжа и метод
ограниченных вариаций. При использовании аналитических методов
задача оптимизации должна быть сформулирована математически
с тем, чтобы можно было обращаться со всеми фигурирующими в ней
функциями и переменными при помощи известных правил. Для
реШения больших существенно нелинейных задач аналитические
методы оказываются непригодными, и поэтому в данной книге
они не рассматриваются.

2. Численные методы, использующие предшествующую инфор-
мацию для построения улучшенных решений задачи при помощи
итерационных процедур. Численные методы применяются для
решения задач, которые не могут быть решены аналитически, и,
поскольку практические задачи поддаются решению численными
 pagebreak 
10 Г лава 1

 

методами, именно эти методы нелинейного программирования явля-
тся предметом обсуждения в данной книге.

К другим обшим методам, которые эффективно применяются
при решении задач оптимизации, но которые здесь не рассматрива-
ются, относятся следующие:

3. Г рафические методы, основанные на графическом изображе-
нии функции, подлежащей максимизации или минимизации, в
зависимости от одной или нескольких переменных. Экстремум
функции в этом случае получают непосредственно путем анализа
ее графика. Преимущество графических методов состоит в том,
что они просты и сразу показывают, существует решение или нет.
С другой стороны, они применимы в тех случаях, когда критерий
качества является функцией одной или максимум двух независи-
мых переменных.

4. Эшериментальные методы. Экстремум функции можно
иногда найти, экспериментируя непосредственно с реальными
переменными вместо того, чтобы исслеДОВать соответствующую мате-
матическую модель. Результаты одного эксперимента используют—
он для планирования следующего эксперимента, позволяющего
получить улучшенные результаты.

5. Методы исследования различных варианта Эти методы осно-
ваны на анализе нескольких возможных решений одной и той же
задачи с целью выбора наилучшего. Таким образом, «наилучшее»
решение, полученное метощвм исследования различных вариантов,
будет скорее всего лишь субоптимальным.

При выборе наиболее подходящего способа описания реальных
процессов приходится сталкИВаться с рядом трудностей, которые
для удобства обсуждения можно подразделить на две группы.
Одна группа связана с построением математической модели про-
цесса, адругая -— с численными методами решения. В этой книге
мы можем только отметить эти трудности и, где возможно, указать
пути их устранения при описании того или иного конкретного ал-
горитма.

Математическая модель содержит функции, участвующие в про-
цедуре оптимизации. Очевидно, для того чтобы искомый экстремум
имел физический смысл, выбранная модель должна адекватно отра-
жать существенные черты реального процесса. Но даже если згю
требование выполнено, при построении модели встречатся следу-
ющие типичные затруднения:

!. ОптимизируеМЫй критерий может быть нечувствительным
к изменениям независимых (оптимизируемых) переменных и по-
этому не удается определить четко выраженный экстремум.

2. Оптимизируемый критерий или некоторые из ограничений
могут принимать в области поиска решения неограниченные зна-
чения; значения частных производных в математической модели также
могут стать неограниченными. Особенно подвержены эгой опасности
 pagebreak 
Введение "

 

модели с полиномами в знаменателе, Так, например, значения
функции
__ до + ”131
у _ ь ::
#14“ №2
и ее первой частной производной по х,

д_!/ _ _ додд +д1ьэх'д

дх, __ (%”1'1'1’35'72)“
обращатся в бесконечность при Ь1х1 = —Ь8х„. Эту трудность
можно преодолеть, ограничив области допустимых значений неза-
висимых переменных путем введения дополнительных ограничений
в задачу, или, же изменив формулировку самой математической
модели.

3. Переменные могут быть плохо масштабироваиы. Трудности
масштабирования могут возникнуть, например, когда один из
членов в выражении для критерия имеет существенно иной порядок
величины, чем другой. При аггом критерий становится нечувстви-
тельным к изменениям значений переменных в мевьшем члене.
Например, значение целевой функции

у = 100х3—о‚010хё

будет мало зависеть от изменения хг если только значение хя вслед-
ствие используемых физических единиц измерения не окажется
много больше значения Х1‚ Если яс2 представляет собой величину
того же порядка, что и ‚$1, то либо одну переменную, либо обе пере-
менные можно умножить на масштабные множители, в результате
чего оба члена в правой части приведенного выше соотношения ока-
жутся величинами одного и того же порядка. Положим, например,

32, = 10х„ хі = 10-233,

х:я = 10—32, 15% = 10533.

Тогда члены в выражении для целевой функции становятся вели-
чинами одного порядка. После того как найден экстремум для

'2 "2
у = х1— 152,

можно определить значения 1:1 и ::2 по значениям х, и х„. Конвчно,
не всегда удается так легко изменить масштаб функций в матема-
тической модели, как это сделано в рассмотренном примере.

4. В плохо построенной математической модели переменные мо—
гут оказаться взаимосвязанными. Взаимное влиянъю переменных
можно проиллюстрировать на примере очень простого критерия,
в который входит произведение двух параметров:

у = %.}:2 + 10.
 pagebreak 
12 Глава 1

 

 

Здесь каждая из переменных х, и :(2 может принимать различные
значения при заданном значении произведения х1хд. В том случае,
когда имеет место взаимное влияние переменных, осуществлять
масштабирование гораздо сложнее. Для исключения членов, со-
держащих произведение двух переменных, квадратичные формы
можно привести к каноническому виду. При этом определятся
новые координатные оси, называемые главными осями, относитель-
но которых данная поверхность второго порядка симметрична, 'На-
пример, поверхность

у=7й+6Ё+ЪЁ—4дщ—Ад№—Юд—2Мг+Ш№+18

путем смещения начала координат и поворота координатных осей
может быть приведена к виду

у—18=3х?+6хё+9х2.
В новой системе координат масштабирование каждого члена зна-
чительно проще, чем в исходной системе. Нелинейные функшш
можно сделать квадратичными при помощи подходящего преобра'
зования модели или разложения соогветствующих функций в ряд
Тейлора с сохранением конечного числа членов. Более тонким
примером, в котором взаимное влияние переменных оказывается
также весьма ощутимым, является следующий:

у = „гейма,

5. В математИческой модели может оказаться, что некоторые
из переменных исключаются путем их надлежащего преобразова-
нная. Пусть, например,

у=хЁ+2х1х2+х3+2=(х,+х„)”+2.
После преобразования хд + хд = 751 получим
у=Ё+2
Таким образом, вместо двух переменных в выражении для у оста

лась только одна переменная х], которую и следует варьировать,
чтобы найти экстремум у.

Вторая группа трудностей связана с численными методами
решения задачи оптимизации:

1. Как выбрать подходящие начальные значения независимых
переменных? Поскольку задача содержит нелинейные функции,
то в отличие от анализа линейных систем при этом“ возможно суще-
ствование нескольких экстремумов. Следовательно, если начальные
значения переменных находятся слишком далеко от искомого экс-
тремума, оптимизация может закончиться не вточке глобального
экстремума, а в некогорой точке, соответствующей локальному
экстремуму. Часто приблизительно оптимальные значения незави.
 pagebreak 
Введение 13

 

симых переменных можно получить на основе ранее проведенных
исследований или исходя из физпчщгких соображений. В крайнем
случае можно выбрать несколько начаЛЬных векторов из допустимой
области и проверИть, дают .;… они одно и то же значение критерия
в точке экстремума. Но при таком подходе имеются свои трудности;
о них уже упоминалось в связи с обсуждением проблемы построения
адекватнои модели.

2. Как учесть стохастическую (случайную) природу физических
переменных? Реальная возможность того, что коэффициентыи пере-
менные в математической модели могут быть случайными величи—
нами, в этой книге не рассматривается.

3. Как уменьшить ошибки вычислительной процедуры? Пог-
решности, возникающие при учете лишь конечного числа членов
при разложении функций в ряды, снижают эфрективность многих
алгоритмов. Устойчивость решения зависит от того, сходится ли в
пределе решение «аппроксимирующей» задачи нелинейного про-
граммирования к решению исходной задачи. Могут возникнуть так-
же неприятности из—за ошибок округления в процессе оптимиза-
ции, особенно при аппроксимации производных разностными выра-
жениями.

Как и любой математический аппарат, методы нелинейного
программирования нельзя слепо применять для решения той или
иной задачи без тщательного предварительного анализа. Практи-
ческое применение методов нелинейного программирования требует
от исследования определенного искусства. При этом совершенно
необходимо корректное построение модели и применение подхо-
-дящих численных процедур.

Книга состоит из трех частей. Первая часть посвящена пробле-
ме нелинейного программирования. Во второй части дается описа-
ние различных методов нелинейного программирования при от-
сутствии ограничений и проводится их сравнение. Наконец, в тре-
тьей части рассматриваются рабочие алгоритмы для нелинейно-
го программирования при наличии ограничений и проводится их
сравнительная оценка. В приложениях содержатся упражнения
(вместе с решениями), и также неопубликованные до сих пор ма-
шинные программы алгоритмов нелинейного программирования.
 pagebreak 
Глава 2

ЗАДАЧА НЕЛИНЕИНОГО ПРОГРАММИРОВАНИЯ
И ЕЕ ОПТИМАЛЬНОЕ РЕШЕНИЕ

В технике, экономике и естественных науках, как, впрочем,
и в других областях, часто возникают задачи оптимизации сложной
совокупности оборудования, операций, цепей или процессов. Тре-
буется минимизировать или максимизировать некоторую функцию,
называемую целевой функцией, которая характеризует цену, вес,
общую эффективность или нечто подобное при определенных огра-
НИчениях. Подобные задачи оптимизации, сформулированные ма-
тематически. могут быть объединены под общим названием задача
нелинвйного программирования ; методы решения таких задач лежат
в основе нелинейного программирования. В этой главе сначала
до некоторой степени формально описывается общая задача нели-
нейного программировжия и некоторые специальные вопросы.
Затем на примере демонстрируется связь между тем, что мы хотели
бы получить при оптимизации реального процесса, и математически…
описанием оптимизации. Далее приводятся необходимые определе-
ния и терминология и, наконец, описываются условия оптимальности,

2.1. ЗАДАЧА ЛИНЕЙНОГО ПРОГРАММИРОВАНИЯ

Задачей линейного программирования называется задача, в ко-
торой минимизируемым или максимизируемым крИтерием является
линейная функция, причем на переменные налагаюкя ограничения,
которые представляются линейными функциями. Комбинация ска—
ляров или векторов, обычно обозначаемых Х„ называется линей-
ной, если она может быть записана в виде

01Х1 + сяхя + ' ' ' + спхт (2'1'1)
где все коэффициенты с — константы. Например, функиия
4х1 + 3х2 + 5х3 + 2
линейна относительно переменных хр хз, хз. тогда как функция
2х? + х1х2 + зе“
нелинейна относительно тех же переменных. Величины Х„ …, Х„

НЗЗЫВЗЮГСЯ линейно зависимыми, ЕСЛИ ДЛЯ некоторого набора 0!
В предположении, ЧТО не все 0, равны нулю, имеет МЕСТО следующее
 pagebreak 
Задача нелинейного программирования 15

 

равенство:
п
сдх1 + е„Ха + - - - + с„Х„ = ;] сдХ, = 0. (2.12)
‚.
С другой стороны, если 2 с,Х‚› = 0 только тогда, когда все коэф—
і=1
фициенты с, равны нулю, то Х1‚ …, Хп назыиются линейно неза-
висимыми.

Линейное программирование стало быстро развиваться после
второй мировой войны,— привлекая Внимание математиков, эконо-
мистов и инженеров благодаря возможности широкого практиче-
ского применения, атакже математической стройности. Применение
линейного программирования оказалось плодотворным в таких
областях, как:

1. Оптимальное регулирование полетов на воздушных линиях`

2. Распределение во времени транспортировки грузов с заво-
дов и складов к базам.

3. Размещение электронного оборудования на морских судах.

4. Планирование промышленного производства.

5. Система оплаты контрактов.

6. Проектирование систем связи и распределение в них пото-
ков сообщений.

7. Распределение кадров.

8. Организация максимальных потоков в транспортных сетях.

9. Эффективное смешивание бензина.

Широкое привлечение внимания к линейному программированию
привело к тому, что до некоторой степени была преувеличена его
значимость; часто упускали из виду, что оно применимо лишь тогда,
когда выполняются лежащие в его основе гипотезы, которые в
свою очередь базируются на линейном математическом представ-
лении реального ‘мира. В нелинейном программировании не ис—
пользуются столь сильные упрощения.

Хотя задача линейного программирования может быть сформу—
лирована по-разному, запишем ее в следующей форме [1, 2]:

минимизировать у = ;: срс, (2.1.38)
при ограничениях

Ёаііхі—Ьі>0‚ і=1, ...‚ т, (2.1.36)

х,>0, і=1, ...,п, (2.1.313)

где а, 17 И с ——- константы, а х — искомые переменные. Для решения
задачи, выраженной уравнениями (2.1.3), были предложены раз—
личные методы, которые можно найти в списке литературы поме-
щенном в конце этой главы. Предполагается, что читатель знаком
 pagebreak 
16 Глава ?

 

 

с модифицированным симплексным методом решения. На фиг. 2.1.1

дано геометрическое представление граничных плоскостей для сле-

дующей типичной задачи линейного программирования:
максимизировать у = З::1 + 5х2 + 4х3

при ограничениях
2351 + 3153 < 8.

2х2 + 5х3 < 10,
3х, + 22:2 + 42:в < 15

для неотрицательных значений х“ ::2 и х„. Здесь целевая функция
изображена двумя плоскостями, соответствующими постоянным

3%: , 50/41. 52/41

    
    
  

2.124— 5а:_, : Ю

5х,+21-г+ 4.1515

2.1:‚+ 53:2: 8

Ф и г. 2.1.1. Геометрическое представление функций в задаче линейного програм-
мирования.

ее значениям. В обозначениях (2.1.3) эта задача может быть пере—
формулирована следующим образом:
минимизировать —у : —— (3х1 + 5х2 + 4х3)
при огранрщених
— <% + 3х2) +8>0‚

_ (2% + 5%) + 10 > 0,
 pagebreak 
Задача нелинейного праграммцровамия 17

 

_ (3х1 + 2х2 + 4х3) + 15 > 0»
х1>0› х2>0‚ хз>0'
Приведенный ниже Пример показывает, как На основании ИмеЮ'

щейся информации математически формулируется задача линейного
программирования.

 

Пример 2.1.1. Формулировка задачи линейного программирования

Этот пример иллюстрирует связь между уравнениями (2.1.3)
и реальной задачей. Фирма грузовых перевозок ассигнонала
600 000 долл. на приобретение грузовиков трех типов. Грузовик
А стоит 10 000 долл., грузовик В — 20 000 долл. и грузовик С ——
23000 долл. Сколько грузовиков каждого типа нужно заказать,
чтобы получить наибольшую производительность в ТОННО—милях
на один день с учетом приведенных ниже условий?

Грузовик А требует для обслуживания одного водителя на каж-
дую смену, максимальное число смен в сутки 3, производительность
2100 тонно—миль за каждую смену.

Грузовик В требует для обслуживания двух водителей на каждую
смену, максимальное число смен в сутки 3, производительность
3600 тонно-миль за каждую смену.

Грузовик С требует для обслуживания двух водителей на каж-
дую смену, максимальное число смен в сутки 3, производительнссть
3780 тоннс—миль за каждую смену.

Кроме того, число водителей должно быть не больше 145, чис-
ло грузовиков — не больше 30.

Эга задача может быть сформулирована втерминах линейного
программирования следующим образом Обозначим число смен
индексами 1, 2 и 3, а число грузовиков каждого типа — прописны-
ми буквами А, В и 0. Сначала необходимо выбрать критерий опти-
мальности. В данном примере этим критерием является произво—
дительность, соответствующая функции (2.1.33):

у : 2100,41 + 4200,42 + 6300/18 + 360031 + 720032 + 10 воовз+
+ 378003 + 756002 + 11 34005,

где у—количество тонно—миль. Запишем далее выражения для
ограничений. Здесь мы имеем дело с ограничениями трех типов:
1) общая стоимость всех грузовиков не должна превышать 600 000
долл., 2) число грузовиков должно быть не более 30, 3) число во-
дителей должно быть не более 145:

1) 10 000 (А1 + А2 + Аз) + 20 000 (31 + в„ + вв) + 23 000 («31 +
+ С; + Са) < 600 000;
 pagebreak 
18 Глава ?

 

2)А1+А2+АЗ+В1+ВЁ+ВЗ+61+С2+СЗ<3Щ

3) А1 + 21412 + ЗА3 + 28, + 413.2 + бвв + 201 + 462 + БСа < 145.
Кроме того, поскольку грузовики являются физическими объекта-
ми и их число не может быть отрицательной величиной, имеют
место следующие неравенства. соответствующие условиям (2.1.35):

Аі>0› Вк>0‚ С1>0» і=1‚2‚3.

Поставленная так задача может быть решена соответствующим
методом линейного программирования; в результате определяется
количество грузовиков типов А, В и С, максимизирующее вели-
чину у.

Решение: 12 грузовиков типа А, О грузовиков типа В и 18 гру.
зовиков типа С.

 

Матричные обозначения позволяют в компактной форме форму-
лировать задачи математического программирования и описывать
алгоритмы их решения. В приложении В приведены некоторые ос-
новные сведения о матрицах. Пусть х и с —— векторы-столбцы раз—
мерности п Х 1 в Е“ (т. е. в п-мерном евклидовом пространстве
переменных), а —— матрица констант размерности п Х т и Ь _ век-
тор-столбец размерности т Х 1

х1 ап ад..., и… [›1 с1

хе а а . . . аг [’я ся
х: : ‚а: д 22 ' … ‚ь: . ‚с: : ‚

х„ и… ап; .. . , а,… ' Ь,; с„

Тогда в матричных обозначениях уравнения (2.1.3) запишутся
следующим образом:

минимизировать у Е { (х) = сТх (2.1.48)

при ограничениях
аТх>Ь, (2.1.46)

х>0, (2.1.43)
где верхний индекс Т обозначает транспонирование. Вектор х*‚
удовлетворяющий соотношениям (2.1.4), представляет собой иско-
мое решение задачи.

2.2. ОБЩАЯ ЗАДАЧА НЕЛИНЕИНОГО
ПРОГРАММИРОВАНИЯ

В самом широком смысле общая задача нелинейного програм-
мирования заключается в отыскании экстремума целевой функции
при заданных ограничениях в виде равенств и (или) неравенств.
Ограничения могут быть линейными и (или) нелинейными.0днако
общепринята несколько более узкая постановка общей задачи не-
 pagebreak 
Задачи нелинейного программирования 19

 

линейного программирования, в которой исключатся из рассмотре—
ния следующие спеЦИальные случаи:

1, Переменные принимают лишь целочисленные значения (не-
линейное целочисленвое программирование).

2. Ограничения включают как параметр время, при этом исполь—
зуются дифференциальные уравнения (оптимальное управление,
динамическая оптимизация).

Пусть непрерывная функция [(х) представляет собой целевую
функцию, И1(х)‚...‚п‚„(х) задают ограничения в виде равенств, &

в…,… (Х , ..., Е„(х)— ограничения в виде неравенств, где х = 1х1,
..., хп] _вектор-столбец компонент @, …, х„в п-мерном евклидовом
пространстве.

Как и в линейном программировании, переменные хг ..., х„

могут быть конструктивными параметрами, установками регулято-
ра, показаниями измерительных приборов и т. д., тогда как целе-
вая функция может представлять собой стоимость. вес, годовой
доход и т. д., а ограничения —— технические требования, условия
работы‚ пропускную способность или факторы безопасности, при-
сущие данному процессу.

Формально задача нелинейного программирования может быть
сформулирована следующъш образом:

минимизировать і(х)‚ хе Е”, (2.2.1)
при т линейных и (или) нелинейных ограничениях в виде равенств
п,(х) =0, ]“ = 1, .. .‚ т, (2.2.2)

и (р — т) линейных и (или) нелинейных ограничениях в виде

неравенств
Е:(Х)>0‚ і=т›+1‚ р. ‘ (2.2.3)

Хотя в некоторых частных случаях ограничения в виде равенств
могут быть явно разрешены относительно выбранных переменных,
которые затем исключаются из задачи как независимые переменные,
и в задаче остатся только ограничения в виде неравенств, чаще
всего ограничения в виде равенств не могут быть явно разрешены
и потому сохраняются.

2 Иногда встречается другое представление выражений (2.2.1)—
( .2.3):

минимизировать {і(х) ] х 6 К}, (2.2.4)

где В — область пространства перемениой х, для которой выполне—
ны условия (2.2.2) и (2.2.3), например
К ={х1пі(х)= О‚ д,(х)>0 для всех і}. (2.2.5)

Знак неравенства в выражении 31 (х) > 0 может быть изменен на
обратный путем умножения на ——1‚ что не изменит математической
постановки задачи.
 pagebreak 
20 Глава 2

 

В качестве простого примера задачи нелинейного программи-

рования, которую можно проиллюстрировать графически, приведем
следующую:

минимизировать {(х) =- 76% + хЁ .|. 2х2
при ограничениях
п1(х)=х‘і`+ ›‹3— 1 =0‚
Ев (х) = ": + 2х2 " 0,5 > 0.
83 (Х) : 361 > 0,
54 (х) = ‚152 > 0.

На фиг. 2.2.1 целевая функция изображена пунктирными Линиями,
ограничение в виде равенства — жирной сплошной прямой, а гра-

 

Ф и г. 2.2.1. Г еометрическое представление функций в задаче нелинейного про-
граммироваиия.

ница области, определяемой ограничениями в виде неравенств,—
линиями со штриховкой (нанесенной с внутренней стороны области).

В каждой точке х п-мерного пространства переменных хр ..., х„
функция [(х) имеет опредеЛенное значение, и, следовательно,
это п-мерное пространство представляет собой скалярное поле
 pagebreak 
Задачи нелинейного программирования 21

 

для критерия оптимальности. Как показано на фиг. 2.2.1, в этом
пространстве можно вычертить семейство линий уровней (эквипо-
юнциальных гиперповерхностей) для выбранных значений функ-
ции [(х). Пространство переменных х., .., х„ является также ска-
лярным полем для функций ограничений, для которых также можно
изобразить графически эквипотенциальные гиперповерхности. При
помощи классических методов анализа в общем случае невозможно
заранее выявить расположение точки х*‚ которая соответствует
минимальному (или максимальному) значению функции )‹ (х),
поскольку она может находшься на пересечении ограничивающих
поверхностей или между ними.

Задачи линейного и квадратштого программирования могут
рассматрИВаться как два частных случая общей задачи нелинейно—
го программирования. Если и функция (2.2.1), и уравнения (2.2.2),
и неравенства (2.2.3) линейны, то мы имеем делосзадачей линейного
программирования. Если же целевая функция квадратична, &
ограничения линейны, то имеет место задача квадратичного програм-
мирования:

минимизировать [(х) = а., + сТх + хтах (2.2.63)

при ограничениях
атх > Ь, (2.2.66)

х >О, (2.2.613)

где 0 —- положительно определенная или неотрицательно опреде-
ленная квадратичная симметрическая матрица, а а и Ь —— матрицы
коэффипиентов, определение которых дано выше в связи с уравне-
нием (2.1.4). В приложении В дано определение положшельно
определенной матрицы. Иногда в задачу квадратичного програм-
мирования включают линейные ограничения в виде равенств

атх = ь. (2.2.6г)
Примером задачи квадратичного программирования может служить
следующая:
минимизировать ‚°(х) = 0,5х? + 0,563 — х! —— 2х2

при ограничениях

е.(Х)=6—2х1—3х„>0‚

3‚(х):5—х1——4х,’‚>.0,

39 (Х) : И > 0,

34 (х) : яс2 > 0.

Во веех трех классах задач — нелинейных, линейных и квадра-
ч . ' 0
тичных -— нужно наити вектор х* = 1х1, …, х…!Ёминимизирующии
 pagebreak 
22 Глава 2

 

(или, наоборот, максимизирующих?) функцию { (х) при следующих
условиях:

И1(Х)=0‚ і=1‚..-‚т.ие;(Х)>0‚ і=т+1‚.--‚Р‹

23. СВЯЗЬ ЗАДАЧИ НЕЛИНЕИНОГО
ПРОГРАММИРОВАНИЯ С РЕАЛЬНЫМ ПРОЦЕССОМ

В некоторых задачах оптимизации, таких. как задача миними-
зации по методу наименьших квадратов («минимизировать сумму
квадратов отклонений наблюдаемого выхоцного сигнала от жела-
емого») или минимизация интеграла, появляющегося в вариацион—
ной задаче, постановку задачи нелинейного программирования
можно легко связать с рассматриваемой физической задачей.
Но в других случаях это не так. Рассмотрение только математической
постановки задачи нелинейного программирования само по себе
не позволяет Выявить все факторы, от которых зависит оптимиза-
ция реального процесса. В этом разделе будет кратко рассмотрена
взаимосвязь физической задачи иее математического представления.

При оптимизации реального процесса параметры и (или) пере-
менные связаны физическими законами, _такими, как законы сохра—
нения массы или энергии, которые должны быть включены в задачу
нелинейного программирования как ограничения в виде равенств,
даже если они только псдразумеваются. Таким образом, одна группа
ограничений состоит из функциональных связей, которые сле-
дует учитывать, чтобы оптимизация была физически осуществимой.
Вторая группа ограничений вклъочает заданные предельные диапа-
зоны значений переменных или параметров, обеспечивающие их
физическую реализуемость или совместимость с данным процессом;
к этой группе относятся ограничения в виде неравенств. Заменить
эти ограничения или добавляться к ним могут эмпирические связи.
как правило, выражаемые равенствами. Наконец, для упрощения
уравнений молели процесса часто вводят новые переменные, которые
образуют дополнительные ограничения в виде равенств в том слу—
чае. когда исходные уравнения не могут быть разрешены в явном
виде относительно определяемой переменной. На фиг. 2.3.1 показа-
ны связи между различными частями задачи нелинейного програм-
мирования и алгоритмом решення4

Каждое огранИчение в виде равенства уменьшает на единицу
число степеней свободы в модели процесса и приводит к появлению
еще одной зависимой переменной. Обычно предполагается, что урав—
нения модели процесса записыватся достаточно аккуратно, так
что все равенства Являются независимыми; если же из-за невнима.
тельности или ошибки в задачу включатся два избыточных, или,
другими словами, зависимых, уравнения, то число степеней сво-
боды будет отличаться от действительиого. Число остаточных сте.
 pagebreak 
Задача нелинейного программирования 23

 

пеней свободы должно соответствовать числу независимых перг-
мгнных (часто называемых переменными решения) в рассматривае-
мой задаче нелинейного программирования. Оно является важным
понятием в задаче оптимизации любого типа при ограничениях
в виде равенств, ибо если число переменных равняется числу
независимых ограничении в впаде равенств, то оптимизировать
нечего— значения всех переменных можно непосредственно

Целевая
функция

Паг)

      

 
      
 
  
 

    

Алгорчтм
‚,ПРИ-44917717“ нелинеинаго Независимые
лраграммирода- перемгнные ::

НИЯ

 
 
   
   
 

Ограничения
! виуераввпотв “.И-0
в шуе неравелвтвуд ;

Ф и г. 2.8.1. Соотношение между отдельными частями задачи нелинейного про-
граммирования и алгоритмом решения.

определить из совместного решения системы ограничений в виде
равенств Н, (х) = 0, ; = 1, …, п. Если число переменных превышает
т _ число независимых ограничений в виде равенств, то единствен-
ный способ решения, приемлемый для данной модели процесса,—
это варьирование (п — т) переменных решения, пока целевая
функция не достигнет своего оптимального значения. Если число
независимых ограничений в виде равенств превышает число пере-
менных, то также возникает необходимость оптимизации, Однако
следует иметь в виду, что целевая функция в этом случае должна
представлять собой некоторый статистический критерий, например
такой, как в методе наименьших квадратов.

Поскольку в задачах нелинейного программирования, соответ-
ствующих некоторым физическим процессам, исключение зависи—
мых переменных путем подстановки нелинейных функций может
представлять некоторые трудности, одну или несколько зависимых
переменных можно рассматривать как переменные решения наря—
ду с действителъно независимыми переменными. Например, в за-
даче

минимизировать [ (х) : х]? —- ЗхЁ + ‚их? + хдад + хз + 6
 pagebreak 
24 Г лава 2

 

при ограничениях

”100:(х1_хя+2)8_0/х_я+ха+2›2=01
”2(х)=х1+х2+хз+3=0

весьма просто разрешить ограничение И, (х) = х1 + ›‹2 + ха + 3 =
= 0 относительно хз, исключить хз из [(х) и И1(х) и устранить
112 (х), тогла как разрешить Ид (х) относительно х1 или 2:2, чтобы
исключить одну из этих переменных из целевой функции, гораздо
сложнее. Обычно оказывается проще, особенно если задача содер—
жит несколько нелинейных ограничений типа равенств, сохранить
(как это имеет место в данной задаче) И1 (х) как функцию—ограниче-
ние и в вычислительной процедуре рассматривать х как вектор,
состоящий из двух переменных. Тем не менее на самом деле здесь
имеется лишь одна остаточная степень свободы, Некоторые алгорит-
мы использут преимущества уменьшенного числа степеней свобо-
ды. учитывая ограничения в виде равенств и акТИВные ограничения
в виде неравенств путем поиска оптимума в пространстве меньшего
числа измерений.

При исключении одной из переменных в целевой функции пу-
тем подстановки необх0димо соблюдать осторожность, чтобы не
изменить область определения переменных. Например, если _і(х) :
= ——-хЁ + х2 и Их) = — х? ——хЁ + 1 = 0, область изменения ›‹:в
должна быть ограничена пределами — 1 < х2< 1, поскольку мень-
шие или большие значения яс2 дают мнимые значения х1. Исключе-
ние х, путем подстановки х? = 1 ——хЁ приводит к [ (яги) = [ (х) :
=х2+хЁ——1 и кажется, что величина ::и может быть неограни-
ченной, тогда как в действительности, чтобы задача не изменились.
к функции )‘(х2) нужно добавить ограничение — 1 < ›‹:3 < 1.

В качестве иллюстрации понятия остатоцных степеней свободы
для п>т рассмотрим задачу нахождения объема и линейных
размеров наибольшего ящика, у которого сумма длины и попереч-
ных размеров не превышает 1,8 м. (Ответ: У = 0,6 >< 0,3 Х 0,3 =
= 0,05 м3.) Эту задачу можно сформулировать как задачу макси-
мизации, в которой критерием качества является объем ящика:

Максимизирова'гь {(х) = хмм… ХЕ Е“, при указанных выше
условиях на линейные размеры; кроме того, имеются неявные усло-
вия, требующие, чтобы размеры были неотрицательными:

31(х):1‚8-—х1——2х„——2х3>0‚
5і+1(х):х,->0, і=1‚...,3.

ЕСЛИ исследователь забудет ВКЛЮЧИТЬ В задачу ЭТИ неявные огра-
НИЧЕНИЯ‚ ТО ОН может ПОЛУЧИТЬ правильное математическое решение,
не имеющее НИКЗКОГО ОТНОШЕНИЯ К действительности.
 pagebreak 
Задача нелинейного программирования 25

 

Поскольку задача не включает ограничений в виде равенств,
она имеет три остаточные степени свободы; это значит, что все три
переменные можно изменять независимо при условии, что не нару—
шаются ограничения в виде неравенств. Если ввести в задачу огра-
ничение в виде равенства, например требование о том, чтобы высота
и ширина ящика были равны, т. е 111 (х) = 16.2 —— ):а = 0, то задача
будет иметь лишь две остаточные степени свободы. Очевтадно, что
в этом простом примере одну переменную х, или хз можно исключить
из целевой функции и задача сведется к максимизации объема путем
изменения лишь двух независимых переменных. Однако в более
реальных задачах исключение одной переменной из целевой функции
может оказаться неосуществимым. Вопрос о том, какие конкретные
переменные взять в качестве независимых, а какие — в качестве
зависимых, решается в некотором отношении произвольно, но ис-
следователь должен всегда иметь в виду определенные естественные
оптимизирующие переменные, связанные с данной моделью процес-
са, которые либо легко контролируются, либо являются удобными
в математическом отношении.

В приведенном внже примере 2.3.1 формулируются отдельные
части задачи нелинейного программирования для иллюстраЦИи того,
как в подобных задачах реальное явление связано с его математи-
ческим представлением. Заметим, что переменные являются тем
механизмом, при помощи которою осуществляется передача инфор-
мации между целевой функцией и заданными ограничениями. В це-
левую функцию могут входить как зависимые, так и оптимизирую-
щие переменные.

 

Пример 2.3.1. Моделирование и оптимизация работы доменной
печи

Планка в доменнои печи является распроотраненной и важной
технологической операцией на любом сталеЛИтейном заводе. В не-
которых отношениях она может рассматриваться как типичный
промышленный процесс. Имеется довольно большое число сущест—
венных переменных этого процесса (некоторые из них не могут быть
измерены), взаимодействующих весьма сложным образом; следует
учитывать большое число ограничений; условия работы завода
часто таковы, что оптимальная рабочая точка значительно изменя-
ется со временем. Таким образом, подробное исследование задачи
оптимизации работы доменной печи оказывается поучительным,
обнаруживая характер и степень трудностей, встречающихся при
математическом представлении типичного промышленного про‹
цесса.
 pagebreak 
Таблица П 2.3.1
Связь между процессом и его математическим представлением

___-Щ

Процесс Анализ процесса Математическое представляющие

 

Передача внешней информации и инфо!» Оптимширующие перемен-
МЗЦИИ () процессе при помощи перемен- нне, зависимые перемен-
ных и параметров ные и коэффициенты

Связь между процессом и его математическим представлением Связь между целевой функцией и моделью про-
цесса

Входные и выход- Сопутствующие цены Целевая функция [(х)
ные переменные и доходы

    

Известняк Руда ] ::с| Предельные 01 Минимизировать
Производствен-
№1“: В Руда 2 : х, ные затраты с, , ("‘) = ”1”! + ‘гхя +
КоксА дд’хёу и т. д. + - ' - +с‚х‚ + ”вх: +
Загрузка же _ Р
лезнаго ме— + " +011 3— +
№427 таллолома: Зі + А1
Руда ,? К х, А Рыночная цена % + “ ' + Сп (№}!-
5 °“ : х, Рыночная цена с, __ Р 51,2
Рууд К°“ В: ха Рыночная цена сд + сы + › +
Чугун в чуш- + +свб+ ---
ддг дата ках: Р Рыншная цена 0]:
ЖЗЛ Зіідгд
мгта—дддддма :! 5”! Газ: 6 Расчетная цена сс Модель процесса
шлак в чушках
 pagebreak 
Материальные и энергетические балансы

Баланс металла
Баланс шлака

Газовый баланс
Энергетический баланс

Балансы элементов (0, Н, 5, Зі, и
т.д,)

Ограничения процесса
Количество кокса

СКОРОСТЬ ПРОИЗВОДСТВЗ ЖИДКОГО ме-
ТЗЛЛЗ

Пригодность руды
Элементы в шлаке

Элементы в металле
Основность

ОграНИчения в реализации

Ограничения в виде ра—
венств

п,(х)=0,і=1….‚т‚
а1х1+а2х2+"'+
Са+М
+аз_ы_5+.…=о

О
[а\ос+аъ1(н_8`) + а1=31><

Х‹х7+хв)т1+
+аюгтз+ш=о
ит.д.

Ограничения в виде не-
равенств

 

Зі… <О,
і=т+ 1. - . р‚
х7<а3ш
[”а/(й + ": +

+ . . .)1<0‚2,

“42 < (Са + М&М
/(5і + АГ)
И Т. Д_
 pagebreak 
28 Глава 2

 

Описание процесса

Доменная печь работает полунепрерывно. Сырьем являются
железная руда, содержащая приблизительно 20—60% железа
в окислах, разнообразные окислы других металлов и неметаллов,
& также кокс, образующий при сгорании домениый газ. Кроме газа,
который может служить средством подогрева для других процессов,
выход печи состоит из расплавленного железа, все еще содержащего
некоторые примеси (в заметных количествах углерод и фосфор),
которые должны быть удалены в процессе изготовления стали,
и шлака, содержащего большинство примесей, который не представ-
ляет ценности. Стоим0сти железной руды и коксового топлива при-
близительно одинаковы. Требуется выбирать руду, скорость про-
изводства и тип процесса, которые бы максимизировали «доход»
огг производства или минимизировали стоимость изготовления требу-
емого количества расплавленного металла нужного качества.
В табл. П.2.3.1 схематически изображен поток материалов в до-
менной печи, являющейся частью большого завода.

Улучшение качества этого (или любого другого) процесса с ис-
пользованием вычислительных, а не экспериментальных методов
может быть осуществлено следуЮЩими этапами:

1. Анализ процесси, при котором определятся важные пере.-
менные и специфические характеристики задачи.

2. Определение целевой функиии и критерия кичества (прибыль,
эксплутационные расходы, объем и т. д.) и выражение критерия
в виде мшпематической функции.

3. Разработка матеМатической модели процесса, которая свя-
зытет переменные входа и выхода и перечисляет ограничения.

4. Применение процедуры оптимизации к матеМатической поста-
новке задачи.

Эти этапы схематически представлены в табл. П.2.3‚1. Поясним
некоторые понятия, лежащие в основе представленных здесь урав-
нений.

Целевая функция

При формулировке критерия в виде функции стоимости следует
рассмотреть две категории затрат:

1. Затраты, связанные с движением материалов (входные и вы-
ходные переменные), как, например, затраты На приобретение ма-
териалов за вычетом дохода от продажи побочных продуктов.

2. Затраты на осуществление технологИческих процессов, ко-
торые связываются с переменными процесса путем анализа или
с помощью эмпирических кривых.

В табл. П‚2.3.1 приведена типичная целевая функция.
 pagebreak 
Задача нелинейного программирования 29

 

М тематическая модель

Следующим шагом в формулировании задачи является построе-
ние математической модели процесса путем рассмотрения основных
химических и физических явлений, лежащих в его основе. В слуЧае
доменной печи типичными являются следующие обстоятельства:

!. Железная руда. В ограниченных количествах пригодны руды
различных градаций. Разные руды имеют различный процент желе-
за и различные виды и количество примесей. Предполагается, что
доля руды каждого типа, переходящей в расплавленный металл,
имеет определенную величину.

2. Кот. Количество сжигаемого кокса в любой печи существен—
но ограничено ее конструкцией. Скорость расхода кокса может
определяться на основе эмпирических соотношений, разрабОТанных
с помощью множественной регрессии.

3. Качество руды. Должно иметь место ограничение на количе-
ство используемых «твердых» руд. Аналогично должно быть нало-
жено ограничение на количество очищенной руды, избыток кото—
рой нарушает поток газа в печи и ограничивает выход продукции.

4. Фосфор. Весь фосфор из сырья поступает в расплавленный
металл. Устанавливается верхний предел допустимого содержания
фосфора, хотя иногда и предписывается точные количества, Обыч-
но дешевле производить железо с большим содержанием фосфо-
ра, однако гораздо дороже затем его очИЩать.

5. Другие элементы. Окислы кальщхя, кремния, магния и алю-
митхя выходят в шлаки. Две трети марганца поступает в расплав-
ленный металл, и устанавливается ограничение на допустимое
количество этой примеси, Количество серы в загрузке не должно
превышать 1,6% общего веса шлака; в противном случае слишком
много серы попадает в расплавленный металл.

&. Шлак. По техническим причинам уровень примесей в шлаке
должен контролироваться. При этом устанавлиВатся верхний`
предел на процентное содержание магния, верхний и нижний преде—
лы на процентное содержание кремния и алюминия и узкие пределы
на отношение основностей ‹сао + МдО /5і02 + Аіяод).

Исходя из эггих и других факторов оказывается возможным
пол чить:

. Набор входных и выходных переменных,

2. Уравнения установившихся материальных и энергетических
балансов между входом и выходом.

3. Набор ограничений на входные и выходные переменные для
условий производства и рынка.

Типичные взаимосвязи показаны в табл. П.2.3.1.

Как и следовало ожидать, основными недостатками формули-
рования этой задачи нелинейного программирования являются
незнание истинных значений параметров в уравнениях Мате
 pagebreak 
30 Глава 2

 

рИЗЛЬНОГО И энергетического баланса; предположение Об установив-
ШИХСЯ УСЛОВИЯХ, тогда как В действтельности В процессе имеют
МеСТО изменения; СТОХЗС’ТИЧеСКаЯ7 а не Детерминистическая ПРИРОДЕ!
переменных И параметров И Т. д. ТЕМ не менее ЭГО скорее недостатки
анализа на стадии ПОСТРОЕНИЯ МОДЕЛИ, чем на стадии оптимизацищ
ЧТО ЯВЛЯЕТСЯ ОСНОВНЫМ предметом ЭТОЙ КНИГИ.

 

2.4. ОБОЗНАЧЕНИЯ И ТЕРМИНОЛОГИЯ

чтобы выделить определенные аспекты ИСПОЛЬЗУЕМОЙ В книге
терминологии, В ЭТОМ разделе сделаны некоторые предварительные
замечания ОТНОСИТЕЛЬНО ряда ТЕРМИНОВ, дОВОЛЬНО часто встречаю-
ЩИХСЯ В литературе по оптимизации.

2.4.1. ОПТИМАЛЬНЫЕ РЕШЕНИЯ

Вектор х*=[хТ, ..., 1:211, удовлетворяющий соотношениям
(2.2.1) — (2.2.3), называется оптимальной точкой, а соответствую—
щее значение [ (#)—оптимальным значением целевой функции.
Пара х* и Нх“) составляет оптимальное решение. Как показано
на примере мультимодальной функции на фиг. 2.4.1, могут сущесг—
вовать различные типы оптимальных решений, если целевая функ—
ция не является унимодальноа (т. е. имеющей один экстремум).
Глобалъное оптимальное решение представляет собой наименьшее
значение [ (х), тогда как локальное (или относительное) оптимальное
решение представляет собой наименьшее значение [ (х) в окрестносги
некоторого вектора х. Как для глобального, так и для локального

минимума
Г (Х“ < ‚ (Х).

но для глобального оптимадьного решения это соотношение Выпол-_
няется для всех х в Б”, тогда как для локального оптимального
решения это имеет место только для малой области С, где“ х -
——х*\|< ;. Если принимается во внимание и точность решения,
то условие оптимальности можно представить в виде

ПХ') «(Х) -‘У‚
Где ’У— некоторая малая величина.

Все алгоритмы, описываемые В ПОСЛЕДУЮЩИХ главах. дают ЛИШЬ
локально оптимальные решения, так как на каждом этапе решения
при дВИЖеНИИ К Х‘ ОНИ ЗаВИСЯТ В ОСНОВНОМ СУГ локальных СВОЙСТВ
целевой функции и ограничений. Правда, некоторые алгоритмы,
такие, как алгоритм, описываемый в гл. 8, вероятнее всею, закон-
 pagebreak 
Задача нелинейного программирования 31

 

Ликвидные оптимумы
при атсутотаци
ограничении

   
  
 
     
  

3,0

25

20
!5

  

Глдбальный
Леулошя тичма “”Ш”-д.04“

 

Ф и г. 2.4.1` Классификация оптимальных решений,

чатся в точке глобального оптимума, так как здесь при поиске
рассматривиется широкий диапазон изменения х, однако сходимость
к глобальному оптимуму не может быть гарантировина без допол-
нительных сведений относительно природы целевой функции и
ограничений. На практике предположение о том, что локальный экс-
тремум является глобальным, может быть проверено путем ис-
пользования нескольких начальных векторов, но даже если найдено
только одно локальное решение‚ в общем случае нельзя показать,
что это решение обязательно является глобальным оптимумом.
К счастью, для задач, соответствующих действительным физиче-
ским процессам, целевая функция обычно является хорошей и об-
ладает единственним эксгремумом. Поэтому для большинстви
практических целей использование численных процедур, дающих
локальное решение задачи программирования, не является боль-
шим недостатком.

2.42. ВОГНУТОСТЬ И ВЫПУКЛОСТЬ

Понятия вогнутости и выпуклости полезны при определении
того, при каких условиях локальное оптимальное решение является
также глобальным оптимальным решением, чю предсмвляется
вахтым в случае множественных оптимумов.

Функция ф (х) называется выпуклой в области К, если для лю-
быхдвух векторов и! и х„ Е К

Мех; + (1 _в) Ха) < ВМХ.) + (1 — 9)Ф (Ха). (2-41)
 pagebreak 
82 Глава 2

 

где 0 _ скаляр, изменяющийся в диапазоне 0 < 9 < 1. Функ-
ция ф (х) является строго выпуклой, если для ›‹1 ;& ›‹2 в выражении
(2.4.1) используется знак неравенства (<). (Векторное неравенство
х > у означает, что х,- } у; для каждого элемента; в слуЧае х > у
справедливо неравенство х; > у, для всех і.) Существуют и ЦРУГИе

фас) ?(ас)

 

Ф и г. 2.4.2. Выпуклые (а) и вогнутые (6) функции (в данной области изменения х).

определения выпуклости, предложенные Понстейном [3]. На фиг.
2.4.2 геометрически изображена строю выпуклая функъшя одной
независимой переменной; выпуклая функция не может принимать
значения, большего чем значения функции, полученной линейной
интерполяцией между ф (х1) и ф (кд. Если имеет место неравенство,
обратное (2.4.1), то функция называется вогнутой. Таким образом,
функция ф(х) вогнутая (строго вогнутая), если —ъф (х) выпуклая
(строго выпуклая). Линейные функции одновременно и вогнутые
и выпуклые. Дифференцируемая выпуклая функция обладает
следующими свойствами:

1) ф<хд—ф‹х1›>7’ф‹хд‹м » кд для всех х„ хз;

2) матрРЩа вторых частных производных ф (х) пох
(матрица Г ессе) положительно определенная
(или положитеЛЬно полуопределенная) для
всех х, если ф (х) строго выпукляя (или просто
выпуклая);

3) в области И функция ф (х) имеет только один
экстремум.

(2.4.2)

Требование унимодальиости функции является значительно
более слабым, чем требование вогнутости или выпуклости, посколь-
ку, как видно из фиг. 2.4.3, а, унимодальность не требует ни не—
прерывности, ни единственности производной.

Множество точек (или область) называется выпуклым в п-мер—
ном пространстве, если дЛя всех пар точек х1 и х… принадлежащих
этому множеству, отрезок прямой линии, соединяющей их, также
 pagebreak 
Задача нелинейного программирования 33

 

Кас) {(х)

.2'
а 6
Ф и г. 2.4.3. Унимодальная (а) и мультимодальная (6) функции.

ПОЛНОСТЬЮ ПРИНШЪЛЖИ’Г множеству. Так, каждая ТОЧКЗ Х, опреде-
ляемая ВЫРЮКВНИЁМ

х=6х‚+(1—6)х2‚ о<е<1‚

также принадлежит множеству. На фиг. 2.4‚4 изображены выпук—
лое и невыпуклое множества в двумерном пространстве. Например,
следующая группа выражений определяет выпуклую область (воз-
можно, пустую или неограниченную):

Е/ (Х) < дд
аітх = 17],

если все 3, (х) выпуклы (фиг. 2.4.5).

Заметим, что из понятия выпуклости вытекает один важный
результат математического программирования [4]. Задача нелиней-
ного программирования, представленная в виде задачи выпуклого
программирования, формулируется следующим образом '):

минимизировать {(х)

при ограничениях
Е;(Х)>0› !=1› ‚0,
х>0.

где Нк) — ВЫПУКЛая функция и каждая функция, задающая огра-
ничение в виде неравенстВа‚— вогнутая функция (ограничения
образуют выпуклое множество}. При этом можно показать справед-
ливость следующего положения: локальный минимум является
также и глобальным минимумом, Аналогично локальный максимум

“ Иногда в задаче выпуклого программирования ограничения в внде ра-
венств Р:; (Х) = 0 добавляются к ограничениям в виде неравенств; и в этом слу-
чае !:; (х) должны быть линейны.

9 444
 pagebreak 
34 Глава 2

 

„, а:, 6 .::,
Ф и г. 2.4.4. Выпуклое (а) и невнпуклое (б) множества.

является глобальным максимумом, если целевая функция вогну-
тая, а ограничения образуют выпуклое множество.
Рассмотрим следующую задачу (фиг. 2.4.5):

минимизировать ;“ (х) = х? + хг — 4х1 + 4

при ограничениях
3100 =”1_хя+2>0.

3„(х)=—х%+ гя—1>0.
Е,(Х)=хд>0,
54(х)=х‚>0.

Внимательнее изучение кривых (к тому же выводу можно прий-
ти и аналитически) показывает, что ограничения образуют выпук-
лую область (допустимая часть области заштрихована), поскольку
функции 3, (х) и 9, (х) (и 3, (х)) линейные и, следовательно, во-
гнутые (правда, они одновременно и выпуклые), а функция ея (х)
сгрого вогнутая. Можно показать, что функция 32 (х) вогну-
тая, заметив, что матрица Гессе функции —- 32 (х) положительно
полуопределеННая:

дядя (” дяди “)
дх? дхддхв [—-2 0]

1923201) №2 (в:)
дхідх, дх;

Целевая функция Нк) строго выпуклая, и локальный оптимум,
являющийся также и глобаЛьНЫм оптимумом, достигается в точке
Т
х* = [0,58 1,34] , где і (х) = 3,80.
В задаче линейного программирования, имеющей оптимальное
решение, целевая функция всегда выпуклая, а ограничения обра-
 pagebreak 
.!атдний \
:: набили"!!!
оптимум

     

Ф и г. 2.4.5. Задача выпуклого программирования. иллюстрирующая допустимую область (представляю-
щую собой выпуклое множество) и глпбальный оптимум.
 pagebreak 
36 Глава 2

 

ЗУЮТ выпуклое множество, так ЧТО локальный ОПТИМУМ всегда ЯВ-
ЛЯЕТСЯ В ТО ЖЕ время И глобальным ОПТИМУМОМ. Ограничения В 33-
даче кзадратичного программирования те ЖЕ, ЧТО И В задаче линей—

ного программирования, а целевая функция выпуклая, если х10х
является положителъно полуопределенной; следовательно, матрица
0 должна быть неотрицательно опредыенной. Однако только
при особых обстоятельствах можно показать, что общая нелинейная
функция } (х) является выпуклой, а ограничения образуюг выпуклое
множество. Так, одной из самых серьезных трудностей является
то, что нелинейные равенсггюа не могут быть частью выпуклой облас-
ти, содержащей больше чем одну точку, поскольку прямая линия,
соединяющая две любые несмежные точки, удовлетворяющие дан—
ному равенству, не может в то же время проходить и через другие
точки, удовлетворяющие этому равенотву, как это требуется для
выпуклости. Тем не менее в особом случае, когда ограничивающее
множество образовано лишь ограничениями в виде неравенств
и все функции—ограничения являются вогнугыми, так что точки,
для которых 3; (х) > 0, образуют выпуклое множество, задача не-
линейного программирования может представлять собой задачу
выпуклого программирования.

2.4‚3. ДОПУСТИМОСТЬ

Любой вектор х, удовлетворяющий ограничении в виде ра-
венств и в виде неравенств, называется допустимой точкой или
допустимым вектором. Множество всех точек, удовлетворяющих
ограничениям, образует допустимую область Дх), которую будем
обознаЧать через К; любая точка вне ]? называется недопустимой.
Условный оптимум предсталяет собой локальный оптимум, лежа-
щий на границе допустимой области. Если ограничения имеют
вид равенств, то допустимый вектор х должен лежать на пересече-
нии всех гиперповерхноотей, соответствующих и, (х) = 0. При
ограничениях в виде неравенств токма х может быть либо внутрен-
ней точкой (допустимой точкой), либо граничной точкой (тоже до—
пусгимой точкой), либо внешней точкаі (недопустимой точкой). Для
внутренней точки 3, (х) > 0; в случае граничшцй точки удовлетво-
ряетоя по крайней мере одно равенство @, (х )= 0, а для внешней
точки имеет место по крайней мере одно неравенство ;, (х) < 0.
Множество точек, удовлетворяющих равенствам @, (х), і= 1,
…, р, определяет граничные поверхности системы ограничений,
заданных в виде неравенств. Активным, или связывшощим, ограни-
чивающим неравенствам называется такое, которое для данного
›‹ превращается в равенство 5,- (х) = 0. Область допустимых зна-
чений переменных может быть односвязной (фиг. 2.4.6, а) и неодно-
связной (фиг. 2.4.6, 6). В последнем случае может оказаться, что
 pagebreak 
Задача нелинейного программирования 37

 

данный алгоритм нелинейного программирования допустит обсле-
дование одной или нескольких допустимых областей, если процеду-
ра поиска не будет включать большое число начальных векторов.
К счастью, большинство задач нелинейного программирования,

‚Лилицуроалей
целями функции

      

.Лшши ален"
.2'2 етвааи'у’врдулжцаа

 

Ф и г. 2.4.6. Примеры односвязной (а) и неодносвязной (б) областей допус'гимос’ги
(относящихся :( ограничениям в виде неравенств).

относящихся к реальным процессам, формулируется так, что допус-
тимая область является односвязной. В разд. 6.2 излагается наи-
более подходящий способ преобразования недопустимой точки
в допустимую (внутреннюю) точку,

2.4.4. ГРАДИЕН’Г

Множество точек, для которых целевая функция имеет постоян-
ное значение, называется линией уровня „х). Несколько таких
линий уровней изображено На фиг. 2.4.7. Если целевая функция
непрерывна и дифференцируема, то существует градиент Нк),
определяемый как вектор-столбец из первых частных производных
Нх) по х, значения которых берутся в данной точке х. Верхний ин-
декс іг, іг= 0, 1, …, используется для обозначения точки в
Е“, в которой берется значение градиента, и, таким образом,
градиент в х… равен

дих“")
дх,

7; (х…) = : . (2.4.3)

д, (ХПИ)
дуг„

Выражение Утки") обозначает вектор-строку. В литера-
туре, посвященной векторам и матрицам, доказывается, что гра-
 pagebreak 
38 Глава 2

 

диент скалярной функции направлен в сторону наискорейшего
увеличения функщхи, т. е. наискорейшего подъема, и что он орто-
гонален линии уровня „х), проходящей через данную точку х….
Вектор, противоположный этому градиенту (отрицательный гради-
ент), направлен в сторону наискорейшего спуска. Любой вектор

№.:)

 

Лалрамегше
7 Кс)

Ф и г. 2.4.7. Градиент (направление наискорейшего подъема) и направлена наи-
скорейшего спуска в двух точках.

\!, ортогональный 71° (х…) [так же, как и касательная плоскость к

ПЖ”) в точке х…], может быть записан как \’Т7і(х…) = 0.
Следует отметить, что градиент не является направлением наи-

скорейшею увеличения [(х), если рассмотрение ведется' не в ев-

клидовой, & в какой-то другой метрике. Например, если определять

длину вектора х не по формуле Нх|| = (хТх)‘/=‚ а по формуле

Пхи = 2 Их,“, то направление наискорейшего увеличения НХ…)

]

можно получить, находя ту компоненту 7/05“), которая имеет
наибольшее абсолютное значение, и полагая соответствующую
компоненту х равной либо +1, либо —1 (в зависимости от знака
компоненты градиента), а остгльные компоненты приравнивая
к нулю, как, например, в симплекс-методе при линейном программи-
рования.
 pagebreak 
Зидача нелинейного програмирования 39

 

2.45, АППРОКСИМАЦИЯ ФУНКЦИИ

Для некоторых процедур математического программировани,
которые будут рассмотрены позднее, необходимо осуществлять
линейную или квадратичную аппроксимацию функций Дх), 3,- (х)
и м, (х). Например, линейная, или первого порядка, аппрокси-
мация целевой функции Дх) может быть выполнена с помошью
усеченного ряда Тейлора в окрестности к“):

их) Ы <::…) + #; №) (х — х…). (2.4.4)

Квадратичную аппроксимацию {(х) можно получить, отбрасывая
в рядах Тейлора члены третьего и более высокого порядков:

і (Х) @ } (х…) + уті (х…) (х — к"”) +
+ % (х _ х…)тт *; №) (х — х…), (2.4.5)
Где 72, (”,”) _ матрица Гессе)е (Х), В (х), представляющая собой

квадратную матрицу вторых частных производных і(х), взятых
в точке к“":

` дяік(х(іг)› дя, “(М> _
дх? ' ' ' ‚дхідхд
72} (х(’г)) ___ н (х…) = . . . . . › (2.4.6)
дя; (х…) ті (х…)
дхддх1 ' ' 6х2

п

2.5. НЕОБХОДИМЫЕ И ДОСТАТОЧНЫЕ УСЛОВИЯ
ОПТИМАЛЬНОСТИ РЕШЕНИЯ

В области нелинейного программирования большое внимание
было уделено определению необходимых и дестаточных условий
того, чтобы некоторый вектор решения х являлся локальным экстре—
мумом. Критерий оптимальносги решения для некоторых Особых
случаев нелинейного программирования, описанных формулами
(2.2.1) — (2.2.3), был сформулирован выше. Однако структура
задачи нелинейного программирования в общем случае такова, что
полностью критерий оптимальности еще не разработан. Вследствие
этого здесь будут рассмотрены только некоторые особые случаи,
но они достаточно важны и часто встречаются На практике. Условия,
при которых некоторый вектор х является решением задачи нели—
нейного программирования, будут сформулированы в виде теорем
без доказательств (поскольку это выходит за рамки данной книги),
а для читателей, желающих познакомиться с этим вопросом по—
дробнее, приведеНЫ необходимые ссылки на литературу.
 pagebreak 
40 Г лава 2

 

2.5.1. НЕЛИНЕЙНОЕ ПРОГРАММИРОВАНИЕ БЕЗ ОГРАНИЧЕНИЙ

Постановка задачи:
минимизировать , (х), )( Е Е”. (2.5.1)

Для задачи нелинейного программирования при отсутствии огра—
ничений необходимьши угловыми того, что х* —- точка локального
минимума задачи (2.5.1), являются:

1) функпия [ (х) дифференцируема в точке К“;

2) ті (х*) = 0, т. е. существует стационарная точка в х*.
Достаточныг условия того, что х* — точка локгшьного минимума
задачи (2.5.1), кроме приведенных выше условий 1 и 2, включают
следующее:

3) 75° (х*) >О, т. е. матрипа Гессе положительно определенная.
Соответствующие условия для максимума те же самые, за исключе-

 

№:?
{(паг.-”
0 а:
0’
Ф и г. 2.5.1. Геометрическое представление функций в задаче нелинейного

програММирования.

нием того, что матрица Гессе для [(х") должна быть отрицательно
определенной.)

На фиг. 2.5.1 показано, что возможно существование минимума,
который не удовлетворяет необходимым и достаточным условиям,
Однако, если достаточные условия удовлетворены, {* обязательно
будет точкой минимума.

2.5.2. НЕЛИНЕЙНОЕ ПРОГРАММИРОВАНИЕ
С ОГРАНИЧЕНИЯМИ В ВИДЕ РАВЕНСТВ И НЕРАВЕНСТВ

Постановка задачи:
минимизировать Дх), х Е Е“,

при ограничениях
11,›(х) = 0, [= 1, ..., т, (2.5.2)

Е/(Х)>°‚ і=т+1‚--„р.
 pagebreak 
Задпча нелинейного программирования 41

 

Задача (2.5.2) идентична (2.2.1) ——-(2.2.3). Необходимые условия
того, что х* является точкой локального минимума, могут быть
сформулированы в двух теоремах, первую из которых (теорема 2)
можно назвать условиями первого порядка (потому что входящие
в них фуниций предполагаются дифференцируемыми), а вторую
(теорема 3) _— условиями второю порядка (потому что входящие
в них функции предполагаются дважды дифференцируемыми).

Начнем со следующего понятия: если х* —точка локального
минимума, то значение функции [ (х) не может уменьшаться при
движении вдоль любой гладкой дуги, направленной из х" внутрь
допустимой области. Пусть вектор ‘! касателен к дуге, идущей из
точки х*. Следуя Фиакко и Мак-Кормику [5], разделим ненулевые
векторы \! на три класса И, каждый из которых представляет собой
множество у, определяемое следующим образом:

Клип: Ограничения В Ш- Ограничения в ви- Целевая ФУнШня
де иерявенств де равенств

“%;-(#) > 0 чтит (х*) =0
1 для активных и для всех и {чту} (х*) > 0}

ограничений [= ‚ . . ., т
„туд, (т > 0 чтят, (х*] = 0 т
в дляактивных " длявсех "{ч7і(х')<0}

ограничений [= 1, . ‚т
"ТЧЬ'і (к“) < 0 чтят, (… + 0
хотя бы для хотя бы для

73 одною актив- ШШ одного ограни—
ного ограниче- чения
ния

Все допустимые изменения х* попадают в объединение У, и У“, и, если
\! содержится в У“, значение функции [(х) уменьшается, а если \!
содержится в 1/1, значение [ (х) увеличивается или остается констан-
той. По существу необходимое условие первою порядка представ—
ляет собой требование, чтобы множество У„ было пустым.

Если У„ пусто, то существование множителей Лагранжа мо-
жет быть доказано в виде следующей теоремы.

Теорема 1 15].

Если (а) вектор х* удовлетворяет условиям задачи (2.5.2),
(6) функции [(х), 3,- (х) и Н, (х) диффереНцируемы и (в) в точке
х* множество У, пусто, то существуют векторы (множители
Лагранжа) “* и “'*‘, такие, что совокупность векторов х*‚ “*, ш"
удовлетворяет соотношениям

(1)И/(Х*)=0‚ і=1‚...‚т‚
(2)Е/(Х"‘)>0‚ і=т+1‚…‚р‚
(3)и}Е/(Х*‘)=0. і=т+1‚...‚р‚
 pagebreak 
42 Глава 2

 

(4) ”?>“ ]=т+1‚р‚
(5) ЧЬ (х*, ц*‚ ш*) = .
В соотношении (5) функцию

т »
Их, “, ш)Еі(Х)+ 2ш1/1;(Х)— 2 №№)
1—1 ]=т+1
можно рассматривать как обобщенную функцию Лагранжа задачи
(2.5.2); следовательно, уравнение (5) можно записать как

т в

% (х*‚ и*‚ и“) = 71° (Х“) +12] ШМ; (Х*) —]_ %+! “;УЕі (Х") = 0.

Чтобы выяснить, при каких условиях множеств У, оказывает—
ся пустым, необходимо еще одно понятие, а именно порядок ограни—
чений. Начнем с ограничений первого порядка. Следуя известной
работе Кунз и Таккера [4], предположим, что х… — допустимая
точка для задачи (2.5.2) и что функции 111 (х), …, Ь… (х),
дт+1(х), …, г„ (х) дифференцируемы в точке х…. К ограничениям
первого порядка относятся такие, когда для каждой граничной точки
множества ограничений, сосюяшего из ограничений в виде равенств
и активных ограничений в виде неравенств, должна существо-
вать гладкая кривая, заканчивающаяся в этой граничной точке
и целиком лежащая внутри области, заданной ограничивающими
поверхностями. Если х* соответствует локальному минимуму, то
значения )* (х) не могут убывать при перемещении вдоль такой кривой
из точки х* внутрь допустимой област. Достаточнши условием
того, чтобы ограничения были первого порядка, является то, что все
градиенты активных ограничений в виде неравенств и градиенты
ограничений в виде равенств, взятые в некоторой пробной точке х*,
линейно независимы.

Убедиться в том, ЧТО множество У, пусто, можно различными
способами, но лучше всего это сделать, опираясь на понятие огра—
ничения первого порядка, что приводит к теореме 2.

Теорема 2 [б. 7].

Если функции НХ), 11100, 11…00, @… (Х), Е» (Х)
дифференцируемы «; точке х* и если в точке К" ограничения являются
ограничениями первого порядка, то необходимое условие наличия
в точке ‚(* локального минимума задачи ( 2.5.2) состоит в том что
существуют множители Лагранжа “* и “!*, такие, что совокуп-
ность векторов к"“, л*, “!* удовлетворяет соотношениям (1) —— (5)
теоремы 1.

Чтобы учесть нелинейный характер функций в задаче (2.5.2),
Мак-Кормик [6] сформулировал необходимые условия второго по-
рядка наличия в тачке х‘ локального минимума. Предположим,
 pagebreak 
Задача нелинейного программирования 43

ЧТО функции 1” (Х), №100, й…(Х). Ет+1‚ ых) дважды диффе—
ренцируемывточке х…, удовлетворяющей условиш задачи (2.5.2).
Пусть \! —— любой ненулевой вектор, такой, что

У773‚(х<’0)=0 для всех активных ограничений в виде нергъ
венств,
“%,-(хдд) = 0 для всех ограничений в виде равенств.

ТОгда если вектор \] является касателъным к некоторой дважды
дифференцируемой кривой ч; (6), 6 > 0, вдоль которой @, (11: (В)) =
= 0 для всех активных ограничений в виде неравенств и п, (тр @» =
= 0 для всех ограничений в виде равенств, то в х… ограничения
являются огрктичениями второго порядка. Достаточньш условием
того, чтобы в точке х… ограничения были ограничениями второго
порядка, является то, что градиенты активных ограничений в виде
неравенств и градиенты ограничений в виде равенств в этой точке
линейно независимы.

Теперь можно сформулировать необходимыеусловия, при которых
ограничения являются ограничениями второго порядка.

Теорема 3 [7].
Если (@ функции ? (к)‚ их}. й…(Х)‚ет+л (Х). @@ дважды
ифференцируемы вточкех" и (6) в х* выполняются классификации-
ные условия ограничений первого и второго порядков, то необходимыми
условиями наличия в точке х* локального минимума задачи (2.5.2)
.ямяется сущестование векторов чп“ = {ш}, …, ш‚'„]Ти "* = [и,‘„+,‚

…, и;]т‚ для которых

… 111(Х*)=0, і=1, ‚.., т,

(2)Еі(Х*)>Ог і=т+1....,р‚

(З)и;>0, і=т+1,...‚р, @
(4) и;81(х*)=°‚ і=т+1‚ ..., р,

(5) УЦХ’“, Н*‚ **)= 0,

и (г) для любого ненулевого вектора У, такого, что утра, (х*) = 0
для всех активных ограничений в виде неравенспт и ЧТ м, (х*) = 0
для всех ограничений в виде равенств, справедливо соотношение

(6) \'7721. (х*‚ ц*, ш*)\/ >О.

Если условия №775‚(х*) = 0 и чтут,- (х*) = 0 выполняются лишь
при \! = 0, то соотношение (6) удовлетворяется тривиалъным обра-
зом, так как активные ограничения пересекаются, задавая, таким об-
разом, единственное решение.
 pagebreak 
44 Глава 2

Достаточные условия того, что в точке х* имеет место изолиро-
ванный ” локальный минимум задачи (2. 5. 2), такие же как и не-
обходимые условия (а), (в) и (г) теоремы 3, если вместо (6) части
(г) теоремы имеет место следующее условие: (г’ ) для любого ненуле-

вого вектора \], для которого \!178, (х')= 0 в случае активных
ог аничений- не авенств, ЧТ х‘ > 0 для неактивных ог ани-
і

чений-неравенств и \! Тун, (х*) = 0 для всех ограничений в виде
равенств, справедливо следующее соотношение [б, 7]:

(6’) “7% (х*, ц*, №) \! >О.
Другое достаточное условие дается теоремой 4.

Теорема 4 [6].

в… функции і‹х›‚ ні (х), .. ., итак), е…“ (х), . . . ‚ @ (х) дваж-
ды дифференцируемы по х, выполняются необходимые условия
( 1)—(5 ) теоремы 3 и детерминант матрицы Якоби для функ-
ций п,.(х), щенок) и 7Ь(х, ц, и) по (х, и, И) не обращается в
нуль & (х*‚ 11“, №). то в точке х* удовлетворяются фигурирующие
в теореме 3 достаточные условия того, что в точке х* имеет место
локальный минимум.

 

Пример 2.5.1. Необходимые и достаточные условия существования
локального минимума в задаче с ограничениями в виде неравенств

РЗССМОТР ИМ СЛ ЕДУЮЩУ Ю задачу:

минимизировать [ (х) = х? + ::а
при ограничениях

31(х)=——(х%+х“‚)+9>0;
5„(х)=—х1—х2+1>0.

В этой задаче Е1(х) >О — активное ограничение, тогда как
ограничение Едбе (х) > 0 не является активным (фиг. П. 2. 5 1)
Нетрудно іі! бедиться, что функции 51 (х) и 52 (х) дважды диффе-
реНЦируемы. оскольку имеет место лишь одно активное ограни-
чение (31 (х) > 0), нет необходимости проверять, выполняются ли
условия первою и второго порядков.
С помощью теорем 1 и 2 нужно показать, что существуют векторы
х“ и ц*, удовлетворяюшие перечисленным ниже условиям.

1’«Изолиронанный» формально означгет, что для 0 <Пхі| < в где & дач
статочно мало, [(х) > Дх").
 pagebreak 
Задача нелинейного программирования 45

         

.Да/тц”) ! ,

уринви :: ,

! ’ Локальный
' , минимум
, ! ! ,
' , ! ,

Функции 3106“) и & (уд) неотрИЦательны, т! е.
—х}2—х;2 +3 >О,

__х;__х;+1>о. (а)

Любая точка внутри или на границах заштрихованной обдасти
является допустимой точкой х:

2х; _ —2х; * —1
111 ]“”‘і—гхё]_”2[—1]=°' «»

2х; —|— 21414: + и; = 0,
1 + 2х3и; + и; = 0,

ИЛИ
 pagebreak 
№

и: ‹— ›‹12— и;? + 9› = 0,
и;‹— хі—х; + 1) = о, @
“:>0 и и;>0. (г)

‘ Если „ ограничениях (в) и] и и; положить равными нулю, ю воз—

никнет противоречиевсоотношениіх (б) (поскольку тогда имели бы

=0>_ Сдедзвательно, не все и могут быть нулями. Предпо-
ложим, чтО ”а =_ 0 Т°Гда "3 "51330117 ограничения в (6) будет следо-
вать, чю Либ° "! _: 01 ли6° “ + ид) = 0. НО последнее невозмож—
но, потом)’ что и, не ‚могут быть отрицательными. Ёледовакльно,
х] = 0‚ Поскольку и12 % Окт В силу ограничении (в) минимум
возможен Либо "Ри хд "' {22 = 9, либо при х; = :|: З.Сднако при
"; = 3, если учесть, ЧТО 261 = 0, нарушается второе ограничен?
в (а)_ Такиз“ 061983054, вектор 36“ найден, а именно х* = [0 _31 _
При этом „| = /.;‚ и, = 0 и ограничи3ающие условия (6), (в) и (г)

оказываются удовлетворенными. Таким образом, необходимые
условия первого порядка полностью выполняются.

Необходим°е условие ВТОРОГО ПОРЯдка, которое также должно
быть выподненщ заключается в том, что для 1)

—— 2х1
[01 02] = 0

.
— 2х2

ИЛИ 0 ' (0) + ”* . (6) = 01 Т. е- ДЛЯ “№10 01 И 02 = 0, должно
иметьіместо следующее соотношение:

… от…, №….

ПОСКОЛЬКУ [‘ : [(х) _ “15160 “" “931 (х)
и 2 (1 + ні) о

„яд =[ О 2%],
получаем

ты; (1 + и;) > 0 > 0.

С ле ДОВ БТР]! ьНО ‚ необходимые УСЛОВИЯ ВТОРОГО пор ЯДКЕ И ДОСТЗТОЧНЫЕ
УСЛОВИ я У довлетвор ЯЮТСЯ .
чтобы ОПР еДеЛИТЬ ‚ УДОВЛ еТВОР Я Ю'ГСЯ Л И альтер Н ативные доста-

___/

1) Здесь оставляется только уравнение „1781 (‚д) __— 0, так как ограничение,

задаваеиое функцией 3, (х), является неактивным. _— Прим. перев.
 pagebreak 
Задача нелинейного программирования 47

 

точные условия, образуем матрицу Якоби для функций
“1 (_ х? _ 1% + 9),
”в (_ "1— "2 +1»
2х1 + 2ихх1 + ит

1 + 2и1х2 + и2
по х„ хз, и1 и и2 соответственно:

———2‚1с1и1 —2х2и1 (—х%——х;+9) О '
1= ’“2 _“2 0 (_хх—х2+1)
(1 +2и1) 0 21:1 1
О 2и1 2х, 1
При х{=0, х;=——З и и;=1/Б, и;=0
‘ 0 1 0 0“
0 0 0 4
деъ1=аеъ % о о 1 гео.
1
0 —з— —6 1-

Таким образом, выполняются и альтернативные достаточные усло-
вия 'ЮГО, чю вектор х* = [0 —З]Т является локальным минимумом.

Пример 2.5.2. Необхошшые идостаточные условия существования
локального Минимума при наличии ограничений как в виде ра-
венств, так и в виде неравенств

В качестве примера задачи нелинейного программирования, со-
держащей ограничения как в виде равенств, так и в виде нера-
венств, рассмотрим следующую задачу:

минимизировать [(х) = х? + Ха, Х Е Е”›
при ограничениях
111(х)= х}’+›с3—9=0‚

$300: —(х1+хё) + 1 >О,

Ев“) =_(х1 + ”в) + ] >0-
В соответствии с теоремой 3 функции /11 (х), 32 (х) и @, (х) должны
быть дважды дифференцируемы, а градиенты активных ограничений
в виде неравенств, а также ограничений в виде равенств должны быть
линейно независимы, чтобы выполнялись условия первого и второю
порядков. Предположим, что некоторая точка А с координатами
х" = [———2‚37 — 1,847, находящаяся на пересечении И1(х) и г„ (х),
на фиг. П. 2.5.2 рассматривается как возможный локальный оптимум.
Образуем линейную комбинацию векторов-градиенюв активных
 pagebreak 
48 Г лава ?

 

ограничений
017111(Х*) + $2782 (Ё) = 0:

2х; —— 1
с1[2х;]+си _ 2х; = 0- (3)

Можно показать несколькими способами, что единственным векто-
ром с, удовлетворяющим уравнению (а), будет с1 = с, = 0; следо—
.1'2

ИЛИ

    

.'із(='3›=-‹1‚№2›+1*0 мас): х‚’+.т;— 9:0

Линии

‘ уравнвй тв)
\ \ \/

\\\
\

вательно, градиенты активных ограничений линейно независимы,
и, таким образом, выполняются условия первого и второго порядков.
Проверим теперь, выполняются ли необходимые условия первого

порядка теорем 1 и 2. При этом в выбранной точке х“=[—2,37—1‚84 11
должно быть выполнено каждое из следующих условий:

1. мг) = х;2+ х;2—9 = 0, (_ 2,37т=+ (_ 1,84)? _в: о,
джа) = _ р:; + ху) + 1 >О, —(— 2,37) —(—1‚84)* + 1 = 0,
 pagebreak 
Задачи нелинейного программирования 49

 

азот = —‹хт +жд + 1 >0‚ —‹—2‚37›—‹—1.84› + 1>о.
2. и3>0 и и;>0.
3. и;(—х;—х;?+1)=о,

и;(—х:—х'+1)=0.

4гг1+ш+згэъ из[:2ы—и4::1=о-

Поскольку в этом примере точка х’" выбрана произвольно для
проверки на локальный минимум подставим эту точку х*—— —

= 1—2 37 —-1,84]Т в выражения приведенные в условиях 2—4, и
проверим, существуют ли такие скаляры ш“ и; и и;, которые удо-

влетворяюг соотношениям
2 (+ 2,37) + ш; (2) (... 2,37) + и; + и; = 0,
1 + ш; (2) (_ 1,84) + 2и;'‹— 1,84) + и; = 0,

ш; = — 0,779 '>‚
и; = 1,05.
Следовательно, скаляры
ш; = —0,779,
и; = 1,05. (6)
и; = 0

удовлетворяют необходимым условиям первою порядка в теореме 2.

Чтобы выяснить, удовлетворяются ли дополнительные требо—
вания теоремы 3 в отношении необходимых условий второго по-
рядка, помимо изложенных в теоремах 1 и 2, поступим следующим
образом. Определим векюр \: при помощи двух уравнений, получен-
ных из ограничения в виде равенства и активного ограничения в виде

неравенства:
2х1
[01 “в] 2х' =().

2

—— 1
[01 1/2] [_ 23%] = 0:

— 2,3701 —— 1,841;2 = 0,
——о1 + 3,680, = 0. (В)

1) —
Так как из второго уравнения условия 3 следует, что ”3 = 0. Прим.
перев.

ИЛИ
 pagebreak 
50 Г лавп 2

Единственным вектором У, удовлетворяющим (в), является нулевой
вектор. Следовательно, существует единственное решение данной
задачи на пересечении ограничений, заданных функциями Ея (х)
и Ш (х). Заметим также, что в этой конкретной задаче

 

 

2 о _ 2 о ‚ о 0 „
[””“] о 0 +‘”! 0 2 _”г 0 __2} :;2 >°>°
или (при ш] = —0,779 и и; = 1,05) неравенство
0,44%; + 0,54%; >О (г)

удовлетворяется для любых ненулевых векторов У.

С другой стороны, достаточные условия того, что в точке 16“ име-
ет место локальный изолированный минимум, следуют и из теоремы
4, поскольку детерминант матрицы Якоби не равен нулю:

' 2х; 2х5 0 О 0 _
— и; —— 2и;х; 0 (_ х} —— ;2+ 1) 0
1: _а; —и; О 0 (—х’[—х;+1) ,
2 + 210; 0 22:1 1 1
_ 0 2 (ш; + и;) %; 2х; 1 _
"_ 4,74 — 3,68 0 0 0 `
— ДОБ 3,86 0 —0,02 0
‹іеі .! = аеі 0 0 0 0 +521 ;& 0.
0,44 0 — 4,74 1 1
0 0,54 — 3,68 — 3,68 1

Выше при иллюстрации применения теорем (› лохальной опти-
мальности использовались лишь простые задачи. В случае задач
большой размерности зги теоремы также применимы, но здесь
могут возникнуть значительные трудности, связанные с необхо-
дим0стью находить аналитические выражения для производных
нелинейных функций [ (х), 3 (х) и и (х).

2.6. ЭФФЕКТИВНЫЕ МЕТОДЫ ОДНОМЕРНОГО ПОИСКА

Многие из алгоритмов, которые будут описаны ниже, основа-
ны на использовании эффективных методов одномерной оптимиза—
ции для обна ужения минимума функции ОДНОЙ переменной. В кни-
ге Уайлда [8 ГИ в других работах, посвященных общей теории опти-
мизации, излагается несколько достаточно эффективных методов
 pagebreak 
Задача нвлинейноги приграммиравания 51

 

одномерного поиска, позволяющих определять интервал значений,
внутри которого лежит минимум той или иной функции. Для прак—
тического применения этих методов необходимо знать начальный

интервал неопределенности АЮ), содержащий минимум целевой
функции ПХ) и в котором функция ‚‘(х) унимодальна. Существуют
различные методы (некоторые из них приведены в табл. 2.6.1) умень-

шения начального интервала А"" до некоторого конечного А‘”).
Мы ограничимся лишь несколькими замечаниями, касающимися

Таблица 2.6.1

Эффективность одномерных методов поиска
(а —число вычислений функции, Ри — число Фибоначчи для и оценок)

 

 

 

 

 

 

Непошдовапмине методы Е Последаватыьпые иетады Е
2 |
Равномерный поиск Поиск делением пополам

и + 1 2п/2

' П Ф 60 '
. оиск и наччи ——
Равномерныи поиск делением 3 + 1 рп

пополам 2

Поиск методом золотого 1
сечения (0,618) _”

 

этих методов, а затем перейдем к некоторым другим методам, кото—
рые обычно на практике оказываются более эффективными.

Уайлл определил эффективность процедуры, включающей п вы-
числений целевой функции, как

(”1
Е=^`__

Аа»

В табл. 2.6.1 сравнивается эффективность пяти различных методов.
В табл. 2.6.2 сравнгшаюкя количества вычислений функшди
[(х). необходимые для уменьшения начального интервала, равного
5 . 10“.
Оказывается, что относительная эффективность двух хорошо
известных меюдов золотого сечения и поиска Фибоначчи несколько
выше эффективности поиска последовательным делением пополам

и существенно превосходит эффективность поиска непоследоваюль-
ными методами.

Поиск с помощью метода золотого сечения основан на разбие—
нии отрезка прямой нв две части, известном как «золотое сечение».
При этом отношение длины всего отрезка к большей части равно
отношению большей части к меньшей. Здесь используются
 pagebreak 
52 Глава 2

 

две дроби Фибоначчи:
г. = _в_—515- &= 0,38,

1

5 — 1
п = ‘Г_2_ @ 0,62.
Заметим, что Р`1=(Р`„)а и 171 + Ра = 1. Поиск необходимо начи-
нать в таком направлении чтобы значение функции [ (х) уменьша-
лось.

Таблица 2.6.2

Количество вычислений функции, необходимое для
уменьшения начального интервала. равного 6404

 

 

Непоследователъные методы Последовательные методы
Уменьшение
шпервам дд равномерный равномерный поиск мето— да… Фибо- пашж делени-
ПОИСК поиск деленн- ДОМ ЗОЛМОГО на.…“ ем подом"
еМ пополам сечения
5.10—3 199 198 11 п 14
5.10-Б 19 999 19 998 21 21 28

Начальный отрезок А, включающий минимум „х), может быть
получен с помощью, например, последовательной серии нескольких
возрастающих шагов по независимой переменной. Обозначим пос-
ледние тёти значения :: через х?” (последняя точка), х?” и хР),

‚а
где ПХЗ )) > ЖЖ,“), и пусть А"” = && ’ — 16$”). Рассмотрим
фиг 2…61 В соответствии с этим рисунком, если мы находимся
на іг-м этапе, то (11 + 1)-й интервал нужно вычислять следующим
образом.

Определим

№ = хг» + №1,
у;!» : худ) + РеАф) : хёіг)_ ‚: 1_Абг)
Егли ‚(!/ЗЫ) <‚(уі2/Ч)’ ТО АФ-Н) : (_,/(Ё)“- хип) И х1ш+13=х® х(й+1)_
2” ).
‚‹
если [(!/((г)) >Н1/(ю)! .… А(гг+1)__ (х ХЁЫ _ у; )) И хіё+п= Йи, хуем) =

—х‘*;’

810 ЛИ ‚}}/(Ёб— ;(ущ) ТО АНРИ): (_,/(Ь) _х1й))_ : (х(іе)_ ИМ) И
дн+) : „( ›, хш+1›_у‹ю

или
х‹Ь+1›_ _ дог) хин] : „(и
 pagebreak 
Задача нелинейном приграммираванця 53

 

Для большей точности каждый раз определятся две новые
точки (а не одна новая точка), поскольку значения Р`1 и 1°`2 не явля-
ются точными; при оперирования только с одной новой точкой ошиб—
ки округления при вычислении могут привести к потере интервала,
содержащего минимум.

В другом классе методов одномерной минимизации текущая точ—
на х вблизи х" [значение независимой переменной, соответствующей

         

т !" щ :
У! *’: Х: 1;

д . да:: 5

ь— “”_—_;

Ф и г. 215.1. Поиск методом золотого сечения (золотой поиск).
Начальные точки: 12°), х?) и иё“).
Паскальку [(:/(до)) >і(9‹„[‚°))‚ А…=(х[3°)—у(.°›)‚ а ХР= 14°) и {@= 83°
ницвмн интервала для этапа 1.

) являются грв-

‚,<'°> = ;:(10) + 0,38А(°),

‚112… =. „(Р) + 0,6%“).

минимуму і(х)] определяется с помощью экстраполяции и интер-
поляции. Были предложены кзадратичные и кубические формулы
аппроксимации либо только значения функции, либо и функции
и производных. Коггинс [91 отметил, что, пользуясь нехитрыми
из методов, основанных на аппроксимации функции полиномом, про—
ходящим через выбранные точки, можно легче обнаружить минимум
‚‘ (х) при заданной точности, чем методами, указанными в табл. 2.6.1.
Бокс, Дэвис и Свенн [10] предложили использовать алгоритм Дэ-
виса, Свенна и Кэмпи (ДСК) [11 ] для определения интервам, содер—
жащего точку минимума, чтобы все последующие вычисления про-
водились по алгоритму Пауэлла [12]. Описание этих двух алго-
ритмов приведено ниже.

При одномерном поиске по алгоритму ДСК проводятся возрас—
тающие по величине шаги до тех пор, пока не будег пройден мини-

МУМ , а 5 атем ВЫПОЛН яется ОДНОР НЭОВ ая КВадр атичная интер ПОЛ Я-

ция. На фиг, 2.6.2 показана такая процедура (здесь х…" —- первое
 pagebreak 
54 Глава 2

 

из значений х, для которого зарегистрировано отклонение от ми-
нимума, а Ах — длина шага), состояшая из следующих шагов:

Шаг !. Вычислить Их) в начальной точъке №1. Если і(х‹°>+
+Ах)< і(х1°>), то перейти к шш—у 2. Если і(х‘°>+Ах) > [(хті),
положить Ах: _Ах и перейти к шагу 2.

Шаг 2_ Вычислить %+“ = ‚№ + Ах.

Шаг 3. Вычислить ПИН”).

Шаг 4. Если і(х‘*+”)< ДМ”), удвоить Ахл вернуться к ша—
гу 2 при 1% = 13 + 1. Если і(х“?+‘›)>і(х<д>), обозначить хш+1> через

     

_, лы) „@:-г) 1-ти!) „(лип ‚‚_.т ‚‚_.
Ф и г. 2.62. Одномерная минимизация методом ДСК.

х…”, х“) через х…?“ и т. д., уменьшить Ах наполовину и вернуть—
ся к шагам 2 и 3 для еще одного (только одного) вычисления.

Шаг 5. Из четырех равноотстоящих значений х{х('"+1>‚ х…),
х1т_1›,.х‘”'—2)} исключить либо ХО"), либо „(…—2) в зависимости от
того, какое из них находится дальше от х, соответствующего наи-
меньшему значению Дх). Пусть х“), №1 и ‚((”—оставшиеся три
значения х, где мы—центральная точка а №) = х‘дй—Ах и х“) =
= хіт + Ах.

Шаг 6. Провести квадратичную интерполяции) для определения
х*:

… Ах и №) — ! (хил
* д, = !» __ _
х х' ” + 2 [Г №) —2/ №) +і‹х‘°>›1
Эти шаги завершают первый этап метода ДСК. При жеЛании про-

(0) …
должить эту процедуру нужно Начать из да““ или из х , еслиі (3: )<

< 7 (д), уменьшить Ах и начать с первою шага.

В алгоритме Пауэлла квадратичная аппроксимация проводится
путем использования первых трех точек, полученных в направлении
поиска. Затем определяется точка х, соответствующая минимуму
квадратичной функции. Такая квадратичная аппроксимация про-
должается до тех пор, пока с требуемой точностью не обнар уживается

минимум 7 (х). Алгоритм Пауэлла строится следующим образом
(фиг. 2.6.3):
 pagebreak 
Задача нелинейного программирования 55

 

Ёша]. От начальной точки х‘ ’ нужно перейти к хм = х… +
+ х.

Шаг 2. Вычислить ПМ”) и ‚“(хт).

Шаг 3. Если і(х<1>)>і(х(2>), положить ‚@ : х… +2Ах.

Если і(х<1>)<і(х<2>)‚ положить х“) = х<1>——Ах.

Шаг 4. Вычислить ПМ”).

 

Ф и г. 2.6.3. Одномерная минимизация методом Пауэлла.

Шаг 5. Вычислить приближенное значение :: в точке минимума
№) по формуле

№№ — ‹х13>›21і‹х<"› + №№ — №… г №) +

+ [№№ — №)?! г №)
№ — „т) ! (х…) + № — х…) ><

>< ! №) + (х… — №) г №)

‚С#

__;
_ 2

Шаг 6. Если х’“ и любое из ЗНачений ХМ“), №), х…}. соответ-
ствующих минимуму } (х), отличаются меньше, чем ни предписан-
ную точность :: или точность соответствующих значений функции

„х), закончить поиск В противном случае вычислить і(х*)
и исключить из множества ‘1 х“), х…] то значение х, которое
соответствует наибольшему значению Лх) если, однако, при этом
не будет потерян интервал, в котором находится минимум „х).
В этом случае следует так исключить х, чтобы сохранить этот
интервал. Перейти к шагу 5.

Работа алгоритма продолжается до тех пор, пока не будет дос-
тигнута желаемая точность, упомянутая в шаге 6

Комбиниция алгоритмов ДСК и ПауэлЛа оказалась эффективнее
 pagebreak 
56 Глава 2

 

по сравнению с Каждым из этих алгоритмов в отдельности.
Комбинированный алгор итм ДСК —- Пауэлла состоит из одного этапа
(шаги с 1 по 6) алгоритма ДСК, на котором определяется интервал,
в котором находится минимум [(х), шага 6 адгоритма Пауэлм
и затем, если это оказывается необходимым, шагов 5 и 6 алгоритма
Пауэлла.

Прямое сравнение метода одномерного поиска ДСК — Пауэл-
ла, например, с методом
золотого сечения с точки
зрения требуемого времени
или числа проведенных
вычислений значений функ-
ции имеет не очень большой
смысл. Правда, такое срав-
нение позволяет исключить
плохие методы; важно, од-
нако, звать, насколько эф-
фективен алгоритм одно-
мерного поиска при реше-
нии оптимизационных задач
большой размерности.

На фиг. 2.6.4 приводят-
ся данные относительно
времени решения двух за—
дач, одна из которых с
двумя, а другая счетырьмя
‚0-1 „,—г ‚0—1 ‚0-4 ‚0-5 ‚0-5 независимыми переменны-

 

Критддий ;(,1М',_г(1т; МИ (см. разд. 3.4).
МОЛЧПНЦЯ ‚(шт, Задача 1. Функция Ро-
”рщиш зенброка
Ф и г. 2.6.4. Время решения двух задач при
использовании азличных методов одноме -
1хэ-юго поиска. р , (Х) = 100 (”в ’— ‘? +

. золотой поиск, задачи 1; [] золотой поиск, за. Я
дача 2; . метод ДСК — Пауэллщзадцча 1; @ ке- + (1 _ Х1) .
тод дСК — Пауэлла, задача 2.

Задача 2. Функпия Флетчера — Пауэлла
ПХ) = (1:1 + 10752? + 5 (353— ха? + (”я _ 2,53)4 + Ю (хх “— ХА)!-

При различных критериях окончания процесса, выраженных через
относительное приращение [* (х), методы поиска ДСК — Пауэлла
и золотого сечения оказались примерно одингаково эффективными
в смысле времени решения, за исключением случая самого низкого
(по точности) значения критерия (1071).

На фиг. 2.6.5 приведены графики зависимости числа оптимиза—
ционных этапов на одну независимую переменную от зничений
 pagebreak 
Задача нелинейнаги программирования 57

 

критерия окончания процесса. Число этапов для поиска методом
золотого сечения в задаче 2 оказалось настолько большим (выходя-
щим за поле графика), что его пришлось опустить. На фиг. 2.6.6 по-
казано, хак изменялось количество вычислений значений фушщии

 
                 

&

й .

= щ“:

Ё 3“ ёЁт

$, за

= 25 $500

& дэ, ‚Ц

Ё °Ё “ \\
Е 20 Ёздоа Р \
ч ЧЁ ’ \
а ; ! П
:: 15 ЗЁЕ

! ёзй

н &=:

‘ 83%

Е '” ЪЁЁ

ч 5$

% 5 5% [00

% аз

Ё 0 чё- 0 .

» т" 10'2 т [0-4 10'5 ёё 10" ю" 10" т- 10"

Кдитерш? гымб- тт)

Ф (М!) _ (И
дритериц Ка: ) $61: ) окончания

дЛ‘П/іЦиКЦЯ ‚(_-= ) )

процесса
Ф и г. 2.6.5. Число этапов, проведен-

ных до окончания процесса, при нс- ‘

ПОЛ ЬЗОЕ ан ии рЗЗЛИ чных МЕТОДОВ ОДНО-
МерНОГО ПОИ ска ,

. золотой поиск. авдача 1; . метод дСК—
Пауэлла. задачи 1; @ метод дск—Пчзлм,
вадича 2.

процесса ”"‘ ,)

Ф и г. 2.6.6. Относительное количест-

во вычислений значений функции на

независимую переменную прн исполь-

зовании различных методов одномерно—
ю поиска.

. золотой поиск. зддача 1: [] золотой по-
нск, задача 2; . метод дск —— Пауэлла,

задачи 1; @ метод дСК—Пвузлла. задача 2.

при различных методах одномерного поиска в зависимости от крите-
рия окончания процесса. Если для вычисления целевой функции
требуется значительное время, то, как видно из фиг. 2.6.6, поиск
методом ДСК — Пауэлм предпочтительнее. Данные относительно
числа вычислений частных производных (компонент градиента)
не приводятся, но следует иметь в виду, что на каждом этапе зада-
чи 1 требовалось вычислять значения производных дважды и четы—
ре раза вычислялись производные на каждом этапе задачи 2.

Если минимизируемая функция локально не унимодальна,
как это предполагалось выше, необходимо добавить к программе
одномерного поиска дополнительную логическую процедуру,
чтобы быть уверенным в том, что величина шага выбранв так, что
гарантируется продвижение к тому лохальному минимуму,
 pagebreak 
58 Глава 2

 

шт

тіллдный
минимум

Ф и г. 2.6.7. Одномерный поиск локального минимума мультимодальной целевой
функции приводит :( неограниченному решению.

который определяется. Например, фиг. 2.6.7 иллттр ирует, как боль-
шой начальный шаг может привести к неограниченному решению,
когда в действительности мы ищем локальный минимум.

2.7. КЛАССИФИКАЦИЯ МЕТОДОВ НЕЛИНЕИНОГО
ПРОГРАММИРОВАНИЯ

Для решения общей задачи нелинейного программирования было
предложено довольно много алгоритмов, поскольку ни один из них
не оказался значительно лучше других. Выбор того или иного ме-
тода определяется конкретным содержанием задачи и опытом иссле-
дователя.

В табл. 2.7.1 приводятся некторые способы массификации
задач нелинейного программирования. Последующие главы этой
книги основыватся на схеме классификации задач по их постановке,
которая в этой таблице обозначена номером 1.1. На не менее важной
является схема, основанная на характерных различиях методов
решения (классификгщия 2 в табл. 2.7.1). Поскольку и технический
и программный уровень современных ЭВМ изменяется Очень быстро,
в згюй книге не рассматриваются методы оптимизации с точки зре-
 pagebreak 
Задача нелинейного программирования 59

 

Таблица 2.7.1
Классификация методов нелинейного программирования

 

!. Классификация по некоторым аспектам постановки задачи
1.1. Характер целевой.функции «: ограничениями, без ограничений)
(3) Без ограничений
(6) Ограничения в виде равенств
(в) Ограничения в виде неравенств
(г) Ограничения как в виде равенств, так и в виде неравенств
1.2. Дискретные (целочисленные) переменные; переменные, принимающие не—
прерывные значения
1.3. Выпуклое, квадратичное. сепарабельное и т. д. программирование
2. Классификация по характерным чертам методов решения
2.1. Методы, использующие производные; методы, не использующие произ-
всдные (поиск)
2.2. Аналитическое определение производных; численное определение произ-
водных
2.3. Методы, использующие первые производные; методы, использующие вто-
рые производные
2,4, Грядиентиые методы; методы, ие использующие градиент
2.5. Грндиентннй метод с малым шагом; градиентный метод с большим шагом
2.6. Одновременная терапия по всем переменным в процессе поиска; релак-
сация (последовательный поиск каждый раз по одной переменной)
2.7. Методы внутренней точки; методы внешней ючки
2,8. Детерминированный поиск; случайный поиск
2.9. Начальный вектор нахошпся в допустимой или в недопустимой области
Классификация по типу вычислительных машин, применяемых при проведе
нии алгоритм

3.1 Цифровая, гибридная или аналоговая машина
4. Классификация по используемому языку программирования

‚‘*’

 

ния категорий 3 шт 4. Гилберт [13] составил аннигированную биб-
лиографию по методам параметрической оптимизации, применимым
для гибридных ЭВМ.

ЗАДАЧИ

2.1. Запишите следующие задачи линейного программирования
в матричной форме:

а) минимизировать [ (х) = 316, —|- 23:32 + ха
при ограничениях-

81“) = 2"1 + 3152 + хз >10»
Ёж“) : 751 + 2,52 + хз >15;
б) максимизировать [ (х) = 5х1 + 10:62 + 12ха
при ограничениях
31 (х) = 15261 + 10хи + 10:63 < 200,
&ш=щ>ц
 pagebreak 
60 Глава 2

88 (х) : хи > 0,
Е! (Х) = ха >О,
‚1100 = 10х1 —|- 25262 + 20263 = 300.

2.2. Запишите в матричных обознвчениях путем введения соот-
ветствующих матриц следующую целевую функцию:

[(х) = 3 + 2х1 + 3х2 + 2х? + 2ясдх2 + 6х; х = [х1 1:2 17.

2.3. Приведите задачу 2.37 к стандартной форме задачи нелиней-
нэгоз программирования, описываемой уравнениями (2.2.1) —
(2.2. ).

2.4. Классифицируйте следующие задачи как 1) линейные,
2) квадратичные, 3) выпуклые, 4) нелинейные задачи программиро-
вания (однв и та же задача может классифицироваться по несколь-
ким признакам):

2.1а, 2.15,
2.16, 2.16,
2.6, 2.18.
2.11,

2.5. Определите, какие из приведенных ниже матриц являются
1) положительно определенными, 2) отрицательно определенными,
3) не относятся ни к одной из упомянутых категорий:

‘“)[3 Т], % 1], °" [3:1 3], “№3 "Т].

2.6. Изобразите графически целевые функиии и ограничения
для следующих задач нелинейного программирования:

а) минимизировать {(х) = 2х';’— 2х1х2 + 2х2 — 6251 + 6
при ограничении
Е1(Х)=х1+ && 2:
б) минимизировть [(х) : х? — Эми2 + 4
при ограничениях
81 (х) = 5751 + 2% >18,
п,(х) = —2х1 + хг: 5;
в) минимизировать [(х) = — 5х3 + хЁ,

ПРИ ОГр ани чениях
2

___”.1.__‘_ -_
Е](х)_хё „2$ 1!
Е„(х)=х,>0,

Ея“) = ": >О-
 pagebreak 
Задача нелинейного программиров ания 6 |

 

2.7. Исследуйте задачи 2.1а, 2.16, 2.38 и задачу 13 (в приложении
А). Для казкдой задачи укажите 1) полное число переменных и
2) число независимых переменных. Предложите подходящую систещ
переменных для обеих категорий.

2.8. Сформулируйте следующие задачи в виде задач нелинейного
программирования.

а) Найти длину, высоту и ширину прямоугольного резервуара,
открытого сверху, которые дают максимальный объем при фикси-
рованной площади поверхности А (А — площадь стенок + пло-
щадь дна).

6) Найти кривую наискорейшего спуска из одной точки в другую,
т. &. траекторию, по которой должна двигаться частици, чтобы
время перехода было Минимальным. (Такая кривая называется бра-
хистохроной.) Такая классическая задача впервые была предложе-
на Джоном Бернулли в 1696 г.

в) Конденсирующийся пар при температуре Т, в теплообменнике
используется для нагревания Масла от температуры Т1 до Тв.
Эффективный выигрыш от добавочной площади теплообменника
может быть выражен в виде дополнительной прибыли исходного
состояния:

К= (2606 — АСрГ—ГСс‚ (1)
… ___—_
стоимость стоимость
приобретенной дополнительном
энергии объема
теплообменники

где
)? — допмнитепьные годовые доходы, долл/год;
(2 —— скорость передачи тепла, БЕТ/ч;
Со — удельная стоимость переносимой дополнительной энергии,
долл /БЕТ;
6 — количество рабочих часов в год;
А — дополнительная площадь теплообменника, используемая
в передаче тепла, фут“;
Ср — удельная дополнительная стоимость площади теплообмен-
ника, долл/фут“;
г— относительные ежегодные издержки, [издержкщ долл1/[сюи-
мость,долл : (год)1;
Сс — стоимость теплообменника без добавочной площади, долл/ч.
Уравнение энергетического баланса, представляющее собой отра-
ничение для целевой функции (1) (полученное на основе макроско-
пической модели теплообменника в установившемся режиме),
имеет следующий вид:
_ _ ТЗ _ Т!
№" (Та " Ті’ “ О _ ”А … пт; _ т'Б/(т—з — т '
где
07 — скорость потока (константа), фунт/ч;
 pagebreak 
62 Глава 2

 

Ср— теплоемкость (константа), БЕТ/фунт - °Р;

и —— общий коэффициент теплопередачи (константа),
БЕТ/ч › футя › АТ.

Найти максимум годового дохода.

г) Капиталовложения в трубопроводы и соответствующие уста-
новки составляют часть общих вложений в химическое предприятие.
Поэтому необходимо выбирать такие размеры труб, при которых
суммарные издержки, включающие в себя некоторые постоянные
издержки и издержки при работе насоса, минимальны. Оптимальная
стоимость трубы может быть выражена следующим образом:

 

 

М№Нд
с=—ЮТ+›_Ш"+(1 ЮХтКд …
поииасть по:;огндёя г;:“ліющая
[‹ К
работы А рмонтнжадер "

нвсоса

где

С — общая сгоимость, долл] (год - фут);

А — константа;

:; —— скорость потока жидкости, футз/с;

р — плотность жидкости, фунт/футв;

ро _— вязкость жидкости, сантипуаз;

К — стоимость электроэнергии, долл /квт - ч;

117 — механическая работа, фут . фунт/фунт;
Н — количество рабочих часов в год;

Ё —— коэффициент полезного действия двигателя и насоса (без-

размерная величина);

У — средняя линейная скорость жидкости, фут/с;

В —— внутренний диаметр трубы, дюйм;

Ь —— длина трубы;

Х — стоимость 1 фута новой трубы диаметром 1 дюйм, долл/фут;

п _— константа, зависящая от типа трубы;

Р — отношение общей стоимости монтажа к стоимости трубы;
Кр —— ежегодные постоянные издержки, включающие расходы

на ремонт.

Уравнение баланса механической энергии для потока жидкости
имеет вид

_ 2№Ь(1_1)
ш_Т

Для вязкого потока (№№ < 2100)

 

__ 16 _ Ы/р
‚е_ „Ке, ”&&—__” :

где
і _- коэффициент трения;
 pagebreak 
Задача нелинейного программирования 63

 

№№ — число Рейнольдса;
& —- 32,17 фут _ фунт массы/с’ - фунт силы;
.! — игносительные потери вследсгвие сочленений и изгибов
(безразмерная величина).
Найти минимум стоимости, соответствующий оптимыъному диа-

метру трубы.

2.9. Что такое унимодальная функция и каково ее значение
в теорИи оптимизации?

2.10. Разделить локальный и глобальный экстремумы следующей
целевой функции:

)“ (х) = 2х? + х; + хіх; + 4х1):а + 3.

2.11. Укажите число независимых переменных в следующей
задаче:

минимизировать 3;— хё + % х; + % х; —- 4:61:65 + 3х1):а —
_2хвхз + Ні + 514% + ЁЁ + 394 _ 295
при ограничениях
уда ЮХ; — % + 3х3 + % + ЗуБ >О,
№5 " 4х1-+ 5%“2’58 +!/5"'1>0у

уваЗх1—2хд+х‚‚—2уд—2>0‚
уд>0‚

% >О.

2.12. Приведите пример выпуклой целевой функиии, вогнутой
целевой функции, выпуклой целевой фунъщии при вогнутых ограни-
чениях в виде неравенств.

2.18. Является ли следующая задача:

 

 

минимизировать {(х) = 100;с1 + 32
при ограничениях
2х 3°° < 1
2 + дх, \ :
хи ха > О

задача": выпуклого программирования?

2.14. Приведите пример положительно определенной матрицы;
полуопределенной матрицы.

2.15. Приведите целевую функцию, у которой имеется более
одного локильного минимума, но не бесконечное число. Выделите
глобальный минимум.
 pagebreak 
64 Г лава 2

2.16. Являются ли следующие векторы:
шх=ю2 щі

(2)х=[10 2 7,511

(3) х=[0 0 ой

(а) допустимыми или недопустимыми по отношению к условиям
задачи 2.16; (6) внутренними или внешними векторами?

2.17. Заштрихуйте область допустимых значений в задачах
2.6 нелинейного программирования. Является ли в этих задачах
х = [1 117 внутренней, граничной или внешней точкой?

2.18. Укажите, какая часть изображенной на фиг. 3.2.18 функ-
ции является выпуклой, а какая вошутой.

:‘(—т)

Ф и г. 3.2.18.

2.19. Является ли квадратичная функция
НХ) = 10 +10х1 .|- хг _ 6х3— 3х3

выпуклой, вогнутой, невыпуклой и невогнутой или и выпуклой
и вогнутой? Является ли в общем случае квадратичная функция
либо только выпуклой, либо только вогнутой?

2.20. Сепарабельные функции —это такие функщхи, которые
могут быть записаны в виде

Ф (х) =Ё Чи ‹х›.

Например, х? + х; + х; является сепарабельной функцией, поскольку
ф (х) = }] хг.

Показать, что если все слагаемые, входящие в сепарабельную
функцию, выпуклые, то сепарабельная функция также является
выпуклой.

2.21. Выясните, являются ли Выпуклыми следующие целевые
функции:

(а) Нк) = 3х3 —— 4х1х2 + я;,
(6) №) =И1+х3+ 1.
 pagebreak 
Задача нелинейного программирования 65

 

2.22. Что является областьюдопустимых значений для х при ука-
занных ниже ограничениях? Изобразите графически область допус-
тимых значений для двумерных оптимизационных задач со следую-
щими ограничениями:

@) ”:(х) =х1+х1—3=0›

”Ах) =2х1—х2+ 1 =();

(6) іщх): хі+х3+ хё=

”20° =х1+х2+хз= 0;
(в) 8100: хд—хЁ—2>0‚

3200 = "1—х2 + 4 >03
(г) и (х) = хг + х; + 3,

Е1(х)=х1_х2+ 2>0

Ев (Х) = Х; > 0.

88 (Х) = хе > 0.

2.23. Ответьте на приведенные ниже вопросы к следующей зада-
че (в каждом случае докажите правильность ответа):

1

минишізировать [(х) = % х} _ —2- хі —- х2

при ограничениях
ч+ё=а
—- 16, < 2.

(а) Является ли данная задача задачей выпуклого программиро-
вания?

(б) Является ли точка х = [1 1]; допустимой?

(в) Является ли точка х— — [2 211 внутренней?

(г) Является ли [ (х) унимодальной функцией?

2. 24. При каких условиях локальный минимум будет одновре`
менно и глобальным минимумом? (Постер айтесь дать краткий ответ.)

2. 25. Найдите выражения для градиента приведенных ниже
целевых фунший и вычислите значения градиента в указанных
точках:

(8) 7 (х) = 3х?— 2361962 + 6х3
в точке к:: [0 011,
в точке х== [1 211;
(6) ‚(3024152— 2х1х2+2х3
в точке х = [——1 0]Т‚

в точке х: [—1 —- 117.
 pagebreak 
66 Г лава 2

 

2.26. Чему равен градиент [(х) = де”: +х1х„
в точке х == [2 31т?

2.27. АппроксИМИруйте [(х) задачи 2.26 в точке х = [1 Пт
с помощью квадратичного приближения.

2.28. Аппроксимируйте с помощью (1) линейных членов (перво-
го порядка) ряда Тейлора и (2) квадратичных (второго порядка)
членов ряда Тейлора целевую функцию

? 2
Дх) =еиі+2”2— 10х1х‚ в точке х= [1 117.

2.29. Если для ограничений выполнятся условия второго по-
рядка, выполняются ли также условия первого порядка?

2.30. Укажите необходимые и достаточные условия максимума
функции одной переменной.

2.31. Было найдено два решения задачи нелинейного програм-
мирования

минимизировать [ (х) : 7х1 —— 6х2 + 4х3

при ограничениях
И1(х)= хі+ 2х; + 3х3— 1 = 0,
п„(х) = 5х‚+5х‚——3х8—6 =0

следующего вида:

0,947 0,534
х = 0,207 ‚ х и 0,535 ‚
_ 0,0772 — 0,219

[(х) = 5,08, мх) = _ 0,346.

Одно из этих решений, очевидно, является максимумом! а другое —
минимумом.
Убедитесь, что эти векторы х удовлетворяют необходимым и дос—
таточным условиям соответственно для максимума и для минимума.
2.32. Известно, что следующая задача:

минимизировть Дх) = 100 (х, —- х‘т') + (1 — ха?
при ограничении
х'і’ + х; < 2

имееч` локальный Минимум в точке х* = [1 117. Убедитесь, что
Необходимые условия для локального оптимума удовлетворены.
Является ли этот локальный оптимум также и глобальным?
 pagebreak 
Задача нелинейного программирования 67

 

2.88, Очевидно, что целевая функция

ПХ) = 1х8!
имеет минимум в точке х = 0.

Можно ли к этой целевой функции применить критерии разд.
2.5?

2.34. Определите, является ли локальным минимумом седловая
точка функции і(х) = 1— х‘і— 4х1х3—х'5’, ограниченной цилиндром
Ё+ё=2

2.35. Для следующей задачи:

минимпзировать [ (х) = ХЁ
при ограничениях

31(х)=_х`3+х`;>0›
32(х)=хі+хг>0,
з„‹х›=х%+»;+2хв>0

проверьте, удовлетворяет ли предполагаемое решение ›‹ = [О 011
теоремам, приведенным в разд. 2.5.
2.36. Определите, является ли оптимальным (с точностью до

двух значащих цифр) предполагаемое решение х=[0‚82 0,43 0,771Т
задачи

2 1 3

мишамизироватъ ПХ) = т + ’;, + 0,2 + хв+ 0,5

при ограничениях
4х1 + 7х2 + 3х3 < 10,
3х1 + 4х2 + 5х8 < 8,

1:1, Хау хв>0—

2.87. Определите, является ли оптимальным (с точностью до
двух значащих цифр) предполагаемое решение х=[0,75 0,75

0,691Т задачи
2 1 3

минимизировать [(х) = т + т + т

при ограничениях
3х1 + 4х, + 5х8 = 8,
Хм ”ъ хз) 0-
2.38. Следующая задача:
минимизировать [(х) = 4х1 — хЁ —— 12
 pagebreak 
68 Глава 2

 

при ограничениях
25 — х'т’ — х; = 0,

10х1—х%+ 10х2— х3—34 >О,

(хг— 3)2 + ("2 — 1)2 > 0.
х„ х.: >О

была численно решена, и получен ответ, который, как казалось,

является искомым решением, & именно вектор х = {1,000 4,9001Т.
Покажите, удовлетворяет ли найденный вектор необходимым и дос-
таточным условиям того, что он является решением данной задачи.
Приведите все вычисления.

2.39. Минимизируйте і(х) = х” — х, начиная из точки ›: = 3,
с помощью следующих методов одномерного поиска:

(а) метода золотого сечения;

(б) метода ДСК _- Пауэлла;

(в) метода ДСК.

Пусть |Ах<°)| = 0,1. Выполните число вычислений функции, до-
статочное, чтобы получить 1Ах®|<10`3. Постройте график зави-
симости [і(х‘”+”)—і(х<*>)] от последователькости номеров }е для
каждого метода. Для этого вы можете методом ДСК определить
интервал, в котором находится минимум, при использовании про-
цедуры поиска методом золотого сечения.

2.40. Найдите минимум №:) в направлеъщи наискорейшего спус—
ка, начиная из точки х…) = [2 211 для [( )=хі +25хЁ‹ [Указаниа
пусть х<1)= х<°> + Аудит). Микимизируйте ПХ…) по А.]

2.4]. Пусть требуется найти действительные корни уравнения

‚°, (х) = 3000 _ 100хв _ 4х“ _ 6х“ = 0. (а)

Как можно привести эту задачу к виду задачи оптимизации?
Предположим далее, что требуется найти действительные корни
одновременно уравнений (2) и (б).

;и (х) = 6х' + 4х“ + 1003:& _ 3000 = 0. (6)

Как можно привести эту последнюю задачу к задаче оптимиза-
ции?

2.42. Коэффициенты в эмпирической модели у = 60 + 61:51 +
+ %% должны оцениваться по методу наименьших квадратов, т. е.
путем минимизации суммы квадратов разностей между предсказан-
ными значениями у (используя оценки коэффициентов) и экспери-
ментальными значениями у. Сформулируйте эту задачу как зада—
чу оптимизации.
 pagebreak 
Задача нелинейного программиров ания 69

 

2.43. Покажите, чю целевая функция

— 3,03 1,345}
х!

1
[(х) = 55,84 + [7,31 26,651х + х [ 1,345 ——6,96

где хт= [):1 №11, строго выпукла. Покажите, что —3(х) строго
вогнута, если

3 (х) = 85,72 + 21.85»:1 + 8,5%, _ 9,2ох5 _— 5‚18х; _- едет,.

Затем покажите, что экстремум, полученный при минимизации [‘ (х),
является глобальным экстремумом.

ЛИТЕРАТУРА

1. Вали; 6. В‚‚ Цпеах Ргодгаштіпц апй Ехіепзіоп, Рп'псеіоп Ппіч. Ргезз. Ргіп-
сеіоп, М. .1‚‚ 1963.

2. Шіібе 1). З., ВеівЫіег С. $.‚Роцпс1вііопз оі Орп'шігаііоп, Ргепіісе-НШ, те.,
Еп31е№оа сть, М. ]„ 1967.

& Ропзіеіп Л., ]. $!АМ Нео., 9, 115 (1967).

4. КцЬп Ш. “!.. ТцсКег А. …А, МопНпеаг Рговгагпшіпд. Ргос. 2…1 Вегкыеу Зушр.

оп МаіЬешаЁісаі Зіаіізіігд апа Ргодгаштіпв, Нпіч. оі СаШогпіа Ргеэз, ВегКе1еу,

1951, рр‹ 481—493.

Пассо А. \!… МсСогтіск @. Р., Мопііпеаг Рюегаштіпе. “]ііеу, 1пс.‚ М. У.,

1968.

МсОогтісК @. Р., 31АМ ]. Аррі. Май.. 15, 641 (1967).

Реппіэі [.., Ттпз. Ат. Мат. $00., 74, 177 (1953).

№№ %Ёі” Оріітит Зеешпв Метщіз, Ргепйісе-Нап, [пм Еп31ешооё СШЬ,

М. .] ., 1 . '

Содеіпз Сч. Р., Нпічагіаіе ЗеагсЬ Мейюкіз, !гпрегіаі СЬетісаі [пацзігіа Л.М..

Семга] іпзйг. ЬаЬ. Кез. Моіе 64/11, 1964.

10. Вох М. Л., Вачіез В.. Зшапп “1. Н., Ыопііпеаг Оріітіиаііоп ТесЬпічцеэ, СЬе-

тісаі [паизігіез Моповгаріт 5. О1ічег апа Воуд, ЕбіпЬш-еі'л. 1970.

11. 1С1 Ноге 64/3, 1964.
12. Рошен М. 1. П, Сотриіег ]., 7, 155 (1964); см. также №1511 ]… ей., Митегісаі

Апвіузіэ. Асадешіс Ргезз 1пс., Ьопйоп, 1966.
[З. 61'1Ьег’с Е. О., Бітиіаііоп, |О, 350 (1967).

599895"

ДОПОЛНИТЕЛЬНАЯ ЛИТЕРАТУРА

Ріассо А. У., Зечпепііаі Ыпсопзігаіпеа Міпітіиаыоп МеіЬогіз [ог Мопііпеаг Ргог
гаттіпе, РЬ. В‚ Віззегіайоп, Могшшеэйегп Пит.. Ечапзіоп, Ш., 1967.

Ріассо А. У., МсОоггпісК С. Р., Зечцепііа! Цпсопзігаіпеп Міпітішііоп ТесЬпічцез
Бог ЫопНпеаг Рюагаттіпа. \Уііеу, М. У., 1968.

Кцп2і Н Р., Хит йецііееп зіапд дег пісЫНпеагеп Оріішіегипдз ТЬеогіе, Ыпіегпеи
тегзіогзсіъ 12, 10968).

Кипа Н. РіёбёгеПе Ш.,ОеШі “!., ЫопХіпеаг Рюегаттіпе, В1аі56е11, шамп…

азы. .
 pagebreak 
70 Глава 2

Кцпиі Н‚ Р., Тизспатсп Н. Ст., 2е|1пс|ег С. А., Мишегісы Метод; оі МаіЬетаНса]
Оріішіиаііоп. Асасіешіс Ргезз, М. У., 1968.

Мапвазагіап О. 1… №п1іпеаг Рговгагптіпц. МсСгаш-НШ, Ы. УХ, 1969.

Мапеазагіап О. Т..., Рготочіі: ТЬе Ргііи-ЛоЬп Месеззагу Оріітату Сопкііііопз іп
{31:3 Рёёэепи оі ЕциаШу апп ]печцаШу Сопзйгаіпіз, [ Мат. Апл!` Арт., 17,

(1 7)

эспесЫег К‘ $., Вечегісіде (3. 8, О., Зцііісіепсу Сопаійіопз іп Сопзігаіпеа \іагіа—
ііопз, [па. Епд. сит. РитішпепіаЬ, 5, 571 (1966).

5с|1есЫег Е. З., Вечегіаве О. & (}., Оріітіиаііоп: ТЬеогу апа Ргасйісе, Места…-
НШ. М. У., 1970.

\ШШе !). ]., внешне: С. $., Роцпааііош оіОріішігаНоп, РгепЪісе-Нап, Епгіешоог]
Сііііз, М. Л., 1967.

[апвшіп \У. П., ЫопНпеаг Рговгашшіпгі А Цпіііеа Арргоась, РхепНсеНаП, Еп;-
1ешоокі Сііііз. П. $.. 1969.
 pagebreak 
Часть И

МЕТОДЫ НЕЛИНЕПНОГО ПРОГРАММИРОВАНИЯ
БЕЗ ОГРАНИЧЕНИЙ

В приведенной выше табл. 2.7.1 при классификации задач непи-
нейного программирования по характерным чертам метода решения
выделяются ме'юды, использующие при оптимизации произ-
водные, и методы, которые не используют производные,— обычно
известные как ме'юды поиска. Ниже в гл. 3 описываются методы
первой группы, а в гл. 4 рассматриваются методы второй груППы,
причем обе для задач без ограНИчений. Затем в гл. 5 сравнивается
эффективность различных методов. Конечно, это не слишком четкая
классификация, поскольку некоторые методы являются смешанными.
например определение составляюших градиента целевой функции
по разностным схемам или минимизация в направлении градиента
с помощью методов поиска. Здесь мы имеем возможность рассмот-
реть только некоторые из многих методов решения задачи нелиней—
ного программирования без ограничений; выбраны были те из них,
которые, с одной стороны, достаточно эффективны, а с ЦРУгой сюрт
ны, связаны с алгоритмами, обсуждаемыми в последующих главах,
посвященных нелинейному программированию при ограничениях.
Некоторые важные алгоритмы нелинейного программирования при
ограничениях требуют использования эффективной процедуры
минимизации без ограничений. '
 pagebreak 
Глава 3

МЕТОДЫ МИНИМИЗАЦИИ БЕЗ ОГРАНИЧЕНИЙ,
ИСПОЛЬЗУЮЩИЕ ПРОИЗВОДНЫЕ

Общая задача нелинейного программирования без ограничений
сводится к следующей:

минимизировать [(х), х 6 Е", (3.0.1)

где } (х) является целевой функиией. Руководствуясь замечаниями
разд. 2.5.1, при решении э'юй задачи мы используем методы миними-
зации, которые приводят к стационарной точке ;“ (х), определяемой
уравнением 7! (х*) = О. В этой главе рассматривается вопрос
о том, как решить задачу (3.0.1) с помощью алгоритмов, использу-
ющих первую и вторую частные производные )* (х), Сначала описы-
ваегСя поиск методом наискорейшего спуска, затем излагаются
меюд Ньютона, метод сопряженных направлений и, наконец,
некоторые из методов, аппроксимирующих (путем использования
только первых производных) направления, определяемые методом
Ньютона.

3.1. ГРАДИЕНТНЫЕ МЕТОДЫ

В этом разделе кратко излагается стратегия градиентных (наи-
скорейшего спуска) методов оптимизации без ограничений; в вы-
числительном аспекте эти методы используюг только первые про-

изводные целевой функции. На !г-м этапе переход из точки к“”
в точку к“”… описывается следующим соотношением:

,вы—1) = ‚«М + Акт) : хи» + мюЗ/а : Хаг) + №0050», (3,1,1)
где
Ахад—вектор перехода из точки к“” в точку х‘м'”;

з®—единичный вектор в направлении АХК”);
`‹›"”—любой вектор в направлении Ах“);

№), А“” — скалярн, определяемые соотношениями

Ах“) : №№) = мюзик
 pagebreak 
Методы минимизации, использующие производные 73

 

31.1. МЕТОД НАИСКОРЕИШЕГО СПУСКА

Применение метода наискорейшего спуска для решения задачи
минимизации без ограничений было рассмотрено еще известным
французским математиком Коши. Как отмечалось в разд. 2.4.4,
градиент целевой фунтщни [ (х) в любой точке х есть вектор в направ-
лении наибольшего локального увеличения {(к}. Следовательно,
нужно двигаться в направлении, противоположном градиенту
НХ), т. е. в направлении наискорейшего спуска, поскольку отрИЦа—

тельный градиент { (х) в точке х… направлен в сторону наиболь-

шего уменьшения [ (ХЕ по всем компонентам х и ортогонален линии

уровня [’ (х) в точке х‘ ’. Введение направления, противоположного
нормированному (единичному) градиенту ‚‘ (х), т. &. направления наи-

скорейщего спуска, определяемого в точке к“” по формуле

% = _ №
5 ”7, (хдд)… ‚ (3.1.2)
‹ › ‚“***-”;

в (3.1.1) дает следующую формулу перехода Из х’ н

ие) (»
‚((и—1) = хи» _ № : х“) __ ”…“ (‚@) (3'13)

Отрицательный градиент дает только направление оптимизации,
но не величину шага. При этом можно использовать различные про-
цедуры метода наискорейшего спуска в зависимости от выбора 1.
иопределения Выражения ““Ы””. Поскольку один шаг в на-
правлении наискорейшего спуска в общем случае не приводит в точ-
ку минимума [ (х), формула (3.1.3) должна применяться несколько
раз, до тех пор пока минимум не будет достигнут. В точке минимума
все составляющие вектора градиента равны нулю. В случае когда

_ 1 7 (И __ (д)
целевая фунхщия Нк) _ [„ ›‹ Ах, выражение И (х ) _ Ах мо—
жет быть непосредственно подставлено в (3.1.3).

Процедура строго наискорейшего спуска может закончиться
в стационарной точке (в которой составляющие градиента ): (х)
равны нулю) различного типа. Обычно бывает необходимо опреде-
лить, является ли данная точка точкой локального минимума
(т. е. решением) или седловой точкой. Если это седловая точка,
ю шедует применить какой—либо нетрадиентный метод, чтобы
выйти из нее, после чего минимизация может продолжаться, как
и ранее. Тип стационарной точки может быть проверен путем иссле-
дования матрицы Гессе (если ее возможно получить) целевой функ-
ции, взятой в данной стационарной точке. Если эта матрица не явля-
ется положительно определенной, то стационарная точка —— седло-
Вая. В качестве критерия окон-тания последователъной процедуры
при движении в направлении наискорейшего спуска применяются
 pagebreak 
74 Г лада З

 

различные правила, основанные либо на значении Г (Х) и величинах
х, 7», 71’ (х), либо на некоторой их комбинации, а также на со-
ответствуюших значениях этих величин на предыдущих шагах.
Успех того или иного метода в смысле эффективности сходимости
к локальному минимуму зависит от этих правил, а также и от са-
мой задачи.

При выборе размера шага применяются два общих метода, хотя
могли бы быть рассмотрены и многие другие возможности. В первом
методе при переходе из точки к”" в точку х“… целевая функиия
минимизируется по ?», в другом методе величина ?. выбирается фик-
сированной или меняется от шага к шагу.

Рассмотрим сначала случай, когда ?» выбирается так, чтобы ми-
нимизировать [ (х) в заданном направлении. При этом на каждом
шаге старая информация отбрасывается и заменяется новой ин-
формацией, так что никакого ускорения оптимизации осуществить
нельзя. Сходимость метода наискорейшего спуска в такой постановке
может быть доказана [1 ]. Можно показать, что для выпуклой целевой
фушщии, имеющей производные до третьего порядка (и для неко-
торых других функций при еще более слабых ограничениях), этот
метод в пределе сходится при /г-› со. Тем не менее упомянутое
свойство метода наискорейшего спусКа не является большим его
достоинством на практике, поскольку скорость сходимости может
быть слишком медленной, как это оказывалось в многочисленных
экспериментах, а также предсказывается теорией [2].

При определении точки х‘Н" на основе формулы (3.1.3) Г (Х) мо-
жет быть формально минимизирована путем вычисления ?. из урав-
нения

днх®+ж^зш> _

(М 0.

В качестве конкретного примера предположим, что [ (х) — квадра—
тичная функция [имея это в виду, подставим в уравнение (2.4.5)

М"“ вместо (х _— х“°’)1. Тогда

(1: ^ !: ‚_ ‚_ ‚_
№ : 0 = УТ; (№) эш + (з…)т нм“), (3.1.4)

что дает следующее выражение для А…:

у 77: № №

№) = _ „
(&‘Ыіт ";пд

(3.1.5)

Функцию [ (х) можно минимизировать также с помошью одного
из методов одномерного численного поиска, изложенных в разд. 2.6.

Интересной чертой процедуры минимизации в случае квадра—

ла ^ »
тичной целевой функции является то, что 7} (х( +“) ортогонален &‘ ).
 pagebreak 
""'!

Ф и 1-4 3.1.]_ Иллюстрация юго, чю мя квадратичной целевой функции
($…” И (‚":-Н): 0, если [ (х) минимпвируется в направлении &‘”)-

.Лшши уровней {(т)

 

(!
г, ’ т,!” И,

Ф и г. 3.1.2, Зигзагообразная траекюрия оптимизации при использовании метода
наискорейшего спувка.
 pagebreak 
76 Глава 8

Это можно показать следующим образом. Отметим, что если
[(х) = & + хТЬ + %Х’НХ,

то градиент )* (х) равен
71° (х) = Ь + Нх‚ {з.щ
так что
тг №) =- ь + нх‹°›,

“(ход; : Ь + нхщ
Подстановка выражения для ті (х…) в (3.1.4) приводит к уравнению

(Ь + "хочу ;и» + @…т …(ЮЗЮ : 0_

^
После подстановки х‘Ніі—хі’г) вместо №№”) и преобразования по-
лучаем

(3007 (|; + т» + (&т)’ н (хінп _- хш) = 0,
ИЛИ

@»Т (Ь + Нх‹*+'» = ‹Зт’ ті (№№) = 0. ‹3-17)

Другими словами, градиент в х0г+п ортогонален предыдущему на-

правлению поиска 5“" (фиг. З.Ы). Если в методе наискорейшего
спуска выбирается фиксированное значение скаляра ?» или величи-
на % переменная, 10 она должна тщательно контролироваться во
избежание как неожиданного роста „х), так ичрезмерного числа
шагов, необходимого для достижения решения. Первое произойдет,
если ?» слишком велико, а второе, если ?» очень мало или еши ?»
настолько велико, что приводит к колебаниям около точки минимума
(фиг. 3,1.2). Таир… образом, величина Ъ. должна уменьшаться при
приближении к точке минимума. Один из возможных методов кон-
троля ?» предполагает установление некоторого критерии для ?»,
основанного на использовании угла 6 между последовательными
векторами шагов в процессе минимизации, Например, если этот
угол становится меньше, чем некоторая заданная величина, то ве-
личина ?» должна быть умножена на некоторую заранее определен—
ную константу а:; если угол становится больше, то )и нужно разде-
лить на о:.

 

Пример 3.1.1. Метод наискорейшего спуска

В том примере описывается несколько ЦИКЛОН метода наиско-
рейшего спуска С целъю ИЛЛЮСТРЗЦИИ методики решения задач
МИНИМИЗЗЦИИ.
 pagebreak 
Методы минимизации, использующие производные 77

 

Рассмотрим задачу
иннимизировать [(х) = х? + 253%.
Возьмем сначала фиксированную длину шага ж, начальное

значение которой равно единице. На каждом этапе нам понадобят-
ся значения следующих функций:

(11! (")
№=2х№ ЁЁ?)=50„‹2Ю‚
д “?> в д (") ’
1|7і(Х‘*’)|\ = 1/ (%#) + (%%—А) .

0 Т
Начиная с точки х‘ ’ = [2 21 ‚
следующими этапами:

поиск минимума осуществляем

 

Вели-іина шага при
переходе к сдедуйще—

М ШЕП
Этап „, :, № @ || 7! (№1 н у у
Ах. | Ах,
0 2 2 4 100 „ 100 —-0‚04 —1‚00
1 1,96 1,00 3,92 50 50,1 —-—0‚078 — 1,00
2 1,88 0 3,76 0 3,76 —1.00 0
3 0,88 0

На фиг. П.З.Ц, а можно проследить траекторию поиска.
Для того чтобы метод сходился, ?» обычно нужно уменьшать,
иначе при подходе к минимуму возникнут колебания («назад——

вперед»). Заметим, что вючке минимумах = [О 01Т7і (х) = 0.
Ниже приводятся результаты трех соотвегствующих этапов

вычисления, в которых вместо использования фиксированного

?» Ищется минимум [(х) в направлении наискорейшего спуска:

 

 

 

 

 

!: #
Этап [: М,?) и, х, “$#! № ! (Х…)
0 2 2 4 100 104
1 2,003 1.92 —0,003 3,84 —0‚1 5 3,19
2 1,850 0,070 0,070 0,14 3,50 0,13
3 0,070 0,070 =0, 000

 

Следует обратить внимание на то, что на фиг. П.3.1.1‚ а градиент
[(х) в начале поиска не направлен в точку минимума, поскольку
коэффициенты при х, и ха различны.
 pagebreak 
78 Г лава 8

 

Путем замены переменной

у : 5х2
минимизируемая футщия принимает вид
Г (Х) = х? + у“,

и вектор градиента в точке х, = 2, у = 5х2 = 10 действителъно
направлен в точку минимума, поскольку коэффипиенты при 15,
и у теперь одни и те же; см. фиг. П.З.1.1, 6.

Если нелинейная целевая функция слишком сложна, чтобы
ее можно было продифференцировать аналитически, то сосТавля-

  

;‘(гр а:‚’+ 25$;

  

Ф и г. П.З.1.1.
__ фиксированное их…); _— — -— 7 (х). мииимизируемая на каждом шаге.
 pagebreak 
Методы минимизации, использующие производные 79

 

ющие градиента, являющиеся частными производными по оптимш
зируемым переменным, аппроксимируются разностными соотноше-
ниями. Например, для функции двух переменных разностные фор-
мулы имеют вид (если разности берутся вперед)

ді №) №3” + 61), № _ ! №, хат

 

 

да:1 ‚"`: 61 ' (а)
анх…) _ {‹хі’”. ‹хэщбт—ш‘”, ху»)
дх, "`" д, ' (6)

где дд—некоторые малые отклонения. При этом необходимо вычи-
слить целевую функцию лишь в трех точках, а именно в точках
(худ), ху”), [(х‘Р—Ъбі), мг] и Щ”, (‚%;>+62)1 на каЖДый цикл 13.
Величины Б,— в общем случае выбираются так, чтобы ошибка в ап—
проксимации производной не превышала разумного уровня. Поскольку
градиент не обязательно направлен в сторону минимума в х… и
градиент заново вычисляется на каждом этапе, величина этой ошиб-
ки существенна главным образом в окрестности минимума, где
мыэа

Для иллюстрации ниже приводятся компоненты градиента для
данного примера, вычисленные по разностным формулам (а) и (б)
при 61 = 62 = 0,05:

   
 

  

0; (№),
дл,

6: №»
дх,

 

 

 

 

„. ] „, „+… „„„, ”$211:- "шпз-
2 2 2.05 2,05 4,05 4,00 101,25 100,0
0,0! 0,01 0,06 0,06 0,070 0,02 1,80 0,50

 

 

 

Из таблицы видно, что на некотором расстоянии от минимума
разностная аппроксимация производных вполне приемлема, однако
вблизи минимума она недостаточно удовлетворительна. Конечно,
можно уменьшать величину 6, в процессе поиска или использовать
более подходящие аппроксимирующие формулы для производных,
но здесь мы не будем обсуждать эти вопросы, поскольку имеются
другие методы оптимизации без ограничений, более предпочтитель-
ные, чем метод наискорейшего спуска.

Основной трудностью при использовании метода наискорейше-
го спуска, как уже видно из приведенного примера, является его
зависимость от выбора масштаба оптимизируемых переменных.
Если гиперпространство очень нытянуто, так что образует
 pagebreak 
80 Г Аааа'З

 

 

«хребет» или «овраг» (отношение максимального значения Н (х) к ми-
нимальному в каждой точке великф, процедура наискорейшего спус—
ка сходится слишком медленно, чтобы быть эффективной, или может
вообще не сойтИСЬ за разумное время. На фиг. 3.1.3 иллюстрируется

Проекция сйт) на
повертновть Мг)

   
   

{(т)

"!

Ф и г, 3.1.3. Типичная зигзагообразная траектория оптимизации при использова-
нии Метода наискорейшего спуска в узкой впадине.

згга трудность; направление наискорейшего спуска оказывается
почти орюгональным наилучшему направлению достижения мини-
мума Нк). Одним из выходов в этой ситуации является использо-
вание информации второю порядка (информации, даваемой вторы-
ми частными производными целевой функшди по независимым пере-
менным или их приближениями). Этот вопрос будет рассматриваться
в разд. 32 и 3.4. Другим подх0дом‚ с которого мыи начнем, является
изменение масштаба независимых переменных в целевой функции.
 pagebreak 
Методы минимизации, использующие производные 81

 

3.1.2. МАСШТАБИРОВАНИЕ НЕЗАВИСИМЫХ ПЕРЕМЕННЫХ

В примере 3.1;1 было показано, что с изменением масштаба
переменных (координат) меняется и направление наискорейшего
спуска. Таким образом, произвольное изменение единиц измерения
независимых переменных изменяет направление наискорейшего
спуска и влияет на эффективность градиентной минимизации.
Избежать эту трудность можно путем введения безразмерных пере-
менных, полученных Делением каждой переменной на интервал
ее изменения, как, например,

^ Т — ’Г ^ р — р
т = ___-Ъ. = ___—‘
ТА _ Т1 , р Р: _ Р1 ,
где в данном случае Т обозначает температуру, & р —- давление. Но
даже это преобразование искусственно подразумевает, что расстоя-
ние ;;и —р1 то же, что и Т2 —- ТГ
Если в п—мерной задаче принять следующее общее определение

расстояния в Е“:

дэ, : |№11'+|4х1і'++|11х„|'
„ ‚

где г — индекс метрики, то можно показать [3], что отношение изме-
нений любых двух немасштабированных координат (при наиско-
рейшем спуске) дается формулой
ах; __ д] (}:)/дх;
4—х,- " | д;‘(х)/дх1

“(’—1)

 

(3.1.8)

Знак плюс используется, когда частные производные одного знака,
в минус —— когда производные разных знаков. В случае обычной
метрики (г = 2) получаем

1х: : + ді(Х)/д›сі

дх, _ д)с (}:)/дх, '

что соответствует направлению, определяемому градиентом.
Предположим далее, что для оптимизируемых переменных про-
изводится изменение масштаба (единиц измерения), так что

;; = ч: (кд,

где х‘ — масштабирования переменная. Обычно такая замена
линейна, как, например, в случае перевода температуры из шкалы
в градусах Цельсия в шкалу в градусах Фаренгейта:

Т(в °Ё)=1,8Т(в °С) +32,

при этом величины рі=дф(х,)/дх,-—константы. Тогда можно по-
казать, что отношение изменений любых двух масштабированных
 pagebreak 
82 Глава 8

 

переменных будет следующим:

„ ›‹ !/‹г—п г/(г—п
“# = і- ————д’ (’”/"51 —’ . (3.1.9)
ФЧ ді(Х)/дХі ”’

 

 

 

Влияние выбора масштаба определяется отношением ]рд/ріі’дЫК
В случзе г = 2

зі: : _дг_‹х›/д7‹_: (щ)
43; а…)‚д7„ ”"

откуда можно заключить, что относительное изменение переменных
‚\:1 и х, зависит от масштабных множителей. Следовательно, един-
ственного направления наискорейшего спуска не существует.

Некоторые интересные выводы могут быть получены при таких
индексах метрики, как г= 0, г = 1 и г= оо. В случае г= 0,
что соответствует (15 = ([ 4х1 „№2 |...] ах„\)_", отношение ‹іхд/кіхі
одно и то же как для немасштабированных, так и дЛя масштаби-
рованных переменных. Бокс и Вильсон [4] осуществили такое же
масштабирование путем приравнивания скорости изменения цепе-
вой функции по одной из безразмерных переменных к скорости
изменения по другой безразмерной переменной,

В случае г = 1 уравнение (3.1.8) приводит к

дх;

4—х,=:ь°°’

откуда следует, что на каждом этапе оптимизации соответствующий
шаг осуществляется лишь в одном координатном направлении,
а именно в направлении, соответствующем наибольшей частной про-
изводной. Эю соответствует попеременному поиску по одной ко-
ординате, причем выбор шага определяется величиной ді/дх,.

И наконец, г = :!: оо соответствует 415 = & ‹іхд, где МХ“ =

=шах(|‹іх‚]) при 7: +оо и |йхді=шіп(|ах,[) при г==—оо.
1
При этом из уравнения (3.1.8) следует
дх! _
'Гх, _ :і: 1,

т. е. на каждом последовательном этапе оптимизации все координа-
ты изменяются на одну и ту же величину. Очевидно, что, применяя
подходящий индекс метрики и проводя масштабирование, можно
получить широкий выбор направлений для использования их в ка‹
честве направления наискорейшего спуска. Проблема выбора ин-
декса метрики в задаче оптимизации еще не изучена, но, видимо,
этот подход может послужить основой улучшения алгоритмов.
 pagebreak 
Методы минимизации, использующие производим 83

3.2. МЕТОД ВТОРЫХ ПРОИЗВОДНЫХ (МЕТОД НЬЮТОНА)
И СВЯЗАННЫЕ С НИМ АЛГОРИТМЫ

Направление поиска, соответствующее наискорейщему спуску,
можно интерпретировать как следствие линейной аппроксимации
целевой функции (фиг. 3.2.1, а). С другой стороны, методы вторых
производных, среди которых лучше всего известен ме'юд Ньюто-
на 1), возникли из квадратичной аппроксимации [’ (х), определяемой
уравнением (2.4.5). Они используют информацию второго порядка,
содержащуюся во вторых частных производных целевой функции
[(х) по независимым переменным.

3.2.1. МЕТОД НЬЮТОНА

Направление поиски & в методе Ньютона выбирается следующим
образом. Если х — х“) в уравнении (2.4.5) заменить на величину
Ах… = хш'н’ —— х… определенную из уравнения (3.1.1), то квад-

‚

ратичная аппроксимация функЦИИ {(х) через переменные АХ…
представляется следующим образом:

7 (”"+“) = і (Х…) + 771“ (№) АХ“) + % (АХ…)Т ?*Г (Х…) АХ” (32.1)

Минимум функции [’ (х) в направлении Ах… определяется диффе-
ренцированием і (х) по каждой из компонент Ах и приравниванием
нулю полученных выражений. Последнее приводит к
№ = — №<х<*»г' «№», (32%
Где [72і(х("))]_1—матрица, обратная матрице Г ессе НМШ), опре-
деленной в разд. 2.4 (матрица вторых Частных производных дх)
по х, взятая в точке к““).
Подстановка выражения (8.2.2) в уравнение (3.1.1) определяет

переход ИЗ ‚((*) В Х№+Ц по методу Ньютона:
хо…) = хоч _ 1721 (‚«ММ—' „(хачу (3.2.8)

Заметим, что здесь и направление и величина шага точно опреде-
лены. Если [(х) _— квадратичная функция, то для достижения ми—
нимума ‚‘ (х) достаточно только одною шага. Но в случае общей не—
линейной целевой функции минимума ;“ (х) нельзя достичь за один
шаг, поэтому уравнение (3.2.3) обытшо приводят к виду (3.1.3)
путем введения специального параметра длины шага 7»:

((г) —1 (12)
Хаан; : х… _ №:) 17’? (Х )] ПГ (Х )] . 32.4)
и № ‹х‘*>›г' … №Я ” (
" Название объясняется тем, что решение системы уравнений и‘ (х) = 0 Ме-

тодом Ньютона приводит к уравнению (3.2.2); иногда они называются мелшдами
коавилинеарцэации.
 pagebreak 
84 Глава 3

 

_ [\'721"(Ы”7)]_171‘(х (Н)

  

6 “°!
Ф и г. 3.2.1. Сравнение метода наискорейшего спуска и метода Ньютона ‹: точки
зрения аппроксимации целевой функции.
а —— наискорейшня спуск: аппроксимация первого порядки (линеаризации) ФУнкцни

[(х) в точке х…; б _ метод Ньютона: аппроксимация второю порядка (кпдрвнчная)
функции , (х) в точке х…].

Отношение АшдпудмхщГ‘ [71° (х<’*>)]||——просто некоторый скаляр
№№; поэтому уравнение (3.2.4) чаще записывают следующим
образом:

хм» : Хаг) __ жаннч (хш’) 7; (х(*’)_ (3.2.4а)

Следует обратить внимание на то, что нап авление поиска теперь
задается вектором зи” = ——Н`](х(’°’)7і(х‘ ’). Уравнение (3.2.43)
 pagebreak 
Методы минимизации, цепользующиг производные 85

 

применяется итеративно, как и уравнение (3.1.3), пока не бу-
дет удовлетворен некоторый критерий окончания процесса.

Заметим, что уравнение (3.2.4а) включает в себя обращение мат—
рицы, и необходимо соблюдать осторожность с тем, чтобы выбирае-
мая процедура решения обеспечивала положительную определен-
ность обратной матрицы (см. ниже). В этом отношении многие стан-
дартные ЭВМ-программы для обращения матриц являются неудов—
ле'гворительными [5]. Заметим также, что этот метод требует вы-
числения значений аналитических вторых частных производных
или их аппроксимаций, что может оказаться в некоторых случаях
непрактичным. Критерий, гарантирующий сходимость метода Нью—
тона в предположении, что функция ‚‘ (х) дважды дифференцируема,
заключается в том, что матрица, обратная матрице Гессе целевой
Ёуъіжции, должна быть положительно определенной (см. приложение

) >:

ш*і‹›‹""›г" зи“ (ход) >о. (3.2.5)

Пример 3.2.1. Сравнение методов, основанных на использовании
производных первого и второго порядков

Чтобы продемонстрировать использование уравнений (3.1.3)
и (3.2.8), возьмем плохо масштабированную целевую функцию,
рассмотренную Розенброком [6], две линии уровней которой ([ (х) =
= 8 и [ (х) = 4) приведены на фиг. П.З.2.1:

г‹›‹› = 100 (хя— хг? +(1—хд2- (а)

Геометрически [(х) интерпретируется как медленно спадающий
искривленный овраг с самой низкой точкой х*= [1 111, где

? (Х” = 0-
Метод наискорейшего спуска
Рассмотрим точку х‘*’=[—0,5 0,511, в которой { (х…) = 85. Нор-
мированный градиент ПХ) в точке х… =[—О,5 0,5]Т равен

1 ді/дх.1 _ 1 47 _ ‚ ‚
[(т./ддт"? (дГ/дхг)я];/(Ё) [ді/дхиікф’ " 68__—,6 [50]— [0,680 0,729] . (б)

Вектор, пртивоположный вектору нормированного градиента
в х…, з‘*>=[—о‚685 _о‚7291’‚ как видно из фиг. п.з.2.1‚
указывает направление наискорейшего спуска и ортогонален уров-
ню [ (х), проходящему через ха”.

') Здесь мы оставили приняюе автором краткое ОБОЗНЗЧСНИЕ положительной
определенности матрицы А : А > 0. хотя оно и не совсем точное —- Прим. перев.
 pagebreak 
86 Г лава 3

.. ::
Чтобы наити новый вектор х‘ +", необходимо выбрать величину

?... Например, можно выбрать заранее определенное значение Жили
найти то значение А, при котором)” (х) достигает минимума в направ-

"::

  
 
 
  

4,0

Направление
в методе
[титана

дх“):

: _аом
“422

        
  
 

 
  

  

Наушники; иящ-ко-
рашки Ф'ЛУС'КП

Ф и г. 11.23.21. Градиентный метод и метод вторых производных в случае функции
Розенброка.

^
лении, задаваемом единичным вектором 50", В точки к“" = [_0‚5
0,511 уравнение (3.1.1) имеет вид

ХМ“ : {_ОЬ} __ №10,685] _ (В)
0,5 0,729
Отсюда
{(%/“+“) = НА) = 100 [0,5 — 0,729?» —— (0.5 + 058510“? +
+ (1 ‚5 + 0,6851)*. (г)

Минимум ГО») по А. достигается в точке `А.=0‚164. Подстановка
№) =0,164 в уравнение (в) цвет новую точку хФ+'1=[—0,612

0,38111, в которой {(х) = 2,6 (см. фиг. П.З.2.1). Новый вектор ЗН!)
определяется уравнением (3.1.2) для точки ХФ“), а затем находится

и №“) в направлении №4") аналогично тому, как была найдена к““).
 pagebreak 
Методы минимизации, использующие производные 87

 

Эга итерационная процедура продолжается до тех пор, пока стано-
вится уже невозможным уменьшать величину ;” (х) или пока не будет
удовлетворен некоторый выбранный критерий окончания процесса.
Интересно, что метод наискорейшего спуска, как видно из этого приме-

ра. не применим для продвижения вдоль изогнутого оврага функции
Розенброка.

М етод Ньютона

Рассмотрим теперь ме'юд Ньютона, начиная из точки

х("’= [———0‚5 0,517. Тогда хи“) определяется путем использова-
ния уравнения (3.2.3) или (3.2.43) следующим образом:

_ (… __ г— 400х, + 1200хі + 2) ‹- 400х1) _
7 і (" " (_ 400х1) 200 Ь ‘
102 200
= [200 200]'
Акт) = —[72‚°(Х®)г1 ИМ") : %[і 1 01,51] 23] =
—0,03
= [_ 0,22}
№№) = [_ 0,5] + [_ 0,03] =[—0‚53]
0,5 —0,22 0,28 '

В точке х"°+‘>=[—0,53 0,28], значение {(х) равно 2,33. По-
лученный вектор Ахш = [— 0,03 —0‚22]Т изображен на фиг. П.З.2.1.
Новый вектор Ахты) вычисляется в точке №44) с помощью уравне—
ния (3.202), ХФ“) определяется из уравнения (3.2.3).
Алътернативная процедура заключается в вычислении 8… =
= Н_1(х(*’)7і(х"")‚ как и в предыдущем методе, и в поиске неко-
торого ?» в направлении 50”, минимизирующего [(х) в соответствии
с уравнением (3.2.4а). В любом случае итерационная процедура
повторяется, пока не будет удовлетворен определенный крите—
рий окончания процесса или до тех пор, пока становится невозмож-
ным уменьшать величину Дх). На практике, чтобы уменьшить

время решения, элементы Н (х) могут вычисляться не на каждом
шаге.

 

Если используется уравнение (8.2.3), то метод Ньютона автома-
тически дает последователшость длин шагов, соответствующих
расстоянию до минимума для квадратичных функций, аппрокси—

мирующих функцию [ (х) в последовательных точках х…. Например,
 pagebreak 
88 Глава 3

квадратичная аппроксимация функции Розенброка в х… =
=[—0, 5 0,51Т представляет собой 17 (х(*))— = —5, 25 — 2х, +
+ 50хв + 200х1х2 + 51х1 + 100хЁ и минимум ‹; (х…) достигается

в х = [—0 53 0‚Т.28] С другой стороны, методы, основанные на

производных первою порядка, линеаризуют ПХ) в х ’, но ли-

нейная функция не имеет минимума (или максимума), не считая
концов; следовательно, нужно выбирать определенную длину шага
в направлении, ортогональном линеаризованной функции [(х).

3.2.2. ГЕОМЕТРИЧЕСКАЯ ИНТЕРПРЕТАЦИЯ

Теперь дадим геометрическую интерпретацию локальной квад-
ратичной аппроксимации целевой функции и проиллюстрируем
важность требования положительной определенности Н" (х).
Функция второго порядка (квадратичная)_ может быть, как видно

Лере— „_асш
тт , ”ЛЬ
Минимдш

Фш и г 3. 2 2 Преобразование координат к главным осям
Хм Х; — исходные координаты хп Х, '— канонические координаты.

из фиг. 8.2.2, преобразована к новой системе координат путем
переноса начала системы координат в точку экстремума функции
и последующего поворота осей для достижения симметрии. Обозна-
Чим старые координаты через ›‹1 и 1:2, а новые координаты, называе-

мые главными осями,— через ›:1 и хд. Эти два преобразования дают
новое, записанное в главных осях выражение для целевой функции,
называемое канонической функцией, причем эта функция много
проще исходной, поскольку исключены все члены первого порядка
и перекрестные члены.

Например, в случае двух независимых переменных квадратич-
ная целевая функция или квадратичная аппроксимация целевой
функции в соответствии с уравнением (2.4.5) будет иметь следую-
щий вид:

[(х) = 170 + Ь,;с, + 17952 + Ьцхі + Ьшхі + 512351952 + 1721362161. (3.2.6)
Уравнение (3.2.6) преобразуется в каноническое уравнение

их) — і ‹х*› : № №222; (3.2.7,
 pagebreak 
Методы ‚минимизации, использующие производные 89

 

где [(#)—значение {(х) в центре квадратичной поверхности,

а Ь“ и 1722 — преобразованные коэффициенты (знак ы обозначает
«в канонической форме»). Перенос начала координат на фиг. 8.22 со-
ответствует исключениюв уравнении (3.2 6) линейных членов, & пово-
рот осей —исключению перекрестных членов Кроме того, на фиг.
3.2 2 на крайнем справа рисунке представлен результат масштаби-
рования преобразованных переменных так что уровни целевой
функции становятся окружностями. На фиг. 3.2 3 приводятся ти-
пичные примеры двумерных функций в исходных и в главных осях.
Элементы матрицы Гессе целевой функции Н (х) можно легко свя-
зать ‹: коэффициентами уравнения (8.2.6):

Я

днк) “%… д’іт =2Ь„= дт!) =2д№ двд,!) “417%.

д ‚‚? __ дх1дх2 д;:‚дх1

 

Кроме того, коэффициенты дд и 172, в уравнении (3.2.7) являются

собственными значениями матрицы 1/‚Н (х( ’) (доказательство
этого факта можно найти во многих руководствах по теории матриц
и линейной алгебре). Матрица, обратная матрице Гессе целевой

фунхщии, взятой в точке х…, дает меру кривизны функции „х)
в окрестности х“)

В табл. 3.2.1 интерпретируется информация содержащаяся
в каноническом представлении (3.2. 7) исходной функции (3. 2..6)

Если |!)11 | >] ьы, то линии уровней вытягишются вдоль х, (мень—
ший коэффициент) и наоборот. Если центр расположен по оси ;с„

на бесконечности и Ь“ отрицателен, то линии уровней представляют
собой параболы, как показано на фиг. 8.2.3, е. Каждая из вырож-
денных поверхностей, изображенных на фиг. 3.2.8, д, называемая
оврагом или хреб-юм, имеет место, когда один из коэффициентов
по абсолютной величине мною меньше другого. В качестве просто-
го примера возьмем функцию [(х)= :? + хЁ + 2х1х‚‚ которая
в результате подстановки х = ::1 + хз преобразуется в і(х)=

і=(х) = 3:2 Тогда ЬЦ— — 1, а 17“ = 0, что соответствует варианту
9 в табл. 3.2.1. Изложенное можно легко распространить на случай
функций более чем двух независимых переменных. Например, когда

все ди равны между собой, поверхности постояшюго уровня целевой
функции представляют собой гиперсферы; когда один или большее

число коэффициентов ди относительно малы, имеет место гипер-
овраг (хребет) и т. д.

Одним из основных требований того, чтобы любая прецедУРа
ОПТИМИзации была успешной, является возможность быстро дви—
гаться в локальной области вдоль узкого оврага (при минимизации)
в направлении минимума целевой функции. Другими словами,
 pagebreak 

 pagebreak 

 pagebreak 
Фиг. 3.2.3 (д, е),
 pagebreak 
Методы минимизации, использующие производные 93

 

хороший алгоритм должен дать направление поиска, имеющее боль-
,шую светавляющую вдоль оврага. Овраги (хребты в случае макси-
мизации) встречаются весьма часто, по крайней мере локально. При
этом вовсе не обязательно, чтобы функция, аппроксимирующая

 

 

 

 

 

Таблица 3.2.1
Интерпретация кнюништй функции
их) чот = дн 3% + ьн »;
Коэффициент Знаки 3
Тип линии Геометрическая ин- Центр «›
5.31%?!- СООТИОШЭВНЕ ‚.‚ЬНЪН уровня ТЕРПреТЩнЯ Ё
7,“ = 77% — — Окружность Круговой холм Максимум ‹:
2 7,“ = Ъ” + + › Круговая впадина Минимум
7; >Ъ — —- Эллипс Эллиптический Максимум
11 и холм
4 Ъ > 7, + + › Эллиптичешая впа- Минимум 5
11 22 дина
5 “@= 7,2 —- —— Гипербола Симметричиое сед— Седловая в
1 ‚ ЛО ТОЧКИ
6 Ъп— „"М _ + › То же То же а
7 Ъд > Ъ“ —— —— » Вытянуюе седло › г
8 7,” = 0 — Прямая Стационарный ') Н“ д
хребет
9 3 = 0 —‹ » Стационарный“ св— › д
и рат
10 ?; =() —— Парабола Поднимающийся‘Л) На °° °
" хребет
” 3“ = 0 + » Спадающий … ОБ- Т° же 3
раг

 

1) Вырождеиие поверхности.
2) к соопюшеишо. приведенному в названии таблицы, нужно добавить два линейных члена.

 

целевую функцию, была вырожденной. Так, например, в типичном
случае, представленном на фиг. 3.2.3, 6 в верхней и нижней облас-
тях, линии уровней напоминают овраги. Овраг располагается в На-
правлении собственного вектора, соответствующего малому соб-
ственному значению матрицы Гессе целевой функции. Наприер,
для случая функции [(х) = х? + 252% из примера 3.1.1 (проиллю-
стрированного на фиг. П‚3.1.1‚ а) матрица Гессе постоянна и равна
2 0

о 50 '
 pagebreak 
94 Г лава 3

 

Для этой матрицы собственные значения, полученные из характе-
ристического уравнения (2 _ Б) (50 _ р) = 0, равны 511 = 2
и рп = 50, (В случае диагональной матрицы собственные значе-
ния _— это элементы главной диагонали.) Собственный вектор, со-
иветствующий 511, может иметь любое значение для компоненты
в направлении х1 до тех пор, пока компонента в направлении х,
равна нулю. Читатель, видимо, уже заметил, как овраг
на фиг. П.З.].і, а вытягивается в направлении хг Еще раз отметим,
что направление —Н_17]°(х)‚ вычисленное в различных точках
пространства х, всегда совпадает с направлением к точке минимума

! (Х).

 

 

Ф…… ‘ х=гг 21Т } х=п 01Т
№10 [103 ] [ Ё ]
% ° 4 _в % ° 4 —2
_.н—Ч7НХ) (—1) х [юс]=[__2] (_в \ [0]=[ 0]
° % _° 5—0

 

В этом примере вектор —!Г' (х) 7} (х) совпадаетс направлением
в точку минимума, поскольку функция і(х) квадратичная, но, да—
же если целевая функция не квадратичная, в общем случае век'юр
_Н—іпі (х) имеет большую составляющую, параллельную собствен-
ному вектору, соответствующему малому собственному значению
Н (х), и направления поиска, как требуется, приблизительно совпа-
дают с главными осями при аппроксимации функции в точке к"”.

Основным недостатком метода Ньютона (кроме трудностей, свя-
занных с определением аналитических производных) является то,
что улучшение значения целевой функции с каждым циклом гаран-
тируется только в том случае, если матрица Гессе целевой функиии
Н (х) = 721‘ (х…) положитльно определена. Н (х) является поло-
житеЛЬно определенной для строго выпуклых функций, поэтому
в случае функций более общего вида метод Ньютона может привести
к направлениям поиска, расходящимся от точки минимума {(х).
Чтобы ясно себе представить, почему выполнение условия (3.2.5) необ—
ходимо для обеспечения сходимости, вспомним, что действительная
симметрическая матрица положительно определена тогда и только
тогда, когда ее собственные значения положительны. При минимиза—

ции, какэто видно из фиг. 3.2.3, когда все собственные значения НОК…)
положительны, локальная квадратичная аппроксимация соответ—
ствует круговой или эллиптической впадине, имеющей минимум.
 pagebreak 
Методы минимизации, использующие производные 95

 

С другой стороны, если пара собственных значений имеет противо-
положные знаки, то, как видно из фиг. 3.2.3, квадратичная аппрок-
симация представляет собой седло, не имеющее локального миниму-
ма. В последнем случае вектор, определяемый уравнением (3.2.3)
[или (3.2.43)! и представляющий в смысле метода Ньютона наилуч-
шее направление поиска, будет направлен к седловой точке вместо
того, чтобы уходить от нее в направлении «вниз».

3.2.3. ПРИВЕДЕНИЕ МАТРИЦЫ ГЕССЕ
К ПОЛОЖИТЕЛЬНО ОПРЕДЕЛЕННОМУ ВИДУ

Некоторые авторы предложили дополнительные преобразования,
делающие матрицу Гессе положительно определенной на каждом
этапе минимизации. Гринштадт [71 построил схему на основе ана-
лиза собственных значений, которая обеспечивает положительную

определенность приближения “. Пусть матрица Н (х) аппрокси-
мирует Н (х). Масштабируем матрицу Н (х) следующим образом:

и (х) = с*1 (х) !? (х) с—‘ (х), (3.2.8)

где С (х) — диагональная матрица, элементы которой равны си =
= (|пдд\)'/‘‚ т. е. представляют собой положительные квадратные

корни из абсолютных значений элементов главной диагонали Н (х).
Тогда в матрице И все элементы главной диагонали либо положи-
тельны, либо отрицательны. Например, пусть

й[11
=14'
'югда
С_[10] с-1 1?
и “02’ =0—2—
[10]1110 1—2—
.[ ][ .]= .
07140? %1

Поскольку С" (х) и Н(х) неособенные и порядка и, то обратная
матрица к их произведению является произведением их обратных
матриц, взятых в обратном порядке, или

п—1 (х) = 0 (х) Е" (Х) С(х).

" Аппроксимадии. используемой вмесю Н’1 (х) в уравнениях (3.2.3) и
(З.2‹4а).— Прим. перев.
 pagebreak 
96 Г лава 3

 

„
..1
ТогдаН можег быть вычислена по масштабированной матрице:

#1 (х) = с-‘ (Х) Ц“1 (х) с" (х). (3.2.9)

В своей работе Гринштадт указал, что [Г'1 (х) можно выразить
через собственные значения щ и собственные векторы матрицы
Ц (Х). Собственные векторы матрицы, обратной к данной, равны
собственным векторам исходной матрицы, а собственные значения
обратной матрицы — прост обратные величины собственных зна-

чений исходной матрицы (мг)). Таким образом,
1 п 1 Т
11— (Х) =2ш` едем
“=]

где еірнормированный собственный вектор, соответствующий соб-
ственному значению сид. Затем вместо ТГ' (х) в формуле (3.2.9) ис-

пользуется П" (х):

71
п—‘ ‹х› =; | от че?

(где любое и, = 0 заменяется малой положительной величиной), так

что теперь обеспечена положительная определенность Н" (х)
при вычислении ее по формуле

гг‘ (х) = г' (х) й-‘ (х) с—' (х). (3.2.10)

В качестве простого примера предположим, что матрица Н:

1 2 __
=[ ; Н 1 не является положительно определенной.

щ; тн; тн; ги; г]-

ВЫЧИСЛИМ
Собственными значениями П являктя @, = --1 и а, = 3, и соот—
вегствующие нормированные собственные векторы имеют вид

1 _х_
1/5 1/5
 pagebreak 
Метады минимизации, использующие производные 97

Следовательно,
1 х 1

П—' 1 1/5 1/5 1/2 +
_ —1 к о 0
№
-'— о _ __ _
! УЁ 1/5 5
+? _ 1 0 о 0
УЁ
Затем вместо П" возьмем
1

„41750 _ё_'5
П=‘_—!1

ТО 0 О
]
ё
!

__ о _ __
1
+‘Т, ___ 0 0 0
1/2

и после подстановки [Г' в уравнение (3.2.10) новая матрица НЧ
становится положительно определенной:

_2_1_
_ 33
1
Т=1і'
Тэ

Заметим, что здесь любое собственное значение, абсолютная вели-
чина которого меньше, 104, заменяется на 10".

Маркуардт [8], Левенберг [9] и Голдфилд, Квондт и Тротер [10]
предложили другую вычислительную схему для обеспечения поло-
жителъной определенности приближения матрицы Н" (х):

Г!“ (х) = С" ‹х› (11 (х) + тг“ с“ (х) = @ ‹х› + № (х))". (3.2.11)

где Б—положителъная константа, такая, что В> _тіп [а]}.
Так как собственными значениями (Ц (Х) + Ы) являются (г:, +
+ В), то уравнение (3.2.11) обеспечивает положительную определен-

ность Н“1 (х), поскольку использование подходящего значения В
в формуле (3.2.11) в сущноггги «уничтожает» отрицательные и малые
собственные значения матрицы, аппроксимирующей матрицу Гессе.
Заметим, что при достаточно большом В произведение Ы может
 pagebreak 
98 Глава :

 

 

‹подавитъ» Ц (Х), и тогда процесс минимизации приблизится к поис-
ку методом наискорейшего спуска.

Зварт [11] предложил третий путь обеспечения положительной
определенности для приближения Н (х). Основным шагом является
нахождение унитарной вещественной матрицы 0, такой, что после

применения преобразования х = Их получается диагональная
матрица Гессе целевой функции

Я"… о

Е(х‹н›)=и7н(хш)и= : Е ‚ (3.2.12)

0 и,…

Этот шаг соответствует повороту осей на фиг. 3.2.2. Для построения
унитарной матрицы |.! необходимо определить собственные значе-

ния и собственные функции Н (х…). Затем, если какиечлибо эле-

менты на диагонали матрицы Н (х…) оказываются отрицательными
или малыми, то они заменяются некоторой малой положительной

величиной‚ что приводит к модифицированной матрице Н“ (х…).
Таким образом, в процессе поиска направление, соответствующее
собственному значению, имеющему не тот знак, который нужен,
_не рассматривается, и, кроме того, на выбор направления поиска
не оказывают доминирующего влияния никакие слишком малые соб-
ственные значения. Наконец, направление поиска находится с по—
мощью следующего соотношения:

50» = _ й * (хип) 7; №). (3.2.13)

Метод Ньютона имеет очевидное преимущество, заключающееся
в квадратичной сходимости в окрестности минимума целевой функ-
ции (если Н (х) > 0 и целевую функцию можно достаточно хорошо
аппроксимировать квадратичной функцией), т. е. как раз там, где
особенно проявляются слабые стороны методов наискорейшего
спуска. Наоборот, в области, далекой от минимума, методы наиско-
рейшего спуска могут оказаться лучше. Отсюда можно сделать
вывод, что подходящая комбинация метода наискорейшего спуска
и метода Ньютона должна оказаться эффективнее каждою из них
в отдельности. Такие комбинированные процедуры излагаются
в разд. 3.4.

33. СОПРЯЖЕННОСТЬ И СОПРЯЖЕННЫЕ
НАПРАВЛЕНИЯ

Как будет видно ниже, квадратичная целевая функция п неза-
висимых переменных, имеющая минимум, может быть минимизиро-
вана за !: шагов (или менее), если шаги предпринимаются в так
называемых сопряженных направлениях. Хотя используемые в ре—
 pagebreak 
Методы минимизации, использующие производные 99

 

альных задачах схемы оптимизации, оказывающиеся эффективными
для квадратичных целевых функций, иногда могут плохо
работать (и в общем случае основанный на этом подход не даст
сопряженных направлений поиска) при более сложных целе-
вых функциях, тем не менее этот подход представляется вполне ра—
зумным. Прежде чем описывать какие-либо алгоритмы, следует
сначала определить и проиллюстрировать свойство сопряженности.
В этом разделе предполагается, если это не оговаривается особо,
что целевая функция квадратична и имеет вид

і(х)= а+ЬТх+ %ХТНХ,

где н — положительно определенная матрица.

3.3.1 . СОПРЯЖЕННОСТЬ

Предположим, что процесс минимизации [(х) начинается в х…)

‚_
с начальным направлением з…), выбранным произвольно или по
какому-либо определенному правилу. Для удобства возьмем его

в виде единичного вектора, т. е. (‚ЗОЖ Б"” = 1. Тогда вектор
х… будет равен

х… = х‹0› + №31», (3.3.1)
где длина шага №1 определяется из условия минимума і(х<°>+
+А3“>) по 7», как это следует из уравнения (3.1.4):

(0) ^(0) ^ ^ ^
№ = 0 = ттг №) &‘” + ‹э‹°>›’\72г (кш») №.

Таким образом,

№ : __ ___—УТ" (“(№№ (3.3 2)
(207); 72, “(“))/БШ! . '

После того как по формулам (3.1.1) и (3.2.2) вычислен х…, для
продолжения процесса минимизации [(х) должно быть выбрано

^ !
новое направление. ЭРО новое направление 5( ) называется сопря-

^ ^ 1 т 0 ^ о
женным к старому направлениюзш’‚еспи(з“) [7’;‘ (х‘ ’)]5"=0.
Вобщем случае система плинейно независимых направлений поиска
в…), з…, ..., 8‘”"" называется сопряженной по отношению кнеко-
торой положительно определенной (квадратной) матрице 0 [12].
если

(М авт =. 0. 0 ‹ іэьі < и _ 1. (3.3.3)
 pagebreak 
100 Г лава 8

 

(Мы предполагаем, что 0 —невырожденная матрица.) Примером

0 может служить матрица Гессе целевой функции Н,
Сопряженность — понятие, аналогичное ортогональности; дей-

ствительно, когда Н = 1, то в соответствии с уравнением (3.3.3)

(5…)т $… = 0. Заметим далее, что с точки зрения топологических
характеристик Квадратичной функции, обсуждавшихся в предыду—
щем разделе, если целевая функция преобразована к каноническому
виду, скажем, [(х) = дии? + бих; = ТНх, ю собственные зна-

чения 1/._. Н находятся на диагонали Н:

й: 5119].
0 1)“

Таким образом, сопряженность можно интерпретировать как ор-
тогональность в пространстве преобразованных координат, если
направления поиска масштабированы подходящими функциями
собственных значений. В новых координатах имеем

(;…)Т н 5… = [711 53!) 3‘1’) + Ева 5930 :

 

 

“!)“(д “итд … ..
5$ 51 52 52 “1 т”
= __„ +———… = (в") з‘” = 0,
дм ди

где

… “(о ‚., ”(ц

… ‹ 5] „ . 8

5$”= 1/7 и @= 27. .

Ь22 УЬ11

ПОСКОЛЬКУ сопряженные направления линейно независимы,

то любой вектор \! в пространстве Е" можно выразить через в…),

з…, следующим образом:
п—1

\] = 2 у(і)5‹д, (33.4)
.=0
Где ,
(8…)7 Н 00 "

№7 н (х) в… '

Для некоторой матрицы Н всегда существует по крайней мере
одна система из п взаимно сопряженных направлений, так как сами
собственные векторы Н представляют собой такую систему.

В дальнейшем при использовании сопряженных направлений
потребуется следующее соотношение для квадратичной функции:

п—1

_] _ 5“) (:…)Т
н _ ‚;]—___“…„М . (3.3.421)

„(11 =:
 pagebreak 
Методы минимизации, использующие лроизводнш 101

 

Чтобы убедиться в его справедливости, рассмотрим матрицу

п—1

2 ар…(з‘Щт, Умножение ее справа на Нздд дает
1=о

гь—1
[ 20 Ос15т(5ш)т]Нз“г› = %ыыыдунзщ : зщ
‚=

если положить щ = “заду н5…]—1_

Таким образом, соотношение (3.3.43) доказано.
Приведенный ниже числовой пример поможет уяснить понятие
сопряженности.

Пример 3.3.1. Сопряженные направления

В качестве примера выбора и построения сопряженных направ-
лений рассмотрим следующую задачу:

минимизировать [(х) = х? —|- х; — 4,
начиная из точки х… = [4 417. Поскольку [(х) ‹: самою начала
представляет собой квадратичное выражение, нет необходимости
ее аппроксимировать. Потребуются следующие матрицы и векторы:

х1—х*‘т]

х2 — ху”

(х — х…) = [

2х
ті (х) = Ь}
нооатпх) =[Ё ;]

Вектор х") вычисляется по формуле х… = Хюэ + мешом

х‘,“ „(Р) №, 350) 4 №) ’;;ш
‚420 = "' ^‚‹о› = 4 + ;© '
2 2

Х?”
В качестве 5‘0’ можно выбрать любое направление, например на-
правление градиента, но в иллюстративных целях мы выберем про-

извольное направление

 

 

^(Ф
5 _

1
Т
—!/3
Т
 pagebreak 
Глава 3

 

[02

Заметим, что

таккак ]
[‘ УЁ]{Т—]=1.

1
[в 8][ 1/23 _|
№) : _ __2.__[__ =_5‚4в
1 1/5 7
[Т —][3 °}[_ }
Тогда
майа) [—2’73]
: —4‚74
и
1,27
"… = —074 '

Следующее направление минимизации з… выбирается сопряжен‹
ным к в…, исполъзуя уравнение (3.3.3) при 0 = Н:

1
А 2
Ы" 55”][0 ці? 1/3 ]= 0.
2

Необходимо еще одно добавочное уравнение (нормировки)

^ ;…
Ы" 5…1[^ 591: 1.

Из этих уравнений имеем

^ …
зі‘>+1/33<‚“=о А ————2—
, так что 5… = _

№ч№ъ1
 pagebreak 
Методы минимизации, использующие производные 103

 

_ 1/2 =_ (а)»!о;
5,45 ‚5,2 ] л :

 

Затем из уравнгния, аналогичного (3.3.2), вычисляется длина
(1)
шага А :

__5

[2,54—1‚48] 12
Т

_ = , 7,

_1/3 14
Г

[231=[_з:3ц+… — :…

На фиг. П.З.3.1 изображена траектория поиска. В этом конкретном
случае целевая функция сферическая; таким образом, направленИя
поиска не только сопряжены, но и ортогональны.
 pagebreak 
104 Г лава 3

 

‚.
Можно показать, что векторы з…, построенные как сопряжен—

ные направления, линейно независимы в смысле, наложенном
в разд. 2.1. Единственный возможный дополнительный вектор,

. ^ а

котрыи взаимно сопряжен со всеми п направлениями &‘ ’,
^ _: „ . „

…, з‘" ›, __ нулевои. Таким образом, изложенныи выше пример

иллюстрирует общее правило, заключающееся в том, что если
используются сопряженные направления, то любая квадратичная
футщия п переменном, имеющая минимум, может быть миними-
зирована ва п шагов, по одному в каждом из сопряженных направ-
лений. Более того, порядок использования этих направлений несу—
ществен.

Это правило для сопряженных направлений можно доказать
следующим образом. Запишем цеЛевую функцию в виде Г(х)=

= а —|- хТЬ + _,}хТНщ при этом 7)‘ (х) = Ь + Нх и в точке миниму-

ма Г (Х), где 71‘ (х*) = 0, х* = — н—'ь. Следует также заметить, что
из коммутативности скалярного произведения

7% №)?!” = @т’ \7)‘ ……)

(что можно получить и непосредственным перемножением элементов).
На п-м шаге в результате применения формул (3.1.1) и (3.3.2) имеем

‚1—1

х‹п› = ха» + 2 ;„‹ы^8‹ь›_
&=!)

На каждом шаге мы минимизируем ”Х“” + №0”) в направлении вт),
чтобы получить №1, что приводит к выражению

п—і ^
х…) : ха» _.. 2 (№) 3”). (3.3.52)

А Т А
‚.::; (5…) на")
Крометого,

(Ё…)Ти‘ (х…) = №№ (№№ + Ь) =
: (Зт›)’{н [хюг + ЁЁ №№] + ь} =
!=!
: (’;…)Т {НХМ _|_ |,},

^ Т ‚\
так как все произведения (8…) Нэт обращатся в нуль вследствие
того, что векторы 5 сопряжены. Таким образом,
п—і

№7 (их“! + №№

х… : ха» _. ^
й=о №“ и?”)

. (3.3.56)
 pagebreak 
Методы минимизации, использующие производные 105

 

По аналогии с формулой (3.3.4) выразим векторы х‘°’ и Н—1Ь че-

рез систему сопряженных векторов …:

п—1 ‚. ^
ХФ) = 2 №51 Нхю’ &‘”
„=0 (;(/:>)7н3ш
п—і А 1 ^
и Н_‘Ь : 2 (5…) Н (Н“Ь) вые)
Ь=0 (Ё…)1Н Ё…
Подстановка этих выражений 5 (3.3.56) дает
№ = _ н—‘ь. (3.3.6)

Таким образом, точка х" (результат п-го шага) совпадает с миниму-
мом [(х).

Г оворят, что некоторый метод обладает свойством квадратичного
окончания, если применение его гарантирует достижение минимума
квадратичной целевой функции за точно определенное число шагов.
В случае методов сопряженных градиентов требуется 11 шагов,
тогда как, например, в методе Ньютона —только один шаг`

Покажем далее, что для сопряженных направлений (или просто
линейно независимых направлений, что в этом случае одно и то же),
если каждый раз і (х) минимизируется в сопряженном направлении
5 в соответствии с формулой (3.1.4), то [(зч’)’ 7і(х”’)| = 0,
0 < і < 1— 1, при использовжии не более „ направлений. Мы
уже видели ранее в разд. 3.1, что для квадратичной функции

1 ‹п
7і(Х")=Ь+Нх .
Следовательно,
1—1 1—1
‚ .
71°(х0) : ь + "(Х“!Ъ + 2 ‚“!/1503): Ь _|_ НХ… _|_ Н 2 311/150),
‚=]; 1—1;
где к“” — произвольная точка, из которой начинается поиск в со-
пряженных направлениях. Поскольку

7105”) = ь + Нх‘”,

ТО
1—1

71° ‹х‘”) = 71° №) + ;; №№.
‚=

ь_ т
Умножение этого уравнения слева на (5( ") дает
1—1

(&‘—"Ы ‹х‘”) = (5"‘_")Т\71(х0") + 23°“ (&‘—"7 из….
‚=

Первый член в правой части раВен нулю, поскоашку, как было
показано в подразд. 3.1.1, градиент в данной точке орюгонален
 pagebreak 
106 Г лава 3

предыдущему направлению поиска,.если точка получается в резуль-
тате минимизации функции в этом направлении. Кроме того, все
члены в сумме исчезают вследствие сопряженности. Таким образом,

(802—151 7)“ (х…) = 0, и поскольку приведенные выше рассуждения
справедливы для любого индекса [г, изменяющегося от 1 до [‚ 'ю

(з…)Ти‘ (х…) = 0. 0 < 1 < 1 — 1. (3.3.7)

: .
Определим теперь матрицу Х” размерности п Х в, в которой
каждый элемент представляет собой

х‹і+1› __ х‘” 3 Ах… : №301,
Х‘” ___ [(х‘" _ х‹0›) (кш _ х…) _ _ _ (ха: _ ‚((г—п)] :

=[АЯЩАЁ“...АХЦ_Щ

или _
’(Ах‹о›)т ” ‚_‹0›(;‹0›)’
‹1 т ‹1›^‹1›’
(ХЩ)Т= (АХ)) # И (5 ) _
(Ах(і—1›)Т „5—1) (#.—157
_ (п)^(6 (01% <°›^ (› _
А 311 %%»...Ъ 551)
(№… (М… (№,
: Я, 3, 1 Х 52 . . . А 3$“)
(5—1 " - . _ ^
] ’*'" №029… ж‘і—“зЁ—н

В соответтвии с уравнением (3.3.7) имеем
(№№и@%=ц і<л_ъ ззы
Возьмем далее еще одну матрицу размерности п >< і:
6‘“ = № ‹х‘”) _ ті №» (\7і №) — 71° ‹х‘”» . . .

… › (ЧГ (Х…) ““Чі (#.—"))] : [АЁЩАЕЩ _ _ . Аги—пъ

где Ая‘і’ауі (х…Ц’) —7]°(х…). Из выражения для градиента
‚‘(х) следует

И®=И№Мщт№№—№ы (Мы

и если положить х = х…“, то

71°(х“‹+") _ \7/ (х…) = 72]; (х…) (ханы, __ х…) Е Н (””Ъ“”). (3.3.10)
 pagebreak 
Методы минимизации, использующие производные 107

 

Тогда на основании (3.3.8) имеем

 

(Х“ЪТ [\71‘(Х"+")—\71(Х"`)| = 0 (3.3.11)
или
(6 »Чх‘НП—хт : о, 0 < і < ; < „_ 1, (3.3.12)
если шаги А…ЁШ’, ”"Е",... осуществляются в сопряженных на-
правлениях.

После изложения некоторых важных свойств сопряженности
можно перейти к рассмотрению алгоритмов минимизации Нх),
использующих сопряженные направления.

3.3‚2 МЕТОД СОПРЯЖЕННОГО ГРАДИЕНТА

В методе сопряженного градиента Флетчера — Ривса [13| строится

последовательность направлений поиска 5, являющихся линейными
комбинациями — \71‘ (х…), текущего направления наискорейшего
спуска, и з…), …, {’“—", предыдущих направлений поиска, причем
весовые коэффициенты выбираются так, чтобы сделать направления
поиска сопряженными. Упомянутые веса такие, что для вычисления

НОВОГО направления поиска В точке х(іг) ИСПОЛЬЗУЮТСЯ ТОЛЬКО теку—

щий градиент и предпоследний градиент. Эта идея заимствована
из метода решения систем линейных уравнений, предложенного
Хестенсом и Штифлем [14], а также Бекменом [15].
Изложим существо идеи. Пусть исходным направлением поиска
.
будет 510) = — \7Г (х…). Затем положим х… — хю’ = ?» (0)5(0) и построим
(] (1 (0)
8’=—71°(Х’)+ш18 ‚
где (в] ——скалярный вес, который выбирается так, чтобы сделать

8… и зю’ сопряженными по отношению к Н:

(з““КНз‘” = 0. (3.3.13)

Чтобы исключить (50357 из уравнения (3.3.13), воспользуемся урав-
нением (33.10) и заметим, что для квадратичной функции Н = НТ

(5‹а›)т _ (х… —х(°)›т _ [71 №) — 7г‹х(°>птн—‘
_ ;: (0) _ ‚: (0) '
Следовательно,

17Г(х…)— 71° ‹х‘°*›1' [— 71 ‹х‘”) + №11 = а.
Вследствие изложенных в подразд. 3.3.1 свойств все перекрестные
члены исчезают, так что
И №) с; ‹х‘”)

“‘ = 771 №) г; №) '
 pagebreak 
108 Г лана 3

 

Направление поисиа 5‘2’ представляется в виде линейной ком-
бинации —- 7і(х‘2’), 5… и за“, причем так, чтобы оно было сопря—

жено с $…. Распространяя эти выкладки на в…, з…, ...(детали пре-

"%
510

2,5

2,0

‹.“, ’ 0 1552
1299

”55

10/6

-/‚5 —!.0 "" 1,0 !‚5 «,

Ф и г. 3,3.1. Траектория поиска минимума функции Розепброка ме-юдом Флет-
чера — Ривса (числа указывают номер ШЗГЗ, Т. е. последовательные направления
поиска).

образований мы вынуждены опустить, но они являются прямым
продолжением изложенного, если учесть, что ($(Ё’)17і(хш+”)=0
приводит к уТі(х‘*’)7і(х‘*+”)=0), получаем общее выражение
для ‹вд:

ЧТ, (х…) ЧГ „%)) (3314)
 pagebreak 
Методы минимизации, использующие производные 109

 

Все весовые множители, предшествующие (ой, а именно (и,…, ‹щ_2‚…,
оказываются нулями, что представляется весьма тонким и инте-
ресным результатом.

Ниже приводятся операции этого алгоритма:

0
1. В х‘ ’ вычисляется
(0)
5 _

7 — 71° (х
2. На іг-м Шаге с помощью одномерного поиска в направлении
находится минимум {( (.х) Это определяет точку х‹й+1)_

3 Вычисляются [ один) и 71° (хит…

4. Направление 502+” определяется из соотношения

т ‹»+1› ш+п
‹!г+1› : __ ((+!) (и 7 :‘(х )7/(х )
5 “ (х ) + 5 Тг №) 71° №)

После („ + 10)-й итерации( (!г —— п) процедура циклически повторяется

с заменой х‘0 ’ на х(”+”,

5. Алгоритм заканчивается, когда |}5""Н<э, где э—произволь-
ная константа.

Прежде всею заметим, что здесь не требуется обратимость
матрицы. Другим преимуществом этого алгоритма является то,
что программа требует довольно ограниченной памяти ЭВМ по
сравнению с (п >< п)- матрицами разд 3.4. На фиг. 3.3.1 изобра-
жена траектория минимизации для функции Розенброка. Оценива—
ние алгоритма Флетчера—Ривса для некоторых тестовых задач
проведено в гл. 5.

(°))

8…

3.3.8, ПАРТАН-МЕТОДЫ

В работе Ша, Бюлера и Кемпторна [16] описаны несколько ал-
горитмов, использующих сопряженные направления (общий партан-
метод) и сопряженные градиенты (партан-метод наискорейшего
спуска, модифицированный партан-метод). Рабочую программу для
этих методов можно получить в фирме Е1ес’сгопіс Аззосіа’сез 1пс.‚
Ртіпсе’соп, М. ]. Партан представляет собой сокращение от терми-
на рагаПеі {апгеп’сз (параллельные касательные). На фиг. 3.3.2
проиллюстрирована сущность этой процедуры для случая квадра-
тичной функции двух независимых переменных. Р! и Р2 — любые
две точки плоскости (1:1, ха). Сначала движемся из Р2 параллельно
касательной к линии уровня в Р1 до тех пор, пока не будет достиг-
нут минимум ‚‘ (х) в некоторой точке РЗ. При этом оказывается, что
касательные в Р1 и Р}, параллельны, а минимум [(х) находится
на линии, проходящей через точки Р1 и

В этом методе используется тот факт, что параллельность линий
сохраняется при общем аффинном (т. е. по существу каноническом)
 pagebreak 
110 Глава 3

 

преобразовании пространства независимых переменных, так что
на некоторые аспекты поиска минимума не будет влиять масштаб со-
ответствующих переменных. Часть процедуры основана на методе
акселерации, разработанном Форситом и Моцкиным [171 для ис-
пользования его в алгоритме наискорейшего подъема.

Общий партан-алгорипш по сУщесгву заклюкгаегся в следующем

(фиг. 3.3.3). Пусть х…), х…, х‘3’‚ …— последовательность векто—

Касательная л: линии уровня а };

 

@

1
Ф и г. 3.3.2. Метод параллельных касательных (партан-метод) в двумерном случае.

ров х в Е", пд _плоскость, касательная к линии уровня і(х)
в точке х…. Каждый шаг делаегся в направлении минимума [ (х).
Из точки хан) (пронумерованной так для симметрии) нужно двигать-
ся вдоль ломаной Линии х…) х”) х… х… …, на продолжении

которой х‘т—“х‘т’ точка х…) представляет собой точку минимума.

?
Начальное направление Х‘ЩХШ ПРОИЗВОЛЬНО', направление Х…

3 .
х" произвольно, но параллельно ло; затем берется х… колли—

неарно х‘о’ и х…. Повторяя пр0цедуру для іг = 2,3, …, проводится
х‘гюхю’н’” параллельно по, п„ пд, …, пдд, а ‚((%-Н) берется кол-
линеарно ‚((и—2,“ х‘щ'). В работе Ша, Бюлера и Кемпторна пока-
зано, что если [(х) — квадратичная п-мерная функиия‚ имеющая
единственный минимум, т. е. положительно определенная квадра-
тичная форма или ее монотонная функиия, то общий партан—алгоритм
приводит к минимуму в точке ха") или ранее. Таким образом, этот
метод обладает свойством квадратичного окончания.

Направления, полученные с помощью общего партан-алгоритма,

являются сопряженными, что можно показать для случая квадра-
„ 1
тичной целевая функции (Г (х) =Т хТНх) п независимых перемен—

ных. Действительно, градиент [(х) равен 7} (х) = Нх. Поскольку

2
путь оптимизации из х‘°’ проходит вдоль вектора (хип —х”)
 pagebreak 
Производите
направление

   
  

ш…

Лалшлмцв,
@) прошедшим, на
:" параллвлшое

Л… "::/‚4
Ф и г. 3.33 Общий партан-алгоритм.

_ дт
-› -› -› наиукареи-
шии слуги:

—— -— итерационный
лцртш—лттлу

Ф и г 3.3.4. Сравнение траекторий метода наискорейшего спуска, итерационного
ииодиізипированного партан-ие'юда.
 pagebreak 
112 Глава 3

 

(фиг. 3. 3.4), пока не будет достигнут минимум [ (х)( точка ха )), век-

‹2
ТО? ‹х‹0›_ х…) параллелен щ, касательной плоскости в х)
(0)—

Кроме того, ветр (х х…) перпендикулярен градиенту [(х)
в точке х…, 7} (,да) = Нхш. Следовательно,

(ХШ) _ #2517; (х…) = (хан __ х‹я›)тнх‹2› : 0,0
п’і №) ‹х‘°’ — х“) = №№ № — к“”) =
так что (х‘°›)тНх ‹2›_ _.(х‘2‘)ТНх‘2’ Продолжая построение, получаем

(х(0))Тнх(2)= (Х(2›) Т=НХЩ (Х…)ТНХЩ _ . . = (Х‹%))Тнх(2› :
: (хш’)7Нх‘°’— (х‹2›)тнхш›_ (х1°›)т Нк…—
= _ . _ _ _(х(2))Тнх(2іг)
В общем случае все эти величины равны (х‘і’ЪТНхШ‘). Кроме того,
из построения требуется, чтобы вектор (х… х…) (фиг. 3.3.4) был

параллелен д… или

(2 (3 Т (0
(Х )—Х )) УПК ))=0
АНЗЛОГИЧНЫЙ анализ ПРИБОДИТ К
хш/ънхещ : хшпнхтен)’

]=0, 1, ...,/г—1, /г=1‚2‚ ...‚п—1.

Особый интерес представляют следующие разности:
(х‹ь+2))Тнх‹2п) _ (х(й‚)-2»Тнх(2п—2› : 0,

(хпе')ТНх(2"' —— (х…)ТНх(2”_г) : 0.
Вычитание вюрого уравнения из первою дает
(х‹1г+?›_ ‚((/г»?“ (хан) __ ‚((эт—2» : (). (3_3_ 15)
У авнение 3.3.15 показывает, что нап авления х‘2’—-х‹°’ ‚ х…—
? р

ХШ), . вплоть до (х(2"’—х‹2""2’) взаимно сопряжены.

В партан-методе наискорейшего спуска направления, произволь—

ные в общем партан—методе, выбираются следующим образом.

2,2
В точках к“”, х… х“’‚... х( )нужно двигаться в ниправлении от-

рицательного градиента. Этот подход согласуется со случаем, когда
)* (х) квадратична и при определении первых производных не имеют
места ошибки. При этом партан-метод наискорейшего спуска имеет
конеЧНую сходимость. Следовательно. в выборе некоторых направ—
лений уже отсутствует произвольноеть, и процедура становится
инвариантной относительно поворота осей, т. е. преобразований
вида у = Цх, где В — ортоюнальная матрица. Тем не менее выбор
масштаба в партан-методе наискорейшего спуска оказывает влия-
ние на промежуточные шаги.
 pagebreak 
Методы минимизации, использующие производные 113

 

Ниже приводятся операции алгоритма итерационного партам-
Метода:

1. Определяется направление отрицательного градиента (наис-

корейший спуск) в точке к"”.

2. Определяется точка минимума х(2 'функции НХ) вдоль

направления отрицательного градиента из х [”.
3. Определяется направление отрицательною градиента в точке

Х“).

4 Определяется точка минимума х‘3 ) функции { (х) вдоль отри-
цательного градиента из х…

5. Точки х…) и х“) соединяются прямой, вдоль которой опре‹

деляется местонахождение минимума і (х); эта точка обозначается

через х….
…

6. Процедура повторяется с начальной точюй х` .
Если задача содержит п переменных, то следует проделать п
градиентных шагов, а затем соединить х‘°’ с х‘”+". Показанные
на фиг. 3.3.4 шаги из к“” в х…

, из х… в к“", из х… в хб) и из х…
в Х… (не показан) являются шагами в направлении наискорейшего
спуска.

Итерационный партан-метод оказался значительно менее эффек—
тивным по сравнению с модифицированным партан-методом, ко-
торый начинаеТся пятью первыми шагами итерационного партан—ме-
тода, & затем продолжается следующим образом (для случая двух
пер еменных) :

6’. Находится направление отрицательного градиента в точке

х….

7. Определяется точка минимума х‘Б’ функции ‚‘ (х) вдоль на-
правления отрицательною градиента.

0 … и
8. Точки х") и х‘з) соединяются прямои, вдоль которои опре-

деляется местонахождение МИНИМУМЭ; эта точка обозначается че-

рез хи»

9‚ Шаг 6’ повторяется с использованием точки, определенной

на шаге 8, вместо х…. В киждом цикле в точках х“…‚іг =2, З,. ...

..., ИСПОЛЬЗуеТСЯ направление НИИСКОРеЙШеГО спуска, а на шаге

_?
акселерации точки х‘2 ’ соединяются с х(2'°+1’.Эффективность

партан-алгоритма оценивается В ГЛ. 5.

33.4, МЕТОД ЗАУТЕНДАЙКА (МЕТОД ПРОЕКЦИЙ)

Заутендайк [18] предложил алгоритм, использующий сопряжен-
ные направления, получеННЫе с помощью проектирующей матрицы.
Хотя проектируЮЩИе матрицы описываются в разд. 6.3, можно прИ—
вести здесь Основные шаги этого алгоритма:
 pagebreak 
114 Глава ‚3

1. Начать 5 Х…) и положить проектирующую матрицу Р‘о’ = |.
2. Для іг-го шага проектирующая матрица вычисляется следу-
ющим образом:

Рад : ' __ 002) [(6(Ёі)760=)]—‘ (0(Ё))Т =
: ',(Ё—Ц _ р(Ё—1)АЕ(Ь) [(А8&))Тр(іг—ЦАЕ(Ё)1—] (АЕПЦ) Раг—і)‘ (3 з 16)

3. Если Р‘Ё’унхшбаьо, положить 5…= —-—Р"”7і(х“”) и мини-

!
мизировать [(2х) в направлении 5‘ '; точка минимума х‘Н’" По—
вторить шаг .После того как пройденоп направлений поиска, на—

чать снова (: шага 1 при х‹°’= х.…
4. Если Р‘ ’7і(х““)_ — 0 и 7] хаки“): 0, закончить поиск.

5. Боди Р“” 7і(х"°’)=0. а 7і(х“");ь0, снова начать с шага 1,
положив х…): х.…

Так как после проведения п итераций Р‘“’= 0, то должен быть
начат новый цикл итераций. Поскольку первым направлением
поиска при повторном цикле является направление наискорейшего
спуска, можно показать [19], что этот алгоритм минимизирует
квадратичную функцию, имеющую положительно определенную
матрицу Г ессе, не более чем за п этапов. Полезно сравнить уравнение
(3.3.16) с (3.4.11).

3.35. МНОГОПАРАМЕТРИЧЕСКИП ПОИСК

В работе Миля и Кентрелла [201 предложен метод поиска, ос-
нованный на использовании двух подбираемых параметров для мини-
мизации [(х) в каждом из направлений поиска. В этом алгоритме
последовательность шагов определяется формулой

хиг-Н) : х(7г›___ А'БМУі (Х…) + ж,?)Ахш—Ц (3317)

На каждом шаге целевая функция НХ… —7ь„7і(х…)+ж1Ах"°"’)
минимизируется как по 7»… так и по ?… а затем вычисляется Х‘
по формуле (3.3.17). При этом можно показать, что 7„і(х‘ ’) ><
Х 7; (х(’г+1))_= О 7 ті(Х(Ь+”)) Ах(*+1›= О и УТ; (ХФ +1!) Ах(й)__ ____ 0

На первом шаге Ах“— ":(), а к“” должно бьггь задано. На
11—м шаге:
1. Выъшсляются х“ Дудко“) и Ах‘*_ ":х‘1— кид).

2. Пользуясь одним из эффективных способов двумерного поис—
ка типа описанных в этой и следующей главе, находятся с требуе-

мой точностью №3“) и М’”.
 pagebreak 
Методы минимизации, использующие производные 115

 

3. По уравнению (3.3.17) Вычисляют хщ'” и переходят к п. 1.

4. Каждый (п + 1)—й шаг начинается с Ах‘д`1’= 0.

5. Процесс заканчивается, когда |Аі(х)|<е.

Для квадратичной функции приведенный выше алгоритм совпа-
дает с алгоритмом Флетчера—Ривса, однако он требует большею

10

. Ф-птччп- Риос
5 о Мило —Кгтре.лл

 

0 5 70 15 20 25 30
Число шага!

Ф и г. 3.3.5. Адгоритм Миля и Кентрелла двухпа аМетрического поиска в случае
функции \11 из табл. .2.1.

времени, так как на каждом Шаге проводится двумерный поиск.
В случае неквадратичных функций при использовъхнии алгоритма
Флетчера—Ривса выбираетсявсущности на каждом шаге наилуч-
шее значение параметра ?… при постоянном отношении ММО, тогда
как алгоритм Миля и Кентрелла оптимизирует как 7»… так и 2,1.
На фиг. 8.3.5 приведены результаты проведенного Милем и Кент-
реллом сравнения их алгоритма с разновидностью метода Ньютона
для двумерного поиска при оптимизации целевой ф нкции \]1 из
табл. 5.2.1. Значения времени реализации алгоритмов идя — Кент-
релла и Флетчера—Ривса на ЭВМ Барроуз Б 5500 составляли
8,8 и 11,9 с соответственно.

Крэгг и Леви [21] распространили метод двухпараметрического
поиска на случай большего числа параметров, когда на каждом
шаге осуществляется поиск более высокой размерности с целью
получения значений параметров, минимизирующих {(х) в данном
 pagebreak 
116 Глава 3

№

Таблица 8.3.1

Сравнение алгоритмов многопараметрической оптимизации
при уменьшении /(х) до 10—15 [21]

 

 

 

 

 

 

 

Функция 1 ‘) Функция 1/1 1) Функция Х 1)
М Раздел данной _ —_
КП Ги, Г Е
тд описиан ие’т‘од ‚жж ::?) 31101311 ‚2%, 3233 время?)
Градиеитный 3.1 Неудачен для решения задачи
Флетчера — Рима 3.3.2 29 1,2 29 2,4 68 14,0
Давидова — Флет-
чера — Пауэлла 3.4.2 21 1,1 39 4,5 30 6,7
Миля — Кентрелла
(двухпараметри-
ческий) 3) 33.5 2 0,6 18 2,0 32 12,8
Крэгга — Леви (че-
тырехпараметри-
ческий)" 3_3_5 2 0,6 4 1,4 7 5,0
Ньютона, неишрав- Сходнтся :(
день",“; 33 в … неотималь- 25 1,6
ной стацио-
нарной
Ньютона, неправ. точке
ленный 3.2 21 0,3 39 1,5 25 1.6

1) Си. табл. 5.2.1.
2›Бремя в секундах на ЭВМ Барроуз Б 5500.

3) Использует метпд Ньютона, модифицированный так, чтобы матрица Гессе была положи‹
тельно определенной при оптимизации параметров ?…

" В СЛУчае функции Розенброка (Функпия 1) применялись только два параметра.

 

направлении. Каждый следующий вектор х вычисляется по формуле

’” ‚
‚(“+” : ‚№ _ №7; №) + 2, ж}*>Ах“—" (3.3.18)

!=!

при т<п— 1. На начальных шагах алгоритма неизвестные

Ах… можно положить равными нулю. В табл. 3.3.1 проводится
сравнение некоторых алгоритмов с алгоритмом Крэгга —— Леви,
в котором для проведения (т + 1)-мерного поиска ?» был использо-
ван модифицированный метод Ньютона. Тот факт, что для поиска
был использован метод Ньютона, безусловйо, способствовал боль-
шей эффективности соответствующих алгор итмов. В работе, к сожале-
нию, не приводятся данные о количестве потребовавшихся вычислений
целевой функции.
 pagebreak 
Методы минимизации, использующие производные 117

 

3.4. МЕТОДЫ ПЕРЕМЕННОИ МЕТРИКИ

Существует класс методов, называемых методами переменной
метрики 1), квазиньютоновскими или градиентными с большим
шагом, которые аппроксимируют матрицу Г ессе или обратную к ней,
но используют для этого только первые производные. В большинстве
этих методов применяются сопряженные Направления, хогя в не-
которых это не делается. При использовании методов переменной
метрики новый вектор ›‹ вычисляется по вектору предыдущего шага
с помощью уравнения, аналогичного уравнениям (3.1.3) и (3.2.4а):

хт+1ъ : Хаг) + ““З“" : х… _ ‚: (ю "] (Хао) …: (х…), (34…)

где матрица ц Ы,”), которую иногда называют матрицей направле-
ний, представляет собой аппроксимацию Н_1 (х). В уравнениях
разд. 3.1 11 (х…) является единичной матрицей, а в разд. 3.2 тих…)
представляет собой матрицу, обратную матрице Гессе целевой
функции Н" (х). Однако при использовании Н“1 (х) необходимо
было точно вычислять вторые частные производные [ (х) и обра-
щать матрицу Н (х), тогда как в метОдах переменной метрики для
вычисления 11 (х…) используются различные соотношения, не тре—
бующие ни того, ни другого.

Вспомним полезное соотношение (3.3.10), связывающее хи…) и

х…, для случая квадратичной целевой фуниции (или квадратичной
аппроксимации целевой функции)

и“ ад””) — тк“) = н №) №” — к“”)- ‹з.4_2а›
Умножая обе части этого уравнения на Н_‘(х‘й'ъ получаем
№" — х"” = н—‘ №) № №“) — ті (хтл. (3.4.26)

12
При этом если [(х) квадратична, тоН(х‘ ') = Н, т. е. постояннзя
матрица. Уравнение (3.4.26) можно рассматривать как систему п
линейных уравнений, содержащих п неизвестных параметров, ко-

торые нужно оценить для того, чтобы аппроксимировать Н_'(х)
или Н (х) при заданных значениях [ (х), 71° (х) и Ах на более ран-
них этапах поиска. Для решения этих линейных уравнений могут
быть использованы различные методы, каждый из которых приводит
к различным методам переменной метрики.

В довольно большой группе методов Н"(х"'+") аппрокси-
мируется с помощью информации. полученной на іг-м шаге:

н-‘ №“) = ши“” = ‹» № + №), (3.4.з›

" В более строгом смысле понятие «переменная метрика» относИтся лишь к
тем методам, в которых делается преобразование независимых переменных, чтобы
промасштабировать их более равномерным образом, но мы не будем употреблять
этот термин в таком смысле.
 pagebreak 
НЗ Глава .?

 

где ц —— матрица, аппроксимирующая Н“1 (х). (Аргумент х матрицы
1. опущен в целях экономии места; таким образом, верхний индекс

». ..
в записи 11 будет обозначать шаг.) Ац‘ ’ представляет собОи опре-
деляемую матрицу, а 0) -— масштабный множитель, константа, обыч—

но равная единице. Выбор Ап… по существу определяет метод пе—

.. »;
ременнои метрики. Для обеспечения сходимости ощ‘ +“ должна
быть положительно определенной и удовлетворять уравнению

(3.4.26) в том случае, когда она заменяет Н".

На (13+ 1)-м шаге мы знаем к““, ИМ“), 71°(Х‘Н`1’) и Ы” и хо-
тим вычислить “(*/+1), так чтобы удовлетворялось соотношение

ЦММЕФ’ = %А <*>. (3.4.25)

Пусть А “" = п‘НЦ—пш. Тогла уравнение
мтв… : % Ах“) _ ““ВАЗ“” (3.4.20

нужно разрешить относительно Ап…. Прямой подстановкой ре—
зультата можно показать, что уравнение (3.4.2г) имеет следующее
решение:

\ (Ь) Т и:) (Ь) т
М У Щ (3.4.4)

где у и 2 — произвольные векторы размерности п >< 1. Если для
‹» = 1 выбирается специальная линейная комбинация двух направ-

лений Ах… и ц…Аящ‚ а именно
У : 1 : АХЩ _ “(1013201

10 используем алгоритм Бройдена (описанный в разд. 3.4.1); ес-
ли же берется

_ (’?) __ (") (Ю
у—Ах‚ 1—ти Аг,

;:
то матрицу п‘ +” вычисляем с помощью алгоритма Дэвидона —— Флет-
чера—Пауэлла (описанного вразд. 3.4.2). Поскольку у и 1 _— про—
извольные векторы, то оказываются допустимыми и др угие воз—

можности, которые будут рассмотрены в последующих разделах.
Если шаги Ах… определяются последовательно путем минимиза-
ции {(х) в направлении 5“), то все меюды, с помощью кот013Ых

вычисляюг симметрическую ‚матрицу “”"…» удовлетворяющую
(3.4.2в)‚ даюгг направления, являющиеся взаимно сопряженными
(в случае квадратичной целевой функции).
 pagebreak 
Мегады минимизации, использующие производные 119

 

3.4,1. СЛУЧАИ. КОГДА Ап… ИМЕЕТ РАНГ ]

Бройден [22] описьшая методы решения систем линейных урав—
нений, показал, что если Ап… оказывается симметрической маггри—
цей ранга 1 и должно удовлетворяться соотношение т|‹”+”АЕ…=
= Ах“), то единственным возможным выбором Ат]… является

№№) — п“) (№51 {(№№ — ц“) (№)?
[(Ахш) _ “(#) (АЕЩЛТ (Авиа)

где в целях экономии места мы положили
іг
(Ахав) : ‚« +11 _ Хаг),

‹Ае‘”) = \7/ №") — и ‹х‘”).

В простейшем алгоритме ЭТОГО туша минимизация начинается

с выбора начальной точки х‘°’ и некоторого “(в) > 0; затем после-
довательно применяются уравнения (3 4.1) (3.4.3) и (3.4 5) до тех
пор. пока, скажем, [[ 71“ (х ›) “ < в. Если для каждого направления
поиска ?» ’ представляет собой скаляр, минимизирующий {(х)
в этом направлении, то данный меюд дает сопряженные направле
ния поиска. Таким образом, при определенных ограничиВающих
условиях описанному алгоритму обеспечена сходимость. В частном
случае, когда целевая функция п независимых переменных квадра—
тична, так что несингулярная матрица Гессе Н является постоянной,
то можно доказать, что после п шагов п… = Н". если пю’ > 0,
если п‘н'“ вьшисляется из уравнений (3.4.3) и (3.4.5), если х'Н'”
вычисляется из уравнения (3.4.1) и, Наконец, если (Ах…) являются
линейно независимыми направлениями. Одной из интересных осо-
бенностей методов ранга ] является то, что 7» (или %*) в уравнении
(3.4.1) не обязательно должно быть параметром минимизирующим
‚* (_х). Бройден показал, что 7» может быть произвольным параметром,
пока не возникла сингулярность ц или знаменатель в правой части
уравнения (3. 4. 5) не обратился в нуль. Это свойство позволяет отка-
заться от одномерного поиска если можно найти адекватный альтер-
нативный метод определения ?ъ (см. разд. 3.4.5). В работе Голдфар—
ба [23] приводятся теоремы, детализирующие доотаточиые условия
сходимости алгоритмов ранга 1. Следует отметить, что излагаемые
в данном разделе методы не требуют обращения матриц.

В случае, когда целевая функция не является квадратичной,
применение уравнения (8.4.5) может привести к следующим нежела-
тельным явлениям:

]. Матрица ц может перестать быть положительно определен-
ной. В этом случае необходимо обеспечить положительную

Аці’” = (3.4.5)
 pagebreak 
120 Глава 3

 

“%+“

определенность МаТрИЦЫ \] С ПОМОЩЬЮ ОДНОГО ИЗ МЕТОДОВ,

отмеченных в разд. 3.2`

2. Вычисляемая величина Ач… может стать неограниченной
(иногда даже в случае квадратичных функций вследствие ошибок
округления).

3. Если Ах“) = —7\‚"’°’т|(х…)7і(х…) случайно совпадает с на-
правлением предыдущего этапа, матрица и(х‘Н”) становится син-
гулярной или неопределенной. В алгоритме Бройдена это тоже будет
иметь место, если в процессе определения направления поиска
по уравнению (3.4.1) либо уравнение

Ч…АЁЮ : Ахо»,
либо уравнение

(ч‘Ё’АЁМ _ Ах…)тАгщ = 0

приводит и

““+” : Ч…, Т. е. к Ап“) = 0.

На фиг. 3.4.1 изображены траектории поиска минимума функции
Розенброка по алгоритму Бройдена с помощью одномерного по—
иска ДСК—Пауэлла. Следует обратить внимание на то, что большой
начальный шаг (шаг вдоль отрицательного градиента) в одномерном
поиске приводит к прескакиванию левой части изогнутого оврага,
тогда как при малом начальном шаге минимизация проходит пол—
ностью вдоль оврага. Машинная программа алгоритма Бройдена
приводится в п иложении Б

Дэвидон [24 предложил по существу ту же схему вычисления
Ап“), что и уравнение (3.4.5), за исключением того, что Ач… ум-
ножается на некоторую функцию двух параметров для того, чтобы

ограничить изменение 11… на каждом шаге, с тем чтобы Ат]…
не было «слишком большим», и сохранить положительную определен-

іг
ность п‘ +1). В этом алгоритме принимается А‘“ = 1. Если после

вычисления “(!:/и) Оказывается, что Нх‘н'“) > ‚‘ (х…), то на сле-

дующей итерации хи“… заменяется на х“). Хотя здесь не испо-
льзуется одномерный поиск, хороший выбор %* и упомянутых двух
параметров оказывает значительное влияние на эффективность ал-
горитма. В работе Пауэлла [25] приводится дополнительный список
работ, в которых предлагается использовать уравнение (3.4.5)
или его эквивалент.

Муртаг и Сарджент [26] показали, что одно из условт'дх сходи-
мости к стационарной точке заключается в том, что норма "]… дол-
жна быть ограничена и сверху, и снизу. Что касается нижней
границы, то можно избежать прямого вычисления нормы матрицы,

ИСПОЛЬЗУЯ более сильное условие ПО отношению к уже вычислен—
 pagebreak 
Методы минимизации, использующие производные 121

 

"`: .
д.0

2,5

 

Ф и г. 3.4.1. Траекто ии поиска при минимизации функции Розенброка ‹: помощью
алгоритма Бройдена числа обозначают этапы, т. е. различные направления поиска).

__ большой начальный шаг в выбранном направлении поиска; в _- ‚ дыни на-
чмьньш шаг в выбранном направлении поиска

ным векторам:

№№; (№ \\
п 7! а"”… > 9“

где рд (здесь и ниже) —— константы. Другое условие сходимости за-
ключатся в ограничении угла между направлением поиска и на-
правлением наискорейшего спуска так, чтобы функция {(х)

уменьшмась при А‘“ > О (конечно, при п“) > 0)”:
| \71 их"") №77 (№ | › рв \\ 71° №) \\ \\ п""пі ‹х""› и.

" Напомним, что у авто а "” > 0 означает положительн но он еделенность
Р У Р
матрицы. — Прим. перев.
 pagebreak 
122 Глава 3

 

В случае, если эти, а также еще несколько менее значительных
условий удовлетворены, можно выбрать 73 таким, что

их“» —-і ‹х'*+"› > „г “№ №) «1% ‹х“*’›—

Основываясь на этих концепциях, Муртаг и Сарджент предложи-
ли следующий алгоритм.

На іг—м этапе:

1. Положить А"”) = 1.

2. Сделать шаг, используя уравнение (3.4.1).

3. Если “ 71° (х‘ь’) [| < и, продолжить одномерный поиск мини-
мума.

4. Провести проверку (тест) выполнения неравенства

их"") — і ‹х‘Н'б > рзж‘ ‘*’УТі №) п‘” ті №) >о.
Если это неравенство не удовлетворяется, исключить один шаг
из одномерного поиска и вернуться к п. 2. Если одномерный поиск
сходится, но тест не удовлетворяется, уменьшить № в 2 раза и вер—
нуться к п. 2
При одномерном поиске считается, что сходимость имеет место,

когда либо 177] (х‘й+1’)Ах‘и|<щ‚ либо АЪ*1|т|®7/”(х"”)||<щ‚ где
[%*—изменение №.
5. Проверить выполнение условия %* > щ и

и №7; №) "
и и №) "

Увеличить масштаб ?:… и уменьшить масштаб п…, если- это
необходимо, чтобы выполнялись тесты 4 и 5.
6. Проверить, является ли все еще положительно определенной

матрица направлений. Если нет, задать заново п…; в противном
случае вычислить поправку для 11… с помощью формулы (3.4.5).
Задать заново матрицу направления можно, положив п…") =!
или пи”… = цш’.

> 91.

3.4.2. МЕТОД ДЭВИДОНА _ ФЛЕЪЧЕРА _— ПАУЭЛЛА

В хорошо известном методе Дэвидона [27], модифицированном
Флетчером и Пауэллом [28], выбирается матрица Ап, имеющая ранг 2.
Здесь также не нужна операция обращения матрицы. Матрица на-
правлений цперевычисляется таким образом, чтобы для квадратич-
ной целевой функции в пределе после :! шагов она равнялась

Н—і. Исходная матрица т] обычно выбирается в виде единичной мат-

рицы п… = ! (но можт` быть и любой симметрической положи-
тельно определенной матрицей), так что исходное направление ми-
 pagebreak 
Методы минимизации, использующие производные 123

 

нимиэации—это направление наискорейшего спуска. Оценка

элементов Н"1 в точке х‘ (экстремум). тем лучше, чем лучше

мы выберем по сравнению с единичной матрицей исходную ц…),

однако выбор "(В) = ! определенно предпочтительнее приравнива-

ния элементов тд…) значениям аналитических частных производных
или их конечно-разностных приближений в начальной точке х…).
В ходе оптимизации имеет место постепенный переход от градиент-
ного направления и ньюггоновскому; при зюм используются преиму-
щества каждого из этих двух методов на соответствующем этапе.
Доказательство сходимости данного алгоритма может быть приве›
дено только для случая квадратичной целевой функции с поло-
жительно определенной матрицей Гессе [смт формулу (3.4.691.

Соотношение для А1]… в алгоритме Дэвидона —— Флетчера —Па-
уэлла, как было отмечено ранее, можно получить путем подстанов-
ки

Уаз) : Ах“) и 20!) : “(ЮАЁЬ
в уравнение (3.4.4). Тогда имеем
"01+” = “(*) + Ааа) _ 80!) =

_ (‚0 (Акт) (№№)“ “(Ё) (Атт) (АЕ…)Т (“0:57
_ "] + (Ахат (№00) _ (Ад‘ЩТ “(ю (Аджи) ' (3'4'58)

где обозначения те же, что и в формуле (3.4.5). Следует отметить
что вторая и третья Матрицы в правой части (3.4.5а) являются.

СИМММРИЧЕСКИМИ, так ЧТО если матрица 11“) _СИММС'ГРИЧЁСКЗЯ‚

Ю И “]“—‚_!) будет симметрической.
Рекуррентное соотношение (3.4.53) на практике вполне удовлет-
ворительно, если:

1) ошибка при вычислении 7! (хш’) невелика;

2) 1]… не становится «плохой».
Роль матрицы А“” в формуле (3.4.53) заключается в обеспечении
того, чтобы 11 —› НЧ, тогда как матрица В“) обеспечивает поло-
жительную определенность “%+” на всех этапах и в пределе исклю-
чает начальную _матрицу ц…). Используем формулу (3.4.5а) на
нескольких этапах, начиная с ч…:

“… = ]+ А!“) _Вап,
пс?) : “… + А… _ В… = ] + (Ааа + А…) _ (вю; + В…),

......................-......

!:

‚“он-1) : |+ Ё А(і›__ ЕВФ-

{—^‹0 і=0
 pagebreak 
124 Глава 3

 

В случае квадратичной функцрш сумма матриц А”) должна рав-
няться Н_1 при !? = п _— 1, а сумма матриц В… строится так,
чтобы она сократилась с матрицей, выбранной в качестве исход-
ной матрицы “(о) (здесь единичной матрицей). Таким образом,
метод Дэвидона —— Флетчера — Пауэлла отражает до некоторой сге-
пени в текущем значении ц всю предыдущую информацию.

Следует отметить, что в случае квадратичной целевой функции
в алгоритме Дэвидона -— Флетчера —— Пауэлла используюгся
сопряженные направления. Для того чтобы последнее направление
в…") было сопряжено по отноШению ко всем предыдущим направле-
ниям, должно выполняться равенство

(х(п—|))7` н$(п—!) : 0

или при з‘""’ : —п‘"_" 7і(х"'_1’)

‹х‘"—")’ Нп‘"—" 71° (№") = 0, (3.4.6)
Где Х определяется в соответствпи с уравнением (3.3.8), Уравнение
(3.4.6) будет справедливо, если Но…“) =! или ““`” = Н”},

поскольку при этом оно сводится к уравнению (3.3.8). Таким обра-
зом, метод Дэвидона -— Флетчера —— Па уэлла можно отнести к катего-
рии мегодов, использующих сопряженные направления. В случае
общей целевой функции эффективность метода Дэвидона—Флет-
чера — Пауэлла является скорее следствием использования сопря—

женных направлений, чем близкой аппроксимации Н"1 мат-

рицей ц.

Зная теперь, что в случае квадратичной функции направления
п—і

поиска являются сопряженными, можно легко показать, что 2 А‘” =
і=0

=Н". Заметим, ЧТО из авнения 3.4.26 следует, чго А (”=
УР &
== НАх‘ю. При этом числитель и знаменатель А““ соответственно
гавны _ _
(АХ‘Ю) (АХ‘ЮУ : О“ (1?) 508) (?“ (к›8‹й›)т

и
(АХ…)Т Ага?) : 0: (,?) $…)Т (Ш' (И 800).
Следовательно,
л_| п—і ‚
… _ \ ‚(О “(:))Т __ _.
‘;“А _ 30№ .- н ‚ (3.4.7)

где правое равенство вытекает из уравнения (З.З.4а).
Хогя Дэвидон в данном направлении поиска использовал толь-

ко один шаг дЛИной АГ"", которая определяется с помощью куби-
 pagebreak 
Метады минимизации, использующие производные 125

 

ческой интерполяции между А‘“ = О и

(1?) _
А‘“: тіп{1‚ №}, (3.4.8)
71°(Х))'| 7/(х )
а {,.—наименьшее ожидаемое значение [(х), в большинстве ва-
риаций алгоритма ДЭВИДОНа функция минимизируется в каждом
выбранном направлении поиска. Для определения минимума
[(х) по ?» в данном Направлении можно применить почти любую
эффективную процедуру одномерного поиска (см. разд. 2.6). Очень
важно. чтобы агга процедура была эффективной, поскольку относи—
тельно большая часть всего времени вычисления приходится на
одномерный поиск.

Флетчер и Пауэлл предложили выбирать первую длину из после-
довательности %* с помощью уравнения (3.4.8) либо положить
А.“… = 1. В гл. 5 при оценке эффективности этого метода исполь-
зуются два хорошо известных различных способа одномерного по-
иска. В приложении Б содержатся их соответствующие машиннщ
программы.

Чувствительность метода Дэврщона —Флетчера—Пауэлла к
критерию окончания процесса в одномерном поиске оказалась мень-
шей, чем можно было ожидать, в отношении как времени оптимиза-
ции, так и числа вычислений функции. Например, в табл. 3.4.1
приведены число шагов, кодичество вычислений функции и значе-

ния функхши Розенброка, начиная с точки ха” = [—1,2 111. Из
таблицы ясно видно, что, хотя требуется значительно больше шагов,
если одномерный поиск проведен недостаточно точно, тем не менее
общее число вычислений функции и время, требуемое для минимиза-
ции функции Розенброка, приблизительно одинаковы для разной
точности одномерного поиска, хотя, пожалуй, цифры несколько
лучше в случае в = 104, чем для в = 104 или в = 10—5, где
8— критерий окончания одномерного поиска по отношению к

?»…” [уравнение (3.4.1)]:
;: (!!—Н) _ ;; (й)

,; (:?—+1) + ‚: <::) <&

 

 

Опыт показал, что в некоторых задачах нельзя достичь мини-
мума целевой функции с помощью методов переменной метрики,
если сгепень точности одномерного поиска недостаточна; поэтому
рекомендуется, чтобы точность одномерного поиска была по крайней
мере эквивалентна точности, требуемой для окончания основного
алгоритма. Цена этого в смысле времени и (или) числа вычислений
функции относительно невелика, тогда как Надежность любого из
этих методов значительно увеличИВается.

Флетчер и Пауэлл предложили, чтобы минимизация заканчива-

ішсь в точке, где при вычислении как вектора “110077 (х…), так и
 pagebreak 
126

Таблица 3.4. 1

Число вычислений функции Ровенброка : процессе ее минимизации
до значения 10"… при различных значениях критерия
окончания одномерного приш :

 

112104

“Ё"- п ‘) ` [ (х) 2) шаг 1.— п"
о 16 1.4.10—‘ 0 27
1 22 2,3.10—х 1 32
2 11 1,6.10'"' 2

3 16 1,5.10—1 з 25
4 15 1,5‚10—1 4 25
5 16 1.4.10—1 5 27
в 14 1,4.111—1 6 27
7 18 1.11.10—1 7 23
в 15 1,0.10—1 & 25
9 18 65.10“2 9 25
10 15 6,340“ 10 19
11 18 2,5.10—2 11 11
12 17 20.10—2

13 18 1.6.10—2

14 16 7,2.10—3

15 13 52104

16 17 4,110—4

17 13 1,6.10—4

18 16 6,6-10"6

19 6 15-111-6

20 9 7.6-10"°

21 1 1,210“…

 

 

24,

 

ю—з 2-10—5
; (х) ?) шаг !: п 1) , (:) ?)
1,9.111—1 о 36 1.9.1021
1,9. 10 -' 1 31 1,9.1о—‘
1,210“1 2 34 1,2.1о—'
8,2-10—2 з 34 7,6-10“2
4.3.10-2 4 35 42104
2.2.10"2 5 36 21.10—2
1,1.10—2 6 36 9,5.10—3
3,9 . 10—41 7 33 3,2 . 10“3
11,610—4 в 34 6.1.10“4
1,7.10—5 9 35 2,6- 111—5
2,0. 10—7 10 28 4,5— 10"7

8,8—

1) п— число вычислений функции иа однак пап.

2) Значение функции в конце шам.

10—11 11 9 4.6-10"п

 

Общее число вычислений функции

Относительное время

.… ‚

 

: = 10—1 в = 10—3 : =1о—5
320 290 380
1,14 1,00 1,12
 pagebreak 
127

   

   

Если Ьвашчцшшть Вычислить : … … ‚

7!(::“”) и лмажцть А…: А:: “ (‚А3 !
'г"’= ! (Ах › Ае

    

(К) (” Тт (*),?

Вт: ':Шда (А; )

(А9 )и (49 ›

      
      
 

    
 
  

     

длрврмить л*…пчт
милимщацииі [:в ‘”—
л*тг‘”\71‘(:с‘*’)]епо—
мпщью ЧНМ ”080
[шишка по &

 
 
 

(
?!#01)___?(Ы+ А(”—Б “

  
  
       
      

  
  

ДЕ“

   

::
’н-л‘“ ’ЧЮУПФШ)

      

Лтиритд, мтмляютш ли при
‚’в/‚...,п соотношения

    
  
  

 
  

{‹щ‘ш’ъгш‘Ч
Пт" )
(И

А:: ‹»

(2) ‘ ЖЖ или |А1‘д ред ,

(”
”‘;

 
 

:) ›г'‚ или …от! ›г, ,

если ?(:)*0;

      
     
   
   
   

дет ‚;(:іьп)_„шш)

 

если псд * 0

Ф и г. 3.4.2. Блок-схема метода Дэвидона —= Флетчера ‹— Пауэлла
 pagebreak 
128 Г лава 3

 

«тг
2,5
2,0
15
(о) 35
’ ю _ 15 67.
5“ а:"
]
5 1,5 30
10 12 5
16 25
15 гг
17 20 ‘
—1‚о ад 1,0 :,
Ь°
‘:
—цд / ‹\

Ф и г. 3.4.3. Траектории поиска при минимизации функции Розенброка ме'юдом
Давидова — Флетчера — Пауэлла (числа указывают номера шафи. т. е. различ-
ных направлений поиска).
Большой начальный шаг в выбранном направлении поиск., А' = 1: — — -— ма‹
лый начальный Шаг в выбранном направлении поиска, № = 10—3.

 

вектора -—-?м'®т|"°)7і(х®) выполнятся один из следующих двух
пунктов:

1. Каждая составляющая этих двух векторов меньше, чем
некоторая наперед заданная величина.

2. Вычисленная длина ( || П) каждого из этих векторов в
точке минимума меньше наперед заданной величины.

В гл. 5 при сравнении различных методов вместо этих показа-
телей успешно применены два других критерия окончания про-
цесса, приведенные на фиг. 3.4.2, где представлена блок—схема
метода Дэвидона — Флетчера — Пауэлла. На фиг. 3.4.3 приведены
 pagebreak 
Методы минимизации, иепользующиг производные 129

 

траектории алгоритма Дэвидона — Флетчера — Пауэлла для функ-
ции Розенброка при двух различных величинах начальных ша-
гов в одномерном поиске №“ = 1 и №“ = 10 _°3 эти траектории
совершенно аналогичны приведенным на фиг. 3. 4.1.

 

Пример 8.4.1. Метод дэвидона _ Флетчера _ Пауэлла

Проиллюстрируем применение метода Дэвидона —— Флетчера --
Пауэлла на примере следующей задачи:

минимизировать 4 (›:1 — 5)2 + (хе — 6)?

В СООТВЕТСТВИИ С ИЗЛОЖбН- “тг
ным выше алгоритмом исполь- 12
зуем следующее рекуррент-
НОЕ СООТНОШЭНИЭ:

Ле !: ’:
Х(И_1)=Х‹ )_^ж( )““)ЧКХК )), (а)
где 10

8 х —— 5)
7, (Хоа) : ( 1
2 (ха — 6)

(‚=)

  

и п задается уравнением д
(3.4.531).
Пусть 11° =! и началь-

7/2

___-—

ный вектор х…): [8 91Т.

гда новый вектор х” вычис- 5
ляется по формуле (а):

‚((!)
„@] = 4
8 „… ! 0 24 о 2 4 б в т,
= ——7ъ . Ф и г‹ П‹З.4.1. Траектория поиска алго-

9 О 1 6 ритма Дзвидона — Флетчера — Пауэлла.

Поскольку целевая функиия весьма проста, то для наглядности

можно определить ?» (° ’ путем минимизации ‚‘ (к" ’) по #, исполь-
зуя аналитические методы вместо процедуры поиска:

дх…) = 4 «8 — №) — 51% + [‹9 — бт) — ег, ”‘"—"‘”) =

117$
= 0 = 51 — 39073,

или ?„°‘°’=0,1307. Итак, на этом шаге х": [4.862 8,7,215]
а і(х)=4‚985, как показано на фиг. П.З.4.1. В точке х…

7; <::…) = [_ 1,108 4,4311’‚
 pagebreak 
ЮО Глава 3

так ЧТО
(Ад)‘°’ = 1— 25,108 _ 1,56917.

Затем ВЫчисляется п‘ 1):

—-— ЗАЗ 0] [_ 3,13 — 0,785]

1 0 { —
‹0 —0,185 0 0 0
" =[0 1]+ —25.108
[—з‚1з _0,7вз1[_1’569]

1 0 [—25‚108 (){—25,108 —1,569 [1 0
[0 1] _- 1,509 0] 0 0 ]0 1]
1 0 —25‚108`
[—25.|08 —1‚5691[0 1“__ 1,509]
1,270-10—1 —3,149.10-2
-з,149_10-2 1,0038

„.
Теперь сном по уравнению (а) можно вычислить х“

х?) 4,862 …) 1,270-10—' 3,149404 —1,1ов

хЁ _ 0,215 " —3‚149-104 1,0038 4,431 '
Как и ранее, А'… получается путем минимизации [(ха’) по
%*. Последующие шаги оптимизации сведены в табл. П.З.4.1а.

 

Таблица П.3.4‚1а

 

 

 

 

 

 

Шаг & #(!” ' *(Ё) , _тёіщ) ! _ашш) › №№) А’ (!:)
. 1
0 8,000 9,000 24,000 6,000 45,000 0,1307
1 4,862 8,215 —|,108 4,431 4,985 04942
2 5,000 6,000 301.104 2.55.1049 9,06-10—15 1,000
3 5,000 6,000 0 0 0
Таблица П.З.4.16
Шаг 0 Шаг |
[1 0] 1370104 —з,149-10—2
п 0 1 —з.149_10—2 1,0038
Швг 2 Шаг 3

 

[ 1350104 43824046 [ 1,250.10—1 1387-10—17
4082404“ 5,000—10*1 —1,387.10—‘7 5000-10"
 pagebreak 
Методы минимизации, испомшующие производные 13!

 

В табл. П.З.4.1б приведены величины элементов матрицы 1] на
каждом шаге поиска, которую можно сравнить с матрицей, обрат-

ной матрице Гессе Н““, в точке Ж“ = [5 61Т:

1
— 0
8
Н=[Ё ;] и НЧ: _
1
0 .д—

 

На практике оказалось, что в методе Дэвидона — Флетчера _
Пауэлла и других методах переменной метрики могут иногда встре-
чаться отрицательные шаги, или эти методы могут оканчиваться
в нестационарной точке. Бард [29] показал, что такое течение про—
цесса является следствием того, что матрица 1] становится сингу-
лярной. ЕсЛи матрица 1] становится почти сингулярной, ю направ-
ления поиска могут быть выбраны так, как в случае, если бы в
задаче были плохо выбраны масштабы переменных, несмотря на
то что на самом деле это не так._«Почти сингулярности» можно
избежать путем увеличения числа получаемых значащих цифр
при вычислениях или путем масштабирования элементов вектора

х с тем, чтобы сделать порядок диагональных элементов Аю’ бдиз—
ким к единице. Если же эти операции недопустимы, т. е. если

косинус угла межлу 7 НХ…) и 1]… 71° (х…) меньше, чем 10'5,
матрицу “ можно перезадать в виде диагональной матрицы, у кото-
рой элемент и„ представляет собой отношение і-го элемента Ах“)

к і-му элементу 7і(х…). Были предложены и другие методы,
в которых поиск начинается заново ‹: пересмотренной матрицей на-
правлений; несколько подобных примеров приведено в гл. 5.
Осталось рассмотрегь последний вопрос: может ли метод Дэви-
дона—Флетчера—Пауэлла успешно применяться в том слу—
чае, когда оценивание произведных осуществляется с помощью
разностных схем? Если да, то исчезнет неудобство, заключающееся
в необходимости получения аналитических формул для вычисления
производных, и процедура Дэвидона приблизится к методам,
не включающим вычисление производных (методам поиска). Здесь
следует обратить внимание на то, что ошибки округления и аппро—
ксимации при вычислениях могут сместить оценки производных
Стюарт [301 показал, как компоненты градиента можно оценить
с помощью отношений разностей, распространяя таким образом
метод Дэвидона на задачи нелинейного программирования (без
ограничений), в которых производные или вообще не могут быть
найдены аналитически, или это нельзя сделать достаточно легко.
Информация, получаемая в процессе минимизации, используется
для определения оптимального размера шага в разностных
 pagebreak 
132 Г лава 8

 

уравнениях. Хотя модифицированный метод Стюарта вычисления
приближенных значений производных очень эффективен в некото-
рых задачах, он иногда либо совсем не годится, либо приводит
к существенно большему числу вычислений функций для достиже-
ния той же степени точности. которая получается методом пере-

Таблица 3.4.2

Сравнение методов переменной метрики ", использующих разностные оценки
производных, : алгоритмом Пауэлла на примере пяти тестовых задач

(Приведенные числа представляют собой количество вычислений функции.)

 

 

 

 

 

Задача 2 Задача 29 Задача 32 Задача 34 Задача уд табл. 5
Метод (прнложе- (приложе- (приложе— (приложе- (приложение А)
ние А) нне А) ние А) ние А)
Пауэлла ?) 262 136 700 86 291
Дэвидона — Флет-
чера — Пауэлла
(а) 132 1625 305 218 702
(6) 12] 1123 205 231 Не приводит к ре-
шению
Бройдена
(8) 139 4336 167 230 1251
(5) 112 Не приводит :( ре- 176 Не приводит и ре-
шению шеиию

1) Включвющих одномерный поиск дСК›Пауэлла.
2) Ш гл. 4.

(д) и = 10—15. т = 10—13, & =1г7.

(61 „=- ю—И. т _ 10—14. 5:10—13.

 

меяной метрики, использующим аналитические выражения для
производных.

В табл. 3.4.2 сравниваются количества вычислений функпии для
алгоритма Пауэлла, одного из лучших алгоритмов, не использую-
щих производные, и алгоритмов Дэвидона —- Флетчера — Пауэлла и
Бройдена, в которых аналитические выражения производных заме-
нены оценками производных по методу Стюарта. В методе Стюарта
требуется, чтобы пользователем были заданы следующие три про-
извольных параметра:

,“ —- порядок значащих цифр, допускаемых ЭВМ;

т—— верхняя граница отрицательного логарифма отношения
ошибки текущей оценки производной к предыдущей оценке произ—
водной;

б — величина шага, который должен быть использован при
вычислении компонент первых двух градиентов.
 pagebreak 
Методы минимизации, использующие производные 133

 

Как 1]. так и т зависят от используемой вычислительной машины,
тоща как 6 связана с минимизируемой функцией. В табл. 3.4.2
приведены результаты для двух систем значений упомянутых
параметров. В нее не включены данные для алгоритмов Дэвидона ——
Флетчера —— Пауэлла и Бройдена, применяющих аналитические
производные (эти данные можно найти в гл. 5), поскольку
трудно решить, какой вес придавать трудоемкости операций по
вычислению производных относительно операций по вычислению
функций,

Результаты, полученные для случая изогнутого оврага (задача
34 из приложения А) и функции Розенброка (задача 2 из приложе-
ния А), отличаются от опубликошнных Стюартом, но это и не
удивитеЛЬно, поскольку использовались различные & и разные крите-
рии окончания процесса. Во всех задачах, кроме задачи 2, началь-

ный выбор 6 = Ю—7 давал оценки производных с малой началь-
ной ошибкой, но в последующем ошибка становилась существен-
ной. В одной задаче такая ошибка случайно уменьшила число
вычислений функции до Величины, меньшей, чем имеет место в ана-

литических процедурах. С другой стороны, при 6 = 10"13 полу—
чали большие начальные ошибки. Поскольку компоненты двух
начальных градиентов должны вычисляться на основе параметров,
задаваемых пользователем, не стоит рекомендовать методы Стюар-
та как более предпочтительные по сравнению с методами, исполь—
зующими аналитические производные, и, как видно из табл. 3.4.2,
метод Стюарта, как правило, не будет таким же эффективным, как
алгоритм Пауэлла.

3.4.3. АЛГОРИТМЫ ПИРСОНА

Пирсон [31 ] предложил несколько методов вычисления матрицы
1], использующих сопряженные направления поиска, Алгоритмы
Пирсона можно получить, задавая различным образом векторы
у и 2 в уравнении (3.4.4).

1. Апгоритм Пирсона № 2. Положимв уравнении (3.4.4) у =

= 2 = Ах“), а а) = 1. Тогда

(Ах… _‚цкю Агиа) (Ахив;

(Ё+‘)___ (Ё)
" `“ + (Ах‘*’>Т‹Ав“"›

0 0
п"=к“,

Где к‘щ—произвольная положительно определенная симметриче-
ская матрица. Алгоритм Пирсона № 2 обычно приводит к «плохим»
Матрицам направлений. Фиг. 3.4.4 иллюстрирует задачу 35 из

приложения А, для которой (начиная из х‘о’ = [2 0,2]Т при “(П) = !)

(3.4.9)
 pagebreak 
134 Глава 3

 

была получена следующая последовательность матриц направ-
лений:

 

Шаг ' Матрица направлении 1100 1 Определитель ци“)

 

  

0 1 0 100000
[0 ]]

1 0.216754 0.15788 0,12004
[0.991423 075250]

2 0,36636 0,15383 0,00831
[0,88737 039527]

3 0,35793 0,11330 000043
[085056 032020]

4 0,35576 0,12809 —0,00001
[0,85077 0,306331

 

Таким образом, через четыре шага матрица направлений пере—
стает быть положительно определенной и на последующих шагах
остается «плохой», колеблясь между положительно определенной
и не положительно определенной. Повторение начала алгоритма

через каждые п шагов (т. е. приравнивание ц‘и'” :( а"” после

каждых :: шагов) помогает избежать трудностей подобного рода,
2. Алгоритм Пирсона № 3. Положим в уравнении (3.4.4) у = 1 =

: „(»›АЕОг)’ & („= 1_

Тогда

„ 00 А (10 т
я“" = п‘” + №”) —— п‘ ’ (Аим)! №‚ 0.4.10)
‚"(с) : К“”.

Траектория поиска алгоритма Пирсона№ 3 при минимизации функ-
ции Розенброка по сушеству та же, что и изображенная на фиг.
34.13, за исключением того, что на каждом этапе делаются мень-
шие шаги. Пирсон исследовал также разновидность этого алгоритма
с циклическим перезаданием матрицы 1].

3. Проективный алгоритм Ньютона -— Рафсона. Пирсон пред-
ложил так называемый проективный алгоритм Ньютона —— Рафсо-
на (РМЦ), который может быть псшучен из уравнения (3.4.4) при

0) —› со и 2 = п…АЕЩ:

поем ___ ‹гг›__ (п… А5?) 51?” А8…”
Е ‹» '
(А! )'| (№ )
”(п) : “(о). (3.4.11)

Уравнение (3,4,11) аналогично алгоритму Заутендайка [описан—
 pagebreak 
Методы минимизации, использующие производные 135

 

“::

   
 

—/‚оа /

Ф и г. 3.4.4. Задача 35, приложение А.

ному в разд. 3.3.4], если проектирующую матрицу в уравнении
(3.3.12) заменить матрицей направлений п…. Величина п…АЕО”
является проекцией Ад”), ортогональной 6“), и на каждых ;:
шагах К… является аппроксимацией Н'1 (х…), так что в сущ—
ности осуществляется (приближенно) поиск Ныотона. Когда [и
кратно л, числу независимых переменных, матрица 110“ заменяется
на К…. Т°Гд3 ;» # №1 (и (ют
‹ге+1›_ ие) ‹АХ‘ —К"Ае ) (п ШЗ ) ‹
К _“ +№. (3.4.12)
Некоторые резулътаты, относящиеся к алгоритмам Пирсона,

Вклшчены в материалы по оцениванию алгоритмов, приведенные
в гл. 5.
 pagebreak 
136 Глава 3

3.4.4. ДРУГИЕ МЕТОДЫ УЛУЧШЕНИЯ НАПРАВЛЕНИИ

Г ринштадт [32] вывел общее соотношение для Ат] путем миними—
зации ‹: помощью множителей Лагранжа нормы Ап, определенной
следующим образом:

№ (Ап) = Тг №№ … ‹Ап‘”’›’1
(где “! —— положительно определенная симметрическая матрица)
при условиях
1) Ап ‘*’ всегда симметрическая: Ап“): (№№)“ ,
2) ц‘”+"Ад“"= Ах‘”, или имеет место его эквивалент— уравне-
ние (3. 4.23).
Полученное соотношение имеет вид

(ё)_ 1 (Ю ‹ют —|
А" —№{^х № > “ +

+ ш—іАЕОБ) (АХФ))Т _ П®А8№ (АЕ…)Т “_1 _

_1 (и идти 1 (тт (и)
“(АЕ (А8 )“ —№ПАЗ )АХ _“

_ ‹А9*">)Тц<"шд‹”ч “Г‘Ад‘” (Авт чг‘} . (3.4.13)

Гринштадт рассмотрел два варианта: “1" = п… и ‘У" = 1;
однако применение уравнения (3.4.13) 8 тестовых задачах в слу-
чае “’" = ! дало плохие результаты, тогла как ЧГ] = 1]… привело
к результатам, вполне сравнимым ‹: результатами, полученными
с помощью алгоритма Дэвидона — Флетчера — Пауэлла.

В работе Г олдфарба [33| указывается, что если положить “’" =

= “(и, ТО получается следующее уравнение"

1

Ап(1»_ _ (Ав‹ы)Тц‹ь'>Адш {Ахщ (АЕЙУПФ + ““МЕ“” (АХ…)Т _

(Аг…)ТАХ‘” “(и (ю (т) Т ца»
_[1 №…)”; (‚№… А; (А;) } (3.4.14)

Если же принять ЧГ‘ =‚юп‘*+`)
1
Апэйз— _ ———№‹„‚‚…… {— Ах”"(Ад(”’)Тц“° — №№ ‹Ах‘”>›Т +
А 0137 (ЮА (#)

+[1-1- ___—‘ “#1531: (Ё ]Ы” (Ах<’*’)Т}. (3.4.15)
Наконец. если взять …“ =ц“‘+"— = Ац‘*’,то получается урав-

нение (3.4.5) (даже если \?!" и не имеет обратной матрицы, по-
скольку АЦФ) в уравнении (3.4.5) имеет ранг 1). Аналогично :( уравъ
 pagebreak 
Методы минимизации, использующие производные 137

 

нению (3.4.5) приводит подстановка
“‚_1 = “… _ чад) два:) [Авшътчод
_(Адш›)'т'ч'‹ь› Ад… ’
Ах… (Акиф)?-
(АХЮУАЕЮ '
Уравнение (3.4.521) можно получить, положив

ш—і ___ “((д) _

ш—і : [(А2®)Т “…АЁЮГАЧЙ'Р" __ [(АЁ‘Ю)ТАХ(Ю],/.п(ю :
= “АЕОЗЭТ ч<Ё+0АЕЙі1—'/яп(’і+1) _ [(АЕО‘ЧТ "(Ё)! З’ЁЧ—‘Ьпид ___

: “(" +1) _ (Ад…)т Ахиг) ]Чя по:) АНО?) (моду ”® :
(АЕ(Ё))Т "(121 №03) (Аи…)т ““БМВ“?!

(д) (А8(Ё›)ТЦ(ЮАЕ® % Ахшцдхшцт
_ " _ _(Ад_‹и›)т „(&—› “(Адкюушиа '

Выражения (3.4.14) и (3.4.15) дают поправки к ц…, обеспечи-
вающие квадратичное окончание процесса для шучая строю вы—
пуклой квадратичной целевой функции, так же, как это имеет
место и при использовании формул (3.4.5) и (3.4.53). Тем не менее
только формулы (3.4.52) и (8.4.15) сохраняют положительную
определенность 1]. Г олдфарб показал, что каждое из уравнений
(3.4.5), (3.4.53), (3.4.14) и (3.4.15) может быть записано в виде
линейной комбинации остальных, и в частности

АШ = ?АЧ(3.4.5а) + (1 _ ’У) Атзлыу

Ади = ?”‘Ачшщ + (1 —У_‘) Шима,
где

(Акту Ах“)
? = (Ад(ю)т ЧЩ А2… '
Следовательно, в общем случае можно записать
Ап… : осАп‘і’д + (1 —ос) Атт). (3.4.16)

Выбирая различные ос, можно получить любое из полученных
!:
выше уравнений для Ап‘ ).

3.4.5. МЕТОД ФЛЕТЧЕРА

Во всех описанных выше процедурах минимизации после вы—
числения направления поиска целевая функция минимизируется
в этом направлении при помощи одномерного поиска. Поскольку
наибольшее количество вычислений приходится на операции
 pagebreak 
138 Г лава 3

 

одномерного поиска, естественно возникает вопрос, будут ли доста-
точны для решения задачи один или несколько шагов минимиза-
ции. Флетчер [34] предложил алгоритм, в котором отброшено усло-
вие квадратичного окончания процесса, т. е, окончания процесса
за п шагов в случае квадратичной целевой функции, но в то же
время сохранено свойство, состоящее в том, что для квадратичных
функций матрица направлений 11 —› Н'Ч (х) в том смысле, что со-
бственные значения 11 стремятся к собственным значениям Н'“'.

Заметим, что соотношение для Апш, крторое входит в уравнение

(3.4.3), основано именно на этом свойстве при условии выполнения
следующего равенства:
“(Ніщдип = Ах“), т. е. Агиа) : (“"‘“)ГШХ‘”.

Улучшающее соотношение Флетчера основано на рекуррент-
ном соотношении для обратных матриц

__ «» Ахив т _ ‚(‹/«› 0» т
№ 1——— № 1—1
АПФ) (А3…)Т
ТАТ“)? А2"… '
соотношении, которое приводит к равенству (№+‘>)"Ах“”= Ава”.
Поменяв 3 (3.4.17) местами Ахо” с А;… и “«+» с (“"‘“)Г', при-
ходим [( рекуррентной формуле

„… = [, _ Ах"*’‹Ая"°›’] „а»[д __ [№ (Ах…)Т] к“” (Ах…)Т .(3.4.18)

(3.4.17)

(Ах…)ТАд‘”) ‹Ах‹ь›)т№‹ь› (АхщуАдад
Описываемый алго итм использ ет соотношение 8.4.53 ‚ если
Р У

(АЗ…)ТЪГ' (хип) Авиа) < (Агат "]… А8…'
и (3.4.18), если

(А3"°’)ТН" (ход) АЦФ) > ( АЕ1/г))тт]0г) Ада).
МОжно также использовать линейные комбинации уравнений
(3.4.18) и (3.4.521). Из рассмотрения тестовых задач, описанных
в гл. 5, видно, что в большинстве случаев направления, получен-
ные на первых этапах оптимизации, основаны на уравнении (3.4.53),
& уравнение (3.4.18) применяется лишь на последних этапах. По-
скольку матрица п, вычисленная с помошью уравнения (3.4.53),
стремится к нулю с увеличением числа шагов, а п, вычисленная
с помощью соотношения (3.4.18), стремится к бесконечности, имеет
смысл применять оба типа уравнений. .

Тем не менее эффективной " процедуру Флетчера делает скорее

не метод вычисления п, а кубическая интерполяция при отыска-

1) Поиск ДСКЛауэлла с масштабированием (см, приложение Б) оказывается
не менее эффективным`
 pagebreak 
Методы минимизации, испальзующие производные 139

 

 

НИИ минимума В данном направлении И ограниченная длина шага.
При этом скаляр А выбирается с помощью уравнения, аналогичного
(3,4.8):
к _ 2 [г №) — ;…1
_— УТГ (ЖФ)) 502) ’

где і,… _ нижняя оценка значений [(х). (Если ‚‘(х) оказывается
ниже, чем {ни, то имеет место окончание процесса.) Для достиже-
ния минимума в направлении поиска используется кубическая

интерполяция на интервале между х… и х… + 7.15”). Поскольку
для проведения кубической интерполяции не требуется использо-
вание всего интервала, содержащего минимум, и результат интер-
поляции может„оказаться неудовлетворительным, если х… нахо-
дится на вогнутой части аппроксимирующего полинома, Флетчер
ограничил значение А, следующим образом: либо оно должно быть
меньше, чем значение №, получаемое с помощью кубической интер-
поляции, либо

#544) : 0,1„9'

где ВЕРХНИЙ индекс 5 обозначает номер В ПОСЛЗДОВЗТЁЛЬНОСТИ ШЗГОВ
ПРИ одномерном ПОИСКЕ.
После каждою шага ПРОВОДИТСЯ тест

‚ (х…) _, (‚{(Ё) _|_ ;„(51 Е(Ё))

_ № УТ; (х…) 50»
и если он удовлетворен, то этап считается завершенным. В против-
ном случае продолжается кубическая интерполяция. Окончательно

процесс завершается. когда Ахі < в = 104. Во избежание большого
влияния ошибок округления или ошибок программ вычисления про-
изводных программа останавливается, когда і(х"‘+")>і(х“") и
(Ах…)ТА9‘*+”<о и (или) (Ах®)ТА2ш>0.

Используя ряд тестовых задач, Флетчер сравнил приведенный
выше алгоритм с алгоритмом Дэвидона — Флетчера — Пауэлла
и показал, что он столь же эффективен, как и последний. При
этом оказалось, что число итераций в каждом направлении поиска
уменьшилось, однако для компенсации пришлось увеличить число
направлений поиска. В гл. 5 приводятся некоторые результаты
применения алгоритма Флетчера к другим тестовым задачам.

> 10",

3.4.6. АППРОКСИМАЦИЯ МАТРИЦЫ ГЕССЕ

Вместо аппроксимации Н_' (‚«и-л)), как это делается в ураВнении
(3.4.3). можно аппроксимировать матрицу Н(х"'+"), а затем по—
строить обратную к ней. Таким образом,

н №”) @ “"+" = г… + АГ“”, (3.4.19)
 pagebreak 
140 Г лава 3

 

где Г‘Ю—оценка Н(х"°), а матрица АГ“” —симметрическая матри-
ца ранга 1, такая, что РМГ“ удовлетворяет уравнению Г‘”"Ах® =
= А9“). При этом

АГ… : №№) — г<*>‹Ах"*>›1 №№) — Р“" (Ах…л’

№№) — Р“” (Ах"’>›1т их“") ' (3420)

Условия сходимости здесь те же, что и описаННЫе в подразд. 3.4.1.

Поскольку (Г(д+")"' может не быть положительно определенной,
следует использовать ограничительные предположения, сделанные
в разд. 3.2, для обеспечения положительной определенности. В из-
честве исходной Г… можно выбрать (цш’Г'.

Соотношение (3.4.20) аналогично (3.4.5), если иметь в виду, что
в случае квадратичной аппроксимации Ад… = НАХ… (здесь) и Ах… =
= Н`1АЕЩ (в подразд. 3.4.1). В принципе возможно записать выра—
жения для АГ“”, эквивалентные приведенным в подразд. 3.4.2—3.4.4‚
но сомнительно, будет ли при этом уменьшаться объем вычислений
при решении задачи оптимизации, поскольку обращение матрицы
должно будет производиться на каждом этапе.

Рассмотрим далее алгоритм Г олдштейна и Прайса [35], оказав-
шийся достаточно эффективным при решении ряда задач. Хотя
этот алгоритм и не попадает строго в категорию методов переменной
метрики, тем не менее здесь на каждом этапе проводится аппрокси-
мация Н (х) при помощи разностной схемы, основанной на полуфак-
ториальном построении, а затем осуществлятся обращение мат—

рицы. При этом для оценки Н (х…) требуется лишь Информация о
Дх…) и 7[(х“")‚ Голдштейн и Прайс утверждают, что данный
алгоритм минимизирует )* (х), если она представляет собой выпук-
лую целевую функиию, при условии выполнения некоторых срав-
нительно простых ограничений, На іг—м этапе алгоритм выглядит
следующим образом (величины 0 < 6 < 1/1 и г> 0 задаются
заранее):

Шаг 1. Вычисляется в качестве аппроксимации Н(х‘”’) матрица
Н(х`*’) размерности п >< п, і—й столбец которой определяется по
формуле

(іг) (# ’!
71°(х + в “;)—№06 »,

где
а“” : г|| ‹р (‚‘“—”и для ь > 0,
6…) = г,

1,- : 1—й столбец единичной матрицы ! размерности :: >< п.
 pagebreak 
Методы минимизации, использующие производные 141

 

ф (х…) — вектор-столбец, определяемый по формуле
‘ —7і(х"”), если &= 0 или Ё(х…)
сингулярна, или [Уті (х…)НЧ (х…) 7! (х…)] <О,

чих…) = '—1
так что Н не является положительно опреде-
ленной;

— Ё—1 (х…) 7)“ (х…) в противном случае.

Заметим, что Н(х“") не обязательно симметрическая матрица, и
если

%* №) …“ №) ті №1 < 0,

то предлагаемое направление поиска ср (х…) и направление гра-

диента 7/(х‘и) отличатся более чем на 90°. Поскольку поиск
проводится в ‹минус»-направлении‚ то отрицательный знак при
квадратичной форме приводит к компоненте в направлении поло-
жительного градиента.

Шаг 2. Вычисляется

„ Хаг) _ Хаг) ‚„ ‚((*)
Е(‚д ›, ‚‘): и )тп “)+ % » _
“7 ПХ ЛПХ )]

Выбирается №) та_к, чтобы 6 < Р (Х“), 1) или 6 < Р (х…, А““) < 1 —
—6, ””$ 1. Эти критерии нужны для того, чтобы не допускать
шагов поиска, которые далеко выходят за область линейного изме-
нения целевой фунтщии в окрестности х…, предполагавшуюся при
аппроксимации Н (х).

Шаг 3. Берется х‘н'” = х… +А‘*’‹р(х“”).

Шаг 4. Процесс заканчивается, когда Нф(х…)||<а.

Таким образом, если матрица Н (х…) сингулярна, или не при-
водит :( «направлению вниз», этот метод сводится к методу наиско—
рейшего спуска. Параметр ! следует выбирать так, чтобы матрица

Н (хщ) аипроксимировала Н (х…) как можно‘бЛИЖе. Величина б

выбирается так, чтобы значения ]“ (х‘й’), 1% = 1, 2, …, представляли
собой монотонно убывающую последовательность; чем ближе знв-
чение 6 к 1/2, тем в большей степени ]“ (х… -|— М) (Х…» прибли-
жается к своему минимуму по 7». Голдштейн и Прайс отметили, что
этот алгоритм по своей эффективнооти в отношении Необходимого
объема функциональных и градиентных вычислений при решении
задачи Розенброкгт эквивалентен алгоритму Дэвидона — Флет-
чера —Пауэлла. Для задач с плохо выбранными масштабами пе-
ременных он оказывается менее удовлетворителъным, посколь-
ку при этом фактически осуществляется движение по методу
 pagebreak 
142 Глава 3

наискорейшего спуска. Наиболее интересной чертой данного алго-
ритма является сравнительно малое число шагов одно мерного поис-
ка, приходящихся на каждое новое направление движения (зггап):
около одного—двух на этап. Некоторые результаты применения
этого алгоритма для решения тестовых задач приведены в гл. 5.

3.5. КРАТКИЙ ОБЗОР АЛГОРИТМОВ
ПРОГРАММИРОВАНИЯ БЕЗ ОГРАНИЧЕНИЙ

В этой главе были рассмотрены некоторые методы оптимизации
без ограничений. В табл. 3.5.1 приведены в виде сводки для основ-
ных алгоритмов рекуррентные соотношения, используемые для

вычисления 11 (х…) 5 11… или в…, входящее в соотношение
Ах… : хины) __ к"" : ‚дожи : _ жив)“ (х…) \7і (ха‹›)_

Ср авнение относительной ЭФФЕКТИВНОСТИ алгоритмов МЫ ОТЛОЖИЛИ ДО
ГЛ. 5.‚ так ЧТОбЫ методы поиска, описанные В ГЛ. 4, также МОГЛИ
быть ВКЛЮЧены В ЭТО сравнение.

ЗАДАЧИ 1)

8.1. Ответьте на следуюшие вопросы относительно метода наи-
скорейшего спуска:

&) Если целевая функция (без ограничений) плохо масштабиро-
вана, Каким будет Начальное развитие поиска: медленным или
быстрым? Каким будет движение вблизи экстремума быстрым или
медленным?

6) Если выбрано направление градиентного поиска в точке
х…, как нужно выбрать размер шага, чтобы достичь следующей
точки ха“)?

3.2 . Докажите, является ли метод нвискорейшего спуска методом,
использующим сопряженные направления при минимизации квад-
ратичной функции с положительно определенной матрицей Гессе.

3.3. Что является направлением наискорейшего спуска в точке

= [1 117 для целевой функции НХ) = х? + 2хЁ? Является ли
эта функция плохо масштабированной?

3.4. Определите вектор, представляющий собой направление
наискорейшего подъема в точке х = [1 Пт для целевой функции
в задачах 2.1а, 2.6а, 2.13, 2.32.

3.5. Проведите два шага оптимизации методом наискорейшего

спуски, начиная из х = [1 1 ]? для целевой функцииі (х) = х? + 2хЁ.

1) Дополнительные задачи. которые можно использовать при изучении этой
главы, можно найти в списке задач, помещенном в конце гл. 4.
 pagebreak 
Таблицл 3.5.1.
Методы нелинейного программирования без ограничений, использующие производные

 

 

Метод \ Раздел | Рекуррентиое спотиошение
Наискорейшъго спусха 3.1.1 Ы") : [
Ньютона 3.2 11”) №; (х…)Г": _ НЧ (х‘ю)
Гринштадта 3.2 11$)ісі\(х‘й›)1'1"с:1(хщ)
Маркуардта 3.2 г.… = 0'1 (х‘д’) (П?)— В!);ЗС'1Ё(Х‘Ё)) й)__ # & т
… ] ,; [Ах‘ АЁ )] [Ах‘ … ›АЕ( )]
Броидена, ранг 1 3.4,1 “(И— ): 1г'‹ ›+ №...
Дэвидонз—— Флетчера— “(;и—1) : Пфі” Ах… ___‹______АХ®)Т _П‘МАЕШ [П…АЁЫЪТ
Пауэлла 3.4‚2 Тщ—Ах(*))ТА3(Ы ‚[ (Агат “(ЁЪАЗШ
(‚”_ (*) ‹ ] (ИТ
;, [АХ '\ АБ ____1____(АХ )
Пирсона №2 з‚4.з „‹*+1›_ _ „‹ )+{————————_ (Ах(,„)‚№„д }
Пирсона №3 3 4 3 (іе+1]_(,г)+ [Ах‘щ— "“”АЕЩПЧЁАЗМК
. — '! —ч (Адан); „имт
Проективный Ньютона 3.4‚3
#) (Ю (‚д) (‚г) Т
Проекции Заутендайка “(#Н) ___ п‘*’— {№№}
(если 1» : 1.) 3.3.4 (Ае‘ ’) п‘ ’Ав‘ ’
Гринштадта и Г олдфарба 3.4.4 ц‘й+”= 11“) + уравнение (3.4.13)
Флетчера 3.4.5 1. ‚“+" = уравнение (3 4 18)
Ф р 3 3 2 (№» 7 из) ___—_____$®°Т/°(хш+”)‘7’ ("”+”)
летчера— иш . . з —— — НХ )+ ЧТ;(х(*›)7[(хш’)
(Ё) _ йОЭА 0?) [А (”а _ й‘Мх‘*‘1’
”(#—Н) и [^_Е___._х__1_3_______
Алпроксимацни Н(х) 3.4.6 Н —Н +{ ““и”—_ Й‘щАхЩгАхш

Применяется разностная схема для аппроксимации элементов Н ( к““) или используется
Голдштейиа и Прайса 3.4.6 зщ = —- 77 (х‘й’ )
 pagebreak 
144 Глава 3

 

СначаЛа используйте фиксированную величину шага. Затем мини-
мизируйте { (х) на каждом шаге Либо численно, либо аналитически.
3.6. Рассмотрите следующие целевые функции:

а) г‹х›=1+х1+х2+—„41—+%;
6) их) = ‹х. + 5›* + (и + 8›2+ (хз + 7? + №3 + №5

Будет ли метод Ньютонз сходиться для этих функций?
3.7. Рассмотрите минимизацию целевой функции

?(х) = х? + х,:с, — хЁхЁ

методом Ньютона, начиная из точки х…) = [1 ПТ. Машинная про-
грамма тщательно составленная для метода Ньютона, оказалась
неудачной. Объясните возможную причину (причины) неудачи.

3.8. Что является начальным направлением поиска по методу
Ньютона для задачи 3.3? Какова длина шага? Сколько понадо-
бится шагов (Направлений поиска) для решения задачи 3.17, для
решения задачи 3.37?

3.9. Объясните топологию следующих целевых функций, ис-
пользуя фиг. 3.2.2 и табл. 3.2.1:

&) 3х1 + 2хЁ;

б) 3 + 2х1 + 3х2 + 2х? + 21с1х2 + 6х5;
в) 3 + 2х1 — 3хв + 2х? + 2х1):2 + 616%;
г) 3х? — 4361262 + хЁ.

3.10. Аппроксимируйте целевую функцию из задачи 3.3411 с
помощью квадратичной функции. Интерпретируйте топологию
целевой функции, используя аппроксимирующую функцию.

3.11. Является ли матрица Гессе для Дх) = 5х12 +ЗхЁ +хЁ—
-— 2х13с2 всегда положительно определенной? Выясните то же для
2х? — хЁ —— х1х2.

3.12. Как можно аппроксимировать матрицу Гессе для функ-
ции {(х) = 2х? _ 2хЁ _ %% с помошью положительно определен-
ной матрицы (3) методом Гринштадта, (б) методом Маркуардта?

3.13. Что можно сказать о сходимости метода Ньютона, исходя
из рассмотрения матрицы Гессе целевой функции в задачах 3.346,
3,34д, 3.36?

3.14. Какие типы поверхностей предсгавлены следующими

выражениями (имеется в виду идассификгщия, представленная на
фиг. 3.2.3 и в табл. 3.2.1):

а) х? — х1хд + 3:3;
6) х? + 2% + хё;
в) 2х? + 2х3 + 8х3 — 4х1х2 + 12х1х3 + выд.?
 pagebreak 
Методы минимизации, использующие производные 145

 

 

3.15. Задана функция [(х) = х? —|— хЁ +2хЁ— х1х2; образуйте
систему сопряженных направлений. Проведите два этапа миними-
зации в сопряженных направлениях, минимизируя {(х) в каждом
направлении (т. е_ на каждом шаге). Изобразите траекторию поиска
и несколько линий уровня целевой функции.

3.16. При каких значениях х направления

___—___ |
3 ——=—
(1) у (2) 1/3
8 : Ё , 5 = __2? _
1 1/3
_1/3'_ _ ° _

являются сопряженными для функции ? (х) = х? + х1х2 + 16хЁ +
2
+ хз — х1х2хв?
8.17. Являются ли направления !?] и Н)] линейно независи—
мыми? Ортогональными? Сопряженными?
3.18. Возможно ли, чтобы ортогональные направления были
сопряженными направлениями? Объясните.

3.19. Покажите, что Направления поиска 5… = [0,453 ——0‚892]Т
и 5… = [0,608 —0,794]Т‚ используемые при минимизации функции
Розенброка {(х) = 100 (;&—ход}- (1— 1:1)2 в точке х = [—0,702
0,46217, сопряжены. _

3.20. Покажите, что выражение (3.3.14) является правильным

весовьпи множитыем для метода сопряженного градиента.
8.21. Дают ли одну и ту же последовательность направлений

поиска $…. $… и т. д. методы, использующие сопряженные направ-
(°)
и

ления и начинающиеся из одной и той же исходной точки х
с одним и тем же эш)? Ответьте да или нет и приведите простой пример
для объяснения ответа.

3.22. Сравните методы переменной метрики по трем показа-
телям:

а) значениям элементов матрицы направлений;

б) направлениям поиска;

в) векторам х
для выбранных вами задач по нескольким этапам, начинающимся
с одною и того же вектора х.

3.23. Для каждого из методов переменной метрики, приведен-
ных в разд. 3.4, укажите значения элементов матрицы направле—
ний на первых трех этапах поиска для задач З.З4г, 3.37, 3.40а.

3.24. Вычислите матрицу направлений с помощью выбранного
вами метода переменной метрики для одной из целевых функций,
приведенных в задаче 3.39.
 pagebreak 
146 Глава 3

 

3.25. Данв начальная матрица направлений п… = !; что пред-
ставляет собой т.… по алгоритму Дэвидона —Флетчера—Пауэлла‚
если {(х) : х12+2хЁ‚ а х… = [1 пт?

3.26. После начального поиска при минимизации функции
Розенброка матрица Направлений в точке х”): [1,441 2,0781Т
имела вид

„‚_ 1,544 . 10—1 3,467- кг1
—3,467. 104 8,578-10`1 '

Каково будет следующее направление поиска в выбранном Вами
методе?

3.27. После 13 этапов минимизации функции Розенброка машин-
ная программа остановилась в точке х =“ НТ. В этой точке гра-
диент в сущности ——нулевой вектор. Какова будет матрица направ-
лений в выбранных вами методе и задаче?

3.28. Использует ли алгоритм Голдштейна—Прайса сопря-
женные направления?

3.29..Выведите рекуррентное уравнение для вычисления мат-
рицы направлений с помощью (а) алгоритма Дэвидона—Флет-
чера—Ривса, б) алгоритмов Пирсона, в) алгоритма Бройдена,
если нужно максимизировать, а не минимизировать целевую функ-

цию.
3.30‚ Все алгоритмы гл. 3 выражены в виде задачи минимиза-

ции. Как простейшим способом использовать эти алгоритмы для
мжсимизации, а не Минимизации?

3.31. На седьмом этапе метода Дэвидона—Флетчера — Пауэл-
ла для случая функции Розенброка были получены следующие
значения:

[(х) = 0,19469; эс1 : 1,4409; ::2 = 20779;
ді (х)/д1с1 : —-0‚1455; 81° (‚()/дд : 0,3565; матрица направлений
0,1544 —0,3467
[_ 0,3467 0,8577] '
Каковы будут направления поиска на последуюших двух эта—

пах?
3.32. Целевая функция

{(х) = (1 + 8х1 —— 7хЁ + %х? _— —2— х?) (;&—*’)

является бимодальной и имеет седловую точку в х = [2 217, где
их) = .

Определите, какой из лохальных оптимумов является глобальным.
Проведите один этап поиска, начиная из седловой точки. Для облег-
 pagebreak 
Методы минимизации, использующие производные 147

 

чения решения проведите линии уровней функции Пк) на плоскости
(хм хз)-

8.38. Решите каждую из следующих систем уравнений путем
минимизации суммы квадратов разностей 2 (д, —— 0)”:

а) х1+313х1—х3=0‚
21сЁ——161х2-—51с1 + 1 =0;

5) х%+(х„—1)”—5=0‚
(х1—1)2+хЁ—1=0.

в) Систему 24 нелинейных уравнений с 24 переменными, пред-
ложенную Пэком и Суоном [36].

3.34. Минимизируйте следующие функции двух независимъпх
переменных:

&) %(1—с08360[(2х—1)2+(2у—1)*]Ч’}[1— ___(у—зт ];

в
б) у+5іпх;
В) —1(у——Х)*+‹1—Х)“;
Г) —х*+х——у2+у+4;

. 2_ ‚52
д)ехрг—‹х—1›*1—і…—22—’—.

3.35. Предприниматель может производить товар А ‹: затрата-
ми в 20 центов за фунт и товар В ‹: затратами в 10 центов за фунта
Служащие, занимающиеся вопросами сбыта, подагают, что фирма
может продавать 1 000 000/х2у фунтов товара А в день и 2 000 ООО/хуж
фунтов товара В в день, х — продажная цена А в центах за фунт,
а у — продажная цена В в центах за фунт, Определите максималь-
ную прибыль, если А и В продаются по одной и той же цене. Чему
равны в этом случае :: и у? Определите максиммьную прибыль,
если А и В продаются по разным ценам. Чему равны при этом
:: и у?

3.36. Ежеюдные расходы, связаННЫе с эксплуатацией газового
компрессора на трансконтинентальном газопроводе, выражаются

формулой
рі
_ каг Р р \
С—т(‘”ТЗ+д)+К‘°2[ 2‹з—'Ро +_4‹5+Рт ]'

 

где
С _ эксплуатационные расходы, долл/год;
О—количество накачиваемого газа, футвідень;
[. — расстояние между компрессорнымъі станциями, мили;
Рд—давление на выходе, фунт/кв. дюйм;
 pagebreak 
148 Глава 8

РГ—давление при всвсывании, фунт/кв. дюйм;
В — диаметр трубопровода, дюйм;
К, К„ 2, $, 11 — константы.

Кроме того,

В2'6(Р2—РЁ )о,54
0=К2 1})..542054 '

П 142 = 1, К = 1370, Ь = 20, Ь = 1,476, К1 = 0,081, 3 = 100
иК2 = 13 определите Р1 и Р„ минимизирующие С
3. 317. аксимизируйте следующую целевую функцию:

? (Х) = х‘? ехр [1:2 —— х? —— 10 (х1 — хт].

Сравните траектории оптимизации в пространстве х при использо-
вании следующих методов:

а) наискорейшего спуска;

б) модифицированном партан-ме'юда;

в) метода Ньютонгц

г) метода переменной метрики;

д) Флетчера — Ривса;

е) Голдштейна — Прайса.

3.38. Максимизируйте следующую целевую функцию:

{(х) = (0,35 + 0,40х1 + 0,31х2)‘1 (0,85 — 0,60х1 +
+ 0,85%)4 ехр [2,00 —— (0,35 -|- 0,401:1 + 0,35хд)‘ ——
— (0,85 — 0,60):1 + 0,85х„)4].

Сравните траектории оптимизации в пространстве х при использо-
вании следующих методов:

а) наискорейшего спуска;

б) продолженного (модифицированном) партан-метода;

в) метода Ньютона;

г) метода переменной метрики;

д) Флетчера _ Ривса;

е) Голдштейна —- Прайса.

3.39. Начиная с точки к"” = [1 ——231Т, определите точиу х‘”+":
1) методом наискорейшего спуска; 2) модифицированным партан-
методом; 3) методом Ньютона; 4) методом Дзвидона — Флетчера —
Пауэлла; 5) методом сопряженного градиента для следующих
целевых функций:

а) Г(Х)=х?+хё+хё;
5) 7 (Х) = 2х? + 2х1х2 + 3х3 + хз;
в) {(х) : еХРЙЁ-і- ХЁ—хз—х1+ 4),
 pagebreak 
Методы минимизации, использующие производные \49

 

3.40. Миниинзируйте следующие фунхщии, начиная с вектора
“’ = [2 —2,5 2 4,51%

а) НХ) = хЁ+ХЁ+ХЁ +165;

6) ? (х) = ("1 _ хдд + (“53 _ м;)“:

в) Г(х)= 1+х2+х3+х4+16х1х2+8хёх3+хзх4+2

3.41. Функция, описанная Уилингом [37], позволяет оценивать
способность того иди иного алгоритма преодолевать разрывы. Эта

функдия
Г(Х)=—3|хь|——|х2|
имеет форму пирамиды в трех измерениях, а ее линии уровня на
плоскости х„ х2 представляют собой ромбы с разрывами вдоль
главных осей. Найти максимум ‚*(х), а также х*: а) методом наи-
скорейшего спуска; б) модифицированным партан-методом; в) мето-
дом Ньютона, г) методом переменной метрики; д) методом сопря-
женного градиента. (Максимум имеет место в начале координат.)
Уилинг начинал оптимизацию с точки х(°)— —[10 1017, где і(х)=
= —-40; попробуйте другие начальные векторы
3.42, Если целевая функция имеет общий вид
п

МХ) = д (№"), (2)
то можно показатъ, что максимум [(х) имеет место в точке, соот-
ветствующей максимуму каждого сомножителя, т. е. в точке х, = і.
Иенользуйте функцию (а) в качестве тестовой функции и вычисли-
те выбранным вами Зметодом максимальное значение следующей

функции: і(х)— _— хіхЁхЁхі е "”‘+х‘+”'+”‘). Сравните результат с извест-

Т

ным максимумом. Используйте две начальные точки: хш’ = [3 4 %— 1]
°>=[1 1 1 117.

3.43. Следующая функция, согласно Бруксу [38], представляет

собой длинный узкий хребет с максимумом в точке х* = [1 ПТ:

{(х) = хёехр [1 —-х.2— 20,250;1 _ хдчіо)

Найдите максимум [ (х), начиная с векторов хо = [0,1 0,11т

х‘"’—- _,[1 9 0,117, с помощью выбранного вами метода. Изобразите
эту функцию и траекторию ОПТИМИзации на плоскости (хі, хя).

8.44. Известно, что при статистическом анализе данных аппрок-
симировать некоторый процесс экспоненциальными функциями
довольно трудно вследствие взаимодействия параметров. По-
следнее приводит в пространстве параметров к гиперболиче
ским хрейгам. В качестве примера Миниинзируйте сумму квадратов
 pagebreak 
150 Глава 3

 

отклонений

‚|
2
Ф = 2 (‚!/наблюмеисе _ !!предсказяиное)і›

і=|
где
іг _ 1 _“
упредскаэанное = ЁЁ)— (е ' '— е 1)

ДЛЯ СЛЕДУЮЩИХ данных:

! Инаблюдаемое
0; 5 0,263

1,0 0,455

1 ‚5 0,548

Изобразите графически поверхность суммы кзадратов для полу-
ченных значений коэффициентов.
3.45. Повторите задачу 3.44 для модели

_ „дщ—
у 1 + ігдх, + 163151
И данных
”наблюдаемое | м :,
0,126 1 1
0.219 2 1
0,076 1 2
0.126 2 2
0,186 0,1 0

3.46. Аппроксимируйте минимальное значение интеграла
1

5[(%)2_2…4…

при следующих граничных условиях:
йу/піх=0 при х=0 и у=0 при х: !.

Указание. В качестве пробной функции возьмите ;; (х) =
= а (1 _— х„)‚ удовлетворяющую граничным условиям, и найдите
значение а, минимизирующее интеграл. Улучшит Ли оценку мини-
 pagebreak 
Методы минимизации, исполдэцющие производные 15|

 

мума интеграла более сложная пробная функция, удовлетворяю—
щая граничным условиям?

3.47. В задаче, связанной с проблемой принятия решения,
желательно минимизировать ожидаемый риск, определяемый сле—
дующим образом:

Ириск} =(1—ти…—г‹ь›1+Ре„е(%+—2%)г(%— ЁЁ”),

 

ь
где 1" (Ь) = 5 ["'/29,414,
—ео

01:1,25- 105, Св = 15, 6 = 2000, Р= 0,25.

Найдите минимальный ожидаемый риск и значение В.

3.48. Пекгрня, производящая однофунтовые батоны хлеба,
обычно выпускгет 10 000 фунтов хлеба в день. Вследствие возник—
шего периода острой конкуренции рыночняя цена этого продукта
упала так низко, что предприятие работаете убытком. При нормаль-
ном производстве (10 000 фунтов в день. 300 дней в году) имеют
место следующие расходы:

!) расходы, связанные с затратами труда и контролем, стои-
мость пара, расходы по продаже и на социальное обеспечение и
т. д.: 600 долл/день;

2) цена сырья: 0,075 долл/фунт продукции;

8) ежегодные налоги, страхование и т. д., доходящие до 25%
вложений: 300 000 долл‚

Предположим, что расходы, указанные в п. 1 и 2, линейно за-
висят от количества продукции, тогда как расходы п. 3 остаются
постоянными. На хлеб спрос постоянный, и эксперты в этой облас-
ти считают, что ни один новый процесс по его изготовлению не явля-
ется допустимым.

Сотрудники производственного отдыха совместно с отделом реа-
лизации и учета выяснили, исходя из наилучших доступных дан-
ных, что себестоимость в долларах на единицу продукции задается
(в пределах производсгва от О до 20 000 фунт/день) уравнением

_ (300 000 долл/день) (0,25/год) 400 долл/день _
С _ (300 день/год) (Р фунт/год) + Р” фУНТ/день + 0,075/фунт +

+ [()-7 131.3,

где Р ——факт1‹1ческая продукция в фунтах в день, и Р” — произ-
водительность при нормальных условиях, 10 000 фунт/день. Отдел
реализации определил, что продажная цена (включая возвраты)
в следующем месяце в среднем будет равна 18,1 цент/фунт.
Основываясь на приведенных выше данных, какой объем произ-
 pagebreak 
152 Глава 3

 

водства вы посоветуете установить в качестве оптимального на
следующий месяц?

3.49. Оправдана ли экономически тепловая изоляция большой
цистерны для хранения нефти и— если да, то какова оптимальная
толщина этой изоляции? Расходы могут быть разделены на две
категории: а) стоимость установки и б) текущие расходы. Стоимость
установки (в долл/год) тепловой изоляции равна с1с‚Ах.

Для поддержания нужной вязкости нефти в цистерне должна
быть установлена также обогревающая спираль; стоимость ее
установки (в долл/год) равна

0
”3“ = им) *
где
_ Аао—ы
“(* 1 ч
ттт? „„

Текущие расходы на Цистерну (в долл/год) составляют 05060»
Найти минимальную величину расходов и требуемую толщину
изоляции ;: при следующих данных: А = 8000; 10 = 120; !„ = 40;
!$ = 250;. !г = 0,024; 01 = 4; с, = 0,20; ::а = 0,8; сд = 0,262; 435 =
= 1,5 — 10—е; дв = 4000; Ьо=15 + 60): + 1018; д„ = 4,0—10х;‚(1 =
= 17.
Что означает отрицательное значение х?
Обозначения
01 —стоимость изоляционного материала, долл/(фут2 поверх-
ности) - (фут толщины);
с2 —амортизационный коэффициент (безразмерный);
сз _ стоимость нагревающей поверхности, долл/фут‘;
с, — амортизационный коэффициент (безразмерный);
в, ——стоимость пара, долл/БЕТ;
1:'; ——количество рабочих Часов в год, ч;
А — площадь изоляции, футі;
Ь„ — коэффициент теплоотдачи стенки цисгерны воздуху,
БЕТ/ч — фут2 . °Р;
Ёп — коэффициент теплоотдачи нефти стенке цистерны,
БЕТ/ч . фут2 - °Р;
іг _- теплопроводность изоляции, БЕТ/ч — фут . °Р;
(2—тепловые потери, БЕТ/ч;
[1 — коэффициент теплопередачи между спиралью и нефте-
продуктом, БЕТ/ч - фут2 - °Р;
[„—температура окружающею воздуха, °Р;
ц, — температура нефти, °Р;
[5—температура спирали обогрева, °Р;
›: — толщина изоляции, фут.
 pagebreak 
Методы минимждции, использующие производные 153

 

ЛИТЕРАТУРА

1. СюідзіеіпА А., Митеіішімщпд, 14611962).

.5

грртнфтэрю

А.](аіКеН., Апл іп:! 8!а1і5!.МпЛі,Таіг_1/а‚ 11. 1 (1959г.

ЕШегН.‚ РЬ. В Оіззегіаііоп, Рипіце Нпіч.‚ [.аіа уеііе, па,1966.

ВохО. Е. Р., \Уі1зопК. В, ]. Коу. 51111131. Зоо., 813, 10951).
ьапд1еу5.ш.,1.Ат.$шЕы ‚45900… 62, 819 (1967).

НозепЬгосКН Н. Ситр иіег], 3. 174 (1960).

(}геепзіа‹11.1„ Мат. Сат тйиіагіоп, 21 360 (1967).

Матч цагёіВ Ш., ]. 81/1 11 431[ (1963)

ЬечепЬега КМ. (2140г! Аррі. Мит, 2, 164 (1944).

ООШіеШ $.М ,Оиапйі К. Е., Тгоііег Н. Р. Есипотеігіси, 34, 541 (1966).
Ешагі. Р. В., Ыопііпеат Ргоагашшіпд: А Оцадгаііс Апа1у515 оі Кіёде Рага1у-
зіз. Шазпіпдіоп Ппіщ Кер. СОО— 1493 21 51. Ьопіз,Мо., Лап. 1969.

Незіепез М. К., Тііе Сопіцдаіе Схгасііепі Матос! іог $о1чіпд [‚іпеаі' $у51еш5‚
іп Ргос. оі 1|1е Зушр. оп Арр1іеіі Маіііешаіісз, \101. …, МсОгаш-НШ, М. У.,
1956. рр. 83—102.

13. РіеісЬег К., Кеечез С. М., Сатрш‘е: .! ., 1, 149 1964).

14.
15.

16.
17.
18.
19.
20.
21.

22.
23.

24.

25.

26.

27.
28.
29.

30.
31.
32.
33.
34.
35.
36.
37.
38.

Незіепезм. К., Зііеіеі Е. 1… .]. Кез. МШ. Биг. ш. 849. 409 (1952).

ВесКі'пап Р. 5, Пт 501п1іоп 01 Ьіпеаі' Ечцаііопз Ьу Ніе Соп шваіе Огааіепі

МеіЬоё, іп1МаіЬеі'паііса1 Меііюсіз іог Відііаі Сошрціегз, Наіэіоп А., “7111

Н.Э.,есів.,\/01. 1,Ші1е,1пс.Ы.У., 1960

5112111 Б. У., ВцеЫеі' Е. ., Кетрпюгпе О., 1.81АМ, 12, 74 (1964).

Рогзуйіе 6. Е.,М012Кіп Т. $., Вц11. Агп. Маш. $0с., 57. 183 (1951).

Ёсціуепёііэ1‹606„ Меіпосіз оі РеазіЫе Вігесііопз, Ашегісап Еізечіег РЦЫ. Си.,

МсСоггпіск 6. Р., Реагзоп З.В., Сішр. 21 іп: 0р1іші2а1іоп, Р1е1с11ег Н, ей.,

Асааегпіс Ргезз 1пс., [.опдоп, 1969.

Міе1е А., Сап1ге11 1. “!., Еісе Шпіч. Аеш-Азігопапіісз Кер’с. 56, Ноцзіоп,

Тех., 1969.

%гадд Е.6 Е., Ьечу А. У., Еісе Нпіч. Аего-Азігопапіісз Кер’с. 58, Нопзіоп,
ех 19 9.

ВюуаепС О., Мат. Сотриіаііоп, 21 368 (1967).

Ёоігіагігэёа СЬар. 18 іп: Орііі'піиаііоп, Пеште! В., её., Асааешіс Ртезз 1пс.‚

В'аЧіаоп \”. С., Сотриіеі ]., 10, 406 (1968); СЬар. 2 іп: 0р1ішіш’сіоп,`Р1е1-

сЬег К., ей.. Асабегпіс Ргезз 1пс.‚ М. У., 1969.

Роше" М. 3.1), Капк Опе МеШобз 101" Цпсопзігаіпеа Оріішішііоп, АЕНЕ
Кер1.ТР 372,1969.

МцгіаеЬВ.А.‚$ащеп1К “1. Н., іп20р11гпі1а1іоп, Ріеісі'іег К. ., ей., Асасіешіс

Рі'езз 1пс., Ьошіоп, 1969

Вачіаоп 1111 С., НЗАЕС Вос. АЫЬ-БЭЭО (теч.), Меч. 1959.

Р1е1с11ег К., Рошен М. Л. В., Ситриіег .1., 6, 163 (1968).

Ваші У., Оп 3 Мштіегісаі 1п51аЬі1і1у оі Вачіаоп-НКе Меііюбз, !ВМ М. У. Зсі.

Сепіег Кері. 320-2913, Аид. 1967.

Зіешагі 6. Ш., .! . Азис. Сатршіег Масіііпггу, 14, 72 (1967).

Реагэоп .1. В., Сотригег !„ 13, 171 (1969).

Отеепзіаьіі Л., Мат. Сотриіагіоп, 24, 1 (1970).

СюіаіагЬ В., Мат. Сотриіпп'ап, 24, 23 (1970).

Р1еіс11ег К., Сотриіег !., 13, 317 (1970).

самые… А. А., Ргісе 5. Р., Митгп'ші Мат., 10, 184 (1967),

гаек 0. С., Зтап (і. “]., .]. Пим Медь, 25, 165 (1966).

‘Уііееііпв К. Р., Сотті Авто. Сотриіе/ Маст, 3, 632 (1960).

Вгоо1<5 5. Н., Оретгіопз дез., 7, 430 (1959).
 pagebreak 
154 _ Г лава 3

 

ДОПОЛНИТЕЛЬНАЯ ЛИТЕРАТУРА
ОБЩИЕ ВОПРОСЫ

Вох М. Л., А Сошрагізоп 05 Зачем! Сцп-епі Оріітіъаііоп Мешоаэ, апа !Ье Цзе
оі Тгапзіогтапопэ іп Сопзігаіпесі РгоЫетз, Сат иіе/ .!., 9, 67 (1966).

Вогп “7. $., Моп1іпеаг Ргоагаттіпв: А. $цгчеу, аппдетепг 8012, В, 171 (1963).

Незіепез М. К.. !. Орг. Тіъеогу птіАррЬ, 4, 303 (1969 .

НШ! .1. .1., А Кечіеш 01 Аідогтхшз іог ОрНтішНоп, піч. 01 1001121 Кер. 22, `Ише
1970. .

Котаик ]., 05Ьогпе М. К., Меіпосіэ іог Ппсопзігаіпеа Оріішішііоп РгоЫешз,
Ашегісип Е1зечіег, М. У., 1968.

Меуегз (3. Е., РгорегНеэ оі Н1е Сощ'цеаіе Огааіеп! апд Вачіаоп МеШоёз, ]. Орг.
ТИеагу Арр!.‚ 2 (1968). ‚

Рошен М. .]. В., А Зигуеу оі Ыышегіса] МеШоёз іог Ппсопзігаіпед Ортітіиапощ
$1АМ Нео., 12, 79 (1970).

КіЬіёге О., Зиг Па методе ‹іе ВачШоп—РіеісЬет—Рошеіі рощ 1а шіпігпізаііоп йез
іопсііопз, Мападетел! ЗП., 18, 572 (1970).

ЗсЬесЫег Е. З., Веуегіаде 6. 5. С., Оріппіиаііоп: ТЬеогу апа Ртасіісе, МсОгаш-
НШ, Ы. `!., 1970.

Зрапд Н. А., 111, А Цечіе“! 01 Міпішіиаііоп ТесЬпічцез 101" Мопііпеаг Рцпсііспзь
зим Нео., в, 343 (1962).

Торікіз 0. М., \іеіпоп А. Р., Оп іЬе Сопчегдепсе оі Зоше РеазіЫе Вігесііоп Аіао-
гіШгпз іог МопНпеаг Ргоегаштіпд, .]. $!АМ Сттоі, Б, 268 (1967).

Ші1с1е960. ]., Оріітшп $ее1<іпд Метоаз, Ргепіісе-Нап, Епдіешоод СННЗ. М. Д.,
1 4.

\Яіібе 0. З., Веівітег С. $„ Роцпааііопз оі Оріішіиайіоп, Ргеппсе-Нап, Епаіе-
чтот! С1іііз, М. Д.. 1967.

Шоііе Р., Веселі Вече1ортепіз іп Мопііпеаг Ргодгаштіпг, Агігдп. Сотриіегз, 3‚›
155—187 (1962).

ДРУГИЕ МЕТОДЫ НЕЛИНЕИНОГО ПРОГРАММИРОВАНИЯ
БЕЗ ОГРАНИЧЕНИЙ, ИСПОЛЬЗУЮЩИЕ ПРОИЗВОДНЫЕ

Вос“! А. В., Ап АррНсаііоп оі [Ье Машей оі Зіеереэі Везсепіз [о Ше 5011111011 01
$у51егп5 оі Мопііпеаг Зішцпапеоцз Ечиаііопз, Отт. .]. Меса. Аррі. мм.,
11, 460, 191 (1949).

Вюуаеп С. О., ТЬе Сопчегдепсе 05 :: Сіазз оі ВопЫе-Капк Міпішіиаііоп АідогііЬшз;
!. 6епега|Соп51дегаЪіоп$, .]. !пзі. Мат, Арр1., 0, 78 (1970).

Вгоуаеп С. О., ТЬе Сопчегдепсе 01 а Сіазз оі ВоцЫе-Капк Міпітіиаііоп АідогіШшэ;
2. ТЬе Меч: А1догі1Ьп15, .і. 1п$!. Мат. Арр1., 6, 222 (1970).

&осйеііёі. О.,БСЬегпой Н.. Сгасііепі Мейюсіз оі Махішішсіоп, Расііів .А Май.,
5, 3 (195 ).

Сшгу Н. В„ Тіпе Меыюй 01 Зіеерезі Везсепі іог Мопііпеаг Міпітіиаііоп РгоЫегпз,
Отт, Аррі. Мат., 2, 258 (1944).

Віхоп Ь. С. №., 31355 М. С., Меапйег —— А Метоп Вазы! Ргосеаш'е гот М-Вішеп-
зіопаі Рипсйіоп Міпітііайоп, ТесЬпісаі Кері. № 9, Пт НаШеШ Ро1уіес1ш1с,
НайііеШ, Еп 1апс1‚ Арт" 1970. ‘

воинам 5. М., иапаі К. Е., ТюЦег н. Р.. Махішіъаііоп Ьу Оцаагаііс Ні" Сііш-
Ьіщ, Ешпотгігіса, 34, 541 (1966).

Нцащ Н. У., Ьеч А. В., ]. Орі. Т/іеагу аті Аррд, 8, 269 (1970).

1асоЬзоп В. Н., Кзтап Ш… Ап Аідогііъгп ТЬаі МіпішіЪез Нотовепеоцз РцпсСі-
опз 01 № \іагіаЫез іп М + 2 Пегатіопз апа Карійіу Міпітіъез Степега] Рип-
сы‘опз, Тесппіса1 Верь № 618, Вічізіоп оі Епвіпеегіпе апа Аррііей РЬузісз,
Нагчагд Опт., СагпЬгісіде, Ма55.‚ Ост. 1970.
 pagebreak 
Методы минимизации, итользующие производные 155

 

Магчцапіі 0. №., Ап Аівогі’сЬт іог Ьеаз! Эчпагез Еэ‘сігпаііоп оі Мопппеаг Рата—
гпеіегз. ЗИМ ]., п, 431 (1963).

Мш-іавп В. А., Загдепі В. “1. Н., А Сопзігаіпеа Міпітіиаііоп Метод т…! @на-
бгаііс Сопуегвепсе, СЬар. 14 іп: ОрНтіиаНоп, Ріегсиег В., её., Асшіетіс Ргезз
1пс., Ьопсіоп, 1969.

Мцгсадн В. А., Загееп! 12. “1. Н., Сотригег ]., 13, 185 (1970).

Рараіоапгюц Т.. КешрШогпе О., РагаПе! Тапдепіз апа Зіеерезі Беты О іі-
]шішііёпоАівол-ішщ \ЧгідЬі-Раиегзоп Аіг Роке Вазе Верь АЮ. 70-0 17,

111 7 .

Роше]! {А 1. 11, Ап Пегаііче МеіЬші іог Ріпёіпа Зіаііопагу \’аіцез оі а Ёцпсйіоп
оі Зечегаі ЧагіаЫез. Сотри!” .! ., Усі. 5, 1962.

знаь В. У., ВЦеШег К. .1.‚ КетрШогпе О.. 1оша Зіаіе Нпіч. Зіаіізс. ЬаЬ. ТесЬ.
Кері. 3, 1961; 2 (теч.), 1962; ]. Зое. [па. Аррі. Мат., Усі. 12, 1964.

5Ьаппо [). Р., ЗММ .]. Митег. Апп1., 7, 366 (1970).

ЗЬаппо В. Р., мат. Сотриіпііощ 24, 647 (1970).

5Ьаппо В. Р., КеШег Р. С., Мат. Сотриіппоп, 24, 657 (1970).

$_Ш‹іа11 .]. Ы., Орйізер Везівпегз Оріішіиаііоп ЗцЬгоцііпез, МсМазЪег Опіш Кері.
МЕ/70/ВЗМ/КЕР/1, РасцНу оі Епдіпеегіпд, Натіпоп, Опгагіо, Сапааа, 1970.
 pagebreak 
Глава 4

МЕТОДЫ МИНИМИЗАЦИИ БЕЗ ОГРАНИЧЕНИЙ,
НЕ ИСПОЛЬЗУЮЩИЕ ПРОИЗВОДНЫЕ (МЕТОДЫ ПОИСКА)

В отличие (Л‘ гл. 3, где изложено решение задачи нелинейною
программирования (3.0‘1) с помощью методов, использующих про-
изводные (или их аппроксимации), в этой главе рассматриваются
методы оптимизации, не использующие производные. Эти методы
обычно называют методами поиска. В типичном методе поиска
направления минимизации полностью определятся на основании
последовательных вычислений целевой функции ПХ).

Как правило, при решении задач нелинейного программирова-
ния при отсутсгвии ограничений градиентные мегоды и мегоды,
использующие вторые производные, сходятся быстрее, чем прямые
методы поиска. Тем не менее, применяя на практике методы, ис-
пользующие производные, приходится сталкиваться с двумя глав-
ными препятствиями. Во-первых, в задачах с достаточно боль-
шим числом переменных довольно трудно или даже невозможно
получить производные в виде аналитических фунгщий, необходимых
для градиентного алгоритма или алгоритма, использующего произ-
водные второго порядка. Хотя вычисление аналитических пронз-
водных можно заменить вычислением производных с помощью
разностных схем, как описано в разд. 3.4, возникающая при этом
ошибка, особенно в окрестности экстремума, может ограничить
применение подобной аппроксимации. В принципе можно исполь—
зовать символические методы для аналитических выражений про-
изводных, но эти методы требуют значительного развития, прежде
ЧЕМ ОНИ станут ПОДХОДЯЩИМ ПРЗКТИЧЭСКИМ инструментом. ВО ВСЯ—
ком случае, мегоды поиска не требуют регулярности и непрерыв-
ности целевой функции и существования производных. Вторым
обстоятельством, правда, связанным с предыдущей проблемой,
являегся ТО, ЧТО при использовании методов оптимизации, ОСНО.
ванных на вычислении первых и при необходимости вторых произ-
водных, требуется по сравнению с методами поиска довольно
большое время на подготовку задачи к решению.

Вследствие изложенных выше трудностей были разработаны
алгоритмы оптимизации, использующие прямой поиск, которые,
хотя и медленнее реализуются в случае простых задач, на практике
могут оквзаться более удовлетворитльными с точки зрения поль—
зователя, чем градиентные методы или методы, использующие
 pagebreak 
Методы минимизации, не использующие производные 157

 

вторые производные, и решение задачи с их помощью может обой—
тись дешевле, если стоимость подготовки задачи к решению высока
по сравнению со стоимостью машинного времени. В данной главе
рассмотрены лишь некоторые из многих существующих алгорит-
мов прямого поиска, причем при выборе мы руководствовались
их эффективностью при решении тестовых задач.

4.1. ПРЯМОЙ ПОИСК

По существу методы поиска простейшего типа заключатся в
изменении каждый раз одной переменной, тогда как другие остают-
ся постоянными, пока не будет достигнут минимум. Например,
в одном из таких методов переменная х1 устанавливается постоян-
ной, а ›:я изменяют до тех пор, пока не будет получен минимум.
Затем, сохраняя новое значение ;:2 постоянным, изменяют %, пока
не будет достигнут оптимум при выбранном значении хи и т. д.
Однако такой алгоритм работает плохо, если имеет место взаимо—
действие между 161 и х… т. е. если в выражение для целевой функции
входят члены, содержащие произведение ):1262. Таким образом,
этот метод нельзя рекомендовать, если пользователь не имеет дела
с целевой функиией‚ в которой взаим0действия не существенны.

Хук и Дживс П] предложили логически простую стратегию
поиска, использующую априорные сведения и в то же время отвер-
гающую устаревшую информацию относительно характера тополо—
гии целевой функиии в Е". В интерпретации Вуда [21 этот алгоритм
включает два основных этапа: «исследуюший поиск» вокруг
базисной топи и «поиск по образцу», т. е. в направлении, выбран-
ном для минимизации. На фиг. 4.1.1 представлена упрощенная
информационная блок—схема этого алгоритма.

Рассматриваемый алгоритм прямого поиска состоит из следую-
щих операций. Прежде всею задаются начальные значения всех
элементов х, а также начальное приращение Ах. Чтобы начать
«исследующий поиск», следует вычислить значение функции 1‘ (х)
в базисной точке (базисная точка представляет собой Начальный
вектор предполагаемых искомых значений независимых переменных
на первом цикле). Затем в пикшическом порядке изменяется каждая
переменная (каждый раз только одна) на выбранные величины
приращений‚ пока все параметры не будут таким образом изменены.

о
В частности, хЁо’ изменяется на величину АхЁ), так что хЁ” =:

= хЁо’ + Ах‘.°’. Если приращение не улучшает целевую функцию,
х?” изменяется на —Ах‘.°’ и значение {(х) проверяется, как и ранее.
Если знзчение [(х) не улучшают ни х‘дщ + АИР), ни хЁо’ — АХЧ”,
'ю ::(?) оставляют без изменений. Затем х?” изменяют на величину

Ах‘яо’ И Т. Д., пока Не будут изменены ВСЕ независимые переменные,
 pagebreak 
158 Глава 4

 

что завершает один исследующий поиск. На каждом шаге или
сдвиге по независимой переменной значение целевой функиии
сравнивается с ее значением в предыдущей точке. Если целевая
функиия улучшается на данном шаі-е, то ее старое значение заме‹
няется на новое при последующих сравнениях. Однако если произ-

   

  
 

дычишщтэ %(!) в
йдшсшш точке (в .,
ша ато тоста

: “” )

   
  
    
  

 
 

[[там/пи цтлеуующий поиск
тили / и: о’тис/тй точки.
Лам: даме лет ошмущшця
стадии иш (ас) летим, чеи
№0! в старой Калина} тает?

 
    
        
      
  
  
 
   

   
  
 

Яшввтт .лц тишина
Мушкин (ли:) левши

 
  

‚‚ ‚ ли „1735/10 биои-

 
  
 
 

Кгттдрдм №№ @@@ ” „ ттт
кат малого чита: ? ‚%:—“’)- Нг)

!]ржсти поиск ла Мршцу

Ллжаг/ш шале ю ий ло ›
тала „ №: %%алёлет «»

   

 
    

шиншил” №№ возму-
щения

   
     

Ф и г. 4.1.1. Информационная блок-схема мннимнзации прямым поиском.

веденное возмущение по х неудачно, то сохраняется прежнее зна-
чение [(х).

После проведения одною (или более) исследующего поисщ
применяется стратегия поиска по образцу. Удачные изменения
переменных в исследующем поиске [т. е. те изменения переменных,
которые уменьшили і(х)1 определяют вектор в Е”, указывающий
некоторое направление минимизации, которое может привести
к успеху. Серия ускоряющихся шагов, или поиск по образцу,
проводится вдоль этого вектора до тех пор, пока НХ) уменьшается
при каждом таком поиске. Длина шага при поиске по образцу
 pagebreak 
Методы минимизации, ме исполдзующие производные 159

 

в ДаННОМ КООРДИНЗТНОМ направлении приблизительно ПРОПОРЦИС-
НМЬНЗ ЧИСЛУ удачных ШаГОВ, имевших место ранее В ЭТОМ КООРДИ-
наТНОМ направлении ВО время исследующих ПОИСКОВ за несколько
предыдущих ЦИКЛОВ. ДЛЯ ускорения процесса оптимизации изме-

"`:
«3,0
2,5
7,2
2,0 5
4
1,5
5,5
22,25 7
20,2: „р
17! "‘9
Б
‚
"}
’,’/6
‚*‘/4,15
7,0 '”:
&“ ч‘з

 

Ф и г. 4.1.2. Прямой поиск минимум функции Розенброка. начиная из точки

х(°)==[—1,2 1,0]Т. В отмеченных ючках указано число Удачных шагов поиска
по образцу.

нение размера шага Ах в поиске по образцу осуществляется путем
введения некоторого множителя при величине Ах,используемой
в исследующих поисках. Иоследующий поиск, проводимый после
поиска по образцу, называется исследующим поиском типа П;

успех или неудачу поиска по данному образцу нельзя устно-
вить до завершения исследующего поиска типа П.
 pagebreak 
160 Г лава 4

 

ЕСЛИ [(х) не уменьшается в процессе исследующего поиска
типа 11, то говорят, что данный поиск по образцу неудачен, и про-
водится новый исследующий поиск типа 1 для определения нового
удачного направления. Если исследующий поиск типа 1 не дает
нового удачного направления, то последовательно уменьшают
Ах, пока либо можно будет определить новое удачное направле-
ние, либо Ахд не станет Меньше, чем некоторая заранее установлен-
ная допустимая величина. Невозможность уменьшить [(х), когда
Ах достаточно мало, указывает на то, что достигнут локальный опти-
мум. Описанная последовательносгь поисков заканчивается, если
оказываются удовлетворенными условия трех основных тестов.
Первый тест проводится после Каждого исследующего поиска и
поиска по образцу: Изменение целевой функции сравнивается с за-
ранее установленной малой величиной. Если значение целевой
фунщии не отличается на величину, большую, чем это число, от
предыдущего основного значения целевой функиии, исследующий
поиск или поиск по образцу считается неудачным. В противном
случае проводится тест для определения, увеличилась ли целевая
функция (неудаЧа) или уменьшилась (удачный поиск), Этот втрой
тест нужен для того, чтобы быть уверенным, что знгчение целевой
функции Все время улуЧЩается. Третий тест проводится после неу-
дачи в исследующем` поиске на стадии умеНЬШения изменения

АХ. ПОИСК может бЫТЬ закончен, если на ДЗННОМ шаге изменение

каждой переменной Ах?” оказывается меньше, чем некоторое за-

ранее определенное число.
На фиг. 4.1.2 приведена траектория прямого поиска при мини-

мизации функции Розенброка, начиная с вектора х(°›= [—1,2 1,011.

 

ПрИМер 4.1.1. Максимизация (без ограничений) прямым поиском
по Хуку и Дживсу

Максимизировать целевую функпию

_ ‘
і(х)— ‹х1+1)*+хё '

 

начиная из хф’ : [2,00 2,801Т с начальным Ах, равным [0,60 0,841т.
Исходное значеНИе [ (2,00; 2,80) в базисной точКе х‘°’ равно 0,059.
Сначала проводится исследующий поиск типа 1 для определения
удачного направления. (Такая процедура называется исследую-
щим поиском типа 1 в противоположность исшедующему поиску
типа П, который следует за поиском по образцу. После прове-
дения исследующего поиска типа 11 принимается решение по
поводу того, было ли предыдущее движение по образцу успешным
 pagebreak 
Методы минимизации, не использующие производные 161
___—___—

или неудачным.)
хЁ” = 2,00 + 0,60 = 2,50, і(2,60; 2,80) = 0,048 (неудача);
х‘.” = 2,0 _ 0,60 = 1,40, ;(1 ‚40; 2,80) = 0,073 (успех);
хЁ’ = 2,80 + 0,84 = 3,64, 711,50; 3,64) = 0,052 (неудача);
хз“ = 2,80 _ 0,84 = 1,96, „1,40; 1,96) = 0,104 (успех).

Исследующий поиск оказался удачным, Заметим, что при каждом
поиске выбирается последний удачный вектор х. Новым базисным
вектором будет (1,40; 1,96).

Теперь из точки (1,40; 1,96) проводится поиск по образцу в

соответствии С правилом акселерзции
!: 1
Х,! +) : ”;и—№№,

где х‘ь’ —— предыдущий базисный вектор х. В данном случяе ею

начальный вектор х‘о’.
хз?) = 2 (1,40) = 2,00 = 0,80,
:“? = 2 (1,96) — 2,80 = 1,12,
і(0‚8; 1,12) = 0,22.

Наконец проводится исследующий поиск типа 11; неудача иди
успех его оценивается путем сравнения с [ (0,8; 1,12) = 0,22:

№ = 0,80 + 0,60 = 1,40, м1 ‚40, 1,12) = 0,14 (неудача);
хР = 0,80 = 0,60 = 0,20, “0,20; 1,12) = 0,38 (успех);
х? = 1,12 + 0,84 = 1,96, і<0,20; 1,96) = 0,19 (неудача);
@ = 1,12 = 0,84 = 0,28, подо, 0,28) = 0,67 (успех).

Чтобы определить, оказался ли поиск по образцу успешным, сраВни-
вают „0,20; 0,28) = 0,67 с „1,40; 1,96) = 0,104. Поскольку
поиск по образцу успешен, то новой базисной точкой будет х“) =
= [0,20, 0,2817; при этом старая базисная точка представлена век-
тором х… = [1,40 1,961’.
Затем вновь проводится поиск по образцу:
хз“) = 210,20) = 1,40 = _ 1,00,
х“) = 2 (0,28) = 1,96 = _- 1,40,
н— 1,00; _ 1,40) = 0,51.
После этого проводится исследующий поиск типа П:

‚59 = _. 1,00 + 0,60 = — 0,40, ;‘(-— 0,40; — 1,40) = 0,43 (неудача);
 pagebreak 
162 Г лава 4

 

х‘Ё’ = .— 1‚оо … 0,60 = _ 1,60, „_ 1‚60; — 1,40) = 0,43 (неудача):
„$) = _. 1,40 + 0,84 = _- 0,56, п— 1,00; — 0,56) = 3,18 (успех).

Поскольку [(——1‚00; ——0,56) = 3,18 > )“ (0,20; 0.28) = 0,67, поиск
по образцу представляется успешным и 355): [——1‚00 —0,561т
становится новой базисной точкой, а х… — старой базисной точкой.

Эта пошедовательность поисков продолжается до тех пор, пока
не будет достигнута ситуация, при которой в конце исследующего
поискз типа Н значение Дх) окзжется меньшим, чем значение
НХ…) в последней базисной точке. Тогда, если даже исследующий
поиск типа П является успешным при одном или более возмуще-
ниях, говорят, что последний поиск по образцу неудачен и про-
водят из предыдущей базисной точки исследующий поиск
типа ! для определения нового удачного направления. В иллюстра-

тивных целях продолжим поиск из х‘5’= [——-1‚00 ——-0‚561Т.

   

 

"“‘ ?
|
|

@ Базистр сектора:
и [&

Шаги цсслеуующггд привіт
‚утес:

.— _ _ неудачи

 

Шаги поиска по образцу
...а-...о успев:
+ + + + неудача
Ф и г. П.4.1.1.
 pagebreak 
Методы минимизации, не использующие производные 163

 

Поиск по образцу:
х?) = 2‹—1,00)— 0,20 = _ 2,20,
х?) = 21= 0,56) = 0.28 = = 1,40,
71—220; — 1,40) = 0,29.
Исследующий поиск типа 11:
„$71 = _. 2,20 + 0,60 = _- 1,60, [(= 1,60; __ 1,40) = 0,43 (успех):
х? = = 1,40 + 0,84 = _ 0,56, „_ 1,60: _- 0,56) = 1,49 (успех).

Однако поскольку [ (—1‚60; —0‚56) = 1,49 < [ (—1‚00; —0‚56) =
= 3,18, то, несмотря на то что исследующий поиск типа 11 оказался

успешным, поиск по образцу считается неудачным, и из х‘Б’ =

= [_1,00 —0‚561Т начинают исследующий поиск типа 1.

Когда достигается стадия, на которой ни исследующий поиск
типа 1, ни поиск по образцу (вместе ‹: исследующим поиском типа 11)
не являются успешными в любом координатном направлении,
говорят, что они оба неудачны и возмущение Ах уменьшают следую-
щим образом:

№501
Ах!.новое-т-Ахьпидыдущее е; ?

 

где Е—чишо последовательных неудач в исследующих поисках
при данной величине шага, начиная ог последнего успешного иссле-
дующего поиска.

(В Э'ЮМ примере максимум і (х) —› 00 при ‚1:1 —› —1 и л; —› 0.)

 

4.2. ПОИСК ПО ДЕФОРМИРУЕМОМУ МНОГОГРАННИКУ

Нелдер и Мид [31 предложили метод поиска, несколько более
сложный по сравнению с прямым поиском, но охазавшийся весьма
эффективным и легко осуществляемым на ЭВМ. Чтобы читатель
смог оценить стратегию Нелдера и Мида, кратко опишем сим-
плексный поиск Спендли, Хекста и Химсворта 14], разработан-
ный в связи со статистическим планированием эксперимента.

Вспомним, что регулярные многогранники в Е” являются симплек-
сами. Например, как видно из фиг. 4.2.1, для слуЧая двух пере-
менных регулярный симплекс представляет собой равносторонний
треугольник (три точки); в случае трех переменных регулярный
симплекс представляет собой тетраэдр (четыре точки) и т. д.

При поиске минимума целевой функции „х) пробные векторы
х могут быть выбраны в точках Е”, находящихся в вершинах сим-
плекса, как было первоначально предложено Спендли, Хекстом и
 pagebreak 
164 Глава 4

 

Химсвортом. Из анзлитической геометрии известно, что коорди-
наты вершин регулярного симплекса определяются следующей
матрицей 13, в которой сюлбцы представляют собой вершины,
пронумерОВанные от 1 до (н + 1), а строчки — координаты, і при-

   

  
   

Центр
/ тяжести

Ф и г‚ 4.2.1. Регулярные симплексы для случая двух (а) и трех (6) независимых
переменных.

@ обозначив наибольшее антенне [ (х). Стрелка указывает направление наношу
рейшего улучшения.

нимает значения от 1 до п:
“"о щ а„...а,
0 412 011…42
[)= О ай 42...62 —матрицап><(п+1)‚

_0. .а, “ф......ад

 

 

 

 

Где
, __
41= „1,2—(1/пи1-1—п—1),
@= „{,5 ‹Уп—1—1),

і—расстояние между двумя вершинзми. Например, для
{:= 2 и і=1 треугольник, приведенный на фиг. 4.2.1, имеет
следующие координиты:

Вершина "1. ! "2, !
 pagebreak 
Методы минимизации, не использующие производные 165
___—___—

Целевая функция может быть вычислена в каждой из вершин
симплекса; из вершины, где целевая функция максимальна (точка
А на фиг. 4.2.1), проводится проектирующая прямая через центр
тяжести симплекса. Затем точка А исключается и строится новый
симплекс, называемый отраженным, из оставшихся прежних
точек и одной новой точки В, расположенной на проектирующей
прямой на надлежащем расстоянии от центра тяжести. Продолже-

“г

 

д`;

Ф и г. 4.2.2. Последовательность регулярных симплексов, полученных при мини-
мизации [ (х).
__ _ _. проекция.

ние этой процедуры, в которой каждый раз вычеркивается вершина,
где целевая функция максимальна, а также использование правил
уменьшения размера симплекса и предотвращения циклического
движения в окрестности экстремума позволяют осуществить поиск,
не использующий производные и в котором величина шага на любом
этапе іг фиксирована, а направление поиска можно изменять.
На фиг. 4.2.2 приведены последовательные симплексы, построенные
в двумерном пространстве с «хорошей» целевой функцией.
Определенные практические трудности‚ встречающиеся при
использовании регулярных симплексов, а именно отсутствие уско-
рения поиска и трудности при проведении поиска на искривленных
«оврагах» и «хребтах», привели к необходимости некоторых улучше-
ний методов [5]. В этом разделе мы изложим метод Нелдера иМида,
в котором симплекс может изменять свою форму и таким образом
уже не будет оставаться симплексом. Именно поэтому здесь исполь-
зовано более подходящее название «деформируемый многогранник».
В методе Нелдера и Мида минимизируется функция п незавжи-
мых переменных с использованием 11+ 1 вершин дефор мируемого мно-

югранника в Б”. Каждая вершина может быть идентифицирована
 pagebreak 
166 Глава 4

 

вектором х. Вершина (точка) в Е", в которой значениеНх)
максимально, проектируется через центр тяжести (центроид) оо-
тавшихся вершин. Улучшенные (более низкие) значения целевой
функции находятся последователшой заменой точки с максималь-
ным знзчением Г (Х) на более «хорошие» точки, пока не будет найден
минимум Нх).

Более подробно этот алгоритм может быть описин следующим
образом.

Пусть х?” = МЙ), , хЪЁ’, , хЕ’ЗГ, і= 1, ..., п+ 1, явля-
ется'і-й вершиной (точкой) в Е" на 12-м этапе поиска, 12 = 0, 1, .. . ,
и пусть значение целевой функции в хЪ’” равно Пуф). Кроме тою,
отметим те векторы х многогранника, которые дают максимальное
и мингшалъное значеьшя {(х).

Определим
№51”) = тах {і №), … . гейма}.
где ХЗ.”) = хЁ-ё’, и
1!) “ХР) = шіп [[ (ХР), . . . ‚ „&:&-1”,
‹

где ХЗ,” ==Х; . Поскольку многогранник в Е" состоит из (11+ 1)
вершин х1, , х…‚хд, пусть х„“ будет центром тяжести всех вер-
шин, исключая хп.

Тогда координаты этого центра определяются формулой

„+1
хщ2‚,=%[(2 ‚@)—№], ;: 1, п, (4.2.1)
где индекс ] обозначает координгтное направление.

Начальный многогранник обычно выбирается в виде регуляр-
ного симплекса (но это не обязателшо) с точкой 1 в качестве начала
координат; можно начало координат поместить в центре тяжести,
как это имеет место в машинной программе в приложении Б. Про-

цедура отыскания вершины в Е”, в которой [ (х) имеет лучшее зна-

чение, состоит из следующих операций:

[. Отражение—проектировжие ХХ” через центр тяжести в

соответствии с соотношением
;: &
Хтъз = ХЦ-г + с: ‹Хщ-г —— ХЕ ’), (4.2.2)
где о: > 0 является коэффициентом отражения; ХЁЬ — центр тя-

жести, вычисляемый по формуле (4.2.1); хЯ" _- вершина, в которой
функция Дх) принимает наибольшее из п+ 1 ее зничений На
іг-м этапе.

2. Растяжение. Эта операция Заключшется в следующем: если
і‹х$513)<і‹х›**), то вектор (хЬЁз—ХЬЪ) растягивается в соответст—
вии с соотношением

‚(944 = ХЯЁЪ-г + ? (Хэн — 712,12); (4.2.3)
 pagebreak 
Методы минимизации, не использующие производим 167

 

где Ют>1 представляет собой коэффИЦиент растяжения. Если
{(хЁ’ +4)<[(х$’”)‚ то 14” заменяется на хіДН и процедура продолжает-
ся снова ‹: операции 1 при іг= %+ 1. В противном случае хі,’ за-

меняется на ‚#13 и также осуществляется переход к операции 1

при Ь = 13 + 1.
3. Сжатие. Если і(х Дз)>і(х$ *’) для всех цен, то вектор
(к}? -х‘‚‚+ ;) сжимается в соответствии с формулой

х‘дд х$."‘ +? + @ (хХ? —— х$.+2 ‚ (4.2.4)

где 0 < 6 < 1 представляет собой коэффициент сжатия. Затем ХЕ,” за-

меняем на 1133.5 и возвращаемся К операции 1 дЛЯ продолжения

поиска на (із + 1)- м шаге.

4. Редукция. Если {(ХЁ’ )>і(х$‚ ”’), все векторы (хЁЮ— х…)‚г— '
= 1, . . . , 11 + 1, уменьшаются в 2 раза с отсчетом от х?” в соот—
ветствии с формулой

$”) = хЪ’” +о‚5(х$’°_ хз»), = 1, ‚ 71 + 1. (4.25)

Затем возвращаемся к операции 1 для продолжения поиска На
(# + 1)-м шаге;

Критерий окОНЧания поиска, использованный ›Нелдером и Ми-
дом, сосгоял в проверке условия

п+| (Ь) :„
{ТП 2 „(№ —‹гх„+›1*} <& (4.25)

где е—произвольное малое число, а і(х$‚+г)—-значеьше целевой

функции в центре тяжести Хп+2.
На фиг. 4. 2.3 приведена блок-схема поиска методом деформируе-
мого многогранника, а на фиг. 4. 2 4 показана последовательность

поискз для функции Розенброка, начиная из х…) = [_],2 1,017.
Деформируемый многогранник в противоположность жесткому
симплексу адаптируется к топографии целевой функуши, Вы-
тягиваясь вдоль длинных наклонных плоскостей, изменяя Направ-
ление в изогнутых впадинах и сжимаясь в окрестности минимуМа.

Коэффициент отражения ос используется для проектирования
вершины с наибольшим знвчением [(х) через центр тяжестидефор-
мируемого многогранника. Коэффициент ? вводится для растяже-
ния вектора поиска в случае, если отражение дает вершину со зна—
чением [ (х), меньшим, чем наименьшее значение {(х), полученное
до отражения. Коэффициент сжатия @ используется для уменьше-
ния вектора поиска, если операция отражения не привела к вершине
со значением Нк), меньшим, чем второе по величине (после наи-
большего) значение „х), полученное до отражения. Таким обра-
зом, с помощью операций растяжения или сжатия размеры и форма
 pagebreak 
Вшщолшт началвныз значе—
ниях? ь=/‚?,‚.. , по], ц ›‘(ш‘ )
начального симплекса

      
 
   
 
  

:* шмитд % 111; кд

дтражвнив .- вмішслитд
.::,„3 : .::-„,: + «(итд -а:‚,)

    
 
 
    
 
 
     

Бычиалитд
”м…, )

Бишияе/пс ли
„„„„…Ъ
н:„.‚›‹№‚‚›г

 
 
 
 

  

Рщтлжвние: шчш' -

лить ::,„4-3”; +

‚
'Ч'Гд'паБ тупа)

Вычислить {(.-ц,“)
” „МЯЛЁГПС
‚. индиго ЯЛ, Нат
Г ,…,) ‹ “Ни ) ?
‚

даже/штд
""/к ”а “’под

      
   
    
   
 

  

шдтиедддічимитб х,"; :
=1лог *‚5 (11. ' “те)

 
 
     

   
 
  
 

   
 

дамвлитд
„тд па ::.-„‚,

  
   

Бмчишштд
‚($ …; )

  
  
  
 

  
  
   

': талиягтгя .ли
ужином”

тс…) ›-г‘(я:,.› ?

        
 
 

дамелцть
.т‚_ на ::

  

1:45

дуутция: заметит
Ме “і на :”Г'ёчжі—
ас,)

    
 

{7% 211%; *Как-…)]? ”‹ а ?

Ф и г. 4.2.3. Информационная блок-схема поиска методом деФОРМИрУемого мн…
 pagebreak 
Методы минимизации, не использующие производные 169

 

деформируемого многогранника мастабирутся так, чтобы они
удовлетворяли топологии решаемой задачи.

Естественно возникает вопрос, Какие значения параметров
ос, В и ? должны быть Выбраны. После того как деформируемый

 

"‘2
до
2,5
2,0
7,5
тт ` , 70
.?
„›, 3 А
—/‚о о (35 до „,
{:

69°
„(25 / (\

Ф и г. 4.2.4. Поиск минимума функции Розенброка методом деформируемого мно-
гогранника, начиная с ючки х… : [-—|,2 1,0]Т (числа указывают номер шага).

Многогранник подходящим образом промасштабирован, его разме-
ры должны поддерживаться неизменными, пока изменения в шпо-
логии задачи не потребуют применения многогранника другой
формы. Это возможно реализовать только при ос = 1. Кроме того,
Нелдер и Мид показали, что при решении задачи с ос : 1 требуется
меньшее количество вычислений функции, чем при 0: < 1. С другой
 pagebreak 
170 Глава 4

 

стороны, 04 не должно быть много больше единицы, поскольку
1) деформируемый многогранник легче адаптируется к топологии
задачи при меньших значениях ос, особенно когда необходимо изме-
нять направление поиска, столкнувшись с изогнутой впадиной,
и 2) в обдасти локального минимума размеры многогранника додж-
ны уменьшаться и большое 08 в этих условиях замедлит сходимость.
Таким образом, значение 0; = 1 выбирается как компромисс.

Таблица 4.2.1
Влияние Б и 1 на решение тестовой задачи 3 (приложение А) 1)

 

 

 

 

 

 

В 1; ‚ (х') КЁЁЁЁСЪМ Вреётягъіше- Точно?} ::;ргёйления
0,2 3 58,903 90 0,381 2,7. 10—7
0,4 3 58,903 55 0,287 7,1 . 10-43
0,6 3 58,903 81 0,388 2,8. 10—7
0,8 3 58,903 95 0,414 9,3. 10—7
0,5 2,2 58,903 47 0,238 9,1 - 10—7
0,5 2,4 58,903 45 0,247 8,5. 10—7
0,5 2,6 58,903 49 0,287 8,5— 10—7
0,5 2,8 58,903 57 0,304 8,1 . 10—7
0,5 3,0 58,903 70 0,343 8,6- 10-77
0,5 3,2 58,903 46 0,266 8,5 10—7

|) другие параметры. использованные при решении тестовой вами 3. имели следующие
авиация: ‹; = 1, 2 = 0,5, &= 1045. В качестве идчальной взята точка х(°)= [90 10]т.

 

Ч'юбы выяснить, какое влияние на процедуру поиска имеет
выбор В и ?, Нелдер и Мид (а также Павиани [В]) провели решение
нескольких тестовых задач, используя большое число различНЫх
комбинаций значений В и т. В качестве удовлетворительных энз-
чений этих параметров при оптимизации без ограничений Нелдер
и Мид рекомендовали ос = 1, В = 0,5 и \, = 2. Размеры и ориента-
ция исходного многогранника в некоторой степени влияли на вре-
мя решения, а значения ос, В и у окизывми зничительно большее
влияние. Павиани отмеЧает, что нельзя четко решить вопрос отн0›
сительно выбора 6 и ? и что влияние выбора 0 на эффективность
поиска несколько более заметно, чем влияние ?. В табл. 4.2.1 при—
ведены типичные резульшты для тестовой задачи 3 (см. приложе-
ние А), в которой в качестве оптимизирующей подпрограммы
Использовался алгоритм Нелдера и Мида. Павиани рекомендует
следующие диапазоны значений для этих параметров:

0,4 < 5 < 0.6.
2,8 < 7 < 3.0.
 pagebreak 
Методы минимизации, не использующие производные 171

При 0 < 5 < 0,4 существует вероятность того, что из-за уплоще—
ния многогранника будет иметь место преждевременное окончание
процесса. При Б> 0,6 может потребоваться избыточное число шагов
и больше машинного времени для достижения окончательного реше-
ния.

Пример 4.2.1. Поиск методом деформируемого многогранника

Для иллюстрации метода Нелдера и Мида рассмотрим задачу
МИНИМизации функции ГТ(х)= “;&—5)2 + (;&—6)“, имеющей мини-
мум в точке х*= [5 61Т. Поскольку і(х) зависит от двух перемен-
ных, в начале поиска используется многоугольник с тремя верши-
Нами В этом примере в качестве начаЛЬного многогранника взят
треугольник с вершинами х]°’= [8 91Т, Х…): [10 11]т ихд “”—— =[8 1111”,
хотя можно было бы использовать любую другую конфигурацию
из трех точек.

На нулевом этапе поиска, іг=0‚ вычисляя значения функции‚
получаем і(8,9)=45‚ і(10‚11)=125 и і(8,11)=65. Затем отра-

жаем хёш— : [10 1111 через центр тяжести точек х]… и х3°’[по фор-
муле (4. 2. 1)]‚ который обозначим черезх4 “’1’
хЬЧё=— (8+10+8)—10]=8,

хЪЧъ=Ти9+11 +11)—щ= 10

с тем, чтобы получить хЁ”.
хЬЧЖ=з+1(в—10)—в,
х5ЧЪ=110+1‹10—11)=9

“& 9)— —

Поскольку і(6,9) = 13 < і(8‚9) = 45, переходим к операции
растяжения:

хЬ‘з = 8+2(6——8) = 4,
‚ =1о+2(9_-10)=
„4 8) = 8
Поскольку „4, 8): 8<і(8. 9) — 45 заменяем хю’ на х?) и полага-

ем х?—— = х… на следующем этапе поиска.

Наконец, поскольку

% пя + 13% + 44=1'/= = 26,8 > 104,
 pagebreak 
№!) - 4.195 + а;; - 40.17, 4213 +136 %

    
 

12
а:“)
’ ___- г
"Ге ‚9- ,?
11.07) ‚
_70 т“? //
/
и
х,!” ‚0
1201.34”)
8 ' в ‚1.7 )_ “"`” :,”
„(зд д.ц)

’(Ё')- ",
"‘: “75

  

4
0 2 4 6’ 6 [о .1', 0 2 4 б 8 .:;

. Ф и г. П.4.2.1б. Т оиск помо ю
Ф и г. П.4.2.|а. Метод Нелдера и Мила при отсу-ютвии ограничении. ритЁЁеЁі’ЗЁЁЁаЁ Ми}; ""’ ш°'
 pagebreak 
Методы минимизации, не использующие производные 173

 

начинаем этап поиска іг = 1. На фиг. П 4.2.1а приведена траекто-
рия поиска На начальных этапах, а в табл. П.4.2.1 приведены
координаты вершин и значения і(х) для четырех дополнительных

Таблица П 4.2.1

ПЯТЬ ЭТЗПОВ вычисления МЕТОДОМ Нелдера И Мила ПВП минимизации
функции …) =…, —5›= + (к. 4)

 

 

 

 

 

Вершины многогранника З ……
Этап шт;, Замечания
‘ 751 12

0 ‚№ 8 9 45 х, = х?”

о м;» 10 11 125 кд = х?

о и;“) в и 65

0 х?) 6 9 13 Получена отражением ‹: по‹
мощъю формулы (4.2.2)

(, „(21)=„ё°і 4 8 8 Получена растяжением по
формуле (4.2.3)

х‘гс” заменяется на ‚:?-=

: х?)

1 „$0 : „$) 4 6 4 ХЗ” заменяется на 5:2) ==
: х?

2 “(хз) : „(??) 6 8 в 1:50) заменяется на х,“) =
:х‘і‘”

3 „(Р) =. „(7% 5 7,5 2,25 х?) заменяется на х?)

4 3:55) = хё‘” 5 5,5 0,25 ”$” заменяется на ХЁ’

 

 

этапов. На фиг. П 4.2.16 изображена полная траектория поиска

до ею окончания. Для уменьшения [ (х) до значения 1 - 10“6 потре-
бовалось 32 этапа.

4.3. МЕТОДЫ РОЗЕНБРОКА ИДЭВИСА, СВЕННА, КЕМПИ

Метод Розенброка [7] является итерационной процедурой, име-
ющей некоюрое сходство с исследующим поиском Хука и Дживса
(изложенным в разд. 4.1), которое состоит в том, ч'ю предпринш
маются малые шаги во время поиски в ортогональных направле-
ниях. Однако здесь вместо непрерывного поиска по координатам,
соответствующим направлениям незавишмых переменных, после
каждою пита координатного поиска можно сделать улучшение
путем сведения направлений поиска в ортогональную систему,
принимая весь шаг предыдущего этапа в качестве первою блока
 pagebreak 
174 Глава 4

 

 

при построении новой системы координат‘ Метод Розенброка опре-

деляет местонахождение хш-Н}, ИСПОЛЬЗУЯ послеДОВательные ОДНО-

мерные поиски, начиная с исходной точки к““, вдоль системы орто
нормированных направлений 531”, …, 5$), полученных при помощи
процедуры Грама —— Шмидта, так что направления поиска вытя—
гиваются вдоль главных осей квадратичной аппроксимации целе—
вой функции. Поскольку эти оси являются собственными векторами
Н (х) и представляют собой особый случай сопряженных направ—
лений, этот метод в некоторой степени аналогичен ме'юду сопря-
женных направлений в смысле сходимости, если применяется
к квадратичной аппроксимации целевой функции.
Рассматриваемый метод реализуется следующим образом.

„ „ …
Пусть 5$), …, 55!” —единичные векторы Е Е”, где индекс із =

= 0,1, обозначает этапы поиска. Ортонормированные векторы

„ „,
зі”…„д‘і’ строятся на основании информации, полученной на

(іг —— 1)-м этапе, по формулам (4.3.1) и (4.3.2), приведенным ниже‘

На начальном этапе із = 0 направления за”, …, $$?) обычно берутся

параллельными осям х1, .... х… В общем случае ортогональные нап-
равления поиска могут быть выражены как комбинации координат
независимых переменных следующим образом:

^ !? ‹!г и

5$”) = 515861 + дитя + ' ' ' + 513,35…

"О: ‚:

82’= аё’і’й + а‘в’Збд—і- - . - + а‘здбш

^ к (

5$? = „№1 + 113362 + . . . + 11,36…
где 6, _ единичный вектор в направлении х„ а и;, представляют

собой направляющие косинусы э,. В матричном обозначении
5… = а“”б.
Р „ (г:) __ (!:—1) „
ассмотрим іг-и этап, и пусть хо _ х„ представляет собои точку
в Е", из которой начат поиск, а д.1, ..., А.„——соответствующие
„

;.

длины шагов, связанные с направлениями 51, , 5".
Поиск начинается из ХБ,” путем введения возмущения, равного
& ^ !:
М ’5‘ ), в первом координатном направлении. Если значение [(Ё)-}-

:: ^ ь
+М’з‘, ’) равно или меньше, чем [(х‘о’"), шаг считаетоя успешным
и полученная пробная ’юъща заменяет ХБ“), МЮ умножается на мно-

жителъ сс>0 и вводится возмущение по направлению 59°. Если зна-
 pagebreak 
Методы минимизации, нг использующие производим 175

 

& ^ » іг
чение {(хБ’г’ + 751,5“) больше, чем ПхБ’), то шаг считается неудач-
ным, ХБ”) не заменяется, М") умножается на множитель 65<0 и сно-

ва задается возмущение по направлению 52“). Розенброк предложил

в общем случае брать значення параметров равны№ @= 3 и @=
= —— 5.
.

После того как пройдены все и направлений 5$”, . .. ‚ $$?), сно‹

ва возвраЩаются к первому направлению в" и вводится возмуще-
ние с длиной шага, равной од»… или БМ“, в зависимости от резуль-
тата предыдущего возмущения по направлению 5‘1’". Возмущения по
выбранным направлениям поиска задаются до тех пор, пока по каждо-
му из направлений за успехом не последует неудача. При эгюм !е-й

этап поиска заканчивается. Поскольку получение одинаковых значе-
ний функции рассматривается как успех, успех в конце концов дости—

гается по каждому направлению, так как множители при ?Х" умень—

шит последовательно ДЛИНЫ ШЗГОЕ. ПОСЛЕДНЯЯ полученная точка

становится начальной ТОЧКОЙ СЛЕДУЮЩеГО этапа, ХЬНН= Хим.

Нормированное направление 53+" берется параллельным

(тд?…— хп”), а остальные направления выбираются ортонормиро-
ванными друг к другу и к 5(Ь+› с помощью Одного из методов,

описанных ниже.

Дэвис, Свенн и Кемпи (ДСК), как это изложено в работе Свен—
на [8], модифицировали поиск Розенброка в направлениях 5$), . ..
.… , 53.’ путем отыскания минимума і(х) в каждом из направлений
5$ ’ способом, напоминающим поиск Дэвидона —— Флетчера — Пауэлла.
объясним эгто подробнее. Пустьх х… представляет собой точку, в к0‹
юрой ПХП) принимает минимальное значение в направлении 55).
Для каждого этапа іг существует п векторов ХЕ? ’ и п оптимальных
значений целевой функции [(хЁ ’). Начиная с хо,” ‚ оп еделяется А." ’
в направлении 83” так, чтобы значение} ‚%*-|№ № ’ ‘ ’} становилось
минимальным. Затем принимается хі" ’— = хи" +% “" &… .Начиная с х‘," ›,
определяется А.? '” так, чтобы Нк.") +?ь2 ‘”0’ 5…) принимало минималь-

ное знаЧЕНие. Затем принимается х!” = ‚(510+ А,;“г’зщ и т. д.
Изложенная с`хема поиска обобщается следующим образом. На-
чиная с ХЦ, определяется М“" в Направлении 55)" так, чтобы
[’(х‘і’ +76…5‘і’2 обращалась в минимум. Затем принимается ХЗ”:
=хЁЁ1+Ъ‚‘/“5Ё’. Этот поиск последовательно повторяется, всегда
начиная из предыдущей точки, пока не будут найдены все х‚‚ і=
=1‚ , п. Дэвис, Свенн и Кемпи определяли м… с помощью
алгоритма линейного поиска, описанного в разд. 2. 6. ОДНако вместо
 pagebreak 
176 Глава 4

 

него может быть использован любой эффеКТИВНЫй метод одномер-
ного поиска.

После завершения іг-го этапа либо с помощью оригинального
метода Розенброка, либо его модификации с использованием метода
ДСК в точке хЁ'Н’ = хи” вышкиоляются векторы новых направле-
ний поиска. В сущности здесь ортогональные направления поиска
поворачиваюгся по отношению к предыдущим направлениям так,
что они оказываются вытянутыми вдоль оврага (или хребта), и
таким образом исключается взаимодействие переменных. Пусть

АУ” представляет собой алгебраическую сумму всех успешных

шагов (суммарное перемещение) в направлении 59” На іг-м этапе;

 

в случае метода ДСК справедливо разенство А?” = Ё…. Опре-
делим :: векторов А1, …, Ап следующим образом:
і: і: 1: ‚а ,! іі
АР=А‹1)5(1)+А(2Ю$Ё)+ ... ——А2’55.’‚
12 !: 12 де Ла
Ар: №№ „Араи! (4.3.1)
#
Аш = №№.
Таким об азом, АЯ") является некто ом пе ехода из ХБ”) в ХЭМ”,
Р Р

АЁ’—вектор0м перехода из х?” в хЪЁ'Н’ и т. д. А‘!” представляет

собой полное перемещение с іг-го этапа на (іг+1)-й этап, АЕ!”—
полное перемещение, но без учета продвижения. сделанного во вре-
мя поиска в направлении 5?” и т. д.

В модифицированном методе Розенброка :: использованием алго-

ритма ДСК во избежание обращения в нуль любого из 52” (ибо в
этом случае данный алгоритм перестает работать) А и 5 в (4.3.1)
нумерутся нижними индексами, так что направления поиска
|А‘1Ю |>|АЁЧ> . - ‹ >|АЁ)|. Тогда если любые т из М") обра—
щаются в нуль, то отыскивают новые направления, как описано ни—
же, лишь для тех (п—т) направлений, для которых А$к)#=0; ос-
тавшиеся т Направлений остатся неизменными:

:… ь .
55+3=5Ё’, :=(п—т)+1,...‚п.

Таким образом, в методе ДСК векторам с ненулевыми А припи—
сывается первъхе (п — т) номеров. Так как первые (л _— т) век-
торов взаимно ортогоъшльны и А, = 0 для і : п —— т + 1, …, п,

первые п —— т векторов Не будут иметь СОСТЗВЛЯЮЩИХ В направле-

ниях 59+”, і= п _— т + 1, …, и. А поскольку эти последние

направления взаимно ортогоншкьны, то из этого следует, что все
направления являются взаимно ортогональными.

СвеНн указывает, что на практике оказалось более удобным
изменить критерий для перегруппировки направлений и вместо
 pagebreak 
Методы минимизации, не использующие производные 177

 

А‘!” = 0 использовать | А‘!" | < в, где в _ заданнзя точность х
или і(х). Эта модификация слегка повлияла на ортогональность

векторов З…, но весьма несущественно. Оказалось, что в случае
линейного поиска редукция длины шага с коэффициентом 0,1 умень-
шает число вычислений целевой функции, и поэтому она вводилась

в программу ДСК каждый раз так, чтобы расстояние между х}?

и хЪ’г'“) оказывалось меньше, чем длина шага на іг—м этапе.
В обоих методах новые направления определяются следуюшим

образом. Первый единичный вектор 593+" из нового набора направ-
лений на (‚‘с + 1)-м этапе направляют так, чтобы он совпадал с
направлением результирующего перемещения на предыдущем эта-
пе АЧ”, Остальные направления поиска строятся как взаимно

ортогонзльншь к А‘.” единичные векторы (ортонормированные
векторы) с помощью метода Грама —Шмиша. Подробное описа-
ние этого построения можно найти в работах по теории матриц
и линейной алгебре Таким образом, набор ортонорМИрованных
215+!) ^‹іг+1›

векторов ‚ ..., $„ на (/г + 1)—м этапе вычисляется при по-
мощи следующих соотношений:
;(и+1>_ АЗЫ
мати ’

ват = Азд— №№) №№ 59+",

» вт)
(’с-+1) 2
$ = _— , 4.3.2

"’ ивэтп ( ›

.................ов

п—1
Б“" : АХ!)__ 21 [(АЁЖ зён'п] #44),
»

іг
Заем) __ ”$)
„ _
из:? н

1

где ПАДЪ—норма А1. Та же процедура поиска, которая проводилась

На 13-м этапе, повторяется затем на (іг+1)-м этапе, начиная с точ-
ки хьцц = хЁ).
(;?)

Палмер [9] показал, что В,.Н и “ВУЗ..“ пропорциональны А‘,“

и
(при условии, что Е(АЁЁ’РЧЬО). Следовательно, при ВЫчислении

і=1
39+” = ВЁЮ/“ВЪЮП величина АЗ,” сокращается, и, таким образом,
ЁЁ“… остается определенным, если даже А;”) = 0. Имея это в вИДу‚
 pagebreak 
_Уь'танмить цачальнмг плиии-
ны щита (: =], , п)
("’-ат ‚юдт, если 4 ті › 0, ] ,

.=0/ , если А::і‹0‚1

     
 

          
    
   

 
 

Бичишитд анач‘е/шя цвлеаай‘тулк-

ции и @ЛМЦЙЦ—ЩЩКЦЧЁНЦИ

     
  
  

  

Ниауятт .‚ш переменная и функ—

Цци' КЦЧЙЯЦЛ 49 Л ‘е—ЛЙЕ' ватаг-
тау алс г : Ни .

Да

         
   
  

  
  
  

Добавить л: лрцырущему
1,- шину шага 0 1106047!
НИЛЩМВ” !!

м::; = „её;, А и;.”

    

Зауатд аг; в виде
тежкего мачты

 
    
 
 
 

  

заменить
4 №5 на -0,.’‚° А т

    

Вмцивлилп „име направления
лоисгл иначалдлмй вектор ос

    
   
  
 

  

Лрммсила ли
числа этапов
лраулисан -

ний пргуел ?

   
    
 

     
  

Дттаточна аш мило измените
целевая; функции и(или) Импо—
нвлт вектора х ?

Ф и г. 4.3.1. Информационная блок—схема алгоритма Розенброка (логическая
часть, служащая для реализации ограничений, здесь опущена).
 pagebreak 
Методы минимизации, не использующие производные 179

Палмер предложил для вычисЛения 9$“) пользоваться приводимы-
ми нтке формулами, что значительно уменьшит необходимое коли-
чество арифмеТИЧеских операций и объем памяти ЭВМ [вывод фор-
мул (4 3. 3) приведен в упомянутой статье Палмера]:

А‘Р— —2_‘‚ А3” в,?” 1<і<ш
№ и №1 |Р — №1 и А?” №

дцп = ___—‚___
и №, п и № н т АУЗ, п' — и А5“) ич ’-

, 2 < ! @, (4.3.3)

#
$,… : __
П А?” ||

При эт0м не требуется перегруппировка элементов А?“ Если АБЗ, =

= 0 то 85’г+1’— = 55_ , кроме случая, когда 2 (А‘?)2 ==

Метод Розенброка не обеспечивает автоматическое окончание
поиска после того, как найден экстремум і (х). Поиск либо прово-
дится На определенном числе этапов, либо заканчивается, как
только величина А1 становится меньше определенного значения
на нескольких пошедовательных этапах. В случае модифицирован-
ного метода Розенброка (с использованием алгоритма ДСК) после
каждою этапа расстояние АУ" сравнивается с размером шага
65”), использованного для получения А?” в линейном поиске.
Еслп А‘д’°"<б‘/°, то 67” делят на 10, и дальнейший поиск осу-
ществляется в [с прежних направлениях с новым Б,. Если А?” >

> 6$”, то поиск продолжается на (13+ 1)-м этапе, как было опи-
сано выше.

На фиг. 4.3.1 представлена- информационная блок-схема алго-
ритма Розенброка, а на фиг. 4.3.2 приведена траектория поиска при
минимизации фуншии Розенброка с помощью этого алгоритма.

Пример 4.3.1. Метод Розенброка

Проиллюстрируем алгоритм Розенброка в приложении к задаЧе
примера З 4 1

Минимизировать і(х)— _ 4(х1—5)”+ (::2 ——6)“. Известно, что эта
фуншшя имеет минимум в точке х“ = [5 61Т ‚ Где і(х*)= 0. (В це-
лях экономии места будем окрутлять числа.) Начнем из точки
х‘°’= [8 911, где і(х(°))— — 45,000, % = 0,10. При этом направления
начального поиска совпадают с координатными осями х1 и х„:

№…. замш—
 pagebreak 
180 Г лава 4

‘”г
3,0
2,5
2,0
1.5
ас“) (, 15 “*
40 50 206
180
48 ?‘5
05 164
56
140
720
76 86 96
___—
..1’0 0,5 ’‚0 ":
‚д‘:
$0
—05 / «›

Ф ир. 4.32. Траектория поиска при минимизации функции Розенброка методом
Ровенброка (числа обозначают количество вычислений целевой функции).

Сначала вычислим )* (х) в точке

[в,оо+о,хо.1 8,10
"= 9,оо+о‚1о-о = 9,00'

Здесь [(х) = 47,44, т. е. имеет место неудача. Затем вычислим

{(х) в точке
__ 8‚оо+о,ю.о 8,00
"— 9‚оо+о‚1о-1 : 9,10 '
 pagebreak 
Методы минимизации, нг использующие производные 181

 

Здесь [(х) = 45, 61 и снова имеет место неудача. Таким образом,

на следующем цикле и А, ‚и 7% должны быть умножены на В = —О, 5,

или 713 = 714 = —0‚ 50 0,10 = —0‚05. Возмущение проводится из

последнего успешного значения х, т. е. из точки х = 18,00 9,001Т.
Сначала вычислим [ (х) в точке

8,00—0,05- 1 7,95
"— 9,оо—о‚05-о _ 9,00 '

Здесь НХ) = 43,81, что означает успех. Затем вычислим [(х) в

точке
7,95 — 0,05 ‹ 0 7,95
= [990 _ 0,05 . 1] = [8,951
где [(х) = 43,125, что снова означает успех, На следующем цикле
71. умножается на 3, т. е. 715 = А„ = 3 — (—0,05) = ——0,15.

Ниже пр иведены несколько последовательных ЦИКЛОН первого
ЭТВ па .

 

 

Номер поиска А ‘ ‚$1 ‘ х; ; 7 [х) {1336112538531}!
5 —0,15 7,80 8,95 40,06 $
6 —0, 15 7,80 8,80 39,20 5
7 —0‚45 7,35 8,80 29,93 5
8 —О‚45 7,35 8,35 27,61 $
9 — 1 ‚35 6,00 8,35 9,522 $
10 ——1‚35 6,00 7,00 5,000 5
11 —4‚05 1,95 7,00 32,21 Р
12 —4,05 6,00 2,95 13,30 Р

 

Теперь уже В каждом КООРДИНЗТНОМ направлении за успехом ПО—
следовала неудача, и, Таким образом, закончился нулевой этап ПО-

1
иска. Затем ВЫЧИСЛЯЮТСЯ новые направления поиска ТЗК, чтобы 51)

было направлено вдоль вектора, идущего из хЪ°)= [8 91Т в хЬ“=

= [6 ПТ, причем последняя точка соответствует наилуЧЩему зна-
чению Дх), полученному на нулевом этапе; 5…ортонормировано к
50" (фиг. П. 4.3 13) Векторы АЁИ АЁ" вычисляются по формуле

(4.3.1), а з. и 39—110 формуле (4.3.2).
 pagebreak 
182 Глава 4

30) _ 1—2 —21т _ [ 1 ]Т
1 _ ___—1— — __ _ _ _ 7
[‹—2›2 + (421 ’-

^‹1›= 11—117 =
“’ […ты—№1”- [_ _]

В первом цикле на первом этапе поиска (12 = 1) берем 761 = ?„ =
= —4‚05 ‹ (—0‚5) = 2,025. Сначала вычислим [(х) в направлении
поиска 1 в точке

_ [6,000 + (2,025) . (_ 0.706) 4,568
" “ 7,000 + (2,025) - (_- 0.706)] = 15,5681

Здесь [(х) = 0,9327, что означает успех. Затем вычислим [(х)
в направлении поиска 2 в точке

_ [4,568 + (2,025) . (0,706) 6,000
" * 5,688 + (2,025) . (__ О,706)] = 14,1861“

Здесь [ (х) = 7,474, что означает неудачу. Остальные данные для
первого этапа приведены ниже:

 

 

 

Номер поиска 1. 161 ‚ хя | 7 … УЁЗЁЁаЁ) (иван
3 6,075 0,272 1,272 1 1,175 Р
4 —1,125 3,852 6,284 5,351 Р
5 “3,038 6,716 7,716 14,722 Р
6 0.506 4,926 5,210 0,646 $
7 1,518 3,852 4,136 8,743 Р
8 1,518 6,000 4,136 7,473 Ё

Поскольку движение в направлении 1 приводит к успеху в
первых двух поисках, а в направлении 2 — к неудаче, то в поис—
ках З и 4 берем А„ = 3 . 2,025 = 6,075 и 7», = —0,5 - 2,025 =
= _],0125 соответственно. Заметим, что после неудачи в поисках
3 и 4 ?», = 6,075 и А, = —1,0125 умножаются на —О‚5‚ что дает
соответственно ?», и Ж,. После поиска 6 имел Место успех по каждому
направлению, а после поиска 8 произошли две последовательные
неудачи, так что в соответствии с данным алгоритмом на этом
 pagebreak 
Ю
_9 ..--..__....._.... (8,9)
|
в |
|
7 —————————— |
6 1] в |
ал а
№№ Мжа???
|
.5 ‚‚ 7 в .9 „’
Ф и г. П.4.3.1а.

4'0

„гоу

      

0 2 4 б 8 .:,
Ф и т. П.4.3.1б. Траектория поиска для алгоритма Роэенброка.
 pagebreak 
184 Г лава 4

 

этап 1 закончился. Теперь должно быть определено новое направле-
ние поиска. На этом мы закончИм рассмотрение данного примера.
Однако приведенная выше процедура была продолжена пока не был
удовлетворен критерий сходимости {это потребовало 111 вычисле-
ний значений целевой функции, и относительное отклонение
Пхи”) от правильного значения, равного 0, соотавило 5,5 - Ю“",
относИтельное отклонение х1 равнялось 3,0 - 10”, а отклонение
х2 составило 4,4- 10““].

На фиг. П.4.3.1б показана траектория основной части минимии
зации на первых четырех этапах (34 вычисления функции); после

проведения этих этапов были получены х… = [5,036 5,9381Т и

[ (х…): 9,46 - 10‘3‚ Остальные 77 вычислений функции понадоби—
лись для увеличения точности х и ‚‘ (х).

 

4.4. МЕТОД ПАУЭЛЛА

В методе Пауэлла [10], который является развтием алгоритма
Смита [11], определяется местонахождение минимума некоторой
квадратичной функции )*(х) при Н > О путем проведения последова—
тельных одномерных поисков, начиная с точки ХЕР, вдоль системы
полученных сопряженных направлений. Напомним (см. подразд.
3.3.1)‚ что два направления поиска 5, и 5, называются сопряжен—

ными, если
№15.- = 0. нед

‹здТОз, >О, і: 1,

где 0 =72і (х‘*’)——положительно определенная квадратная матрица.

Нижние индексы обозначают векторы одного этапа (последние
обозначаются верхним индексом). Идея алгоритма Пауэлла в сущ-
ности заключается в том, что если на данном этапе поиска опре-
деляется минимум квадратичной функции „х) вдоль каждого из
р (р < п) сопряженных направлений и если затем в каждом направ-
лении делается некоторый шаг, то полное перемещение от начала
до р-го шага сопряжено ко всем поднаправлениям поиска. Таким
образом, этот метод аналогичен партан-методу, описанному в под-
разд. 3.3.3.

Переход из точки хЬ'” в точку ХЬЁ’ определяется формулой
» [а "‘—' н »
х‘‚„>=хЬ’+2М’эЁ-’. і=1‚...,т—-1. (4.4.1)
[=“

Вычислительная процедура данного алгоритма проводится следую-

щим образом. В точке ХБ“) в Б” начальные направления 53°), ..., 5$?)
 pagebreak 
Методы минимизации, ме использующие производные 185

берутся параллелшыми координатным осям Е". Первый шаг делает-

0
ся в направлении 551 ’, т. е. минимизируется {(хБО) + АзЁЁ”)по ?» (с по-

мощью одномерного поиска) для вычисления А3”. Затем полагается

@ ,да)

    

.. а 0
Ф и г. 4.4.1. Метод поиска Пауэлла.

(0)
1
то первый обнаруженный минимум. Затем вдоль каждого из п на-

х‘1°> = хЁ” + №0520). Как видно на фиг. 4.4.1, в точке х имеет мес-

правлений 55°), і = 1, ..., п, в свою очередь минимизируется [ (хЪО’ +
+ Ыо’), определяется соответствующее АЁЩипоследователы-ю вычис-
ляюгся по формуле (4.4.1) новые значения ХБО’. На фиг. 4.4.1

0 ‹:
показано расположение точек ХЕР), мас), 3320) и 163) для следующеи

целевой функции, представляющей собой функцию двух переменных:

Дх) = 2х? + х; —— хм,.
 pagebreak 
|86 Глава 4

 

Координатные оси в Е" имеют направления

1 0

(0) (0)

$ __ ‚ _ ‚
1 [0] 82 [1 ]

Они Тортогональны, т е. (5…))Т (5% о)): 0 но не сопряжены, поскольку

(530$ №9”: 4550. Расположение соответствующих минимумов [(х)
показано в следующей таблице:

 

(0 Т А…) Ш) Г , ХФ) в точке
№1 … | ‚ … №№
0 [О 1] —\ [2 1] 7
1 [1 0] — 1,75 [0,25 1] 0,875
2 [0 1] -—0‚875 [0,25 0,125] 0,109

Чтобы понять, какую роль в алгоритме Пауэлла играют сопря-
женъхые направления, рассмотрим следующую теорему, имеющую
место для квадратичных целевых функций:

Теорема

Если при начальной точке к“” поиска в направлении 5 минимум
[(х) находится в некоторой точке х… и если при начальной точке
х… ;& х…) поиска в том же самом направлении 5 минимум НХ)
находится в точке х…; то при [ (х…)<і (х…) направление
(х… _— х‘“’) сопряжено с з.

Приведем доказательство этой теоремы, Из формулы (3.3.7)
следует, что для первого поиска

эти №) = вт (Нк… + Ь) =

577} (х…) = вт (НХ… + Ь) = 0.
ВЫЧитая‚ получаем
5Т Н (х… __ х(“)) = О

Следовательно, $ и (х…— х…) сопряжены. Из фиг. 4.4.1 видно, что

(и хю (0 ХШ)
(ха ’— :”) Н<хз ’— х›=0
(0)

где хо соответствует точке х“ в формулировке теоремы, а любая

точка на прямой (хз ‹0›__ х‘д‘”) соответствует точке х ’. Для примера
фиг. 4.4.1

_ 4 _1 (025—200) :
“035—0250 (0,125 1,000)1[_1 2] [‹0'125_ дощ]

и для второго
 pagebreak 
Методы минимизации, не использующие производные 187

 

Эта теорема непосредственно может быть распространена на слу-
чай нескольких сопряженных направлений; если, начиная из

х‘°’, точка х… определяется после использования р сопряженных
направлений (р< п) и аналогично если. начиная из х”, точка
х… определяется после использования тех же направлений и

[(х) минпмизируется на каждом шаге, то вектор (х… _— х‘”) соп-
ряжен ко всем р направлениям.
Таким образом, мы определили два сопряженных направления,

в которых следует вести поиск. Следовательно, направление а“”

должно быть заменено на направление вектора (х‘о’ _ к“”), пред-
ставляющего собой полное перемещение из первого минимума.

Направления ПОИСКЕ на следующем этапе таковы:
8… _ 5(20)

5(1)_ __(х(0)_ кап)).

Второй этап поиска снова начинается минимизацией, на этот раз
вдоль направления $…. Затем осуществлятся, если это оказыва-

ется необходимым, перемещения в направлениях з") и $52“.
Вспомним, однако, что для квадратичной целевой функции двух
переменных после использования двух сопряженных направлений
сразу достигается минимум (фиг. 4.4.1).

Алгоритм Пауэлла несколько отличается от простых начальных
шагов, описанных выше.

В общем случае На іг-м этапе метода Пауэлла используются „

линейно независимых направлений поиска; при ЭТОМ ПОИСК начи—

нается в некоторой точке хЪ ’ = 32:1“ и проводикя следующим

образом:

Шаг !. Начиная из хо ‚ с помощью какого- -либо одномерного
поиска определяется А“” так, чтобы [(хЬ’” + Мэ)” ) принимала мини-
мальное значение, и полагается х…= “” +73”); ('”. Начиная на х…,
определяется ?»“ так, чтобы {(Х “')-4425$”) обращалась в минимум
(" ’: к“” + „”$ ,” .Поиск продолжается последователь-

(’?)

и полагается хи
но в кзждом напр=авлении, всегда начиная из самой последней точки

последовательноети, пока не будут определены все А“”, != 1, …, п

Величина М). полученная при минимизации Нк) в направлении; 5)?" ";”
непользуется на шаге 4 (см. ниже).

Шаг 2. Пауэлл отметил, что поиск, осуществляемый в соответ—
ствии с шагом 1, может привести к линейно зависимьш направле-
ниям поиска (см. разд, 4.3), как, например, в случае, когда одна
из компонент 5… становится тождественным иулем, поскольку
в этом направлении не может быть движения. Следовательно. два
направления могут стать коллинеарными. Таким образом, не
 pagebreak 
188 Г лава 4

 

следует заменять старое направление на новое, если после этого нап-
равления нового набора становятся линейно зависимыми. Пауэлл
показал также (на примере квадратичной функции), что при нор-
мировании направлений поиска в соответствии с формулой

(#))ТНЗЪ-ты, [= 1, „,

определитель матрицы, столбцы которой представляют собой на-
правления поиска, принимает максимальное значение тогда и только

1:
тогда. когда в,!) Взаимно сопряжены относительно Н. Он пришел

к выводу, что направление полного перемещения на !г-м этапе
&… должно заменять предыдущее направление только в том слу-
чае, потда заменяющии вектор увеличивает определитель матрицы
направлений поиска, поскольку только тогда новый набор направ-
лений будет более эффективным. Следовательно, после минимиза-

ЦИИ " (х) в каждом из п направлений, как на шаге 1, проводится

один дополнительный шаг величиной (х?) — ХБ“), соответствую-

щий полному перемещению на !г-м этапе и приводящий в точку
(2х9 —— хБ’”). Затем проводится тест (см. шаг 3), чтобы убедиться,
уменьшается ли определитель матрицы направлений поиска путем
включения нового направления и отбрасывания старого.
Шаг 3. ОбознаЧИм наибольшее уменьшение ‚‘(х) в каком-либо
направлении поиска на !г—м этапе через
№ = _ так {і №.) —і(х$'”)}-

»:1, п
Направление поиска, соответствующее з-юму максимальному изме-
нению Дх), обозначим через 5%). Чтобы сделать обозначения более
;; ::
компактными, положим [1 = НхЪ )), & = Пхи и {‚ = {(2х2‘) — ХБ”),
_ :: ь "
где ХБ”) = ::(: 1) и ХЦ”: ХЁЦ + 73:52) = хъ ) + 2 Мюзі-Ё). Тогда если

ъ'=1

Гз>і1и ("ли) (Ё—21%+іэЖ/сх—ів—А(Ё))2>0›5Ащ‹і1_‚з)2› ТО

следует использовать на (12+ 1)-м этапе те же направления 5$“),

(!:+1) А

;; .

…, 5%”, что и на !г-м этапе, т, е. &; —-$$-’ для ъ=1‚...,п, и на-
1 іг :;

чать поиск из точки х8“+’=х(‚{г) [или из Хён”) = 2х9—х5’ = ХБ,“ 1

в зависимости от того, в какой точке х функиия [(х) принимает
наименьшее значение].
Шаг 4. Если тест на шаге 3 не удовлетворен, то ищется мини-

;;
мум {(х) в направлении вектора &‘ ), проведенного из ХХ” в хи"; точ-

ка ЭТОГО минимума берется В качестве начальной ДЛЯ следующего

(іг+1)—го этапа. Система направлений, используемых на (іг+1)-м

этапе, та же, что и на !г-м этапе, за исключением направления 5%),
!:

которое заменяется на &‘ ’. Однако 5“" помещают в последний стол-

бец матрицы направлений, а не на место 5352. СледователЬНо, на
 pagebreak 
Методы минимизации, не использующие прошврдные 189

 

(іг+1)-м этапе будут использоваться следующие направления:

[5‘1"+1)5Ё”+” . . . 555+”1 : [ЗЁЮЗЬЩ . . . 5531155341 . . . $Ё)5(ь)1.

Шаг 5. Критерий удовлетворительной сходимости для метода
Пауэлла, используемый для определения момента окончания поис—
ка в конце любого этапа, состоит в том, что изменение по каждой
независимой переменной должно быть меньше, чем заданная точ-
ность е„ і = 1, ..., п, или ЦХЁ) — ХБ”) || < 0,1 &.

Зангвилл [121 показал, что процедура Пауэлла (немного моди—
фицированная) будет сходиться к точке, в которой градиент [(х)
равен нулю, если [(х) —— строю выпуклая функция. Такая точка
представляет собой локальный экстремум.

На фиг. 4,4.2 приведена информационная блок-схема алгоритма
Пауэлла, а на фиг. П.4‚4.2 показана траектория поиска при мини—
мизации функции Розенброка.

 

Пример 4.4.1. Метод Пауэлла

Продемонстрируем метод Па элла на примере следующей зада-
чи: минимизировать і \х) = 4 х1 — БР + (х., — 6)“, начиная из
точки к“” = [8 91Т. В точке х… функция [(хш’) имеет значение
45, 000. Сначала минимизируется [ (х…), 1») по ?… с помощью одно—

мерного поиска в координатном направлении 1:1 (х, остается равным
9,000):

 

‚1:1 ’ ! (х)

 

8,000 45,000
7,992 44,808
7,952 43,857
7,752 39,294
6,752 21,278
1 ‚752 51 ‚1 98
5,460 9,847
4,043 12,657
6,335 16,135
4,919 9,026

5,000 9,000 (минимум [ (х…)
 pagebreak 
Если &=& эіюлмагцютея парал-
лмдними таруинитнпм атм,
Мрааующим Е”

  
    
 

   
 

 

     

   

Выполняются иш „щадящим
шыш»: ‹ Ю"“ и
::; д[_м) _ :: ш

_Пгі-‹5‚і=/‚…, !: ?
!

   
   
 

    

     
 
 
 
 

( ;
длреуншлп .;1‘ ‚(:,/там „”’а—
лилшшции (аль.` нц $,- )

: димащью оуламе лага доис—

ки ли А,.

   
    

тенитд 5… на этти дуги.:

”В Меди
35/5555!“ Ы, л ‚› і; т

ь' ›

 
 
 
    

     
 

    
       

длреуелитд минимум {(лет ) .;

налрамемии а“} начинаддиз т,?!
Мажито ас равным 0:„ '

 
 
  

  
 
   

… Би

:!:”, = 2“:

ислатв
3) _ :“…

   

„

 

     
  

 

       

Вмчц итд ато м
›‹(шЁЁ— мг;“; „“В“./, л.

Инуетож т абоэличитв ла-

правлеізце $$?, тотаетдтвую—

щее А’

      
 
      
    
  
 
 

   

тт:“? ›; пт:”) ……
(г) [«.-355); - глаз;“ › + миг}, ›][і‹ас‚5^’›—г‹аь‘„‘”)—А“’ ‘;

> (и ‚ "’[і(м5,“›— ‚(а:‘і’, ›]г?

   
  
  
 

   

  

‘ лажцть
5 .и: :;

 
     
 
 

ттт»
"”а : ш,",

   
  
 

    

   
 
 

 

№355 шыш) г

      
   

Жо.,ложитв
:‚ " - ас,?”

Ф и г. 4.4.2. Информационная блок-схема для метода Пауэлла.
 pagebreak 
Методы минимизации, нв использующие производные 191

 

Затем одномерный поиск осуществляется в направлении х„
начниая из точки с координатами хЁ') = 5,000 (эта коордушата

остается далее постоянной) и иё” = 9,000:

 

 

#2 ! (8)
9,000 9,000
8,991 8,946
8,946 8,678
8,721 7,403
7,596 2,547
1,971 16.232
6.142 0,024
4,549 2,104
7.127 1,271
5,534 0,217
6,000 5,44- 10—15

Осуществление шага 363.1 = 2х5?) 4— х‘оо’ приводит к

2 5,000 __ 8,000 : 2,000
6,000 9,000 3,000 '
В этой точке ;(хщі) = 45,000. При этом значение АЮ) равно

№ = тах 1110,91— 115,91]. 1100140011) = 36.
Заметим также. что

712,3) = 45,000 > ? (8,9) = 45,000
и

11° (8.9) -— 2і (5,6) + і(2‚3›10°(8‚9› ——і(5‚6)— 36]2 >
> 0,5 - 36 0 (8,9) — 1 (2.3012 > 729 > 0.

Следовательно, на следующем этапе вектор поиска будет тот же,
что и на предыдущем. Тем не менее поиск заканчивается в точке

х* = [5 611, поскольку критерий сходимости удовлетворен. На
фиг. П.4.4.1 приведена траектория поиска.

Пример 4.4.2. Метод Пауэлла для функции Розенброка
Применение алгоритма Пауэлла к функции Розенброка

ПХ) = 100 (хи— 163)“ + (1 —- хд)’
 pagebreak 
192

Глава 4

 

2 6

Ф иг‚ П.4.4.1. Траектория поиска в

случае использования алгоритма Пау-

элла (числа обозначают количество вы-
числений целевой функции).

4

<!) : х10)_ (0)_ _ О 995

52 2 ° [_ 0, 990

1/ (з…)? + (зё")ё= У— 4,21

… 0,999

52 = ‚
——0‚0488

 

дт,

показывает, ЧТО ПРОИСХОДИТ ПРИ
МИНИМЦЗЗЦИИ неквадратичной

функции. Начнем с точки ХШ):
=1=1‚2 1,01’, где их“”) =
= 24,2. Начальные направления
поиска следующие:

°]

[111] &=&

Сначала минимизация Дх) осу-
ществляется в направлении по—
иска 51(°>‚т. е. в направлении ›:1
(детали этой процедуры здесь не
приводятся), что приводит к точ-
—‚—09951‚000]Т, в ко-

торой і(х‘, ‘”) = 3,990. Затем осу-

ществляется поиск, использую-
щий вектор 52°), т е в направ—
‘Щ— _— 0, 995

лении хз, что дает хг =

О ‚9901 ‚ где ;“(хё 0’) = 3 ,.980 Пос—
ле выполнения шага

0,995
(0):
"3 2[ 0,990

_ _ 1,200 : 0,790
1,000 0,980 ‘
где { (№ 0’1 = 15, 872, вычис—
ляются новые направления по-
иска:
% = И
_ 12,00 0205
1,000 -—,’0010
10—?=0,206,

поскольку не удовлетворяется упомзшутый выше (см. шаг 3) крите

рий (А…): 24 2 —— 3, 99: 20 „21)

№5…) —

15,872 < ‚° №) = 24,2

(а)
 pagebreak 
Методы минимизации, не использующие производные 193

 

и
[24,2 —2 - 3,980 + 15,372] [24,2 —— 2,980 — 20,21]2 <

<0,5 - 20,21 - (24,2 —— 15,872)“. (6)

Результаты нескольких дополнительных Э'ГЗПОВ поиска, начи-

 

 

 

ная с точки 718” = [—0‚990 0,9901Т, приведены в следующей таб—
ЛИЦЕ:
Этап „1110,7 , [55210] ‚ „(ь) „,…,
1 [0 11 [0,205 —0‚0101 х51>=[—0,990 0,990[7 3,969
х?) = [—0,990 0,9901Т 3,959
х‘,“ = [—0,984 0,9791Т 3.948
2 10 11 №53 —0.8921 хз” =[—0‚761 0,5401Т 3,257
х52>=[_.0,761 0,579? 3,101
‚4,9 = [—0,702 0,402]? 2,986
3 [0,453 _ 0,892] [0,608 —0,7941 „1,31 =[—0‚503 0,203]7 2,510
43) : [—-0‚538 0.27з[Т 2,390
::(23) = [—0,466 0,1781Т 2,301

 

 

На фиг. П.4.4.2 представлена траектория поиска. В общей слож—
ности для получения минимума целевая функция вычислялась

1562 раза, при этом минимум имел место в точке х* = [1,000 1,0001Т
И і(х*) = 1,338 - 10_1° @ 01

 

4.5. МЕТОДЫ СЛУЧАИНОГО ПОИСКА

Излагаемые ниже методы случайного поиска наименее изящны
и эффективны по сравнению со всеми другими алгоритмами поис-
ка, однако благодаря использованию современных высокоскорост-
ных цифровых и гибридных вычислительных машин эти методы
все-таки оказываются практически полезными. Обзор различных ти-
пов методов случайного поиска сделан Бруксом [13]. Фавро 1141 и Ман-
сон предложили методы выполнения случайного поиска на аналого-
вой вычислительной Машине. Митчелл [151 предложил метод, исполь—
зующий гибридную вычислительную машину, в которой выбор
различных стратегий случайного поиска и изменение величины
 pagebreak 
194 Глава 4

3.0

2:5

1,5 т,

 

Ф и г. П_4.4.2. Траектория поиска при использовании алгоритма Пауэлла (числа
обозначают количество вычислений целевой функции).

шага осуществлятся логическим блоком цифровой части. Ниже
кратко излагаются некоторые процедуры, использующие случайный
поиск.

4.5.1. КОМПЛЕКСНЫЙ МЕТОД

Хотя комплексный метод был разработан Боксом [161 примени-
Тельно к задачам нелинейного программирования с ограничениями
в виде неравенств, мы включили его в настоящий раздел потому,
что он основывается на использовании случайных направлений
поиска. Этот метод возник из симплексного метода Спендли и др.,
описанного в разд. 4.2. Здесь вершины вычеркиваю'юя и добавля-
 pagebreak 
Методы минимизации, не использующие производные 195

 

ются, как и в симплексном методе, но не делается попытки сохра—
нить регУлярную фигуру. что характерно для симплекс-метода.

Затруднение, встречающееся при использовании метода Спенд-
ли и Нелдера, а также метода Мила при часто повторяющемся ог—
раничении. состоит в том, что необходимо удалить каждый раз
недопустимую вершину многогранника, пока'не будет получена
допустимая вершина. После ряда таких операций многогранник
становится размерности (п —— 1) или меньшей и процедура поиска
значительно замедляется. Более того, если данное ограничение пе-
рестает быть активным, то такой «сплющенный» многогранник трудно
«расширить» снова в п-мерное пространство. Чтобы избежать этих
трудностей, Бокс выбрал многогранник с более чем п + 1 верши-
ной, который он назвал комплекса . (Митчелл и Каплан, рабога
которых приведена в списке литературы в конце этой главы, описали
комплексный метод, не использующий случайную процедуру.)

В комплексном методе используются (п + 1) или более вершин р_
(каждая из которых должна удовлетворять ограничениям на всех іг

этапах). Сначала определяется некоторая начальная точка хі')’,
а затем выбираются (р -— 1) дополнительных вершин с помощью псев-
дослучайных чисел в соответствии со следующим соотношением:

х$°>=ь‚+г$°’‹и‚‹——Ь‚-›‚ '=2. -р‚

где [„ и 0, представляют собой соответственно нижнюю и верх›

нюю границы для х‚., 8 г$°’ является диагональной матрицей псев-
дослучайных чисел, равномерно распределенных на интервале
(0,1). Если границы неизвестны, то исходный многогранник должен
быть выбран так, чтобы он покрывал область поиска.

Затем целевая функция вычисляется в каждой вершине, и вер—
шина, в кторой [ (х) имеет наихудшее значение, заменяется новой
вершиной, находящейся на прямой, проходящей через отброшен-
ную точку и центр тяжести оставшихся точек на расстоянии, рав-
ном или большем, чем расстояние от отброшенной точки до центра
тяжести. Если окажется, что в новой вершине имеет место наихуд-
шее значение і (х) по сравнеНИЮ со всеми вершинами в новом мно—
гограннике, она заменяется другой вершиной, расположенной на
расстоянии, равном половине расстояния от новой вершины до
центра тяжести. (Если нарушается ограничение. то невая вершина
также передвигается на половину расстояния к центру тяжести,)
Исходя из эмпирических исследований, Бокс предложил, чтобы
растяжение многогранников определялось множителем, равным
1,3, и чтобы при поиске использовались р = 2п вершин. Растяже-
ние на этапе отражения многогранника и использование более
чем (п + 1) вершин являются как раз теми чертами процедуры,
которые предназначены для предотвращения «уплощения» многоч
гранника, когда поиск происходит вблизи ограничений. Процедура
 pagebreak 
196 Г лава 4

 

поиска продолжается, пока многогранник не будет стянут в центр
тяжести в пределах заданнои точности.

Числовые результаты, полученные Хиллари [17], показали.
что скорость сходимости комплексного метода зависит от характера
исходного многогранника. С другой стороны, Бокс пришел к вы-
воду, что метод Розенброка более эффективен, чем симплексный или
комплексный метод для задач без ограничений, и что при увеличе—
нии размерности п функции [ (х) количество необходимых вычисле-
ний целевой функции для комплексного и симплексного методов
возрастает вдвое быстрее, чем для метода Розенброка.

4.5.2. ПОВТОРЯЮЩИИСЯ СЛУЧАЙНЫЙ ПОИСК

Келли и Уилинг [18] предложили алгоритм полностью случай-
ного поиска на каждом этапе минимизации. После того как задана

начальная точка х…, строптся случайная траектория дня после-
довательности шагов, каждый из которых проводится в направле-
нии от некоторой точки х, где НХ) минимальна на данном этапе
случайного поиска, до следующей точки х, соответствующей еще

более низкому значению функции. Таким образом, начиная из
(0)

точки ›‹ , случайное значение х… получается по следующему
соотношению:
(!:)
?: 1 12 [г 2 із
х(+)=х()+7ь[)[БЩ+(1—Б)г()]‚ (4.5.1)
где

ж… _величина шага, скаляр, который увеличивается после

успешного шага И уменьшается после неудачного шага;
(Ё)

: _вектор «предыстории», указывающий среднее направле—
ние поиска на предыдущих шагах:
(& 1) 1; :: 1 (л; (ь _
: + :ти”+‹1—т›‹х‘+’—х ’)з ’,
г… ——единичный вектор нормальных отклонений, реализуемый

генератором псевдослучайных чисел;
6— коэффициент, изменяеМЫй в процессе поиска;
? _ постоянный весовой множитель;

ь „
5‘ ’ _ вектор масштабных множителеи для «подходящего» мас-
штабирования пространства х;

На 12-м этапе, чтобы получить ХИ", случайный вектор гиг) и
вектор предыстории :… усредняются, как видно из соотношения
(4.5.1), Вектор х"+1 будет принят или отвергнут в зависимости
от того, выполняется или нет неравенство [(х’°+')< Нхо”).

После того как хи" принят (или отвергнут), №) увеличивают

(или уменьшают) с помощью множителя, грубо говоря, зависящего
 pagebreak 
Методы минимизации, же использующие производные 197

 

{",—‚

`!

Ф и г. 4.51. Типичная траектория при случайном поиске. Пунктирными стрелка-
ми представлены исследующшэ шаги, которые были отвергнуты. а сплошными
стрелками — шаги, на которых значения целевой функции уменьшались,

 

от того, был ли поиск трудным или легким. На фиг. 4.5.1 приведена
гипотетическая траектория поиска в двумерном случае.

Проведенные испытания этой программы на некоторых задачах
показывают. что она работает в общем случае менее удовлетвори-
тельно‚ чем другие алгоритмы, описанные ранее в гл, 3 и в настоя-
щей главе. Мы не будем обсуждать этот вопрос подробно (тем не
менее читатель может обратиться к табл. 9.3.3 и 93.4).

453. СЛУЧАЙНЫЙ ПОИСК С ПОСТОЯННЫМ РАДИУСОМ
ПОИСКА И СЛУЧАИНЫМ НАПРАВЛЕНИЕМ

На фиг. 4.5.2 проиллюстрирован ме'юд поиска, в котором ра-
диус поиска в любом направлении постоянен, но направление
поиска случайно. В двумерном случае проводится окружность
с начальным вектором х‘°’ в качестве Центра. В п—мерном случае
это соответствует гиперсфере. В выбранных случайным образом

точках на этой окружности вычисляют { (х) и отмечают точку к“”
с пандучшим значением целевой функции. Затем проводят поиск

вдоль прямой, проходящей через х… и ха”, и отмечают точку х…,

где )* (х) имеет минимальное значение, После этого процедура по-
вторяется, начиная сточки х…. С увеличением радиуса окружности
поиска (однако так, чтобы он не был слишком большим) точка х…
будет приближаться к х* (искомяя точка минимума). Любая точка
на сегменте, заключенном между пунктирными линиями на фиг;
4.5.2, лучше, чем точка, определенная минимизацией по методу
 pagebreak 
198 Г лава 4

 

наискорейшего спуска, но хуже, чем точка х…, полученная по методу,
использующему производные второго порядка. Чтобы получить
удовлетворительную сходимость, последовательность радиусов
окружностей (или гиперсфер) периодически уменьшается. Поиск
может быть ускорен, если точки на гиперсфере выбираются слу-
чайно, но с ограничением, чтобы они отклонялись по крайней мере

Сектор, рающии'

лучшее налрамекие,
\/ чем грауиелт

  
  
   
 

\
\ Налрамение поиска

\ , ум? окдужнаати №!

.
\ Направление пошта /
\\ № окружности №2 /
зтижгэужнаоти \ Ю
\

    

$

и] ‹› -
по до лета
лацикорейиёіа

служа

Направление
отрицатвлшаю
тушит

.:
Фиг 4.5.2. Случайный поиск, иллюстрирующий эффект изменения радиуса

ПОИСКЕ.

не более чем на некоторый минимальный угол как по отношению
друг к другу, так и к предыдущему направлению поиска. Этот
минимальный угол может быть также изменен во время поиска.
Можно показать,_ что если выбирать направляющие косинусы
0, определенным образом, то случайные направления поиска будут
покрывать проетранство х по закону равной вероятности, Действи-
тельно, определим направляющие косинусы следующим образом:
4$
«%+ +45” '

где (1, —— случайная переменная, подчиняющаяся нормальному за-
кону распределения с математическим ожиданием, равным 0, и
дисперсией о’і. В двумерном случае угол поиска равен

[_

95 = агсщ %:— : агстд % .
 pagebreak 
Методы минимизации, нг использующие производные 199

 

Можно показать, что переменная ф равномерно распределена в
интервале (—л/2‚ 11/2). Если размерность задачи равна п, то углы
ф… спроектированные на любую коордшштную плоскость, также
равномерно распределены.

Для сравнения случайного поиска, оптанного выше, с неслу-
чайным поиском определим относительное улучшение, или «выиг-
рыш», в {(х) за один этап как

_. __ ‚‹(ХОЮ) _ і (‚‘(Н—Н)
Ь (Ё) & , (х…)

Если в окрестности х… на поверхности гиперсферы выбирается М
векторов х и Линейный поиск проводится в ка›:‹дом направлении

1,0 —ггг|—Т—|—т—г—‹

пяід

`
М

  

Латшатичгстое ожирение [(г)

‹;о

 

100

1_._|.__т..|п_.1_ыі__...__|__д_._1___і
г 5 Мю га 50

Ф и г. 4.5.3. Математические ожидание выигрыша на цикл в зависимости от чис-
ЛВ векторов Х, ИСПОЛЬЗОВЗННЫХ ДЛЯ определения направления ПОНСХЗ (целевая
функции — сфероидальная) [20].
п — размерность задачи.

7

х…, то можно получить математическое ожидание величины Е (іг)
как функции М и размерности и. На фиг. 4.5.3 приведены графики
математического ожидания Е (іе) для задачи со сфероидальной целе-
вой функцией. Эти графики могут быть интерпретированы следую-
щим образом. Сравним „ = 18 и М = 3, что дает Е_(З) % 0,12,
с п = 18 и М=6, что дает Е (б)ъ0‚17. На двух циклах с М=3
выигрыш будет … 0,24 по сравнению с 0,17 для тою же числа
 pagebreak 
200 Глава 4

вычислений целевой функции при М = 6. Следовательно, при и =

= 18 более эффективно использовать меньшее число векторов ):
на гиперсфере, но чаще делать итерации.

Общий принцип, заключающийся в том, что для хорошо промас-
штабированных функций регулярная процедура минимизации более

10000

1000

100

 

1 10 то юао ' 10000
Иша иичшжиё „”типа

Ф и г. 4.5.4. Сравнение трех методов для случая 18-мерной задачи.

. градиентный метод; А повторяющнйся случайный поиск: . метод, использую—
щий направления линейного поиска. определяемые по 18 случайным точкам иа гиперсфевщ

і (х) = :? 4—м; + 315+ 4х2 + 513+ 6хё+ 7:34- вдё + 9х3 + хоха, +
+ 0.9%, + шах?2 + оля?з + а.ехі4 + 0,5% + 0,4»?6 + 0.3%, + 0,2%.

эффективна. чем чисто случайная, проиллюстрирован на фиг. 4.5.4,
где сравниваются три метода:

1) граДИентный метод (подразд. 3.1.1);

2) повторяющийся случайный поиск (подразд. 4.5.2);

3) метод, использующий направления линейного поиска, опре—
деляемые по случайным точкам на гиперсфере (подразд. 4.53).

Второй и третий методы минимизации приблизительно равно-
ценны по эффективности и оба менее предпочтительны. чем первый
метод. Случайные методы и методы «последовательные перебора
переМенных» без поворота осей менее эффективны, чем неслучай—
ные методы, описанные в предыдущих разделах.
 pagebreak 
Методы минимизации, пе использующие производные 201

 

ЗАДАЧИ ' )

4.1. Для целевой функции
ПХ) = 3х? + 5165
(0) __

проведите три этапа поиска Хука—Дживса. Используйте Ах _
= [0,5 0,517, начиная ‹: базисной точки х…) = [2 Пт. (На каждом
этапе проводится локальное исследование с последующим ускоре-
нием.)

4.2. Продолжите поиск Хука _ Дживса из точки х‘
4.4.1 для — этапов.

4.3. Определите регулярную симплексную фигуру в трехмер—
ном пространстве, такую, что расстояние между вершиними равно
0,2 и одна вершина находится в точке (—1‚2 ——2).

4.4. Используйте симплексную фигуру, построенную в задаче
4.3, для проведения восьми циклов ‹угбрасывания вершин и полу-
чения новых при поиске минимума целевой функции

і(х)= хЁ—і—ЗхЁ—і—Бхё.

4.5. Трехмернъхй оптимальный. симплексный поиск минимума
дал следующие промежуточные результаты:

7) примера

 

Вектор .: Значение целевой №№
[0 о 011 4
[4/3 —1/3 _1/з1Т 7
[—1/3 4/3 —1/31Т 10
[_1/3 4/3 —4/31Т 5

 

Какая следующая точка подлежит вычислению в процессе поиска?
Какая точка опущена? Что будет центром тяжести нового сим-
плекса?

4.6. Для функции

Нк) = 4х?+хё—40х1—— 12):2 + 136,

начиная из точки х(0› = [4 817, проведите —— этапов поиска
Нелдера и Мида, включая отражение, расширение или сжатие
и т. д., пока не будут исключены три исходные вершины симплекса.

4.7. Что будет исходным симгілексом в случае поиска Нелдера

“ ДополниТельные задачи, подходящие для этой главы, можно найти среди
задач, помещенных в конце гл. 3.
 pagebreak 
202 Глава 4

и Мида для функции ‚‘ (х) = 2х? + хг? Какая из вершин исключа-
ется первой? Второй?

4.8. Путем подбора величин Б и у в алгоритме НеЛдера и Мида
найдте их оптимальные значения для задач 26—32 из прило-
жения А.

4.9. П идавая па имет ам ос и Б в методе Розенб ока азные
Р Р Р Р
значения, определите наиболее эффективные из них для случая
квадратичной функции
мх) : 10»? +о‚1›?.
Повторите то же для
;(х)=о‚1х%+10хё.

4.10. В конце одного этапа метода Розенброка имели место
следующие значения при поиске ьухинимума Пк):

 

 

Результат
161 ха
Х1 | 12
Начало Начало 3 7
Неудача Неудача 4 8
Успех Успех 2 8
Успех Успех 1,5 7,5
Неудача Неудача — 1,5 10,5

Неудача

 

а) Какие два направления поиска использовались на этом этапе?

б) Каковы должны быть два новых направления?

4.11. Используйте поиск Розенброка для обнаружения мини-
мума целевой функции

„х) = 3х? + @
при {5 = 1/2 и а = 3, пока дальнейшее улучшение не станет невоз-
можным_
4.12. Каковы будут два следующих этапа в методе Розенброка

после вычисления функции [ (х) = 4 (1:1 — 5)“ + (::2 — 6)2 в точке
х = [7,35 8,8017 ? Предположите, что должно быть получено новое

направление поиска и при этом 51 = [1 011, $2 = [0 Пт.

4.13. После минимизации функции'і (х) = 2:31 + хЁ + дх? мето-
дом Пауэлла вектор х оказался равным х = [0,371 0,11617 и і(х)=
= 0,443.

Затем было вычислено новое направление поиска и достигнута
точка х = [0,574 0,30817. Каково следующее направление поиска?

4.14. Выпишите направление поиска для метода Пауэлла в слу-
 pagebreak 
Методы минимизации, не использующие производные 203

 

чае минимизации {(х) = 2х? + ;& — хіхя, начиная из точки х…) =
= [2 217.
4.15. Найдите направление, ортогональное вектору

зана— —— %

х : [о 0 шт
Найдите направление‚ сопряженное к 5 для целевой функции {(х) =
= ::1 + 2хЁ — хр:2 в той же точке.
4.16. Поскольку метод Пауэлла использует сопряженные на-
правления, можно ли гарантировать отыскание минимума квадра—

тичной целевой функции п переменных за 11 шагов?

4.17. Выпишите четыре первых направления поиска для метода
Пауэлла в случае минимизации і (х) : х? + ехр (х? + хё), начи-
ная из точки х‘°’= [2 211

4.18. Объясните. как методом Пауэлла получают набор сопря-
женных направлений поиска для трех». дерной задачи. После про—
движения вдвух направлениях поиска опишите подробно определе-
ние третьего направления. Станут ли все направления поиска
сопряженными после двух этапов?

4..19 Даст ли метод Пауэлла тогг же Набор направлений поиска,
что и метод Ровенброка, если начать из той же начальной точки х?

4.20. Пара уравнений хЁ+хЁ= 1 и ;сд—і—х2 ні имеют решения
(1,0) и (0,1). Линил уровней

Г(Х)=(›Ё+хЁ—1)2+(х‚+х‚_ „а
ПОКЕЗЫВЗЮГ, ЧТО имеют место МИНИМУЧЫ В ТОЧКаХ (10) И (01) И

седловая точка (4 из ‚4 1’3). Могут ли методы поиска обнаружить
оба минимума или только единственный минимум? Объясните.

4.21. Начиная из точки х = [3 31Т‚ постройте траектории
(с указанием значений целевой функции ! (х) в зависимости от числа
итераций) для следующих методов поиска при решении задачи 4.20:

а) Хука — Дживса,

б) Нелдера — Мида,

в) Розенброка,

г) Пауэлла.

Что произойдет, если начать из селловой точки?

4.22. Рассмотрите функцию

г‹›‹› = (х? + хЁ) + %% [% ‹хё —хё› .— хіхд +
1 2

+ ухи х3+о‚25х‚_ %]
2

В точке
 pagebreak 
204 Глава 4

 

а) Постройте линию уровня [(х) для „х) = 1, используя
прибор для вычерчивания кривых.

6) С помощью метода наискорейшего спуска за 8 итераций были
достигнуты следующие точки:

 

 

хх ‘ Хя ‹ Г (Х)

 

х(°) 0,119 0,677 1,000
… №) 0,007 0,006 0,006
ха» —0,598 4,502 1,000
(2) № _0,012 _0‚005 0,005

 

Сравните их с результатами других методов поиска.
Какой метод оказывается лучшим?
4.23. Найдите наилучшие оценки параметров &… 11, и в модели

3 = до + Ьіечх

^
путем минимизации суммы квадратов разностей 2 (у,— уж… ,)”, ео
ли дано

Уэксп. і ::
5 1 ‚6 0,4
53,4 1 ‚4
20,0 5.4

—42 1 9,5
——3,0 48,2
—4‚8 95,9

Используйте метады

а) Хука — Дживса,

б) Нелдера —— Мида.

в) Пауэлла,

г) Розенброка,

д) случайного поиска.

4.24. Минимизируйте полную величину капиталовложений на
расширение производства Р в (долларах), если дано, что

0,550

0,88 п$=`1 0,88 10 0.559 п—1 0,88 10
Р=4900/го +__/е,— ‚… + 60—20, „:,— ‚
'=' 2 ігі і=0 2 ге,-
і=0

і=0
 pagebreak 
Методы минимизации, ме использующие производные 205

где 120 — начальный размер вложений, а !г, _ размер дополнитель-

ных вложений, в целых числах, т. е. 1гд= 1, 2, 3... . Найдите ми-

нимальное п, п = 1, 2, 3, ..., и соответствующие іг, если іед : 1.
4.25. Найдите минимум и максимум функции

[(х) = 20 + 0,3):1 — 4х2 + 0,3% + 0,3хё + 0,4х1х2

одним из методов поиска. Начинайте из точек

”ХЗ: =,[025 251,
бп? =,[25 2,51;
в)х(°) =[—о‚25 —2,51’.

4.26. Функция

?(х) = (1 + 8х1 _ 7х? + + к? _ + А) (;&—**) г (хз)

имеет два максимума и седловую точку. Для (а) Е(хз) =1 и (6)

Р (хз) : хзг ““+” найдите глобальный оптммум с помощью какого-
либо метода поиска.

[Ответ:(а)х*= [4 21 и(б)х*= [4 2 пт.]

4. 27. Можно ли найти решение задачи 4 26, начиная из точек
(а) х‘°’= [2 11 и (б) х‘°*= [2 1 117.

Повторите для (а) ›‹0 =[2 2]Т и (6) х… = [2 2 ПТ.

(Указание: [2 2 1]Т—седловая точка.)

4.28. Имеет ли функция
і(і)=1+!+і2+г3

минимум? Максимум?
4.29. Минимизируйте

(3) [(х) = 1 + ::1 + 1:2 + хз + хд1 +х1х2+х1хз+х1х4+х2хв+
+ хвхд + хэхд + ;и + 1% + хз + хі, начиная из точек х‘ °) : [— 3
+30 —4 _о‚ 111 и х‘°’= [о 5 1,0 8,0 —о‚71’,

(6) [(х)— _ х,:сёхзЫ [ехр — (›:1 + ):2 + ::8 + Д)], начиная Из точки

= (3 4 0,5 11Т.

4.30. Определите коэффициенты уравнения

ь
у = ахгхг’

по с.педующим экспериментальным данным путем минимизации
суммы квадратов разностей между экспериментальными и пред-
сказанными значениями у.
 pagebreak 
206 Глава 4

Уэксп. ! ] и И
46,5 2,0 36,0
591 6,0 8,0
1285 9,0 3‚ 0
36,8 2,5 6 25
241 4,5 7, 84
1075 9,5 1,44
1024 8,0 4,0
151 4,0 7,0
80 3,0 9.0
485 7,0 2,0
632 6,5 5,0

 

4.31. Стоимость очищенной нефти, перевозимой морским путем
через Малаккский пролив в Японию (в долларах на килолитр),
определяется в виде линейной суммы стоимости неочищенной неф-
ти, затрат на страхование, таможенных тарифов, затрат на фрахт
нефти, затрат на погрузку и разгрузку, платы за морскую стоянку
судна, затрат, связанных с подводным перекачиванием и хранением,
стоимости площади под цистернами, стоимости очистки и затрат
на перевозку продуктов 1191:

_ 2,09. юч—°›3°'7 ‚ 1,064. 10%:04925
””Ред—“”' ”Т`гт`1'
+ 4,242. 1оэаг°-7952+ 1,81Зір („+ 1,247) + 4,25 _ 103я(л!+1,2‹7) +
52,474 - 360 52,474. 360
5,042, …за—0,18% 01104940671
+ ___—360 + ___—360 '

где
и — фиксированные ежегодные расходы в относительных вели-
чинах (0,20);
с‚— цена неочищенной нефти, долл/кл (12,50);
— страховка, долл/кл (0,50);
с„ — таможенные тарифы, долл/кл (0,90);
і — норма процента (0,10);
п —— число портов (2);
р 7 цена земли, долл/м2 (7000);
‹]іпроизводительность установки для очистки нефти, бар-
рыь/день;
г— объем танкера, кл.
Считая значения, указанные в скобках, заданными, вычислите
минимальную стоимость нефти, оптиальный объем танкера и
 pagebreak 
Методы минимиалции, не использующие производные 207

производительность установки для очистки нефти следующими
методами (заметим, что 1 кл = 6,29 баррель):

?“."? Р‘Р?” .“?

11:

12.
13.
14.

15.
16.
17.

18.

19.
20.

а) Хука —— Дживса,
б) Нелдера — Мида,
в) Розенброка,

г) Пауэлла,

д) случайного поиска.

ЛИТЕРАТУРА

НооКе К., Леечез Т. А…, .]. Айас. Сотршег Мат., 8, 212 (1962).

\Уоос! С. Р., Арріісаііоп оі «Оігесі 5еа1‘с11» Со Ше Зоіцііоп 01 Епеіпеегіпе Рю-

Ыет5, \Уезііпапоцзе Кез. ЬаЬ. Зсі. Рарег 6-41210-1—131, 1960.

МеШег ]. А., Меаа К., Сотриіеі [, 7, 308 (1964).

$реп‹11еу Ш., Нехі & В., НітзшогН] Р. К., Тесітотгтсз, 4, 441 (1962).

Вох М. .1., Сотриіег ]., 8, 42 (1965); Сатреу 1. О„ Міс1ю15 1'). О., Зітр1ех

МіпітіЪаСіоп, ітзегіш Сітегп. 1п6и51гіез, 1.111. 1961.

Рачіапі В., РЬ. . Віззегіаііоп, Т11е Нпіч. оі Техаэ, Ацэііп, Тех., 1969.

КозепЬюск Н. Н., Сотриіеі ]., 3, 175 (1960).

$шапп “Г. Н., Керогс оп Ше Оеуе1оргпепс 01 а Маш Оігесі Зеагсп Метод оі

Оріітіиасіоп, 1трегіа1 СЬет. 1пацзсгіе5, ма. Семга] 1пзіг. [‚аЬ. Кез. Ыоіе

6413, 1964.

Ра1тег 5. п., Сотригег ш, 12. 69 (1969).

Р0№11М. ]. В., Сатриіег .1.‚ 7, 155 (1964); 7, 303 (1965).

5п1і111 С… 5… тт Аціотаііс Сот ц’саііоп оі Махітцт 1‚і1‹е1іЬоо‹1 Езіітаіез,

ЫСВ Зсі. Верс. Кері. $С846/МК/ 0, 1962.

2ап5ші1101. 1., Сотриіг/ .)., 10, 293 (1967).

!. Орггагіопз дез., 6, 244 (1958).

Рачіеац К. К., Ргап1<5 Н. Съ Е., Зіаіізіісаі Оріітіиасіощ Ргос. 21-м] 1п1егп.

00111. 10: Апа105 Сотрціаііоп, ЗтгазЬоцгг, 1958, Ргеззез Асааетічцез Ето-
рёепез, Вгцзэе1э, 1959, р. 437.

МіісЬеП В. А., Зітиіаііогь 4‚ 399 (1965).

Вох М. ]., Сотриіеі ]., 8, 42 (1965).

Ніпеагу К, Е., Н. 8, Ыача1Роз$згадцаіе $с1юо1Тес1ш. КерС/КеЗ. Рарег 59,

Маки 1966.

Кану Н. Л., шпееппд Н. Р., А Шайа! Сотрціег Рговгат іог Оріітіяіпд Моп-

11пеиг Рипоііопз, МоЬі1 0і1 Согр.‚ Кезеагсп Верь, Септгаі кеэеагсп вт.,

Рп'псеіоп, М. ]., ]ц1у 1962

Пспіуата Т., Н аіосагЬип Ргосезз, 47 (12), 85 (1968).

КцзЬ'пег Н., Еіісіепі Негатив МеЦюгіз {ог Орсітіиіпе те Регіогтапсе 01

%%Ъіі—Зёбатеіег Ыоі$у $у5$еп15‚ МП Ьіпсот ЬаЬ. Нері. 226-0043 (АВ 245802),
С › .

ДОПОЛНИТЕЛЬНАЯ ЛИТЕРАТУРА
ОБЩИЕ вопросы

Вох М, Л., А Сотрагіэоп 01 $еЧега1 Спггепі Оріішіш’гіоп Метода апа те Цэв

01 Тгапзіогтаііопэ іп Сопэігаіпеа РтоЫетз, Сотри!” ]., 9, 67 (1966).

Вот \У. Б., Мопппеаг Рювгагптіпз: А Зишеу, Мапаветепі за., 9. 171 (1963).
КошаНк ]., ОзЬогпе М. К., МеШоаз іог Ппсопэігаіпеа Оріітіиаііоп РгоЫетз,

Атегісап Е1$ечіег, 1968.
 pagebreak 
208 Г лава 4

 

Рошен М. 1. В„ А Зцгчеу оі Мшпегісаі МеШодз (ог Цпсопзсгаіпес! Оріітіиаііощ
$!АМ Его„ 12, 79 (1970).

Эспестег К. Э., Вечегіаде Сх. 5. О., Оріітіиаііоп: ТЬеогу апа Ртасіісе, МсСхгаш-
Н…, М. У„ 1970.

Зрапа Н. А., 111, А Нечіеш оі Міпітіиаііоп Тесппічцез іог Мопи’пеаг Рцпсііопд
$1АМ Кеш, 4, 343 (1962)

шішіезбз. Щ, Оріішцш ЗееКіпв Ме‘сЬосЬ, Ргепіісе-НаП, Еп31ешооа Сііііз, Ы. ].,

\ПіШе В. Л., Веіаппег С. Э., Роцпсіатіопз оі Оріітіиаііош Ргепіісе-НаП Епаіе-
тош! С|і№‚ М Л., 1967.

“10166: Р., Несет Вечеіоршепіз іп Ыопііпеаг Ргоегаштіпе, Ааоап. Сотриіегз,
з, 155—187(1962).

ДРУГИЕ МЕТОДЫ НЕЛИНЕЙНОГО ПРОГРАММИРОВАНИЯ
БЕЗ ОГРАНИЧЕНИЙ, НЕ ИСПОЛЬЗУЮЩИЕ ПРОИЗВОДНЫЕ

НЕСЛУ Ч АИН ЫЙ ПОИСК

Вегтпап О., Міпітіиаііоп Ьу Зиссезэіче Арргохітаііопз, 81АМ Митегіса! Апа-
іуэіз, 3, 123 (1966).

Веппап О., ышсе Арргохітаііопз ’!о “те Міпітпа оі Рцпсііопз оі Зечегаі \!агіаЬ—
1е5, ]. 11.5500. Сотриігг Мат., 16. 286 (1969).

Сатреу !. О., Місіюіэ 1). б., $ітр1ех Міпітіиаііоп, 1трегіа1 СЬетісаі 1пс|цз’сгіе5‚
[м., Аин. 1961.

Пеіспег Ц., Рипсііопа1 Міпітіиап'оп шііпоиі Ечаіцаііпв Вегічаіічез, Сотриіег ].,
8, 33 (Аргі! 1965).

Кіеіег ].. Збезццепсіаі Міпітах веши {от а Міпітцт, Ргос. Ат. Млин. Баа, 4,
502 19 .

Кіеіег 1}, Ор ітцт Зе цепііаі Зеагсіт аш] Арргохітаііоп Метшіз ипаег Міпітшп
Кедціату Аэзцгпр іопэ, $1АМ ‚]., Б, 105 (1957), '

МіісЬеП К. А., Кар1ап ]. [… Мопііпеаг Сопзігаіпі Оріітіиаііоп Ьу а Ыопгапаот
Сотріех Метод, ]. Кез. Ма”. Биг. ‚ЗЫ, 726, 249 (1968).

Зрепаіеу “!., Нехс 6. К., Нітзшогііт Р. К., ТЬе Зечиепііаі Арріісаііоп оі $ігпр1ех
Веэбізпэ іп Оріітіиаііоп апс! Ечоіи’гіопагу Орегаііоп, Тесішотеігісз, 4. 44|
(19 2).

Зшапп “1. Н., Нерогі оп Ше Оечеіоршепі оі а Ме“! Вігесі: веши МеНюа оі Оріі-
шіиаііоп, [трепа] СНетіса! [паштет, ца., Сетка! 1п52г. 1.81). Кез. Моіе
64/3, 1964.

\іідпез ]., Аідогіспте рощ іа сіёіеггпіпаііоп ‹і’ип ехігетит іоса] а'цпе іопстіоп
ае ріизіев чагіаЫез, Кен. !пзг. Напр. Рёиоіе, 23, 537 (1968).

\Ш'Ате В. Р. ш., Тшо Мет ВігесС Міпітцт Зеагсп Ргосесіш'ез іог Рцпсііопэ оі
$ечегв1 \іагіаЫез. Зргіпд .!оіпі Сошрціег Свт., Шазыпзіоп, 1). С., Аргіі
1964.

\Уоод С. Р., Арр1ісаііоп оЕ «Вігесс Эеагсп» [о Ше Зоіщіоп оі Епдіпеегіпв РгоЫет5,
Шезііпепоизе Неэ |.аЬ. $сі. Рарег 6-41210-1—Р!‚ 1960.

СЛУЧАЙНЫЙ ПОИСК

ВеКеу 6. А., бгап М. Н., ЭаЬгоіі А, Е.. \Уопе А., Рагатеіег Оріітіиаііоп Ьу
Капдот вешь Цзіпе НуЬгіа Сошри’іег Тесппічиез, Ргоо Ран Лоіпі Сотри-
іег Сопі., 1966, р. 191,

ВгооКз 8. Н., А Візсиззіоп оі Капдош Метоаз (ог ЗееКіпа Махігпз, ]. Орегаііопз
дез., 6, 244 (1958)‚
 pagebreak 
Методы минимизации, не использующие производные 209

 

Вгоойз 5. Н., А Сотрегі5оп об Махітцт ЗееКіпв МеШоёз, .! . Ореюііопз Кез. Бас.

т., 7 1959).

Рачгеаи Н. 1%, РтапКз Н. 6. Е., Капаот Ор’сітіивііоп Ьу Апаіов ТесЬпішхез, Рюс.
2116 іпН. Сопі. іог Апаіое Сотрціаііоп, $1га5Ьоцге, Ргапсе, Зерс. 1958, Рпез-
зев Асааётіццез Ецгоре’епез, ВгцзэеЬ, 1959, р. 437, 443.

банданы Р. .]… МОР—1, Ап Оріітіиіпа Ноцііпе ог Ше [ВМ 650, Сап. 6. Е. Січі—
1іап А’штіс Роше: Вері. Кері. КбОсАРЗБ, 1960.

МсАгН-шг В. З., Зігаіеву іп Везеагсй, Аііегпа‘січе МеШодз іог сне Везівп оі Ехре-
гітепіз, [КЕ Т/ап$., ЕМ-В, 34 (1961).

Маіуаз ]., Капёот О іішіиаііоп, Аиіотаііс апа Кетаіе Солггад 26, 244 1965).

МіСсЬеН В. А., А. Ну'Ёгід Апа1ое—Віеііаі Рагатеіег Оріітіиег іог АЗТЦ С Н,
8іти1аііоп. 4. 398 (1965).

Мипюп ]. К., КпЬіп А. П., Оріішіиасіоп Ъу Напдот Зеагсн оп Ше Апаіов Сотри-
іег, !КЕ Пат., ЕС-8, 200 (1959).

ЗсЬцтег М. А‚‚ Зіеівти К., !ЕЕЕ Тгапв. Ашот. Сопггоі, АС-із, 270 (1968).

БЬітпиш Т., А Зіосйавтіс Аррюхішаііоп Метод іог Оріігпіяаііоп РгоЫетз,
!. Азов. Сотршег Май., 16, 511 (1969).

2е1!пі1‹ Н. Е, Запаай М. &, Оачіз К. $., сгинет ЗеагсЬ Орі’ішііаііоп, Сілет.
Енг. Ргогы 58 (8), 35 (1962).
 pagebreak 
Глава &

СРАВНЕНИЕ АЛГОРИТМОВ НЕЛИНЕИНОГО ПРОГРАММИРОВАНИЯ
ПРИ ОТСУТСТВИИ ОГРАНИЧЕНИЙ

В этой главе будет проведено сравнение эффективности алгорит-
мов, описанных в гл: 3 и 4 (не всех, конечно, но большинства из
них). Особый интерес представляют ответы на следующие вопросы:

1. Какие алгоритмы являются лучшими, а какие худшими?

2. Как влияет природа задачи, а именно степень нелинейности,
число переменных и т. д. на качество работы алгоритма?

3. Какова эффективность алгоритмов, не использующих произ-
водных, по сравнению с алгоритмами, использующими их?

4. Почему определенные алгоритмы в некоторых условиях не
работают?

Прежде чем проводить сравнение качества работы различных
алгоритмов, необходимо сначала установть подходящие критерии
оценки. Сначала рассмотрим различные критерии, а затем, исполь-
зуя два из них, оценим некоторые алгоритмы.

5.1. КРИТЕРИИ ОЦЕНКИ

Прежде чем оценивать эффективность различных алгоритмов
при отсутствии ограничений, сделаем несколько замечаний отно—
сительно критериев, используемых при оценивании эффективности
алгоритмов. Алгоритмы можно исследовать как с теоретической,
так и с экспериментальной точек зрения. Первый подход может
быть использован только для весьма ограниченного клисса задач,
поэтому мы будем оценивать эффективность алгоритмов с помощью
эксперимента, т. е. решения тестовых задач. Алгоритмы могут быть
проверены на специальных задачах как с малым, так и с большим
числом переменных, на задачах с различной степенью нелиней-
ности, а также на задачах, возникших из практических приложе-
ний, таких, как задачи минимизации суммы квадратов, решение
систем нелинейных уравнений и т. п. Можно надеяться, что иссле—
дование эффективности алгорИтма при решении различных задач
позволит предсказать общую эффективность алгоритма при реше-
нии других задач.

Одним из важнейших вопросов является вопрос о широТе при-
менения алгоритма, т. е. можно ли с помощью данного алгоритма
решить большиттво задач? Конечно, любой алгоритм может ока-
 pagebreak 
Сравнение алгоритмов при отсутствии ограничений 211

 

заться бессильным решить специальным образом построенную
(«патологическую») задачу. Даже и для других. не обязательно
«патологических» задач мы не можем требовать, чтобы алгоритм
решал все возможные задачи, поскольку легко поставить задачу
нелинейного программирования без ограничений. приводящую :(
отрицательным аргументам, делению на нуль, разрывам и т. п.
Более того, нельзя ожидать, что данный алгоритм выберет гло-
бальный минимум, если в задаче имеется более одного минимума,
но он может считаться успешным, если ему удается достичь по край-
ней мере локального минимума. Кроме того, то, что один человек
считает успехом, другой может расценивать как неудачу. Напри-
мер, рассмотрим задачу 31 из приложения А, иллюстрированную
фиг. 5.2.7 (метод штрафной функции), у которой глобальный ми-
нимум находится на ———00‚ а локальный минимум —— в окрестности
точки (1,7; 1,3). Если процедура минимизации осуществляется
в направлении глобального минимума, должно ли это считаться
успехом или неудачей? Если эта процедура используется как под-
программа в методе штрафной функции, то здесь скорее ищется
локалъный, а не глобальный минимум.

Результаты любого экспериментального сравнения алгоритмов
в значительной степени зависят от того, как алгоритмы запрограм-
мированы для ЭВМ. Мелкие детали программирования могут
оказывать существенное влияние на эффективность алгоритма.
Небольшие изменения в критериях окончания процесса, процеду-
рах одномерного поиска, тестах на сингулярность матриц, процеду-
рах обращения матриц, перезадания и т. п. сильно влияют на
эффективность алгоритма. Даже изменение начального шага в одно—
мерном поиске, как было показано в разд. 3.4, оказывает серьез-
ное влияние на траекторию поиска при минимизации функции
Розенброка. Некоторые из этих факторов игнорировались авторами
при сообщении результатов проверки того или другого алгоритма,
поскольку они считались не связанными собственно с алгоритмом,
тем не менее их вклад в работоспособность алгоритма не должен
оставаться незамеченным. Для повышения эффективности многих
алгоритмов требуется введение эвристической логики. Такая логи-
ка основывается на опыте экспериментальных неудач и имеет мало
общего с фундаментальным понятием, лежащим в основе алгорит—
ма, но тем не менее делает его работоспособным.

В этой главе рассматриваются следующие критерии для оцени-
вания алгоритмов нелинейного программирования при отсутствии
ограничений:

1. Успех в достижении оптимального решения (в пределах
заданной точности) для широкого круга задач.

2. Число необходимых вычислений целевой функции.

3. Машинное время, требуемое для реализации алгоритма
(в пределах желаемой степени точности).
 pagebreak 
212 Глава 5

 

№:)

М)

?(3' на:“’› =>

 

тт _”!Л'П ;

 

„@@@/›

Ф и г. 5.1.1. Объединенные критерии окончания процесса минимизации ‚ (к) для
двумерного случая. Критерий, основанный на неравенстве

[(Х‘”+")— их””)
пх‘т

ПРИБОДИТ К преждевременному окончанию процесса на ПЛОСКОМ плзто; критерий,
основанный ТОЛЬКО На неравенстве

хае+п _ хип
Хаг)

<В ‚

<Е-

ПРИВОДИТ к преждевременному ОКОНЧЗНИЮ на крутом спаде.

Ниже мы рассмотрим некоторые вопросы, касающиеся выбора
того или другого из этих критериев и связанной с ними неопреде-
ленности.

Основной критерий, используемый при оценивании алгоритмов
общего типа, заключается в том, может ли данный алгоритм ре-
шить большинство предложенных задач. С этим связано понятие (›
приемлемой точности решения, т. е точности определения значе—
ний целевой функции і(х*) и элементов вектора х*. Обычно
 pagebreak 
Сравнение алгоритмов при отсутствии ограничений 213

 

точность реШения зависит от критериев окончания, применяющихся
для определения момента завершения вычислительной процедуры.

Чтобы добиться некоторой стандартизации в критерии окон-
чания, во всех излагаемых здесь (ранее не опубликованных) рабо-
тах алгоритмы модифицировались так, чтобы одна и та же относш
тельная ошибка как в определении оптимального вектора х, х*‚
так и в определении [’ (х*) была общей основой при выборе момента
прекращения поиска в каждой программе. На фиг. 5.1.1 видно,
печему должны удовлетворяться оба критерия. Если алгоритм
заканчивается только из-за того, что относительное изменение
[(х) меньше некоторого малого числа, плоское плато может выз-
вать преждевременное окончание. Если же алгоритм заканчивается
только на основании относительного изменения в элементах х,
крутой склон может вызвать преждевременное окончание. Исполь—
зование для этой цели только составляющих градиента может при-
вести к окончанию в седловой точке, & при минимизации штрафных
функций составляющие градиента могут быть малы, но, несмотря
нв это, вектор ›‹ может значительно изменяться. Следует отметить
одно обстоятельство, касающееся критериев окончания и заклюию—
щееся в том, что, когда [ (х) и (или ) х стремятся к нулю, критерием
окончания должно быть изменение функции или переменной по
отношению к некоторому значению, а не по отношению к их теку-
щему значению, чтобы избежать деления на малое число. Некото—
рые авторы в качестве критериев окончания использовали норму
и‘ (х), норму х или норму $, и, хотя эти критерии являются вполне
адекватными, в большинстве случаев они имеют те же недостатки,
каторые проиллттрированы на фиг. 5.1.1.

Если данная задача может` быть решена рассматриваемым алго-
ритмом, то второй широко применяемый критерий начинзет играть
важную ролъ. В этом случае мерой зффективносш алгоритма явля-
ется количество вычислений функции { (х), необходимых для дости-
жения определенной точности в {(х) и х. Безусловно, этот крите—
рий лучше, чем критерий, использующий число этапов, нескольку
последнее меняется в очень широких пределах для разных алго—
ритмов и во многих алгоритмах понятие «этап» означает нечто
совершенно отличное от выбора нового направления поиска. Тем
не менее число вычислений целевой функции само по себе не слиш-
ком подходит в качестве меры эффективности для алгоритмов
с очень разными стратегиями, поскольку число вычислений целевой
функции для выбора направления поиска по отношению к числу
вычислений функции при движении в данном направлении сильно
меняется от стратегии к стратегии. Более того, с каким весом долж-
но браться количество вычислений производных по отношению
к вычислениям самой целевой функции, чтобы при оценке методов,
использующих производные, учитывались и количество вычисле-
ний целевой функции, и количество вычислений производных?
 pagebreak 
214 Глава 5

 

Наконец, количество вычислений функции может быть уменьшено
с помощью всевозможных тестов, также требующих машинного
времени, специальных эвристических операций, матричных опе-
раций и т. д., так что сравнение, основанное только на количестве
вычислений функции, может легко ввести в заблуждение.

Следовательно, третий из упомянутых выше критериев _ машин—
ное время, необходимое для реализации алгоритма, также может
рассматриваться как мера эффективности алгоритма. Хотя относи-
тельное время решения не является особенно подходящей мерой эф-
фективности алгоритмов нелинейного программирования при отсут-
ствии ограничений, за неимениемлучшей меры часто приходится ис-
пользовать именно ее. В разд. 9.1 сделаны некоторые замечания по
поводу трудностей. которые могут возникнуть при использовании
в качестве критерия времени решения. Для простых тестовых за-
дач время, требуемое для ввода данных и извлечения из памяти
команд печати (но не самой печати) в программес не очень детальной
распечаткой, скажем только х и } (х) на каждом этапе, может быть
в 2—3 раза больше времени, оцениваемого без учета этих фаз про-
граммы. В ЭВМ, где` центральный процессор работает по несколь-
ким программам в режиме разделения времени, полное время с уче-
том сумммарного времени ввода —вывода может в 2 или 3 раза
превысить время, необходимое для решения. Таким образом, тип
ЭВМ‚ тщательность программирования алгоритма и характер учи-
тываемого времени имеют существенное значение при использо-
вании времени решения в качестве критерия. Подобная информация
обычно опускается в публикациях, описывающих работу того или
иного алгоритма.

5.2. ТЕСТОВЫЕ ЗАДАЧИ

Различные авторы алгоритмов нелинейного программирования
использовали для их проверки большое число тестовых задач.
Некоторые из этих тестов использовались так часто, что стали
играть роль «классических», поскольку много раз применялись
для сравнения качества работы разных алторитмов, обычно, чтобы
показать, что новый алгоритм не хуже или лучше предшествующего.
В табл. 5.2.1 приведены десять целевых функций, которые доста-
точно часто встречались в литературе в качестве тестовых функштй;
задачи 25—35 из приложения А представляют собой дополнитель-
ный набор тестовых задач, причем некоторые из них раньше не
использовались. На фиг. 5.2.1—5.2.8 приведеНЫ линии уровней
двумерных целевых функций. Функция Розенброка (функция 1
в табл. 5.2.1 и задача 23 приложении А), которая многократно рас-
сматривалась в гл. 3 и 4, имеет крутую закругленную впадину

вдоль кривой 1:2 = 1:12; целевая функция Н также имеет впадину,
но более мелкую; у функции … имеется крутая впадина вдоль
 pagebreak 
Таблица 5.2.1
Функции нелинейном программировани при отсутствии ограничений, применявшиеся в качестве тестовых функций

 

Значения 7 (х) в точке

 

 

Фу Литература НачшЁЁЁЁТвекюр минимума
, н… | г
1: 100 ‹ха—хЭча—хт … ‹—1‚2: 1) о ‹1‚ 1)
11: ‹хг—х‘эанп —х‚›* {21 ‹—1‚2; 1) о (1, 1)
Ш: ‹х„—›%›*+ 100 ‹1 —х,›* [21 ‹—1‚2; 1› о ‹1. 1»
П]: 100 (;и—‚фит _:ст [21 (—1,2; 1) о (1, 11)
\!: [1,5 _ ‚\:1 (1 _ хж + [2,25 _ х, (1— ‚сёла + [31 0 (3, 7)
+ [2,625 _ х, (1 _ „$)?
и: то (‚;&—‚фига —х1)2+90(х4—хё)3+(1—— [4111 (%.—1, —3‚ —1› о ‹1. 1, 1, 1)
` Хз)“+11)0.1 (ха— 02+ (14— 1)$ + 19,8 (хи — 1) ><
Х (Х — '
УН: ‹хд-10х‚›+5‹хз—хт+‹хя—2хз)4+ 151$) (_в, —1‚ о, 1) о «›, о. о. 0)
+ ‘10 (Х] '— 354).
У…: (с{ — 12)4 + 100 (х, —х‚)" + іе‘ (хз — 1%) + х? + [6] (1, 2, 2, 2) 0 [О, 1. 1, (1 :Ъ пл)]
+ (16 —— 1 *
1Х: функ4ция Ъ задачи 10 из приложения А
Ссылка на лн- Детали изложены Детали изложены в прило-
тературу да— в приложении жеиии А; описание фуик`
на в прило- А; описание ции Р см. в гл. 7
жении А функцин Р см.
Х: функпия Р задачи 18 из приложения А в г.п. 7
Детали изложены Детали изложены в прило-
в приложении жеиии А: описание функ-
А; описание ции Р см. в гл. 7
функции Р см.
в г.п. 7

 

!) Функция имеет несколько локальных минимумов; ую обстоятельство может вызвать преждевременное окончание процесса.
2) Заметим, что мпрнцд Гессе этой функции в точке инквиуив сингуляриа.
 pagebreak 
„„ [.
\
&
\
1,00 * ° \
$
‘ {_ [
4,00 —7‚00 000 1,00 2,00 1,
400 "100 _
Ф и г. 5.2.1. Функция ]: [ (х) = 100 (х, —х%)*+ (1 _ Ф и г. 5.2.2. Функция 11: [(х) : (х, —Х‘Ё)я + (1—

——х1)’. —х1)’.
 pagebreak 
2,00

Ш

      

Ф и г. 5.2.3. '
Функция …. ‚* (х) = (‚с, … х%)+100(1—-х1)2‹

|__/`°ъ °
—/ 00 ©
' &

Ф и г. 5.2.4. Функция 1\/:і(х)=100(х‚—х‘1‘)’ + (1 _
__хдя
 pagebreak 
‚@
год
&
// —4‚00 -д‚00 100 цао 1100
’о 400
1100 о '
%—
*"о 400
9.7

     

\0
` —50
4.00 . / , о

Ф и г 5.2.5. Функция \]; ; (х) = [1,5 __ х, (1 __ для + [2,25_ Ф и г. 5-26- Функция 28 приложенияА: Нк) = (хдд!- хя— ”›“г
_ х, (1 _— хёт + [2,625 __ Х] (1— ‚сёня. + (11 + х; _ т.
 pagebreak 
219

 

В разрыв

“2,00
Ф и г. 5.2.7. Функция 3] приложения А: [(х) = (3:1 — 2)2 + (::2 — 1)2 +

004 1
___—„’ _ —2 12.
+ _(йё/‘ю—Хё’і'і +012 (301 Х2+)

\

    
 

2
Ф и г . 5.2.8. Функция 33 приложения А: [ (х) = в (‚“—хг) [%%4‘ ЗХЁЪ
 pagebreak 
220 Г лава 5

 

прямой х1 = 1; у функции 1\/ крутая впадиъіа вдоль кривой »; =
= хЁ’; функция Виля \! также имеет узкую закругленНую впадину,
приближающуюся к прямой ::2 = 1. Функции 1Х и Х предста—
ляюг собой штрафные функции (они будут описаны в гл. 7),

5.3. ОЦЕНИВАНИЕ АЛГОРИТМОВ НЕЛИНЕИНОГО
ПРОГРАММИРОВАНИЯ ПРИ ОТСУТСТВИИ
ОГРАНИЧЕНИЙ

Сначала рассмотрим некоторые опубликованные работы‚ а за-
тем обратимся к неопубликованным результатам и сравним боль—
шинство алгоритмов, изложенных в гл. 3 и 4, на единой основе.

В работе Леона [71 среди других алгоритмов сравнишаются в
частности следующие:

1) Метод Дэвидона в том виде, как его запрограммировал
Стивенс [8].

2) Программа Баера [9]. Эга программа генерирует последо—
вательность ограниченных минимумов и проводит между ними
интерполяции) в окрестности НХ).

3) Партан-метод наискорейшего спуска.

4) Модифицированный партан-метод [10].

5) Итерационный' партан-метод.

При этом используюпя первые пять целевых функций, приведен—
ных в табл. 5. 2. 1. Соответствующая таблица результатов (табл.
5.3.1) содержит несколько начальных векторов, конечный вектор
х, значение [(х) в конечном х и относительное машинное время,
необходимое для выполнения минимизации. Все значения, за исклю-
чением относительных значений времени, округлены до третьего
десятичного знака. Партан-метод наискорейшего спуска и итера—
ционный партан-метод не включены в табл. 5.3.1, поскольку эти
алгоритмы работали очень плохо в том смысле, что в значительной
части тестовых решений конечные векторы х отклонялись от
известных векторов х*‚ соответствующих минимуму, более чем
на 5%, а во многих случаях эти отклонения составляли свыше
100%.

Из табл. 5.3.1 следует, что процедура Дэвидона —— Флетчера ——
Пауэлла представляется наилучшей в смысле общего метода нели-
нейного программирования при отсутствии ограничений в отно-
шении получения правильных значений вектора х в точках мини-
мума целевой функции. Процедура Баера приводила к ошибкам
при минимизации целевой функции Виля, если процесс начинался
с некоторых определенных начальных векторов, тогда как модифи-
цированный партан-метод оказался неспособным справиться с функ—
цией Розенброка. Поскольку относительные значения времени
выполнения алгоритмов были приблизительно одинаковы, метод
 pagebreak 
Таблица 5.31

Результаты минимизации пяти целевых функций различными методами
|

 

 

 

 

 

 

 

 

дэвидои Баер Модифицированный партан-метод
тно- отно- Отно-
си› СНА сть
.; Начальные значения тель- тель- “„„„
5 х, х, ПХ) конечные значения ное конечные значения но: конечные значения ное
Ё х. ›‹, {(х) вре- 1: ›‹. ПХ) вре— Х. х: ГШ вре.
е>° ия” ия” ия‘)
№
1 —1,200_ 1,000 24,200 1,000 1,000 34107” 1,00 1,000 1,000 271042 0,50 0,939 0,882 3,7.10—2 0,50
_2,000 —2,000 3609,0 1,000 1.000 6,5›10—" 0,64 1,000 1,000 4,3-10—12 1,71 1,002 1,003 4,0.10—‘5 0,35
5,621—3,6351,24-105 1,000 1,000 9,310—13 0,78 1,000 1,000 1,0-10—12 1,62 1,000 1,000 9,6.10—3 0,41
_—0,221 0,639 36,320 1,000 1,000 7,510“'; 0,66 1,000 1,000 1,7.10—12 0,92 0,940 0,883 3,6-10—з 0,50
11 —2,000 —2,000 45,000 1,000 1,000 1,410*12 0,51 1,000 1,000 7,2-10—'° 1,77 0,999 1,000 1,010-6 0,34
0,803 —0,251 0,840 1,000 1,000 5,010“15 0,26 1,000 1,000 9,740… 1,11 0,991 0,979 9,2-10—5 0,19
0,211 3,505 12,600 1,000 1,000 151044 0,30 1,000 1,000 2,9-10—15 0,29 1,000 1,000 2,210“6 0,27
111 2,000 —2,000 136,00 1,000 1,000 5510712 0,44 1,000 1,000 5,6‹10—‘5 0,50 1,000 1,000 4710—11 0,17
1,992 _3,222 150,10 1,000 1,000 1,1.10—‘2 0,34 1,000 1,000 2610—10 0,20 1,000 1,000 1,1.10—'2 0,16
1,986 5,227 98.86 1,000 1,000 2710—12 0,23 1,000 1,000 22-10—12 0,32 1,000 1,000 1.0.10—12 0,12
11! 1,200 —2,000 1389,8 1,000 1,000 2310—13 0,95 1,000 1,000 2,1—10—‘з 1,05 1,000 0,999 9.8-10`7 0,94
0,248 ——3,082 964,54 1,000 1,000 5,6.10—13 0,92 1,000 1,000 1,0-10—в 0,90 1,000 1.000 9,910“3 1,16
4200—1000 57,840 1,000 1.000 9210—13 1,00 1,000 1,000 5,2.10—и 0,98 1,000 1,000 1,1.10—‘3 1,15
\1 0,000 0,000 14,200 3,000 0,500 1,8.10—15 0,54 3,000 0,500 2,3.1о—'2 0,87 2,999 0,500 3,3.10—7 1,07
8,000 0,200 81,700 3,000 0,500 1,010… 0,67 2,045 0,075 5,4.10—‘ 1,21 3,002 0,501 8,7.10—7 0,40
5,000 0,800 0.490 3,000 0,500 2,2.10—13 0,42 3,000 0,500 3,6.10—'4 0,94 3,000 0,500 3,7.10—13 0,43
8,000 0,300 2,042 3,000 0,500 2,6.10—12 0,62 7,996 0,374 3,8- 10—‘ 0,10 3,000 0,500 1.100 0,37

') Время, отнесеииое ко времени иииимизации функции 1 методом дэвидонщ начиная ‹ 'ючки ХФ) =[—1,2 1.0].7

 

ШЗ
 pagebreak 
222 Глава 5

 

Сравнение нескольких методов миними

 

 

Метод Дэвидом — ФттчеРа — Пауэлла Метод Ныоюна

Уотмин [11] Флетчер—Пауэшп [12] (Уортан [П])
Функцияихф) Ё‘Ёё %ЁЁ ЁЁЁ

;— 3 :— °“ . Ё °
1(_1‚ 2, 1, 0) 1-10—“ 23 120 1.10—8 10 _ 3.10"3 17 вв
1‹—2547‚ 1, 489) 6-10—16 16 87 6.10—16 20 130
11 (0,211, 3,505) 1—10—‘1 9 36 210—18 в 28
1\/(——1‚ 2. 1, 0) 3-10—12 21 120 мой15 25 127
шт, 248, —3‚ 082) 7.10—15 23 115 2.10А19 16 71
що, 0) 710"4 12 39 210—17 9 31
\!(в, о, 8) 7-1044 21 119 0,250 400 1922
\7110—1. о, 1} 5.10“… 32 149 25.10"8 в — 8-10—12 20 95

1) Мдтрицд Гессе не является положительно определенной, поэтому был использован поиск

Дэвидона -— Флетчера —- Пауэлла представляется предпочтитель-
нее других.

В другом исследовании, проведенном Уортманом [11], приме-
нялись методы Дэвидона _ Флетчера _Пауэлла и Ньютона сов-
местно с методами поиска Хука —-— Дживса и Пауэлла (описанными
в гл. 4); последние включались в качестве подпрограмм полных
машинных программ решения. Были проверены функции 1, 11,
П’ и \’11 табл. 5.2.1. В табл. 5.3.2 приведены результаты Уорт-
мана, а также некоторые данные, полученные другими авторами,
в виле количества необходимых вычислений функции. (В табл.
7.2.1 представлены некоторые соответствующие результаты для
фун1‹ции 1Х табл. 5.2.1.) В табл. 5.32 в столбЦе «этапы» приведены
числа успешных направлений поиска (т. е. число минимумов, най-
денных при осуществлении линейных поисков по этим направле-
ниям). В процессе линейного поиска осуществлялись последова-
тельный поиск и подгонка кривой.

Используя процедуру Хука и Дживса, Уортман немного моди`
фицировал ее по сравнению с описанной в разд. 4.1 так, что в слу-
чае успешного шага следующее значение х, берется в два раза боль-
шим предыдущего х„ тогда как при неудаче следующее значение
х, берется в два раза меньшим предыдущего х,. Для поиска по
методу Хука и Дживса столбец «этапы» относится к исследующему
поиску и, возможно, продвижению по образцу, тогда как в случае
поиска по методу Пауэлла этап включает обнаружение минимума
 pagebreak 
Сравнение алгоритмов при отсутствии ограничений 223

 

Таблица 5.3.2

зации при ОТСУТСТВИИ ограничений
‚___—___—

 

 

 

 

Метод Дэвис: — Свеина — Метод Хукв и_ джинса Метод Пауэлла
Кеппи (Флетчер [13]; (Уортман [1111 (Уортман [1111 Пауэлл [щ
___—___—
Ё’Ё % ёё ; ёё ; ёё Ё
:! о о ‚` :а ‹» ^ : о .»
Ё „=… 553 3 5 55% 3 5 %зё @ % зад
` % 95$ __ э: ёё … 1; На __ в Ёёе

1,5.10—12 21 187 2.10—7 87 353 4-10—14 15 192 7.10—‘° 13 151
2.10—9 142 588 9.10—„ 17 216
2.104" 40 168 6-10—15 7 66
:ио—9 |% 458 5.10—13 17 202
3-10-7 44 181 9-10-16 24 333
1-10—‘1 43151 1.1(›-'5 7 77
мг… 56 230 1.10—17 9 119
1.6.10—" 12 196 2‹1‹›—8 100 769 3-10—9 19 89 5-10—9 16 235

методом ивисиорейшею спуска; ‘конечное = [1.94 0.858]т_

 

с помощью линейного поиска в каждом из № независимых коорди-
натных направлений и, возможно, в смешанном направлении.

Все конечные значения элементов вектора независимых пере-
менных отклонялись от истинных значений элементов х* не боль-
ше. чем на 10'5 (Ю" для процедуры Хука —-— Дживса), за исклю—
чением особо отмеченных случаев. Приведенное здесь число вычис—
лений функпии несколько больше, чем в случае, если бы удалить
Одну из частей программы, работающей как маШИнная подпро-
грамма, и использовать ее отдеЛЬно. Тем не менее алгоритм Дэви—
дона — Флетчера _Пауэлла оказывается почти таКИМ же удов-
летвориельным, как и метод Ньютона. (Когда в этих примерах
при использовании алгоритма Ньют0на матрица Гессе оказывалась
не положительно определенной, матрица направлений заменялась
единичной матрицей, т. е. в качестве направления поиска выбира-
лось направление трицательного градиента.)

В табл. 5.3.3 для нескольких алгоритмов приводится число
этапов, приведенных в сообщении Пирсона, необходимых. чтобы
уменьшить і (х) ниже уровня 10—19. Эги числа в сущности не явля-
ются количеством проведенных вычислений ф нкции, поскольку
на каждом этапе для обнаружения минимума (х) осуществлялся
одномерный поиск Фибоначчи. Изменяя критерий окончания про-
цесса одномерного поиска, получИМ различное число итераций;
сдедовательно, данные, приведенные в таблице, должны рассматри—
ваться скорее как относительные, чем как абсолютные. Столбец
 pagebreak 
Таблица 5.33

Число этапов для уменьшения ] (х*) дв значений. меньших 10"|З [15]
№

 

Функции 1 по Функция \71 по Функция „( …,
НМЁЁЁЁЗБЁЁЁРИЯ Табд- 5%;$У№я "бд 5111) Функция Х по табл. 5.2.12)
Алгоритм Разды
без пере- с пере— без пере‹ ‹: пере— без пере› ‹: пере- без с пере—
ЗЁДЕНИЯ заданием задания заданием задания ЗЕМНИШ перезадаиия заданием
Пирсона №2 3.43 18 31 36 47 27 (62) 22 (60) 134 (221) 98 (187)
Пирсона №3 3.4.3 2! 37 46 47 33 (67) 22 (54) 136 (246) 100 (168)
дэвидона — Флетче-
ра—Паузлла 3.4.2 [9 35 @0 49 27 (60) 22 (56) 406 (500) 97 (169)
Ньютона 3.2.1 12 _ 23 —— 11 (22) — 30 (48) —
Флетчера _ Ривса 3.3.2 _ 16 _ ЗО —- 34 (Р) — >489 (Р)
Проектнвннй
Ньютона (Пирсона) 3.4.3 36 21 58 55 31 (20) 67 (54) 166 (230) 113 (1861
Противный
(Заутендайка) 33.4 -— 42 —-— 65 (26) (70) (120) (21 1)

'3 Числа без скобок для : = 1; со скобками — для ‚= 2,44—10—4 (си. гл. 7»
гимн без скобок для г= 1: со скобкаин—лля := ц0625 (см. гл. 7).
— неудача.
 pagebreak 
Сравнение алгоритмов при отсутствии ограничений 225

 

 

«с перезаданием» указывает‚ что после (п + |)-го шага величина

пт“ задавалась заново равной К“” и алгоритм повторялся;
в методе Флетчера — Ривса и проективпом методе начальная точка
всегда должна перезадаваться.

Метод Ньютона всегда оказывался лучшим; что же касается
остальных методов, то, за исключением метода Флетчера — Ривса,
который не сработал в некоторых тестах. все они оказались прибли—
зительно равной эффективности. Из табл. 5.3.3 видно, что переза-
дание п дает существенный выигрыш для целевых функций, полу-
ченных ‹: использованием понятия штрафной функции, ибо, как
только х приближается к активным ограничениям, матрица Гессе
для штрафной функции становится Очень «плохой». Для других
функций задание заново 11 не приводит к каким-нибудь преимущест-
вам. Мак-Кормик и Пирсон [141 пришли к выводу, что использова-
ние методов Переменной метрики с перезаданием является наиболее
подходящим на ранних этапах оптимизации, тогда как отказ огг
перезадания предпочтителен на более поздних этапах, когда х ока-
зывается настолько близок к х*, что эффективными становятся
свойства сопряженности алгоритмов переменной метрики.

Рассмотрение приведенных выше результатов тестов дает лишь
частичную картину относительной эффективности алгоритмов не—
линейного программирования при отсутствии ограничений, пос-
кольку в каждом исследовании использовались различные методы
одномврного поиска, разные критерии окончания процесса и раз-
личные методы подсчета кинчества вычислений функции. Более
желательным является проведение оценивания с использованием
единого набора` стандартов и тестовых задач. Для уменьшения
объема данных, которые могут быть получены при решении тесто-
вых задач, до разумно достижимого предела мы воспользуемся
тем фактом, что все алгоритмы уменьшают (по крайней мере долж-
ны уменьшать) Целевую функцию монотонно от этапа к этапу.
Так, представляется разумным строить графики ”(х) _} (х*)1.
“(х)" или, что еще лучше, 13 [[ (х) —-і(х*)1 в зависимости от
колИчества вычислений функции или времени, т. е. кривые типа
изображенных на фиг. 5.3.1 и 5.3.2. Можно было бы взять 1| х —х* ||
или другой критерий для сравнения, но эти функции не будут
уменьшаться монотонно. Такие кривые дают эмпирическую меру
скорости сходныости соответствующих алгоритмов. Заметим, что
если заканчивать процесс оптимизации всегда при заданной разум—
ной степени точности в ”(х) -—і(х*)1‚ скажем 10‘”, то можно
использовать соответствующее этому уровню число вычислений
функции или время в качестве единственной меры эффективности
алгоритма. Хотя абсолютные значения количества вычислений
функции или времени могут не иметь большого смысла, относитель—
ное ранжирование алгоритмов по этим величиим оказывается ра-
зумным количественным механизмом сравнения.
 pagebreak 
о- - - -о Флетчер—‚Ривс ‚___. Пауля

.. _. тдщтедк-лмйе о—ю дтенфт

&— Хут—Джиае - - _ {[г./[дер чту

. ....... .. д'ддйуен
ь - —А Диарра — флеш чер — Лауэлл
<>- - % Ларсон .?

--- таг —— да желт №3 ;- перг-
. _. удалит %сткде тбщвние)

|
г..,

штатки

        

.................. . .. .

то 200 `зоо 400 юао
джапвмелтнде число адшислений фултции

Ф и г. 5.3.1. Сравнение глгоритмдв нелинейного программирования при отсут—
вии ограничений для функции Розенброка.
 pagebreak 
о- - - ‹; шетчер фидо о—-О Паузы
. - —9 [Шуштгйн-Лрайс О-—0 Розенбро/с
… Хук “Джи“ _ _ _ Нелугр-Мцу
.…... . Еройуен
А— -—А Дмиуон-флетчер—Лгхузлл

О- - —(> Литл
.. . . ..| №ртаг _Ларуявелт №3 @ переживаем
(частное сообщите)

    
   
  
 
  
     

___-1 ‘ ‚тетива
' "_О- -.—_--—<>_ --—-"0—"—-"-<>

“"“.

..и—___.._.._..

о

и [«за—№№]

-—_-—-_-—.._._-_.—

     

     

1000 2000 5000 4000 5000
Зтоителтное тмичес'тт шчиелг/шй функции

Ф и г. 5.3.2. Сравнение алгоритмов нелинейного программирования при отсутствии
ограничений для функции Вуда.
 pagebreak 
228 Г лава 5

 

Попытки сравнения различных алгоритмов на основе количества
вычислений функции могут быть менее удовлетворительными, чем
сравнение с использованием времени решения, особенно если
последнее может быть определено для одной и той же ЭВМ, исполь-
зуются общие подпрограммы и задачи решаются до одной и той же
степени точности. В качестве примера приведем (см. фиг. 5.3.1)
одну из причин, почему испальэование количества вычислений
функции в качестве критерия является не очень подходящим.
Эквивалентное число вычислений функиии в методе Пауэлла пред—
ставляет собой просто число вычислений целевой функции; в методе
Флетчера —- Ривса оно представляет ‘собой колИЧество обращений
к фунщиональной подпрограмме, составленной так, что один
градиентный вызов (содержащий две производные) эквивалентен
одному вызову целевой функции; в алгоритме Голдштейна — Прай—
са вычисление двух компонент градиента также считается эквива-
лентным одному вычислению целевой функции. На фиг. 5.3.2 один
градиентный вызов эквивалентен двум обращениям к вычислению
целевой функции. Однако компоненты градиентав алгоритме Голд-
штейна —— Прайса вычисляются гораздо чаще, чем в алгорИтме
Флетчера ——Ривса‚ что приводит к некоторому агносительному
искажению при сравнении по тому критерию указанных алгорит-
мов из-за произвольного определения эквивалентного количества
вычислений функции, Именно поэтому время решения до заданного
значения 15; [[ (х) — [ (х*)1‚ & не эквивалентное количество вычисле-
ний функции было выбрано в качестве единственной наиболее под—
ходящей меры эффективности.

Там, где это было удобно, применялись метод золотого сечения
и поиск ДСК —— Пауэлла. Эти методы описаны в разд. 2.6. В при—
ложении Б содержатся машинные программы этих процедур и
ряда алгоритмов. Критерии окончания процедур одномерного
поиска были одними и теми же. Окончание процедур основных
алгоритмов тоже проводилось по одним и тем же критериям. Для
Оценивания времени решения все тестовые задачи решались на одной
и той же машине ЭВМ СВС 6600. Время печатания, периферичес-
кой обработки информации и время работы на пульте исключены
из времени, приведенного в табл. 5.3.4, так что эти данные
действительно представляют собой число секунд, необходимых для
реализации алгоритмов без какого бы то ни было прерывания
процесса.

В табл. 5.3.5 дана Оценка алгоритмов на основании данных
табл. 5.3.4. Все алгоритмы вместе со своими подпрограммами ран-
жировались в порядке возрастания времени от номера 1 (самый
быстрый) до номера 11. Алгоритм Пирсона № 2 не рассматривался
из-за повторяющихся неудач. (Оценки некоторых других менее
надежных алгоритмов приводились в гл. 3 и 4.) После ранжиро—
вания по каждой задаче результаты были усреднены по всем 11
 pagebreak 
Таблица 5.3.4
Сравнение времени решения (в секундах) для одиннадддти тесювых задач ‹: помощью одиннадцати алгоритмов

___—№
‹Зшчи из приложения А или табл. 5.2.1)

%
гп”) } \!11) 1 260/11”) 31 за №),
№
Бройценд 3.4.1

Алгоритм Раздел 28 29 30 32 33 34

 

 

 

 

 

 

 

 

 

ДСК 0,013”) 0,089 0,060 0,040 0,031 0,024 0.010 0.125 0,015 0,037 0,013

3 0,016“) 0,092 0,046 0,012 0,018 0,021 0,006 0,109 0,016 0,132 0,012
Давидова —— Флет-

чера — Пауэлла ЗАЗ

дск 0. 01 4“) 0,088 0,104 0,027 0,099 0,027 0,008 0,052 0,015 0,056 0,015

3 0,016“) 0,113 0,088 0,010 0,046 0,025 0,019 0,121 0,016 0,134 0,010
Пирсона №2 8.4.8

ДСК > 1,00 Ё Р` > 1,00 Р Р 0,008 Р` 0,022 Р` Р

3 >1_00 Р` Р` >1‚00 Р Р 0,011 Р Р —
Пирсона № 3 3.4.3

ДСК 0,058 (035303) > 100 0.028 ' 0.059 0,046 0,008 > 10 0.024 > 10 0,016

3 о_051 (12331933) 2,763 0,011 0,106 0,065 0.010 > 10 0,016 > 10 0.013

-—-———-—-————————_———______________.___________—_______
 pagebreak 
Продолжение табл. 5.3.4

 

(Задачи из приложения А или табл. 5.2.1)

 

 

 

 

 

 

 

 

 

 

 

Алгоритм Раздел 2 (11), и” 126 01111); 23 29 во 31 32 33 34 зв (1/11)

Голдштейиа ——

Прайса 3.4.6

ДСК 0,016?) 0,079 0,100 0,052 0,026 0,021 0,096 0,066 0. 035 0,158 0,014

3 0,013 0,089 0,057 0,014 0,044 0,029 0,145 0,149 0,020 0,097 0,016

гп _ _ _ 0,081 — — „ 0,094 — 0,043 —
Флетчера —— Ривса 3.3.2

ЦСК 0,027 25,041 0,144 0,055 0,069 0,019 0,015 Р 0,013?) 0,064 0,012

3 —- 0,830 2,330 — — —- — Р — 0,975 ——
Флетчера 3.4.5 0,022 0,024 0, 050 0.006 0.018 0,012 0,004 0, 050 0,010 0,028 0,011
Хука— Дживса 4,1 0,100 0,152 0,067 0,008 0,167 0,018 0,012 0,1276) 0,054 1-` 0,009
Нелдера—Мида 4 ‚2 0,097 0, 154 0.072 0,024 0,036 0,148 71 0, 6853) 0,019 0,531 0,014
Розенброка 4.3 0,058 0,378 0,097 0,035 0,125 0,131 0,025 0,202“) 0,027 0,148 0,025
Пауэлла 4.4

ДСК 0,035 0,041 0,084 0,006 0,014 0,014 0,005 0,178 0,017 0,025 0,012

3 0,050 0,098 0,174 0,021 0,106 0,028 0,015 0,857 0,018 0,108 0,027

1) Римские цифры означают иоиер задачи по табл. 5.2 1.

2) Время увеличивается на 70—100%‚ если поиск проходит по изогнутой впадине.

3) С перезадвнием.

4) С переиздание!!! на (п + 1)-м этапе.

5) Работает толъко с масштабированием (си. иашпииую прсгршму в приложении 5).
6) Закончил решение на плоском плато до достижения иивимуиа.

7) Поиск стал уходить в иащмвлвпии глобашьиою минимум:; на ——о‹›.
Обозначения: ДСК -— метод ДСК; 3 -— метод золотого сечения; Р -— неудача; ГП — иетод Голдштейна =— Прайса.

Щ
 pagebreak 
Сравнение алгоритмов при отсумтвии ограничений 231

 

задачам, причем предполагалось, ЧТО задачи имеют равный вес.
Конечно, можно было бы считать, что более трудные задачи должны
иметь больший вес, чем более легкие, но это не было сделано.
Тем не менее возможное различие при применении двух подпро-
грамм одномерного поиска было исключено путем слияния двух
ранжировок в одну общую для каждого алгоритма.

Интересным результатом такого ранжирования было то, что
алгоритмы оказалось возможным объединить в группы. В табл.

Таблица 5.35

Оценка алгоритмов нелинейного программирования
при отсутствии ограничений, исходя из времени решения

 

Кшесификвция Алгоритм

 

Флетчера

Дэвидона -— ФлетЧера—Пауэлш
Наилучший Бройдена

Пауэлла

Хороший Голдштейна —Прайса
Нелдера — Миди
Роаенброка

Благоприятный Флетчера — Ривса
ХУка —!дживса
Пирсона № 3

Ненадежный Пирсона № 2

 

5.3.5 приведены в порядке уменьшения ранга (увеличения времени
решения) разлщные алгоритмы. Эти алгоритмы разбиты на группы
в соответствии с их качественными характеристиками: «наилуч-
ший», «хороший» и «благоприятный». Ввиду ограниченного набора
тестовых задач такая классификация представляется более разум-
ной, чем непрерывная классификация. Внутри каждой группы алго-
ритмы расположены в порядке вычисленного ранга.

Как и следовало ожидать, алгоритмы поиска работают медлен-
нее, чем алгоритмы. использующие производные, но особенно инте-
ресно то, что алгоритм Пауэлла имеет высокую эффективность.
Алгоритмы Бройдена и Пауэлла в более сложных задачах (таких,
как задачи 26 и 32), по-видимому, работают лучше, чем алгоритм
Дэвидона — Флетчера —— Пауэлла, тогда как для некоторых более
простых задач имело место обратн0е.

Пять алгоритмов попадают в класс «благоприятных» алгорит-
мов. Каждый из этих алгоритмов обычно требовал больше времени,
чем алгоритмы из «наилучшего» класса. Кроме того, эти алгоритмы
менее надежны, чем алгоритмы из «наилучшей» группы, поскольку
они могут закончиться преждевременно или быть неэффективними
 pagebreak 
232 Г лава 5

 

из-за чрезмерно избыточного использования машинного времени.

методах, использующих производные, медленные колебания
в процедуре поиска указывают на то, что матрица направлений ста-
новится почти сингулярной. Включение в алгоритм п0дх0дящей
процедуры перезадания начальной точки, восстанавливающей мат-
рицу направлений до положительно определенной формы, возмож-
но, может улучшить некторые методы переменной метрики.

Алгоритмы Хука —-Дживса‚ Нелдера —Мида и Роэенброка
оказались довольно слабьши при решении задачи статистической
оценки (задача 32). В этой задаче в окрестности минимума целевая
функция была нечувствительна к изменениям переменных, т. е.
в этой обдасти целевая функция имела вид плато.

Все тестовые задачи, результат решения которых использо-
ваны при построении табл. 5.3.5, содержали всего лишь несколько
переменных. Очень важно выяснить, как ведут себя эти алгоритмы
с увеЛИчением размерности задачи. К сожалению, в этом отноше—
нии имеется очень мало данных. Для выяснения этого вопроса
Флетчер и Пауэлл (1963 г.) предложили тестовую функцию для
задачи минимизации, содержащую регулируемое число пере-
менных:

п п 2

[(х) = 2 [Б‚—— 2 (А;,зіп х, + віісозх,)] . (5.3.1)
1:1 ‚= 1

Функция (5.3.1) соответствует решению совместной системы транс-

цендентных уравнений

Ё1(А„51'пх,+в‚›ісозх,) =Е‚-, і: 1, , п,
[=

полученному минимизацией суммы квадратов разностей. Коэффи—
циенты А„ и В„ генерируются в виде псевдослучайных целых
величин с равномерным (прямоугольным) распределением вероят—
ностей на интервалах ——100 < А„ < 100 и —100 < В„. < 100.
Значения Е, были промоделированы путем генерированм различ`
ных по величине групп из х, от 71 = 5 до п = 100 как псевдо—
случайных действительных чисел в интервале от ——л до я.

Целевая фушщия Дх) минимизировалась по отношению к век-
тору х= [хв …, х„]Т, начиная с вектора к“” = 1х1 + 0,161, ..., х„ +
+О‚16„]т‚ где бі—случайные числа на интервале от —п до я.
Втабл. 5.3.6приведено эквивалентное количество вычислений функ`
ции, необходимое для уменьшения измеНения каждого х, до вели-
чины, меньшей чем 10—4. Для разных начальных векторов могут
быть достигнуты различные минимумы, так как, конечно, такая
функция, как (5.3.1), имеет много минимумов; с другой стороны,
при некоторых начальных векторах локальный минимум может
бы1‘ь и не найден.
 pagebreak 
Сравнение алгоритмов при отсутствии ограничений 233

 

Хотя табл. 5.3.6. может дать только качественное представление
относительно эффективности соответствующих алгоритмов при ре‚
Шении Задач большой размерности, создается впечатление, что
методы Давидова — Флетчера —— Пауэлла и Пауэлла (1964 г.),
грубо говоря, эквивалентны и явно лучше других методов, за исклю-

Таблица 5.3.6

Влияние размерности на алгоритм минимизации
(Средние значения эквивалентного количества вычислений фунвщии 1).
взятые из работы Бокса [‘161)

 

Число нерешенных

 

 

 

Алгоритм Раздел
5 ] 10 | за

Флетчера — Ривса 3.3.2 ‘286 1925 8150
дэвидоиа _— Флетчера ——

Пауэлла 3.4.2 126 358 1910
Нелдера — Мида 4,2 241 891) 9760
Розенброка 4.3 426 1258 7770
Дэвиса — Свенна — Кемпи 4.3 298 1530 6450
Пауэлла (1964) 4.4 103 399 1863
Пауэлла (1965) [17] 22 35 56

1) Эквивалентиое количество вычислений функции для методов. использующи производ-
ине, означает, что одно вычисление функции Плюс п вычислений производных считаются как
«11+ 1) эквивалентных вычислений функции.

 

чением метода Пауэлла (1965 г.). Высокая эффективность алгоритма
Пауэлла (1965 г.) при решении задач типа (5.3.1) приводит к воп-
росу: насколько эффективны рассмотренные алгоритмы при приме—
нении ИХ к ТОМУ ИЛИ ИНОМУ СПециальному ТИПУ задачи минимиза-
ции суммы квадратов и, в частности, каковы они по сравнению
с классическим методом наименьших квадратов Гаусса?

Для целевой функции, представляющей собой сумму квадратов

их) = Ё фт) = 9%) ф (х),

!=1

7…) = 21Т‹х›ф‹х›‚

где ] (х) _ матрица Якоби размерности ‹; >< п:

 

'дфі...Ё1__
611 дхд
“@= . . .
Ш...№

0х1 ах„
 pagebreak 
о———-о Дэвида” - Флеш чер -//аумл +золотае сечение-

Ь .. 1 Ларсон 5 + золотое сечение
П- --—-П дройуеін зматое сечение

 
 
 
  

0—0 Мета; наименошшг квадратов

19[і(ас)— ”.и-")]

0 ! 2 3 1! 5 6 7 8 З Ю П 12 15
Число этапов
Ф и г. 5.3.3. Сравнение различных методов при использовании их для решения за-
дач, сводящихся к звдгіЧе минимизации суммы квадратов (задача 35 из приложе-
ния А).
 pagebreak 
Сравнение алгоритмов при отсутствии ограничений 235

 

а ф _ вектор-столбец из @ функций. Если градиент в т0чке хде”…
аппроксимируется по формуле

71°М“")т21Т(х"")ф(х‘”+")‚ (5.3.2)

и
а ф(х‹ +1)) в свою очередь аппроксимируется членом первого
порядка разложения в ряд Тейлора

ф (‚(%—Н)) : ф (ход) + " (ход) (хкіг-Н) _ Х…), (533)

то подстановка (5.3.3) в (5.3.2) дает приближенное выражение для
градиента целевой функции в новой точке. Необходимые условия

существования минимума В точке Х‘Ё-Н), СОСТОЯШИе В ТОМ, ЧТО

::
ті (х‘ +”) = 0, приводят к вычислению Хард) по методу наимень-
ших квадратов Гаусса:

к““… = к“” _ [1Т(х®) 1 (›‹“дл—1 1Т‹х<’”)ф(х“°). (5.3.4)

(Модификация Левенберга—Маркуардта, оггмеченнзя в разд. 3.2,
заключается в замене [іт(х‘ю)1(х…)] на ‚[1Т(х“")1(х‘ю) + 511.) При
использовании метода Гаусса или метода Маркуардта требуется
такой алгоритм обращения матриц, который гарантировал бы
паложительную определенность получаемой обратной матрицы при
положительно определенной исходной матрице. К сожалению,
такая процедура отсутствует во многих широко используемых ма—
шинных вычислительных методах программирования.

Алгоритм Гаусса состоит в следующем. Начиная из точки х

1) определить Лх…) и вычислить НТМ”) .| (х"")]—1 и ф(х‹ю);

2) по формуле (5.3.4) вычислить х‘ы’“;

3) повторять переход от шага 2 к шагу 1, пока не будет удовлет-
ворен критерий окончания процесса.

На фиг. 5.3.3 сравнивается метод наименьших квадратов Гаус—
са с другими методами минимизации при решении систем уравнений,
но это не слишком показательно, поскольку один этап в ме-
тоде наименьших квадратов не то же, что один этап в других мето-
дах. Аналогично трудно сравнивать количество вычислений функ-
ции и количество вычислений производных. В табл. 5.3.7 приво-
дится время решения (на ЭВМ СВС 6600) семи задач методом
наименьших квадратов, а также лучшее время, полученное при ис-
пользовании алгоритмов табл. 5.3.4. Задача 29 из приложения А не

была решена из—за возникшей неопределенности матрицы (171).
(В таблицу включена и статистическая задача—задача 32 из
приложения А.)

Из табл, 5.3.7 видно, что для задач этого специального ти-
на метод Гаусса может конкурировать с лучшим из алгоритмов

(Й) .
 pagebreak 
Таблица 5.8.7

Сравнение метода наименьших квадратов ‹: другими методами (лучшими
по времени решения) для целевых функций, представляющих собой сумму

 

 

квадратов
Задача Время решения мето-
(приложением дом наименьших Лучшее время решения другими ме'юддми. :
квадрдтпв, с

2 0,0!2 0,013 (метод Бройдена]

26 0,058 0,046 (метод Бройдена)

28 0,013 0,006 (метод Пауэлла, Флетчера)

30 0,015 0,012 (метод Флетчера)

32 0,06! 0,050 (метод Флетчера)

34 0,020 0,025 (метод Пауэлла)

35 0,017 0,010 (метод Дэвидона _Флегчера—Пауэлла)

 

Таблица 5.3.8

Результаты применения различных алгоритмов при решении задач
минимизации суммы квадратов

Число попадании

 

П
Группа и:; Алгоритм ($$$? в “шен
ранг рангов
| и | …
А 1 Г аусса 26 0 0
2 Маркуардта (разд. 3.2) 32 0 0
В 3 Бройдена (подразд. 3.441) 1) 73 2 2
4 (подразд. 3.4.6) 77 З 1
С Б Алюритм Дэвидона _- Флетчера _— 97 3 3

На уэлла (подразд. 3.4.2)

 

1) Здесь собственные значения могут устанавливаться на некоторых абсолютных уровнях.
как это следует из процедуры Гринштадп (разд. З.2)‚

 

Таблица 53.9

Влияние количества оцениваемых параметров на работу алгоритма
при решении задачи минимизации СУММЫ КВЗДРВТОВ

 

Ранг для указанного числа параметров
Алгоритм '

 

з 5 в | в [ ю

Гаусса ! 2 1 2 1

Маркуардта (разд. 3.2) 2 1 2 1 2

Бройдена (падразд. 3.4.1) 3 3 З 5 5
дэвидона — Флетчера —

Пауэлла (подраад. 3.4.2) 5 5 5 4 3
 pagebreak 
Сравнение алгоритмов при отсутствии ограничений 237

нелинейноюп ограммирования при отсутствии ограничений. В дру-
гих работах 1618—21], где рассматривается специальный случай
рецюния системы совмеСТНЫх нелинейных уравнений рутем мини-
мизаЦИи невязок‚показывается‚что методы переменнои метрики не
всегда являются надежными.

[Три исследовании алгоритмов вычисления нелинейных оценок
в статистических задачах Бард |22] проверил пять суцюственно
нелинейных моделей, содержащих от трех до десяти параметров,
охарактеризовал работу каждого алгоритма для каждой из задач
(ранг 1 определялся как лучший), & затем классифицировал резуль—
таты следующим образом:

класс 1: лучшие результаты;

класс И: не такие хорошие результаты, как в классе 1, но вполне
приемлемые.

класс 111: неприемлемые результаты и (или) отсутствие сходи-
мости.

В табл. 5.3.8 приведена средняя сумма рангов для различных
алгоритмов и число попаданий каждого алгоритма 5 классы 11 и
111. С увеличением числа оцениваемых Параметров ранги в столбце 2
табл. 5.3.8 сдвигаются ненамного, как это видно из табл. 5.3.9.
Хотя методы Гаусса и Маркуардта с увеличением числа параметров
все еще представляются лучшими, метод Дэвидона — Флетчера —
[Тауэлла становится относительно более предпочтительным.

ЛИТЕРАТУРА

1. КозепЬюск Н. Н., Сотриіег .!., 3, 175 (1960).

2. }УЁіМе В. Р., НОЫ \”. К., $ргіп3 _Тоіпі Сошрціег Сет., \УазЬіпаЪоп, В. С.,
9 .

3. Веаіе Е. М. 1… Он ап Пегаііче МеШоа оі Ріпйіпд а Ъоса! Міпітцт оі а Може

ТЬап Опе \!агіаЫе, Ргіпсеіоп Ппіч. Зіаъ ТесЬп. Кез. Стцр ТесЬп. Карт.

25, Меч. 1958.

\Уоос! С Р., \Уезііпвіюцзе Кез. ЬаЬз.

Роше" М. 1. В., Сотриіег .1., 1, 155 (1964).

%%; Е. Е., Ъечу А. У., Кісе Ппіч. Аею-Азігопаціісз Нері. 58, Ноцзіощ Тех.,

Ьеоп А., А Сотрагізоп Атон; Еідт Кпошп Оріішіиіпе Ргосеапгез, іп:

ЙеСепЁ Айуапсез іп Оріітіиаііоп ТесЬпічиеэ. Ьачі А., \1051 Т. Р., е‹15„ \Чііеу,

…С. М. У., 1966.

8. Зіечепз 1). Е, Хпзппсііопз іог ’сЬе Цзе оі \’АКМШТ, Ппіч. оі СнШотіа, [‚аш-
гепсе Кааіаііоп ЪаЬ., ВегКеіеу, .!цпе 1961.

9. Ваег &‘ М., Сотри!“ ]., 5. 193 (1962).

10. ВоегПег Т. Е., Рагіап Міпітіиаііоп Ьу Метод оі РагаПеі Тнпвепіз, 100/21
Зіаіе ит., Ашез, Коша; Аргіі 1964.

11. шептал ]. В., МЬРЦОО, ВаНізііс Кез. ЬаЬ. Метп. Пері. 1958, АЬепіееп
Ргочіпд бюцтіэ, Мф, .!ап. 1969.

12. Пеіспег К., Рошен М. 1. В,. Сотриігг ‚!., 6, 163 (1963).

13. Ріеіспег К., Сотриіе/ ]., 8, 33 (1965).

14. МсСоппіск @. Р., Реагзоп .]. 11, Спар. 21 іп: ОритіъаііощНеісЬег К., её.,

Асааешіс Ргезз, 1пс., Ьопёоп, 1969.

." 9$"?
 pagebreak 
238 Г лава 5

15

16,
17.
18.
19.
20.
214

22

. Реагзоп ]. В., Сотриіе: ]., 13, 171 (1969).
Вох М. .1.‚ Сотриіе/ ]., 9, 67 (1966).
Роше]! М. .]. Г.)., Сотриіег .!., 7, 303 (1965).
Вох М. .1., Сотриіе: !., З, 67 (19662.
Вагпез]. 6. Р., Сотриігг ]., 8, 66 1965).
Роше]! М_ 1, В., Сотриів/ ]., 7, 303 (1965).

[пс., Ьопаоп, 1969.

БретЛеу “!., СЬар. 16 іп: Оріішіиаііощ Ріеіспег В., её., Асадетіс Ргезз,

. Ван! У… Сошрагіэоп оі Сигааіепі Метогіз іог спе Зошсіоп оі МопНпеаг Рагн—

тпеіег Езіітаііоп РгоЫетэ, ШМ М. У. Эсі. Сепіег Кері. 320-2955,
$!АМ ]. Митеііса! Апаіч 7, 157 (1970).

1968;
 pagebreak 
Часть "!

МЕТОДЫ НЕЛИНЕИНОГО ПРОГРАММИРОВАНИЯ
ПРИ НАЛИЧИИ ОГРАНИЧЕНИЙ

В области нелинейного программирования с ограничениями ‘)
методы решения менее разработаны по сравнению с областью не-
линейного программирования, охватывающего круг задач, в кото-
рых ограничения отсутствуют. При решении задач нелинейного
программирования с ограничениями встречаются гораздо ббльшие
трудности, чем при решении сопоставимых (т. е. обладающих
приблизительно такой же размерностью и такой же «степенью»
нелинейности) задач безусловной оптимизации по той причине,
что искомое решение доджно подчиняться дополнительному требо-
ванию, а именно удовлетворять фигурирующим в задаче ограничи-
вающим условиям Опубликованные вькчислительные процедуры
решения задачи нелинеиного программмирования, содержащеи
ограничения, в большинстве своем опираются на один из следующих
подходов:

1, Распространение аппарата линейного программирования на
условия нелинейного программирования путем использования про-
цедуры последователъной (повторяемой определенное число раз)
линейной аппроксимации.

2. Преобразование задачи нелинейного программирования с
ограничениями в эквивалентную ей последовательность задач
безусловной оптимизации путем введения в рассмогрение штраф-
ных функций.

3. Использование скользящих допусков, позволяющих опери-
ровать в процессе решения задачи оптимизации как с допустимыми,
так и с недопустимыми (но близкими к допустимым) векторами в
пространстве решений.

Основные характеристики и потенциальные возможности ряда
методов решения задач нелинейного программирования при нали-
чии ограничений в систематизированном виде представлены в

 

') Задача нелинейного программирования при наличии ограничений в общей
постановке представлена соотношениями (2,2.1) —- (2.2.3).
 pagebreak 
Таблица А

Характеристики некоторых методов нелинейного программирования при наличии ошаишеиий

 

Структурные харак-

теристики решает“

ззлдч и харакири:—
тики Ме'іодв

Целевая функция

Позволяет манипули-
ровать ‹: ограниче-
ниями в виде ра-
ВЫСТБ

Позволяет манипули-
ровать с ограниче-
ниями в виде нера-
ВЕПИВ

Начальная точка

Позволяет решать не-
выпуклые :адачи

Скорость сходиивсги

Промежуточные ре-
шения

 

‹` Метод
ап прок-
сими-

рующегв
програм-
мирова-
ннп (пид-
раза
6 . 1.1›

Л и НЛ
Нет

НЛ”

Л
да

Низкая

Д

Г лава 8
Глава 7 Метод
Глава 6 Методы П%еЗбржЁкпя скользя—
Методы линейной апп кешацни имено уи е
ро (метпды штрафных функций) “},;ЁКЁО'

Метод

М Розена

гра-

(ПЁ‘ЁЁД’ “Защ диета,
”"-’) (подразд.

6.3.1)

ЛиНЛ ЛнНЛ ЛиНЛ
Нет ЛиНЛ Л

Линд ЛиНЛ Линд?)

д и Н Д И Н Д
да да да
Низкая Низмя Высокая“
Л Д Н Н д

ОГМОП

Проек-
тивный
вариант
метода
Дэвидс-

(подразд. Флетче-

63.2)

ЛиНЛ
ЛИНЛ

ра — ПБУ`
мда
‘под-
разд.
6 З.Ы

 

ме…“ Метод Метод
ддпус’ приве- Розен-
тимых денима брока
““Р”" грвдиен- (под-

”ений та (разл разд.

(ЁЯЁД‘ 6.5) 7.1.2)

 

Метод
Дзвидо- МПБМ
на—МБП (разд.
(под- 7.2)
разд.
7,13)

Линд ЛиНЛ Линл Линл ЛиНЛ ЛиНЛ ЛННЛ

.'1

ЛпНЛ ЛнНЛ

дин
Да

Низкая
д и н

“ Неэффективен при решении задач с линейными ограничениями.
2) Весьма неэффективен при решении ззлдч : нелинейными ограничениями.

3) Применим № для решения задач : линейными ограниченнями,
Обозначим: л — линейки (не). НЛ —— нелинейнвя (на, д _ допустили (ые), Н —— не пляши мпустиъюд (не является допустимыми).

___—___Щ

д
Да

СРЕДНЯЯ
д

Нет Л и нл Нет

Нет л л инл

ЛиНЛ ЛиНЛ ЛиНЛ ЛиНл ЛиНЛ ЛиНЛ

д д и Н Внутр‚
да да Да
Высокая Средняя Средняя
д д д

Внутр. Внутр. Д н Н
да дв да
Средняя Высокая Низкая

д Внутр. д и Н
 pagebreak 
Методы нелинейного программирования 241

 

табл. А; более подробно эти методы обсуждаются в гл. 6—8. Сле-
дует отметить, что в табл. А включены только те методы, которые
удовлетворяют ряду конкретных требований; при этом основными
критериями являются:

1) относительно высокая эффективность рассматриваемого ме-
тода как инструмента, позволяющего получать численные решения
задач нелинейного программирования;

2) простота логики построения вычислительных процедур;

3) наличие машинных программ, позволяющих реализовать
рассматриваемый алгоритм на ЭВМ.
 pagebreak 
Глава 6

ПРОЦЕДУРЫ МИНИМИЗАЦИИ ПРИ НАЛИЧИИ ОГРАНИЧЕНИЙ:
МЕТОДЫ ЛИНЕЙНОИ АППРОКСИМАЦИИ

Поскольку методы линейного программирования успешно при.
меняются для решения задач большой размерности при ограниче-
ниях, записанных как в виде равенств, так и в виде неравенств
(разумеется, линейной структуры), способ решения задач нелиней-
ного программирования с помощью процедуры линеаризации,
реализуемой по надлежащим образом построенной схеме итера—
ционного процесса, относшся к числу наиболее очевидных. Два
из рассматриваемых ниже методов (возможно, являющгіхся в неко-
тором отношении наиболее эффектИВными) предполагают линеари-
зацию только ограничений, оставляя целевую функцию нелиней-
ной на всех этапах минимизации. Один из этих методов основан
на использоізании прсектирующих матриц, позволяющих проекти-
ровать вектор, который определяет направление поиска оптималь-
ной точки, на подпространство, связанное с некоторой модифициро-
ванной совокупностью активных ограничений; во втором методе
используется идея приведенного градиента, определение которого
дается в разд. 6.5.

Линейная аппроксимация фигурирующих в задаче [см. соотно—
шения (2.2.1)—(2‚2.3)1нелинейных функций достигается путем
замены этих функций членами первого порядка в соответствующих
разложениях в ряд Тейлора в окрестности рассматриваемой точки
х…. В результате повторяющегося процесса линеаризации нелиней-
ных функций путем разложения их в ряд Тейлора в окрестности
каждого промежуточного решения образуется последовательность
х…, х1,...‚х…, которая при определенных условиях сходится
к оптимальному решению х* исхолной задачи нелинейного про—
граммирования. Чтобы пояснить сущность данного метода, обра-
тимся к задаче нелинейного программирования в ее общей поста-
новке [см. соотношения (2.2.1)—(2.2.З)], т. е. рассмотрим следую-
щую задачу:

минимизировать { (х), ›‹ Е Е”‚

при ограничениях
иі(х)=0‚ і=1‚ ..., т,

. (6.0.1)
е‚(х)>0‚ :=т+1‚р-
 pagebreak 
Методы линейной аппроксимации 243

Эта задача может быть модифицироващ путем замены каждой из
фигурирующих в (60.1) нелинейных функций двумя первыми
членами в соответствующем разложении в ряд Тейлора в окрест-

ности к“”. В результате вместо (6.0.1) нам потребуется

минимишровать Пхи”) + УТНх‘ю) (х — ха“), х 6 Е",
при ограничениях
ні №) + 7% (№) (х— к"“) = 0, і = 1, .. . , т,
3, (х…) + 773, (№) (х _ х‘”) >О, і = т + 1, ... ‚ р.
Поскольку их“”). и №), А, №), чт №), в; №) и 78, №) яв—

ЛЯЮ’ГСЯ либо ПОСТОЯННЫМИ векторами, ЛИбО СКЗЛЯРНЫМИ констан—

тами (значения которых вычисляются в точке х…), задача (6.0.2)
представляет собой задачу линейного программирования.

Чтобы ПРОИЛЛЮСТРИРОВЗТЬ метод линеаризации задачи нели-

нейного программирования в окрестности некоторой точки к””,

рассмотрим следующУю частную задачу:
минимизировать [ (х) = 4х1 — ):Ё — 12, х 5 Е ". при ограничениях

(6.0.2)

п1(х)=25—х%—хё=о‚
32(х)=10х1—х%+10х2—хЁ—34>0‚
ев(Х)=хц>0‚

84(х)=х2>0-

Пусть х“) = [2 41т. Замена фигурирующих в данном примере не-

линейных функций на аппроксимирующие их (в окрестности х…)
линейные выражения приводит к следующей задаче линейного
программирования:

минимизировать ,; (х…) = 4х1 — 8х3 —|— 4, х 6 Е", при ограничениях
1310$”) = 45 —— 4х1 —— 8х2 = 0,
$206”) = _ 14+ 6х1 + 2162 >О,
дих"”) = х, > 0,
ёдхт’) = хз > 0.
Чтобы оттенить то обстоятельство, что вместо исходных функций

взяты их линейные аппроксимации, мы воспользовались зна-
ком (м). Метод оптимизации, требующий линеаризации только
 pagebreak 
244 Г лава б

 

ограничений и не предполагающий линеаризации целевой функции,
иллюстрируется геометрически на фиг. 6.0.1.

Таблица 6.01, содержащая перечень алгоритмов, описание
которых дается в настоящей главе, может служить ориентиром
при ознакомлении с основными характеристиками указанных ал-

` ;(тЩ)-бх‚+2хг—Щ ——*0

Я(="”)- 45—4я'г81'2-0

 

‹; ! '2 а 4 5 д.:,

Ф и г. 6.0.1. Пример линеаризации ограничений в окрестности
точки, заданной вектором х… = [2 411.

горитмов. Некоторые другие алгоритмы, являющиеся по сравне—
нию с алгоритмами, приведенными в табл. 6.0.1, менее эффектив-
ными или оказываюшиеся достаточно эффективными лишь приме-
нительно к задачам специального типа (как, например, к задачам
выпуклого программирования или к задачам, в которых фигури-
руют только линейНЫе ограничения), а также алгоритмы, характе—
ристики которых пока не опубликованы, здесь не описываются.
хотя ссылки на них можно найти в конце данной главы. Методы,
описанию которых посвящена настоящая глава, образуют своею
рода «ряд», начинаюшийся методами с плохими характеристиками
и заканчивающийся методами, которые можно отнести к разряду
отличных.

Сходимость к искомому решению задачи (6.0.1) гарантируется,
если выполняются следующие условия:
 pagebreak 
Методы линейной аппроксимации 245

 

[) Дх), &, (х), …, &… (х), вт.… (х), ,.., ;д(х) являются непрерыв-
ными и дифференцируемыми функциями;

2) функция і(х) выпуклая, а сумма Ей,?(х) выпуклая в !?;

3) 5‚„+‚(х), ..., анх) предсювляют собой вогнутые функции;

4) допустимая область непуста. т. е. действительно существуют
такие значения составляющих вектора х, для которых удовлетво-
ряются все условия, определяемые ограничениями задачи (т. е.
задача имеет решение);

5) множество К замкнутое и выпуклое;

6) существует е>0‚ такое, что „…… <& 0:1, ..., т) и
3,(х)>—в (]=т+ 1, ...,р), т. е. фигурирующие в условиях
фунщии ограничены.

Таблица 6.01
Характеристики методов линейной аппроксимяции

Ограии- Ограни-
Раз- Целевая чения чения Начальный
ме…… дел функция в виде в виде векюр 1)
равенств неравенств
Аппроксимирующее линейное
программирование
6.1.1 ЛиНЛ ЛиНЛ ЛиНЛ Д
ПОП 6.1.2 ЛиНЛ — ЛиНЛ Дин
НЛП 6.2 ЛиНЛ ЛиНЛ ЛиНЛ дин
Проективные
Розена (проекции гра-
диета) ‹- 6.3.1 Л и НЛ Л *) Л 2) Д
Обобщенного градиентно-
го поиска 6.3.2 Л и НЛ Л и НЛ Л и НЛ Д и Н
Дэвидоиа — Голдфарба—
Дэвиса 6.3.3 Л и НЛ Л Л и НЛ Д
Заутеидайка (допусти-
мых направлений) 6.4 Л и НЛ — Л и НЛ Д
ПриведЕнного градиента
обобщенного приведен-
ного градиента 65 Л и НЛ Л и НЛ Л и НЛ Д 1; Н

 

1) Внутренняя точка при необходимости без труда находится путем минимизации суммы
квадратов нарушенных ограннчении в виде неравенств.
2) Существующие в настоящее время машинные программы обеспечивают лишь решение
задач г. линейными ограпИчеииямн.
Обозначения: д—допустииыи (ая, ые), Н — не являющийся допустимым, л —липеИ-
ный (ая, ые), НЛ — нелинейный (ая. ые).

 

На практике любой из алгоритмов, включенных в табл. 6.0.1,
позволяет найти локальный оптимум даже в тех случаях, когда
условия 1—6 не выполняются (при этом многое зависит от харак-
тера решаемой задачи). Специфические тонкости большинства
из описанных в данной главе алгоритмов будут отмечены в гл. 9.
 pagebreak 
246 Глава 5

 

6.1. АППРОКСИМИРУЮЩЕЕ ЛИНЕЙНОЕ
ПРОГРАММИРОВАНИЕ

61.1. МЕТОД АППРОКСИМИРУЮЩЕГО
ПРОГРАММИРОВАНИЯ (МАП)

Гриффин и Стюарт (фирма «Шелл-Ойлэ) П] описали метод ап—
проксимирующего программирования, который основан на много—
кратном применении алгоритмов линейного программирования,
обеспечивающем в пределе сходимость последовательности решений
промежуточных задач линейного программирования к решению
задачи нелинейного программирования (6.0.1). (Такой метод
иногда называют градиентньш методом с малой длиной шага в от-
личие от так называемого крупношагового градиентного метода,
описание которого дано в разд. 6.3.) После выполнения проце-
дуры линеаризации задача формулируется так:

п

(Ь)
мшшмизировать [ (х) — ‚‘ (ход) = 2 Ёі—(дЁ/і- Ах,…
‚'ы

при условии, ЧТО имеют место ограничения В виле равенств
п

дп (ко”) (ю »› ‹
2 _!ЩГА"! : "'“:(76 ›, ‘
1 !

И ограничения В виде неравенств

||

1, ...; т, (6.1.1)

 

 

" (*)
2 №Ах}”’>—Е:(Х®)‚ і=т+1‚р‚

дх;
і=1

где Ах?” = (хг — №. Метод аппроксимирующего программировах-шя

позволяет учитывать все ограничения, записанные в вила нера-
венств, и этим отличается от некоторых из рассматриваемых ниже
методов, которые оперируют лишь активными ограничениями в виде
равенств. [В методе Гласса и Купера [2], который подробно здесь
не обсуждается, даже в том случае, когда неравенс’гвщ полученное
в результате линеаризации исходного ограничения, удовлетворя-
ется при одновременном нарушении соответствующего неравенства
в (6.0.1) (и, следовательно, х выходит за пределы допустимой об-
ласти), направление поиска можно выбрать правильным и, таким
образом, вновь оказаться в пределах допустимой области, если
к правой части линеаризованного неравенства прибавить кон-
станту.1

Метод Гриффица и СТЮарта реализуется по следующей схеме.
Пусть х… —допустимая точка в К. Произведем в (6.0.1) замену
нелинейных функций их линейными аппроксимациями, найден-
 pagebreak 
Методы линейной аппроксимации 247

 

ными в окрестности точки х…. Это приводит к соотношениям, име—
ющим вид (6.1.1) [5 (6.0.2)1. Затем решим задачу линейного про-
граММИрования, представленную этими соотношениями, при сле-
дующем добавочном условии:

ВЁ—1ХЁ"+”—ХЁ-”|>0‚ і=1‚п‚ (6.1.2)

где |х}д+”—-х}*›] —абсолютное значение приращения х], & 6}Ю>0

(] = 1, …, п) есть малая величина, ограничивающая длину шага при
перемещении в том или ином направлении и, таким образом, не
позволяющая вектору х выходить за пределы допустимой области
задачи (6.1.1), Решение задачи (6.11) с учетом (6.12) для разности

х _ хо” при х‚ обозначенном теперь как х, дает
‘ „
х<я+ › : Хаг) + (х_х‹ь»_

Вычислив хщ'”, мы многократно повторяем указанную выше

операцию при постепенном уменьшении 6… (с тем, чтобы довести
отклонения элементов х до величины, определяемой принятым
допуском), стремясь достичь такой ситуации, когда минимизирую-
щая поправка к найденному на предыдущем шаге значению [(х)
оказывается меньше некоторого наперед заданного (малого) числа.

В задаче (6.1.1) дополнительные ограничения для х можно ввести

и несколько иным способом. Обозначим х—х‘” при х>х‹’"

через А+ х…, 3 при х < к“” через А‘ х…. Тогда, прежде чем реа-
лизовать очередную аппроксимирующую процедуру, следует
учесть ограничения для допустимых перемещений в пространстве

решений, определяемые следующими СОО’ГНОШСНИЯМИ:

» Те іі —— ‚1 ;‘е
р}’А+х})+‹7})А х})<т})‚ ]=1, ...,п, (6.13)
где @
›
‹») _ ’"і .
Р! —Шах[1‚ [];—>65” },
(іг)
‹т ’"]
=п1ах 1 _— '
Ч] ( ‚ х?” __ Ц ] ‚
т;") — максимально допустимое перемещение вдоль і-й оси

координат на іс—м шаге;
1,›——нижняя границ:; для хі;
!}, —верхняя границз для х].

Если А`х‘,” = 0, то р$*)А+х}-ю < т?). Когда значение 1:5") близкок сво-
ему верхнему пределу, т. е. (О‚—х}*’)=0‚ то в { 1, т?]Пі—хЁ’}
максимальным оказывается член “#”/11, —— худ. Следовательно,
хі—х}”’<Пі—х}*’, или хі<01‚ т. е. мы имеем гарантию, что
 pagebreak 
248 Г лава б

 

хі не МОЖЕТ превысить свое верхнее предельное значение. Анало-

гичные рассуждения применительъю к условиям, когда А+х®= 0,
позволяют убедиться в том, что х, не может принимать значений,
меньших Ь.

Соотношения (6.1.1) и (6.1. 3) образуют систему линейных соот-
ношений, которая и подлежит анализу с помощью методов линей—
ного программирования. Первый шаг в процессе поиска решения
данной задачи линейного программирования с помощью медифи-
цированного симплексного метода заключается во введении в рас-
смотрение переменных еще двух категорий, а именно так называе'
мых ослабляющих и искусственных переменных. С помошью ослаб-
ляющих переменных ограничения в виде неравенств преобразуются
в ограничения в виде равенств. Используя для обозначения ослаб‹
ляющих переменных символ ні, можно записать ограничения, ко-
торые в (6.1.1) фигурируют как неравенства, в следующем виде:

дык") + @ " дик…) — «» ‹ь›__ аг)
Ё—ттх АХ _ЕМдх] А Хі "и:“ ——Е;(Х )‚

]=1 [=] .
1=т+1‚ ..., р,
…

где и. > 0. Чтобы преобразовать в равенства ограничения
(6.3.1), также используются ослабляющие переменные (обозначит
их через и,); В результате вместо (6. 3.1) получим

рЁЬА+х""+ ;У‘Щ х…+и“”— = ті, ]=1, . . ., п

Искусственные переменные Ш! ВВОДЯТСЯ ЛИШЬ С ТОЙ целью, ЧТО-
6Ы ИМЕТЬ ВОЗМОЖНОСТЬ ЗЗДЗТЬ В качестве начальной ДОПУСТИМУЮ
ТОЧКУ В случае, КОГДЗ начальный вектор Х оказывается вне преде-
ЛОВ ДОПУСТИМОЙ области ПУТЕМ включения искусственных пере-
менных В ограничения, записанные В виде равенств, И В ограниче-
НИЯ В виде неравенств получаем

" дт № " дл №) — :; из
2 дБ“ )А+х$”’—2 [_дгі А „()+шкю ——н,(х ›),
’в] '=1
{ : 1, .. . , т,

и
” д. 1/3) ” д', (Г?) __
2 ———%‘23 ) “#”—23 %; ) А ‚(;и—„№№ =—в‚(х""›‚
!=! ]=1

=т+ 1; .... Р,

где ш,. >О. Искусственные переменные отличны от нуля, если
условие, определяемое соответствующим ограничением, не удовле-
творяется. Применение медифицированюго симплексного метода
позволяет обратить каждую из искусственных переменных в нуль

путем минимизации Хшг
 pagebreak 
М етодм линейной аппроксимации 249

 

Пока на каждом шаге процесса поиска получаемое решение
оказывается допустимым, методаппроксимируЮЩегопрограммирова-
ния «работает» весьма бЫСтро. Однаковслучае, когда на каком—либо
шаге вектор х, дающий минимизирующую поправку к значению
целевой функции 1‘ (х), выходит за пределы допустимой ‚области.
процесс в значительной степени замедляется. В ходе линейного
программирования вначале стремятся удовлетворить ограничения,
не позволяющие вектору х выходить за пределы допустимой области,
а затем пытаются улучшить значение целевой функции. При этом
не исключена возможность того, что решением (6.1.1) и (6.1.3)
на следующем шаге снова будет такой вектор х, который, обеспе—
чивая минимизирующую поправку к полученному ранее значению
{ (х), окажется вне допустимой области. Таким образом, как только
сразу несколько ограничений становятся активными, МАП начи-
нает работать весьма медленно. Следует отметить, что, поскольку
на каждом этапе минимизации осуществляется полная релинеарн-
зация рассматриваемой задачи, вся ранее полученная информация
становится бесполезной; следовательно, МАП может быть применен
для решения невыпуклых задач. Промежуточные решения при
использовании МАП являются либо допустимыми, либо близкими
к допустимым.

Олсон [3] показал, каким образом данные относительно осцил-
лирующвго поведения алгоритма на предшествующих этапах про-
цесса поиска могут быть использованы с целью увеличения или
уменьшения максимальной длины шага т‚-. К числу наиболее
широко известных в этой связи правил относятся следующие:

 

 

 

Едриант таги ОЁЁЁВЗ'ЁБЁЁЁЁЕЁЁЁРЁЁЁХЪ Изменение длины ша" ті
переменных
1 ;& +, _, —-‚ +, _— туЧ' “ = ситу"
_, __ __ +. +_ + тун): щту!)
п >в +. —‚ +, —‚ +, — т?“ = 05%”
<В —. —. —. +, +, + т}*+'>=о,вдх}*> _,…

 

Здесь он есть коэффициент сжатия (или сокращения), значения ко-
торого лежат в интервале от 0,5 до 0,8; 062 —- коэффициент расшире-
ния (или растяжения), значения которого лежат в интервале от
1,2 до 1,5; ‚% _предельная верхняя или нижняя граница х, в
направлении перемещения на іс-м шаге.

На фиг. 6.1.1 приведена обобщенная блок-схема обработки
данных при машинной реализации алгоритма МАП. На основе
данного алгоритма Г риффицу и Стюарту удалось решить задачу,
 pagebreak 
Таблица 6.1.1

Применение МАП при программировании процесса очистки нефти

 

 

 

 

 

 

 

 

 

Этап 1 2 з | 16 11 ….[27 , 28 29
Значение целевой функции 100. О 107, 9 116, 9 . . . 122,0 122,1 122, 1 . 122,0 122 1 122. 0
Число изменений переменных 22 22 21 . . . 8 5 4 4 5
Переменные (начальное значение дано
в скобках)
Исходный материал (17,00) 18,00 19,00 20,00 . . . 21, 67 21, 67 21, 67 . 21, 69 21, 69 21,70
Температура (920,0) 930 0 925,1 924, 9 . . . 915, 4 915, 4 915, 4 . 916, 4 9172 915 7
Высокооктановнй бензин (104, 0) 92,8 104, 3 108,1 . . . 103,4 103, 5 103, 9 . 103. 8 103,7 103, 8
Обычный бензин (156, 9) 172,8 172, 8 173,0 . . . 162, 2 162, 7 162,1 . 161,1 160,41 161, 5
Время, мин
Запись матрицы 10,4 5,6- 4,1 . . . 4,3 4,2 4,2 4,5 4,4

13/90 3,1 2,1 2,8 2,0 2.0 4,2 2.1 3,4
 pagebreak 
Методы линейиай аппроксимации 251

 

содержащую примерно 30 переменных, при числе нелинейных огра-
ничений, превышающем 100. Олсон провел анализ затрат машинно-
го времени (применительно к возможностям электронно-вычислитель-

СЧЦШЫ0ПНЦБ' НПЧЦЛЬЯЛЗЛ вел:—
торл ::
Лицтивулив иллраклидирующиш
тлкции, Щимелава/(ии втрдк, ш' —

мша’л 10 и.:- лерш, миэт; ища има-
2235‘011611 загмшквв !

Вычисление матрицы .И]
И ее дйпидб

ение шения рия _
атЙцн .! спамащма лу-

лтграммы [Р/9_0;аа0уд :

жилащиустршстаадлач.

„мерки жлуиммти:требув
ся аи лраиамуитв замену
о’шишшга аттара ?

Вычисление смташляющиа'
ниша Йанглагд аемтара

 

Ф и г. 6,1.1, Блок—схема вычислительного процесса для алго—
ритма МАП.

ной машины КВМ 7094), расходуемого при реализацииМАПв интер-
вале между записью матрицы и фазой линейного программирования
(см. блок—схему 6.1.1). При этом в нелинейных функциях решае-
мой задачи фигурировали 27 переменных, а матрица линейного
программирования содержала 205 строк. Суммарное время для
29шагов процесса поиска составило 229 мин. Заметим, ЧТО метод
Гриффица и Стюарта оказывается относительно малоэффективным
при решении задач оптимизации без ограничений (по сравнению
с другими методами, предназначенными для решения этих задач)
и при решении задач линейного и квадратичного программирования.
 pagebreak 
252 Глава 6

Пример 6.141. Аппроксимирующее программирование
Метод Гриффица и Стюарта можно проиллюстрировать на сле-
дующем примере. Пусть требуется

минимизировать [(х) = х? + хЁ — 16261 — 10х13
при ограничениях

31(х)=11 _;ё +6х1—4х2>0,

$200: х1х2—3х2—ех‘4+1>0‚ (а)
Ев (х) = 751 > 0:
94 (х) : х, >О.

На фиг. П.6.1‚1 дано графическое представление (топографи)
задачи (а); пунктирными линиями изображены уровни целевой

 

Ф и г. П‚6_1‚1. Г геометрическое представление (топография) задач (а) и (6).

функции [ (х), а сплошными кривыми —два первых нелинейных
ограничения, соответствующие 51, (х) = 0 (і = 1, 2). Оси коорди-
нат соответствуют уравнениям дд (х) = О и 54 (х) = О. Решением
задачи (а) является х* = [5,27 3,687; при этом НХ) = —79,9.
Начальные шаги пропедуры поиска решения сводятся к следую-
щему:

1. В Качестве начальной (допустимой) точки выбирается х…) =
= [4 311, в которой ‚‘ (х°) = —69.

2. Линейная аппроксимация задачи (а) в окрестности точки
 pagebreak 
Методы линейной аппроксимации 253

 

хю’ = [4 311 достигается путем замены фигурирующих в (а)
нелинейных функций их линейными приближениями; линеаризация
приводит к следующей задаче:

минимизировать і(х`°)) = — 8х1 —— 4х1 —— 25
при ограничениях

ёж“) = —2х1—4х2+ 27>о‚

Ьйщ=&%м+№—Ъ№>Ц @
ёв ‹х‹0)) = 351 > 0,
34 (№ = ха >О.

Как уже отмечалось выше, символ м означает, что берется линей-
ное приближение рассматриваемой функиии. Допустимая область;
определяемая линеаризованными ограничениями задачи (а) в окре—

стности к“” = [4 311. ограничена на фиг. П.Б.… сплошными пря—
мыми, а уровни линеаризованной целевой функции )* (х‘щ) представлен
ны пунктирными прямыми. Решением задачи (6) является х") =

= [13,5 011; этот вектор допустим по отношению к задаче (б) и
не являеТся допустимым по отношению к задаче (а).

Чтобы предотвратить выход ›‹ из допустимой области задачи (а),
на х накладывают ограничения вида (6.1.2), т. е. полагают

|ХЭ')—›с5°’[<б$-°’. і=1‚п. (в,

Начальное значение а“” можно выбирать произвольным образом;

для задачи (а) подходящим оказывается, например, 8‘°)= [0,5 0,511.
Заметим, что перемещение от точки х‘°’= [4 317 к точке х…:

= [13,5 011 сопряжено с существенным увеличением 1:1 и заметным
уменьшением хг Учтем теперь условие (в). В полученной точке

х") = [(4 + 0,5) (3—05)? = [4,5 2,51Т функция мх…) : _ 70,65.
На следующем шаге ([а = 1) положим 6… = 0,86…) = [0,4 0,417.
Линейный эквивалент задачи (а) в окрестности х… = [4,5 2,5]т име—
ег следующий вид:
минимизировать Дх…) = -— 71:1 -— 5х2 —— 36
при ограничениях
[31 (х…) = 31,4 — эх, _ 4х, > 0,

};", (х… = 5,42 _ 1,9%1 + 1,5х‚ >О,
&Ы%=м>ц (п

&Ы%=м>ш
 pagebreak 
254 Г лава 6

 

Решением задачи (г) является х‘” = [5,45 3,5811; данная 'ючка
расположена весьма близко к допустимой области задачи (21). На-

ложив дополнительное условие |№ — ;;" [ < 6?“ (] = 1, …, п), в ка-
честве допустимой точки ХШ получаем ха): [4,9 2,9]Т; в этой точ-
ке [(х‘в’) = 75,1. Следующий шаг (&= 2) состоит в выполнении
вычислительной процедуры по приведенной выше схеме при бш<
<&… (например, при 6… = 0,86‘”). Итерационный процесс заквнчи-
вается, как только выполняется условие [бші < 18| (где |в|—до-

статочно малая величина) и х‘ы'” оказывается внутри допустимой
области. На каждом шаге при выходе х из допустимой области,
прежде чем продолжать процесс минимизации, методом линей-
ного программирования определяется решение, являющееся до-
пустимым.

 

6.1.2. МЕТОД ПОП

В 1965 г. Г . Смитом был разработан метод отыскания оптимально-
го решения, основанный (аналогично методу, рассмотренному в
разд. 6.1.1) на линеаризации и пригодный для решения задач не-
линейного программирования в случае. когда ограничения в виде
равенств отсутствуют. Этот метод положен в основу универсальной

машинной программы, известной под названием ПОП " (проГрамма
оптимизации процессов). В соответствии с ПОП процедура линеари-
зации выполняется на каждом шаге и каждая из промежуточных
линейно—оптимизационных задач решается с помощью модифици-
рованного симплексного метода. Повторяющийся процесс линеари-
зации (релинеаризация) осуществляется в окрестности найденной
на предыдущем шаге оптимальной точки, а предельные значения
для длины шага устанавливаются с таким расчетом, чтобы не выйти
за рамки, вне которых соотношения, палученные в результате ли—
неаризации, не могут быть использованы. Как уже отмечалось вы-
ше, с помощью рассматриваемого метода не удается решать задачи
с ограничениями, записанными в виде равенств; исключение со-
ставляют случаи, когда каждое из равенств может быть представ-
лено в виде двух неравенств, например, по следующей схеме:

равенство и (х) = 0

заменяется эквивалентной ему парой неравенств

’11(Х)+Е>0 И Н2(Х)-—`ё<0.
(В подобных ситуациях в прецессе поиска оптимального решения
значение % постепенно уменьшается.) Однако такой способ обращения

') Подробный анализ поп (в английском варианте РОР — Ргосезз Орііті-
иаііоп Рюдгатп) содержится_в работе [4].
 pagebreak 
Считывание исшоу
нии: уанныш

Считывание и 500,7 функций На:) и еда:)

Вычисление частиц.: праиз-
доунцт На:) и (‚!,-юа)

Вычислите влечений фут:—
ции ааади/тоц тачке

”(:::/прогнав матрицы ‚ли-
неиного прдграммироваяия

Башиаттце агмтара ‚;и/гудков; выявле—
ЛЦЕ неролустимма: ттшящши ДЛЕ”?
да 1; ддічий—ЛЕЛЦЯ, ЛддбМЯЮЩЦВ прове >

‚лит.„ ”2 551-247!!!” «ЛЦ ЛЗЖ/іідр ‹1' ЗП уста-
ЯПЫЛЕН/[біг ПДе'уЕ-ЛЬ!

 
     

    
       
     
    
 
   
 
  

Решении задачи линейного про—
граммирдванш

Ь'лгюжденце числовым значе—
лцц тенты: параметров

Лигита на сщимость к: ‹Ло-
жалитму ттимуму

   

дли мили «ашрам:- жатки
№ исимыа: „ ' ! 'мвлипя' ИЯ

     
 

   

Ф и г. 6.1.2. Блок-схема вычислИтельного процесса для алгоритма ПОП П.
 pagebreak 
256 Глава 6

 

с ограничениями в виде равенств редко оправдывает себя на
практике. Поэтому ПОП, вообще говоря, используется лишь для
решения задач следующего вида:

минимизировать [ (х), х & Е”,
при ограничениях

в‚‹х›>о‚ і=1‚……р (6.1.4)
Ьі<хі<11і‚ і=1,...‚П‚.

При решении локально линеаризованной задачи нелинейного про-
граммирования применяют метод линейного программирования та-
ким образом, чтобы последовательность решений промежуточных
линеаризованных задач сходились к решению исходной нелиней-
ной задачи (6.1.4). Получаемые при этом век'юры ›‹ могут быть
как допустимыми, так и недопустимыми, На фиг. 6.1.2 приведена
в общем виде блок-схема вычислительного процесса (или блот
схема обработки данных) при реализации алгоритма Смита.

ПОП автоматически формирует матрицу локального линейного
программирования (ЛП) (фиг. 6.1.3), элементы которой выража-
ются через коэффициенты линеаризованной модели. При этом в
строках, номера которых равны или превосходят (п + 1), распо-
лагаются значения первых частных производных целевой функ-
ции и функций, фигурирующих в ограничениях, по независимым
переменным х,. Числовые значения этих частных производных бе—
рутся в точке, задаваемой текущим вектором х. Следует отметить.
что отдельная строка отводится для каждой независимой перемен—
ной х„ Кроме того, каждому активному ограничению соответ-
ствует отдельная строка.

Матрица, ассоциированная с алгоритмом линейного програм-
мирования, содержит также ряд дополнительных строк и столб-
цов, в часгности следующие столбцы:

!. Вектор-столбщ, задающий предельные значения для пере-
мещений в пространстве решений (вектор допусков). Элементы
этого столбца, расположенные в первых п сгроках, которые ас-
социируются с независимыми переменными, представляют собой
наименьшие значения пределов перемещений вдоль соответствую-
щих этим переменным направлений (или, другими словами, наи-
кратчайшие расстояния до ближайшей границы внутри допусти-
мой области по каждому из упомянутых направлений). Элементы.
расположенные в строках с порядковыми номерами, лежащими в
интервале от (и + 1) до (п + т + 4), представляют собой либо
текущее значение 31, либо разность между текущим и ближайшим
предельным значением д,.

2. Вектор-столбец, ассоциированный : вспомогательными впе-
рациямц. Этот вектор-сюлбец используется при выполнении вы—
числений неявного характера, а также в связи с реализацией над—
 pagebreak 
Методы линейная? аппроксимации 257

 

лежащих вычислителъных процедур в тех случаях, когда исходный
(на рассматриваемом шаге) вектор выходит из допустимой области.

Если какая-либо из независимых переменных х, принимает не-
допустимое значение, допустимость восстанавливается путем заме-

   

Номе
столбЁа ” + '

 

 

 

Вектор-столбец, п + 2 п + 3
1 2 . . . п управляющий Вектор Рабочее
вспомогательными допусков поле
операциями
1
2 1 0
„. . о .
п \
_д__г (х) , ›
дх,- п +
п + 2
и + 3
_ д_е‚‹х› `”________________+'”+‘
дх; 11 + т + 2 Вспомогательная 100
операция
п + т + 3 Функциональное —500
уравнение

 

п+т+4

Штрафная по-
правка

 

 

 

 

 

Ф и г. 6.1.3. Структура части матрицы линейного программирования.

ны данного значения х на наименьшую из разностей между рас-
сматриваемым значением этой переменной и ее предельными зна-
чениями. На данном шаге требуется также внести надлежащие из-
менения в структуру вектора допусков. Возникающие нарушения
ограничивающих условий временно устраняются путем комбини-
рования составляющих получаемого вектора с произвольно выби-
раемыми элементами, которым придаются значения 100 и — 500
(см. матрицу на фиг. 6.1 3).

Промежуточные задачи линейного программирования решаются
с помощью модифицированного симплекс-алгоритма. Для Каждого
 pagebreak 
258 Глава 6

 

из промежуточных решений в соответствии с машинной программой
вычисляется приращение вектора ›‹ (которое мы обозначим через
Ах) и осуществляется слежение за тем, чтобы значение целевой
функции в точке (х + Ах) улучшилось по сравнению со значением
Дх), найденным на предыдущем шаге (т. е. в точке х"‘>) при не-
значительных аппроксимационных погрешностях [см. приведен-
ные ниже соотношения (6.1.5)]. Каждый такой цикл построения
матрицы линейного программирования и решения промежуточъюй
линеаризованной задачи называется петлей. Петли повторяются
в автоматическом режиме до тех пор, пока не будет найдено опти-
мальное решение или пока число выполненных вычислительных
циклов не превысит максимально допустимое значение, установ-
ленное пользователем.

1. Нахождение числовых значений частных производных.
Как уже отмечалось выше, чтобы сформировать матрицу линей-
ного программрхрования, требуется знать значения первых частных
производных целевой функции и функиий, фигурирующих в огра-
ничениях, по каждой из независимых переменных х,. Для прибли-
женного вычисления этих частных производных в ПОП исполь-
зуется численный метод центрированных разностей. Чтобы опре-
делть значение первой частной производной целевой фунхщии по
независимой переменной х,- в текущей точке х…, по программе на-
ходятся значения [(х) в точках х… + 8; и х"‘> — 6„ где вектор
&, определяется параметрами, устанавливаемыми пользователем.
Тогда на 12-м шаге числовое значение первой частной производной
целевой функции по х, вычисляется по формуле

аг №» : их"” + в;) _ г № — в;)

дх] 26, 1=1,….‚п,
где
із :; н :; кт
х”+8‚=[х(1),х(2)‚ .... х}’+б,-, ..., хр]
!: ь т
и х‘”’—б‚=[х‘{", ХБ”), ..., хР—бі, ..., 7:5.) .

Аналогично для вычисления первых частных производных 51, (х)
используется формула

дві (Х…) : в; (Х… + 61) _В: (х…—
дхі 26;

і=1,...‚ р, і=1‚ „„ и.

На протяжении всего процесса оптимизации выбранные вначале
значения 6‚ остаются неизменными, причем от выбора этих значе—
ний существенно зависит точность численных оценок упомянутых
выше частных производных.

2. Адаптияиые предельные значения для длипы шага. Исполь-
зуемые в ПОП Н предельные значения для перемещения в про-
странстве решений (или длины шага) в направлениях, ассоцииро-
 pagebreak 
М етоды линейной аппроксимации 259

 

ванных с независимыми переменными х„ можно получить одним
из следующих способов (выбор остается за пользователем). Во-
первых, упомянутые предельные значения могут устанавливаться
пользователем по его усмоггрению и рассматриваться как исходные
данные (так, например. длина шага может составлять 10% от дли—
ны рассматриваемого диапазона изменений х,); в этом случае про—
граммой предусматривается (после выполнения надлежащего мас-
штабирования, описание которого приводится ниже) правило
обраЩения с такого рода фиксированными входными данными. Воз-
можен и другой вариант, когда вычисление предельных зничений
для длины шага при реализации каждой петли возлагается на саму
программу. Оценивание адаптивных предельных значений для
длины шага осуществляется способом, аналогичным способу на-
хождения числовых оценок первых частных производных Нх) и
3, (х) по х,. В соответствии с программой для независимых перемен-
ных х, вычисляются максимальные значения перемещений, при ко-
торых погрешность, обусловленная линеаризацией (см. ниже),
не превышает максимально допустимую погрешность, указанную
на входе как для целевой функпии, так и для каждою из ограни-
чений. По программе находятся числовые значения {(х) и 3 (х)
(і = 1, ..., п) в текущей точке хі"), а также в точках х ) +Ёіи
х‘Ёі—бр Поскольку оценивание адаптивных предельных значе-
ний для длины шага выполняется одновременно с нахождением чи-
словых значений первых частных производных, вычисление і(х)
и 5, (х) ($ = 1, …, п) в точках, задаваемых векторами х + 6],
х и х —— 6,3 осуществляется только один раз сразу для обеих из ука-
занных целей. Затем в соответствии с ПОП находится линеариза-
ционная погрешность для целевой функции по формуле

Е,.о=і‹х)— №, і=1‚ п, (6.1.5а)

и для функций 31 (х) с помощью следующих соотношений:

Е…=;‚(х)—__Еі(х+ьі)33і(х_ьі) , і: 1, ..., п; і=

=1‚ …, р. (6.1.56)

Получаемые числовые погрешности используются для нахожде—
ния предельного значения перемещения по х,. Если исходить из
точности линеаризации целевой функции, то предельное значение
для длины шага получается в Виде

Ахі‚0‚тах : 6] Х

/ максимально допустимы! ЛИНЕЗРИЗЗЦИОННЗЯ Чп
, ]

Х погрешность для целевой функции
Е:;о

=], ..., п,

(6.1.63)
 pagebreak 
260 Г лава 6'

 

а еСЛИ ИСХОДИТ Ь ИЗ ТОЧНОСТИ ЛИНЁЗ РИЗаЦИИ ограничений, ТО

максимально допустимая линеаризационвая )‘А
‚

Мм, :… = 6‘(№

і=1,...‚п, і=1‚...,т. (6.1.66)

Для каждой независимой переменной х, предельное значение
длины шага, используемое в процессе решения локальной (полу-
ченной методом линеаризации в точке хи”) подзадачи линейного
программирования. равняется (в зависимости от того, что окажется
меньшим по своему значению) либо (1) наименьшему из Ах,; ;(і =
= 0, …, т), либо (2) удвоенному предельному значению, установлен-
ному априори. Альтернатива (2) может иметь место, если только [ (х)
и 51, (х) линейны по х,. Метод нахождения адаптивных предельных
значении для длины шага по каждому из направлений в простран-
стве решений позвшіяет варьировать упомянутыми предельными
значениями с учетом степени кривизны той или иной модели. С дру—
гой стороны, предельные значен'ия длины шага могут оказаться
слишком малыми; в этом случае процесс оптимизации сильно замед-
ляется. При этом независимо от того, как выбраны предельные
значения длины шага, последние умъюжаются на переменную величи-
ну &, которая равняется вначале единице, а затем (по мере прибли-
жения к оптимуму) постепенно убывает (см. описание соответствую-
щей процедуры в следующем подразделе).

3. Завершение вычислительной процедуры. Алгоритмом, зам»
женным в ПОП Н, предусматриваются два автономных критерия
определения оптимума. Если безусловный оптимум (экстремум)
находится в точке, которая расположена вне области, определяемой
ограничениями задачи, то соответствующий условный экстремум
достигается в конце фазы линейного программирования при полу-
чении такой ситуации, когда ни одна из компонент вектора х(’*+'> -—
— к"” не превышает соответствующее предельное значение длины
шага. Если же безусловный экстремум лежит внутри или на грани-
це области, задаваемой ограничениями исходной задачи, то соот-
ветствующий условный экстремум достигается в силу того, что либо
точка, определяемая текущим вектором х, осциллирует относиИ
тельно оптимальной точки, либо последовательность перемещений
в пространстве решений при очень малых оптимизирующих
поправкахктекущимзначениямі (х) приводит к тому. что В начи-
нает принимать значения, меньшие предельных значений. предпи-
санных пользователем. Логика тестов на завершение вычислитель-
ной процедуры отражена в общих чертах на блок-схеме. приве-
денной на фиг. 6.1.4.

Если приращение х,- соизмеримо ‹; предельным значением длины
 pagebreak 
нвпризовашт задачи ( :
№911 ЛЦЛЁЙ!!030 „№!-
№1110? )№№М

  
       

  
 
  

 

ыдмцуетт ла миша =
:|: гв., т.е. сво арагтл пе—
. меценцг по №90»: из на-

: ! мели? маши: №
аличглиш ?

  
   
 

  

   
      

Яшедпт ли Аі!1"’"’) —

4771! ’).иамй шииинлй
(‹б*› ?

   

. Удел чить значе-

ние ;да]

  
       

.
Быпшняетая .Ъи
умами ; 5 5 ‚?
1 (1

ддт?!" ””' ь .; славный
м лежит рп ищу.!!!
МЕ лету, 0/1- “ай! ита:
: ' : ляелшц л- „ вн!
ііичешт.ми .;а— ”
ричи)

    
   

    
   
 

. Индимдтар цикла желт—

             
   
 
 

Нгт

 
  

ЕС.,” РЗЩВНЦЗ ”890-
› луштшцтімгтт

 
    
  

' 5 пт ртлиэонано
ёпт увезти цикл:

   

далершить ще а_уил цим

Ф и г. 6.1.4. Блок-схема вычислительного процесса, основанного на использова-
нии критериев сходимости в алгоритме ПОП 11.

МАХЬМ -— миксииальио допустимое число последовательных Федьшн» шагов
[Переиещеиий). предшествующих иачдлу возрастания %. (Как правило, % = 3.) МАХЗМ—
ияксииально допустимое число шелких» шагов (‹мялыхь перемещений), которое может

иметь места до того. как % начнет уйывать. Как правило, = 2.)
Е' —- минимальное н: допустимых значений . (Чпще всего = 0.05.)
 pagebreak 
262 Г лаза б

 

шага, 'ю весьма вероятной оказывается возможность продолжить
оптимизационный процесс путем дополнительных перемещений в
указанном направлении. Тест окончания процесса осуществляется
с той целью, чтобы установить,—— большой или незначительной ——
можно считать положительную оптимизируюшую поправку к те-
кущему значению целевой функции. Оптимизирующая поправка
считается большой, если она превышает некоторое фиксированное
число, установленное пользователем”, и незначительной. если это
условие не выполняется. Данный классификатшонный признак
используется в связи с заданием в вычислительнои программе изме-
нений по счетчикам больших перемещений [, и малых перемещений
8. На фиг. 6.1.4 случай, когда 8 = +! и Ь = +!, означает,
что показание каждого из счетчиков возрастает на единицу; случай
же, когда Ь : 0 и 8 = 0, указывает на то, что счетчики больших
и малых перемещений устанавливаются на 0. Смит рекомендует
увеличивать предельное значение длины шага путем умножения
& на 2 и уменьшать это значение в такой же пропорции (т. е. путем
деления множителя & на 2).

Для компоновки машинной программы, реализующей алгоритм
ПОП 11, требуется, чтобы пользователь подготовил специальную
подпрограмму (называемую моделью), назначение которой состоит
в том, чтобы обеспечить нахождение числовых значений целевой
функции [(х) и функций 5, (х) для заданного вектора х…. Под-
программа модели должна обеспечивать переоценку значений
{(х) и 3, (х) после завершения каждого этапа линейного програм-
мирования. Кроме того, пользователь должен задать полный набор
входных данных, включая начальный вектор х, нижнюю и верхнюю
границы значений независимых переменных и большое число дру—
гих параметров оптимизации и контроля за протеканием вычисли-
тельного процесса. В саму программу может быть внесено так мно-
го различного рода коррекций, что часто остается неясным, какое
влияние оказывает тот или иной параметр на ход оптимизационного
процесса.

В гл. 9 будет проведено сравнение алгоритма ПОП Н с други-
ми оптимизационными алгоритмами; однако подробные примеры
в данной связи приводиться не будут, поскольку это было бы со-
пряжено с рассмотрением большого числа разли-шых альтернатв,
каждая из которых требует проведения серьезного анализа с тем,
чтобы стала ясной связь того или иного из возможных вариантов
с базовой структурой рассматриваемого алгоритма.

') Смит в качестве наиболее типичной пороговой коистанты называет число
0,25; при этом, однако, следует, иметь в виду, что раЗМериость константы должна
совпадать с размерностью целевой функции.
 pagebreak 
Методы линейной аппроксимации 263

 

6.1.3. ТРУДНОС’ГИ, ВОЗНИКАЮЩИЕ
ПРИ АППРОКСИМИРУЮЩЕМ ЛИНЕЙНОМ ПРОГРАММИРОВ АНИИ

Цварт [51 обратил внимание на следующие четыре трудности,
которые возникают при решении задач нелинейного программиро-
вания путем многократной линеаризации и использования аппара-

та линейного программирования:
1. Оптимизация происходит медленно, если стремиться сделать
векторы №4), кф], №…, допусшмыми или очень близкими

Налдимвние в/юриатаиил Кас)

Мадам» тройустимма:

 
 
   

решти!
Допустимая тачка эс"…

_ —— Точка пс“ "сиг допуч
Ш '- -‘ стамай области

#7113“ )-0 |

‚у,- (:):0

 

‚дапуртмая войдет. Разрешенное „”Кандела: _,

шп уллус/пижпя' значении

 

:!
Ф и г. 6.1.5. Влияние размера допуска на длину шага в двумерной задаче. Квад-
рат, изображенный пунктирНЫМи линиями представляет зиачения 65,1], фигури-

рующие в соотношении (6. 1. 2. ); @ ”(хщ) : 0 представляет собой динеаризованиое
ограничение

к допустимым. На фиг. 6.1‘5 иллюстрируется случай, когда малый
допуск при учете ограничений приводит к тому, что поиск опти-
мального решения оказывается слишком ‹мелкошаговым», т. е.
протекает медленно. При увеличении допуска решение задачи не-
линейного программирования может остаться недопустимым, если
произойдет останов работы ЭВМ из-за ограничений по времени.

2. Трудно сравнивать следующие один за другим два вектора х,
которые приводят к разным значениям ‚‘ (х) и в различной степени
нарушают некоторое подмножество ограничений. Действительно,
допустим, что мы хотим сравнить векторы х… и х"…і. Пусть
[ (х…) < [ (%*-Н)), но ограНИЧение & (х) > 0 для хи" нарушается
сильнее, нежели ограничение Е1(х)>0 (или, возможно, другое
ограничение & (х) > 0) для вектора к““). Можно ли утверждать,
что первый из этих векторов предпоЧтительнее второго?

3. Если целевая функция характеризуется ВЫСОКОЙ степенью
нелинейности, то на основе решения линеаризоваННой задачи
 pagebreak 
ддт) = 17 ни пшератоетц

9,61) ›0 710% „%%лраснт

"'г

{Иитдіженив лианеризоааниой
агракичивающей рассуждаете:
в ошетиости ас‘ ’

‚у,(.2')= Л

Фиг. 6,1.6.

:: — пересечение уровней целевой функции с поверхностью, заданной активным
ограничением; б= контуры. получаемые вп поверхности, заданной линеаризованннм
ограничении.
 pagebreak 
Методы линейной аппроксимации 265

 

направление поиска оптимальной точки может быть выбрано слишком
неточно. ВСПОМНИМ, что одна из трудностей градиентного метода,
изложенного в гл. 3, заключается в том, что градиент оказывается
направленным в сторону минимума‚если только масштаб по каждой из
переменных выбран таким, что уровни целевой функции представ-
ляют собой гиперсферы. Линейное программирование не позволяет
правильно выбрать направление оптимизирующего поиска также
и в том случае, когда поверхность, ограничивающая допустимую
область, слишком растянута. На фиг. 6.1.6, а изображена целевая
функция и ограничивающая поверхность 3100, а на фиг. 6.1.6, 6
показано направление поиска на ограничивающей поверхности
(01' х… и ЖИ“), определяемое с помощью линейного программи-
рования для б„ соответствующего показанному кубу. Приведен-
ный на фиг. 6.1.6, 6 дополнительный рисунок содержит более по-
дробную информацию относительно направления оптимизирующего
поиска на линеаризованной гиперповерхности, определяемой

огрангишешлемд1 (х…) = 0. Аналогичная трудность возникает в тех
случаях, когда ограничивающая поверхность имеет ребристую
структуру, если даже вид целевой функции достаточно близок к
линейному.

4. Следует, кроме того, отметить, что при использовании метода
аппроксимирующего линейного программирования трудно при-
думать такую процедуру учета априорных данных, которая бы
надлежащим образом ускоряла процесс оптимизации.

6.1.4 КВАДРАТИЧНОЕ ПРОГРАММИРОВАНИЕ
И ДРУГИЕ ПРИБЛИЖЕННЫЕ МЕТОДЫ РЕШЕНИЯ ЗАДАЧ
НЕЛИНЕЙНОГО ПРОГРАММИРОВАНИЯ

Вместо того чтобы аппроксимировать целевую функцию линей-
ной функцией, ее с равным успехом можно аппроксимировать не—
которой квадратичной формой. Уилсон [6] и Бил [71 разработали
алгоритмы, реализующие подобный подход на практике; однако
при этом не всегда оказывается ясным, позволяют ли такого рода
более сложные алгоритмы сократить время выполнения вычисли-
тельных процедур по сравнению с временем, требуемым для ре—
шения исходной задачи методом линейной аппроксимации. В этой
связи накоплен незначительный практический опыт. Можно от-
метить лишь вычислительную программу, предложенную Уилсо-
ном; однако эта программа в конструктивном плане еще не дора-
ботана.

Грэйвс и Уинстон [8]. обнаружив, что при оптимизации без
ограничений учет квадратичных членов в разложении функций в
ряд ускоряет сходимость, расширили метод линейной аппрокси-
Мации путем введения в рассмотрение при решении общей задачи
 pagebreak 
266 Глава 6

 

нелинейного программирования членов второго порядка. При этом
были сформулированы условия первого порядка для локальной ста-
ционарной точки. Для задачи без ограничений адгоритм указан-
ных выше авторов переходит в обычный алгоритм спуска, учиты—
ваюший квадратичные члены. В случае когда ограничения линей-
ны, а целевая функция имеет квадратичную форму. алгоритм
Грэйвса и Уинстона становится тождественным алгоритму Франиа
И Вольфа [9]. Грзйвсом и Уинстоном при решении задач 8, 10, 11 и
18, приведенных в приложении А, установлено. что при исполь-
зовании метода квадратичной аппроксимации для достижения за-
данной точности при нахождении оптимума требуется гораздо
меньше итераций, нежели в случае метода. основанного на линеа-
ризации исходных функций. Для упомянутых задач, начиная из

точки, заданной вектором х…) = [3 З З 3]Т‚ получаем:

 

При учете толъко первых производных При ьчете вторых производных

 

 

Н
Омер задачи "ТЪЪЁЩЙ і 0… ИЁЪСЩЙ 7 (х')
… >2оо _з2,зшз 9 —32,3487
18 >2оо 42,8153 16 —32‚3478
п 7 -—30665.29
8 50 2,25. ю-° 32 0

Интересно отметить, что, несмотря на различие в необходимом
количестве итераций, машинное время, требуемое для поиска опти-
мального решения методом квадратичного программирования (с ис-
пользованием матрицы Гессе), составляло 60—90% машинного
времени, расходуемого при поиске оптимума методом линейной
аппроксимации. Поскольку критерии завершения вычислитель—
НЫХ процедур (останова) были для этих методов разными, метод
квадратичного программирования, возможно, несколько более эф-
фективен, нежели это можно заключить на основе приведенных
выше данных.

62. АЛГОРИТМ НЕЛИНЕИНОГО ПРОГРАММИРОВАНИЯ

Метод нелинейного программирования (сокращенно — метод
НЛП) разработан Барноом [10]. Он представляет собой обобщение
алгоритма, предложенного Дибелла и Стивенсом [11]. Алгоритм
Дибелла и Стивенса предназначался для решения задач нелинейного
программирования при наличии ограничений толъко в виде равенств
(плюс ограничения, задающие верхний и нижний пределы изменения
значений независимых переменных); данный алгоритм основан на
 pagebreak 
М етоды линейной аппроксимации 267

 

использовании линейной аппроксимации нелинейных функций в
окрестности некоторой допустимой или почти допустимой точки
х…. Идея Дибелла относительно минимизации [(х) путем приме—
нения градиентного и линейно—аппроксимативного методов полу-
чила дальнейшее развитие у Бернса, которому удалось обобщить
упомянутый выше алгоритм на случай, когда в дополнение к огра-
ничениям в виде равенств имеют место записанные в общем виде
ограничения в виде неравенств. Таким образом, с помощью алго-
ритма НЛП можно решить задачу нелинейного программирования
(6.0.1).

При реализации данного алгоритма в качестве начального могут
использоваться как допустимые векторы, так и векторы, выходящие
за пределы допустимой области. Если хі°> не является допусти—
мым, алгоритм реализует фазу наискорейшего спуска с тем. чтобы
получить такой вектор х, для которого множество ограничивающих
условий «почти» удовлетворяется. Затем алгоритм работает на ос‹
нове метода линейной аппроксимации с применением аппарата ли-
нейного программирования и, следовательно, обеспечивает по-
строение надлежащей матрицы локального линейного программиро-
вания, элементами которой являются значения первых частных
производных целевой функции и функций 8; (х) по независимым
переменным. Задача линейного программирования решается с по—
мощью модифицированного симплексного метода; при этом к зна-
чению целевой функции добавляется оптимизирующая (минимизи-
рующая) поправка в небольшой област, являющейся окрест-
носгью текущей точки к. После 'этого процедура Линейного про-
граммирования повторяется. На любом этапе вычислительного
процесса, когда в качестве текущего реШения находится вектор
х, отклоняющийся от допустимой област сверх установлениого
предела, повторяется фаза наискорейшего спуска.

При обсуждении алгоритма НЛП удобно отдельно рассмотреть
фазу наискорейшего спуска и фазу линейного программирования.

Фаза наискорейшего спуска в алгоритме НЛП сопряжена лишь
с повышением степени допустимости вектора х с точки зрения уче-
та подмножеств ограничений И,. (х) = О и 3, (х) >О; на этом этапе
об улучшении значения целевой функции не заботятся. Подпро—
грамма наискорейшего спуска реализует безусловную МИНИМИза-
цию суммы квадратов остаточных погрешностей, т. е. выражения

т и
Т (х) = .; игр:) + $3“ 16,9% (х). (6.2.1)

Совершенно очевидно, что для ограничений в виде равенств оста-
т0чная погрешность равняется и, (х) (і : 1, …, т), а для огра—
НИчений, записанных в виде неравенств, остаточная погрешность
равняется @, (х), если @, (х)< 0, и обращается в нуль за счет
 pagebreak 
268 Глава 6

 

оператора Хевисайда (и,), если 9, (х) > 0 (і = т + 1, …, р); другими
словами, и, = 0 при 3, (х) > 0. Сумма квадратов остаточных по-
грешностей вычисляется перед началом каждого этапа наискорей-
шего спуска и каждого этапа линейного программирования неза—
висимо от того, принадлежал ли предыдущий текущий вектор х
допустимой области.

После вычисления Т (х) машинная программа осуществляет
тесты, разработанные на основе анализа большого количества прак-
тических результ‘а'юв решения различных «пробных» задач.
С помощью этих тестов можно убедиться в том, что точка, заданная
вектором х, действительно находится вблизи допустимой области,
либо установить обратное. Если рассматриваемая точка находится
достаточно близко от допустимой области, вычислительный процесс
переходит в стадию линейного программирования, осуществляе-
мого по алгоритму Гриффица и Стюарта (см. разд. 6.1); в против-
ном случае вычисления продолжаются в режиме наискорейшего
спуска.

Ускорение или замедление вычислительного процесса на стадии
линейного программирования достигается путем варьирования мак—
симального значения величины Ахі. В тех случаях. когда точка,
заданная вектором х, осциллирует относительно «хребта» или «до—
лины», в рассмотрение вводится параметр р„ меняющий знак,
как только два последовательных шага Ах, оказываются противо-
положными по знаку. Параметр рі воздействует на счетчик ?»,
(где вначале устанавливается единица), который используется для
того, чтобы определять необходимость изменения предельной длины
шага ті. Значение ?…, определяется числом, коюрое показывает,
сколько раз перемещение по переменной х; осуществлялось в одном
и том же направлении. Таким образом, числовое значение 9»,- от-
ражает количество благоприятных (оптимизирующих „х)) прира»
щений х; в одном и том же направлении; значение %„ вновь стано—
вится равным единице, как только направление перемещения по
х, меняется на противоположное. Если 9, меняет знак, то вместо
значения ті, которое использовалось на предыдущем шаге, берет-
сязначение ті/‘2. Если же знак р, не меняется, & числовое значение
?…, превышает 4. значение т„ использовавшееся на предыдущем
шаге, удваивается. Акселерация вычислительного процесса может
вывести вектор х за пределы допустимой области; однако так как
сумма квадратов остаточных погрешностей (Т (х)) вычисляется по-
сле каждого изменения х, то в случае (шишком больших отклонений
текущей точки от границы допустимой области начинает работать
метод наискорейшего спуска.

После каждого перемещения в пространстве решений на ста-
дии линейного программирования проводится тест, цель которого
состоит в том, чтобы выяснить, является ли используемое прира-
щение Ах, по своему абсолютному значению меньше некоторой за-
 pagebreak 
Методы линейной аппроксимации 269

 

 

д`:
„5-10
5
0
/. “"'"
5 у о
‚ «4

   

.:“! ‚9621=/0.1:‚-.т,2+/01‚-15—54 30
! ЙЙ'Ргд—кЁ—шдЁд

:; і 2 а 4 5:2,

Ф и г. 6.2.1. Траектория поиска оптимального решения с помощью алгоритма НЛП
для условий задачи, проиллюстрироваиной на фиг. 6.0.1.

ранее установленной (по усмотрению пользователя) константы &
(данная константа может быть выбрана произвольно, но следует
иметь в виду, что она должна быть одной и той же для всех незави-
симых переменных).

Если условие [“‘/Ю — х}”`”| < в выполняется. поиск за-
канчивается; в противном случае поиск оптимального решения
продолжается.

На фиг. 6.2.1 показана траектория поиска применительно к ус-
ловиям задачи, проиллюстрированной на фиг. 6.0.1.

6.3, ПРОЕКТИВНЫЕ МЕТОДЫ

ПроектиВные метоцы образуют целое семейство. Иногда их
называют методами допустимых направлений или градиентньпии
методами с большой длиной шага; последнее название подчеркивает
разницу между алгоритмами данного класса и алгоритмами, рас-
смотренными в разд. 6.1, которые можно назвать градиентньши ме-
тодами при малой длине шага. Сущность этих методов заключается
в следующем: линейные или линеаризованные ограничения обра-
зуют линейное многообразие (определяемое пересечением ограни-
чений), на которое можно спроектировать выбранНое направление
поиска 5 в пространстве решений (см‚ разд. 6.3.1 и 6.3.2). Один из
первых опубликованных методов такой структуры, а именно метод
 pagebreak 
270 Г лава б

 

Розена [12—16], по-видимому, является наиболее хорошо известным.
поскольку для его реализации на ЭВМ существуют готовые машин-
ные программы.

Все проективные методы (или методы допустимых направлений)
предполагают реализацию на каждом іг-м этапе указанной ниже по-
следовательности шагов:

1. Алгоритм начинает работу в допустимой точке х….

2. Определяется допустимое направление 5… (точное опреде-
ление допустимого напраВления будет дано позднее).

3. В допустимом направлении выбирается шаг длиной №“,
минимизирующий {(х), но в то же время сохраняющий вектор
х“°+“ = х”) + №№… допустимым.

Алгоритмы рассматриваемого семейства отличаются друг от
друга прежде всего способами определения направления $”); од—
нако все они характеризуются тем, что поиск начинается с допусти—
мого решения и развивается (при линеаризованных ограничениях)
в направлении, обеспечивающем уменьшение целевой функции при
сохранении текущей точки х внутри допустимой области.

Заметим, что большинство алгоритмов решения задач линейно—
го программирования представляет собой модифицированные ал—
горитмы обращения матрицы Так; например, симплексный метод
линейного программирования соответствует методу обращения мат-
риц, известному под названием «метод Гаусса —— ЖордаНа». Метод
Фриша и метод Розена представляют собой два различных подхода
к обращению симметрической матрицы АТА (где А — матрица,
элементами которой являются коэффициенты при независимыхупе—
ременных в соотношениях, задающих ограничения). Однако следует
отметить, что проективные методы не требуют, чтобы все ограниче-
ния в виде неравенств были заменены эквивалентной системой огра-
ничений в виде равенств путем введения в рассмотрение ослабляю—
щих переменных (как это имеет место в линейном программирова—
нии); проективные методы на каждом итерационном шаге вовлекают
в вычислительный процесс по возможности минимальное количе-
ство ограничений в виде неравенств из числа активных ограниче-
ний. Прежде чем перейти к рассмотрению алгоритма Розена, пояс-
ним более подробно понятие проекции.

То, что здесь подразумевается под проекцией. ассоциируется с
понятием проекции вектора, описываюшего локальное приращение
функции при перемещении в заданном направлении.

Пусть АТ = [а1 &, а„] —- прямоугольная матрица с ли-
нейно независимыми вектор-столбцами, определяющими некоторое
пространство К. Допустим, что А допускает разбиение на две мат-

рицы Ахт = [гц а,] и АД; [а… ап]. На векторы, входяшие

в АТ, натЯнуто п-мерное пространство, и, следовательно. любой
вектор в К может быть однозначно представлен в виде линейной
 pagebreak 
Методы линейной аппроксимации 271

 

комбинации векторов а„ Т. е.
:\

х = 2 ща,- или х = Атта (6.3.1а)
1:1
(Таким образом, коэффициенты т, представляют собой координаты
вектора х относительно базиса А.) С другой сторонъг, векторы, со-
ставляющие матрицу А7, задают пространство лишь 1-й размерности,
и, следовательно. только для некоторого подмножества векторов
в К имеет место соотношение
!

х = 2 т‚а,- или х = АдТт. (6.3.16)
і=1

Уравнение аіТх = 0 определяет в К гиперплоскость, проходя-
щую через начало координат. Обозначим пересечение множества
всех гиперплосиостей с ]“ = 1, 2, …, ! (т. е. систему уравнений
А,х = 0), формирующих линейное многообразие ') размерности
(п — 1), через ‚14. Ортогональная проекция х на м (которую обозна-
чим через хм) обладает тем проективным свойством, что хм и х —

—— Хм ОРТОГОНЗЛЬНЫ, Т. 6.
{и (х— хм) = 0.

Тогда п-мерная квадратная проектирующая матрица Р,. опреде`
ляемая условием

хм : Р,х (6.3.2)
И вычисляемая с ПОМОЩЬЮ соотношения [17]
р, = 1 _ А,’ (А,А‚Т)—‘А„ (6.3.3)

позволяет найти хм. В одном предельном случае Р.) !. Это озна-
чает, что если подмножество [ векторов пусто (т. е. 1 = 0), то хм =

Ш

 

1) Понятие многообразия в Б“ почти совпадает с понятием подпространства в

Б“. Разница заключается лишь в том, что многообразие не обязано включать в себя
начало координат, как это должно быть в случае подпространства. Когда говорят,
что линейное многообразие м имеет размерность (п —1)‚ то имеют в виду то обсто-

ятельство, что если рассмотреть систему линейных уравнений АТх=!7‚то наиболь`
шее число линейно независимых векторов, формирующих решение, оказывается
равным (п— 1). Например, если Ат есть (! >< п)-матри11а (п > 1). причем каждая из
! строк определяет линейно независимое уравнение, то (п — !) есть чиию независи-
мых переменных в системе уравнений, 8 [ соответствует числу ограничений (или
числу зависимых переменных} В Е” точка имеет размерность ! = 0, так что
п —- [ = п; гиперплоскость имеет размерность [ = 1, и, следовательно, п — ! =-
= п — 1 и т. д. Таким образом, добавление независимого уравнения к заданной
системе линейно независимых уравнений сокращает размерность многообразия

,“ на единицу.
 pagebreak 
272 Глава 6

 

  
    
   

  

‘ допустимая тіг
\ция грагиента
' 7 (шт)

“" “ч) Ддлуатщмая Млщ-ть

   

Ит…)

`
"...-

.:В,
Ф и г. 6.31. Проекция градиента на активные ограничения в случае ограничений

В виде неравенств.
в точке А активно одно ограничение. и, следовательно. и — 2—1 = 1; в точке В

активными являются два ограничения, и. пким образом. п—! = 2—2=0‹ В точке ‚(“'—1).
являющейся внутренней допустимой точкой. активные ограничения отсутствуют и Р.. : !,

так что проекция градиента ті (х‘Ё—Щ совпадва :: самим градиентом. Заметим. что на не-
ресеченни в точке х( )двух активных ограничений Р. а 0 и единственной возможной |ра-
екциев градиента 7 Пхи”) является указанная точка.

   

= х; следовательно, вектор х совпадает со своей проекцией. В дру—
гом предельном случае Р„ = 0, т. е. подмножество векторов в К
является полным, и, следовательно, ! = 11, 8 Хм = О (проекция

на точку есгь нуль-вектор, как показано на фиг. 6.3.1). В случае
когда на пересечение подмножества ограничений проектируется
градиент целевой функции в точке хт) (т. е. 7 ‚‘ (№0), метод опти-
мизации называется методом проекции градиента.

6.3.1. МЕТОД ПРОЕКЦИИ ГРАДИЕНТА (МЕТОД РОЗЕНА)

Обратимся теперь к рассмотрению метода Розена. По существу
этот метод минимизации представляет собой метод наискорейшего
спуска, применяемый в сочетании с ортогональным проектировани—
ем отрицательного градиента на линейное многообразие ограниче-
ний или их аппроксимаций. В допустимой точке х… ограничения,
имеющие вид равенств (активные ограничения), линеаризуются
(если являются нелинейными) и временно заменяются соответ—
ствующими (т. е. касательными к ним в точке к“”) гиперплоскостя—
ми. Предполагается, что эти, гиперплоскости линейно незави-
симы и, следовательно, нормали к ним также линейно независимы.
(Как показано Розеном, метод проекции градиента не позволяет
манипулировать ограничениями, представляющими собой линейные
 pagebreak 
Методы линейной аппроксимации 278

 

комбинации других ограничений). Эти нормали (соответствующие
составляющие как для №7] (хдд), так и для 7/1, (х<">) будем обозна-
чать через дд, (х<’°>)/дх,‹) используются для составления проекти-
рующей матрицы, которая проектирует градиент целевой функции
7} (х), найденный в точке к“”, на пересечение касательных гипер-
плоскостей. В пространстве без ограничений п переменных форми-

“":

 

Ф и г. 6.3.2. Метод проекции градиента при активных ограничениях в трехмерном
пространстве,

допустииая область и едс'гивляет собой многогранник, состоящий И} граней (дву.
мерные многообразия), ре ер (одномерные многоибразия) и вершин (нульмерные

ииогообразия). Стрелка указывает направление проекции градиента, кю) _— началь-
ндя точка; х… — минимальное смещение и (х… — х‹°))-напрявлении и т. д.

руют п-мерную область. Однако, если в точке х“) должны удов-
летворяться ! ограничивающих условий (ограничивающие условия
в виде равенств плюс активные ограничивающие условия в виде
неравенств), размерность пространства, ассоциированного ‹: ли-
нейно независимыми векторами, уменьШается на 1, т. е. становится
равной (п — 1). Понятие приведенный базис, или базис при наличии
ограничений, означает совокупность линейно независимых гипер-
плоскостей, пересечения которых ограничивают область поиска.
Основной особенностью метода проекции градиента является то,
что он преобразует (проектирует) градиент целевой функции так,
что его составляющие лежат в (п —— 1)—мерном многообразии, опре-
деляющем допустимую область, в которой удовлетворяются ! огра-
НИчений в виде равенств. Рассмотрим фиг. 6.3.2.

Обозначим через А, матрицу (размером п >< !) частных произ-
водных активных ограничений (для экономии места зависимость
 pagebreak 
274 Глава 6

 

А, от к… будет предполагаться, но не будет указываться в обо-
значениях в Явном виде):

до №» де, (х…)
дх, ах„ а11 а…
А,=..........=‚_____
(78101…) 1731$…) ад ... Щ„
дх1 "' дхп

В силу соотношений (6.3.2) и (6.3.3) проекция 7! (хи!) на актив-
нне ограничения определяет новое направление поиска 5%“):

№" = Рті №) = И №) — А? (А1А7)”’А№і(Х‘*’›- (6.3.4)

Выражение (А‚А‚Т)"А, \7і (х…) = и можно рассматривать как
вектор-столбец, элементами которого являются множители Ла-
гранжа (так называемые теневые параметры). С его помощью можно
определить новое направление

вин”) = \717 (х…) _ АТЦ.

При этом составляющие и,- вектора " позволят уточнить, можно ли
в ходе поиска по данному направлению получить дополнительные
оптимизирующие поправки для целевой функции. Если хахая—либо
из составляющих и, отрицательна, соответствующее ограничение
в виде неравенства можно исключить из приведенного базиса до
того, как будет продолжен оптимизационный поиск. Из-за взаим-
ного пересечения ограничений одновременное удаление из приве-
денного базиса более одного ограничения в практическом отноше-
нии нецелесообразно; при этом удаляется то ограничение, которое
соответствует наибольшей по абсолютной величине составля-
ющей щ.

Если активные ограничения линейны, составляющие вектора
нового направления №44) будут лежать на самих ограничениях
(фиг. 6.3.2). Если же активъше ограничения нелинейны, как это
имеет место в задаче. иллюстрируемой на фиг. 6.33, то состав`
ляющие вектора нового направления будут лежать на гиперпло-
скостях, касательных к ограничениям в точке к““). Таким образом,
в случае, когда у некоторой граниигной точки дальнейшее `переме-
щение по градиенту целевой функции сопряжено с выходом за
пределы допустимой области, вместо перемещений по составляю-
щим градиента производится перемещение по составляющим проек-
ции градиента. Следовательно, если задача содержит нелинейные
ограничения, а к““… оказывается вне допустимой области, то при-
меняется (в том или ином Виде) алгоритм проекции градиента, что
позволяет вернуться в ближайшую допустимую точку. После этого
работа алгоритма повторяется. Оптимизационный процесс реали-
 pagebreak 
Методы линейной аппроксимации 275

 

зуется большими шагами ‹: линейными ограничениями, причем в
конце каждого этапа текущий вектор х непременно является до—
пустимым и либо лежит на поверхности, порождаемой одним из
ограничений, либо может быть разложен на составляющие, лежа-
щие в плоскостях, представляюших некоторое подмножество ограни-
чений. В случае задачи оп-
тимизации без ограничений
метод Розена сводится к ме-
тоду наискорейшего спус-
ка, описание которого
приведено в гл. 3.
Переходя к подробному
описанию алгоритма Розе—
на, мы вме0то общей зада-
чи (6.0.1) ограничиіися рас-
смотрением задачи нели-
нейного программирования
с линейными ограничени-
ями, поскольку данными
относительно его практи-
ческого применения в ус-
ловпях общей постановки
задачи (6.0.1) мы пока не
располагаем“. Рассматри-
ваемый алгоритм начинает

      

Литвинов
ограничение

 

личение

., _ Ф и г. 6.3.3. Метод проекции градиента при
работу с допустимои точ активном ограничении. Если активное огра-

ки и Продцолжает Эффек_ ничение В точке ‚((Б) нелинейно, Точка ‚((Б)
тивно деИС’ГВОВаТЬ как может оказаться вне допустимой области.

метод наискорейшего спу—
ска до тех пор, пока не будет достигнута точка, для которой
становятся активными одно или несколько ограничений. Если за-

дача содержит ограничения В виде равенств, ЗКТИВНЫЕ ограниче-
НИЯ ИМЕЮТ МЕСТО на каждом этапе ЁЫЧИСЛИТЕЛЬНОГО процесса;
ЕСЛИ же В задаче фигурируют ограничения ТОЛЬКО В виде
неравенств, ТО ПО истечении некоторого времени МЫ ДОЛЖ—
НЫ оказаться В граничной точке (если решение задачи не

представляется внутренней точкой). В граничной точке х…
функция & (х…) = О и ых‘“) = 0 для 1": 1, ..., 1, где 1< п
(п—чиспо переменных). В методе Розена УПК…) проектируется
На пересечение ! ограничений {х‘*>;д‚‹х“*>)=о и пі(х(*))=0,
і: 1, 1}. Пусть Р, = 1—А,Т (А‚А;Т)`1А, — проектирующая
матрица. При != 0 (в этом случае к”“ является внутренней

‘) В подразд. 63.3 обсуждается метод аккомодации нелинейных ограничений,
прошедший экспериментальную проверку.
 pagebreak 
276 Глава 6

 

точкой) Ро представляет собой единичную матрицу (Р„=|). Про-
екция иш…) на пересечение всех гиперповерхностей д‚(х“")=
= 0 и п,(х"")=0 (і = 1, …, !) находится с помошью соотношения

(6.3.4) В разд. 2.5 отмечалось, что х… является решением задачи
нелинейного программирования тогда и толыю тогда, когда Р‚><

>< 71° (х…):О и ц=(А,А17)"А,\7і (х…) > 0. С учетом этого обстоятель-
ства рассмотрим отдельно случаи Рті (х…) #: 0 и Р,\7і (х…) = 0.
(Если решением является внутренняя точка, то Роу] (х…) =
= ті №) = 0.)

Условие 1.- Р,7і(х…)=;&0.

Пусть 3“) есть еДИничный вектор в направлении проекции
7і(х“°’) на пересечение всех ограничений &.(х’г) =0 и ддт) =0:
^… РМ (х…)

5 =——————. 6.3.5
птпхщп ( )

Как обычно, воспользуемся соотношением

хи“… : х… + Ж… 80".

Путем одномерного перемещения из точки к“" вдолъ проекции
градиента можно определить такое А, которое минимизирует значение
і(х) и одновременно сохраняет к“”… внутри допустимой области.
Точнее говоря, в результате одномерного перемещения в направле-

нии 5… мы определяем ж*=тах{жгх“"+ ?…;(Ё’ЕЮ, где К=

: {х[д,(х)>0 и Иі(х)=0‚ і= 1, ..., р}, а затем наХОДИМ А"”,
удовлетворяющее условию 0 < Мю< №, так что значение [(Я/”+

(ити ^‹/г›
+7» 5 ’) в ндправленииз оказывается минимальным. Тоша зна—
чение А’“ есть максимальная длина шага, который можно сделать

^
в направлении 5… из точки к“”

допустимой области К.

Если 7»…<Ъ‚*‚ то число ограничений в виде равенств, которые
удовлетворяются в точке х"‘+", ‚не меняется; иначе говоря,
@, (х(’°+“)=0 и иі(х“‘+”)=0 для і: 1, …, 1, и, следовательно
элементы ад,. матрицы А„ используемой на (13+ 1)—м шаге, оста—
тся без изменений. С другой стороны, если 7»… =?\‚*‚ то в точке
Х“… в дополнение к ! ограничениям, которые учитывались в точке
х… в виде равенств (и сохраняющим ВИД равенств при переходе
от х… х ‚((и-ю), доджны приниматься во внимание нелинейные
ограничения (одно или более), представленные в виде соответ-
ствующих равенств. Рассмотрим переход от хо к х…, показанный

, не выходя при ЭТОМ за пределы
 pagebreak 
М етоды линейной аппроксимации 277

 

графически на фиг. 6.3.2. В этом случае производится вычисление
элементов новой матрицы А, кото ая включает в себя все ограни-
чеНИя, принимающие в точке х“е “ вид равенств. В дальнейшем
работа алгоритма повторяется.

Условие 2: Р,7і(х”") =0.
Из формулы (6.3.13) следует, что УПК…) можно выразить
через А1? и и, а именно

7; (х…) : Ага. (6.3.6)
Умножая (6.3.6) слева на (АдАдТГ'Ад получаем
(А1А1Т)"Ад7і(х…) = и.

Если иі > 0 для всех значений і = 1, …, 1, то х“) есть иско-
мое решение. В противном случае подбираем такое и… < 0. для ко-
торого значение Ца… [] ит отрицательно “ и максимально по
модулю, пренебрегаем соответствующей гиперплоскостью, вычер‹
киваем в матрице А, т-ю строку и возвращаемся к соотношению
(6.3.5). Новая проектирующая матрица Р… удовлетворяет условию

Риш“ №) =— Р…Агц эе 0.

Таким образом, на каждом этапе вычислительного процесса
возможны следуюшие варианты: 1) совокупность активных огра—
ничении может остаться без изменений; ?) в дополнение к имев-
шим место может добавиться одно активное ограничение; 3) из со-
вокупности активных ограничений одно ограничение может быть
исключено. Случай, когда условию 2 удовлетворяют два или более
активных ограничения, называется вырожденным. Подробное
обсуждение вопросов, связанных с вырождением, можно найти
у Кюнци [18] или у Флетчера [19]. В этих работах описыва-

ются эффективные способы нахождения (А„„АЁНГ1 и (А1_хА1Т_1)"1
при заданной матрице (А‚А‚Т)"; методика вычисления (А…АТНГ'
и (А;_1А‚7_1)—' рассматривается также в разд. 6.3.3.

63.2. ОБОБЩЕННЫИ ГРАДИЕНТНЫИ МЕТОД
ОПТИМИЗАЦИОННОГО ПОИСКА

Программа, реализующая обобщенный градиентный метод опти-
мизационного поиска, разработанная Кроссом и Кефартом (Ппіоп
СагЬіое Стр., Оак Кідее, Тепп., НЗА), позволяет одновременно опе-
рировать как линейными, так и нелинейными ограничениями, запи-
санными в виде равенств и неравенств. Эта программа осуществляет
оптимизационный поиск методом наискорейшего спуска внутри

” Символ [| [| здесь используется для обозначения нормы вектора ат.
 pagebreak 
278 Глава 6

 

допустимой области; при этом численная аппроксимация частных
производных целевой функции (по формуле упреждающей разности) и
длина шага в заданном направлении на (із +1)-м этапе являются
функциями числа результативных шагов на іг-м этапе вычислительно
го цикла. При наличии нетривиальных ограничений (т. е. ограниче-
ний, не имеющих вид [„ < х, < [!,-) после их линеаризации приме-
няется метод проекции градиента. При этом необходимо иметь
записанные в явном виде аналитические выражения для частных
производных функций, задающих нетривиальные ограничения.
В окрестности ограничения используется параболическая аппро-
ксимация векторатрадиента, что позволяет определить (приближен-
но) точку касания ограничивающей гиперплоскости с поверхностью
данного ограничения. Машинная программа содержит также ряд
специализированных стратегий для манипулирования с «хребтами»
и тривиальными ограничениями, а также для ускорения сходимо-
сти промежуточных точек и оптимальному решению, В процессе
оптимизации для перехода от недопустимой начальной (стартовой)
точки к допустимой используются проективные методы.

На фиг. 6.3.4 показана полученная градиентным методом траек—
тория оптимизационного поиска в области оврага (являющегося
эквивалентом хребта в задаче максимизации). Наличие оврага
можно установить, обнаружив изменение знака составляющих гра-
диента целевой функции (например, изменение знака градиента
целевой функции по переменной х,). Чтобы ускорить оптимиза-
ционный поиск в области оврага, в точке х… длина шага при пере—
мещении по х, сокращается до 0,64 его первоначальной длины, так
что траектория проходит по ломаной, представленной на графике
пунктирными линиями (не совпадающей с ломаной, представленной
сплошными линиями). Если после первого сокращения длины шага
знак частной производной продолжает «осциллировать», следует
провести дальнейшее уменьшение шага Если же осцилляция знака
презиращаетсщ то длина шага в направлении ;(2 умножается на
1,2 .

Другой способ ускорения сходимости, используемый при фор—
сировании вычислительного процесса на «градиентной» стадии оп-
тимизационного поиска, заключается в применении метода парал—
лельных касательных (см. разд, 3.3.3), с помощью которого после
прохождения точек 2 и 4 на фиг. 6.3.5 удается попасть в точку А,
минуя точки 5—8.

Когда нарушенным оказывается тривиальное ограничивающее
условие (т. е. условие 1‚,- <хі< [],-), производится оокраЩение
длины шага путем умножения текущего значения длины шага на
отношение разности меЖДу значением ХЭ,” и граничным значением
хі к длине шага. фактически реализованного в направлении х,.
В ситуациях, когда условие Ь,- \<_ х, < П,— нарушается сразу для
двух или более переменных, длина шага сокращается в такой
 pagebreak 
с:,

Ф и г. 6.34. Корректировка траектории оптимизационного поиска на этапе исполь-
зования метода проекции градиента.

 

Фиг. 6.8.5. Использование партан-метода на некотором этапе использования
МЕТОДЗ проекции градиента.
 pagebreak 
280 Глава 6

 

степени, чтобы удовлетворить ближайшему ограничивающему усло—
вию. Если проекция осуществляется на ограничивающее условие,
имеющее вид неравенства, используется другая вычислительная
процедура. Составляющая ді (х…)Юх, приравнивается нулю, а при
проектировании градиента целевой функции переменная х, исклю-
чается из рассмотрения путем приравнивания нулю дд,- (х<’Ч)/дх‚‹
для каждого 1-го ограничения, принимающего при проектировании
градиента вид строгого равенства. Таким образом, операция про-
ектирования выполняется в подпространстне, в котором і-я коорди-
ната ‹тгсутствует.

Когда нарушаются нетривиальные, причем нелинейные, огра-
ничения, для нахождения следующей допустимой точки может
потребоваться несколько последовательных итераций. Пусть Ах
есть п-мерный вектор—столбец, переводящий вектор х, не являю-
щийся допустимым, в допустимый вектор х‘Н'“, а АЬ представ—
ляет собой р-мерный вектр—столбец, показывающий, какие изме-
нения требуется произвести в ограничениях задачи, чтобы они ока-
зались удовлетворенными. В линейном приближении

АЬ : ААх, (6.3.7)

где А——матрица первых частных производных по х, функций,
задающих ограничения. ПриращеНие вектора х (т. е_ Ах) находится

путем умножения Ат на р-мерный вектор у1Ах= Аду, так что
АЬ= ААТу. Следовательно, поскольку АЬ и А известны,

«, : (АА’г‘Аь. (6.3.8)
Фактически реализуемый шаг находится из соотношения
‹н-п _ ‹») Т дп
х, _х‚ +(Ах) ($757), (6.3.9)

где !: — та часть матрицы, которая ассоциируется с актиВНыми
ограничениями,

Чтобы знать, какие из ограничений в виде неравенств следует
в каждой текущей точке рассматривать как равенства в дополнение
к исходной совокупности ограничений в виде равенств для каждого
ограничения, записанного в виде неравенства, иахоци'юя скаляр-
ное произведение градиента целевой функции (или отрицательного
градиента в случае минимизации) и единичной нормали п, и соот-
ветствующей ограничивающей поверхности:

(и
т (1; т (и УДМХ )
\7і(Х ))П1=71°(Х ))…-

нтк“)…
При этом ограничение, соответствующее наибольшему значению
такого скалярного произведения, добаВЛяеч-ся к первоначальной
совокупности ограничений-равенств также в виде равенства. Затем
 pagebreak 
Методы линейной аппроксимации 281

 

ті (х…) проектируется на полученное таким способом множество
ограничений, после чего этот вычислительный цикл повторяется
до тех пор, пока проекция градиента на пересечение ограничений
не определит допустимое направление. Так, например, изображен-
ное на фиг. 6.3.6, и скалярное произведение 7} (х…) и еДИНИчной
нормали в точке х… указывает на то, что к Множесгву активных
ограничеНий следует присоединить ограничение, представленное
функцией & (к…). Поскольку проекция И (х…) на 32 (х…) =0
определяет допустимое направление, ограничение, задаваемое функ-
цией 31(х“‘))‚ в систему активных ограничений включать не сле-
дует. Таким образом‚ несмотря на 10 что 71° (х…) может нарушать
сразу несколько ограничений-неравенств, не всегда возникает не—
обходимость проектировать 7! (х…) на все нарушаемые ограни—
чения. Если при перемещении в допустимом направлении встре—
чается друюе ограничение, то его добавляют к системе активных
ограничений, после чего вновь ищется проепщия 71° (х). Исклю-
чение ограничений из группы ограничений в виде равенств осуще-
СТВляегся на стадии, предшествующей вычислению нового градиента
целевой функции.

На фиг. 6.3.6, 6 показано, что происходит в оптимальной точке
х“). Как и в случае, иллюстрированном на фиг. 6.3.6, и, в группу
активных ограничений вводится ограничение, задаваемое функ—
цией & (х…). поскольку

т ш % (Х…) т … №1 (Х…)
Х ___ > х _— .
" і ( ) “72304“… 7 і ( › №1 ‹х"**›н

Однако при эггом проекция 7і(х“") на Еги…) нарушает ограни-
чение, представленное функцией 31(х…)‚ и, следовательно, не
является допустимым вектором. Поэтому 31 (х…) добавляется к системе
активных ограничений, и И (х…) проектируется на пересечение

ограничений, п едставленных функциями 5101…) и 3„(х’?)‚ что дает
нуль-вектор. птимизирующии поиск заканчивается, если на двух
последовательных этапах вычислительного процесса не удалось
определить такие перемещения в пространстве решений, `кото-
рые вносили бы минимхазирующую гюправку в значение целевой
функциуь

Сравнение обобщенного градиентного метода (основные элемен-
ты которого представлены на фиг. 6.3.7) с другими алгоритмами
оптимизации проводится в гл. 9‚ В работе Кросса [20] отмечается,
что обобщенным градиентным методом решались задачи нелиней-
ного программирования, содержащие около 50 ограничений при
таком же количестве переменных.

Одна из трудностей, с которой сопряжено применение рас-
смотренного выше метода, состоит в том, что значения элементов
 pagebreak 
6 "':
Ф и г. 6.3.6. Включение ограничений в виде неравенств в систему активных огра-
ничений при оптимизационнсм поиске обобщенным градиентным методом с по-
следующим применением метода проекции градиента.
а г НЕОШЁИЁЛЬЁМ “ЧКЗ; 6 := ОПТИИЗЛЬНИП точка.
 pagebreak 
Намжш'нце уалустимші
стартовал птицншцс'”
нд шлемы уикустцмш}

  
   
    

  
   

Ему констант
и перемглимх®

     
 

Лао‘др ла шт иппршшм/ті/щви" 5 преум—
ш .и цели;: :‘(авъимртша минимума

, тт [шее плите
{%%/м „.,—м ”’”

   

  
   
     
  
   
     
  
      
   
 
 
   
 
 
     
 
 
   
  

  
  
 

   
  
   
  
   
   

длреуглгкиг ц:

ет Бичимение частям.? :: ши тц:
аюо‘ршнмти „и ’” 0,9

)‘(л') рпшпщдю ушиуа/ощш: разно-
вшей

Ш? ”щ….‚тн- Аид, …,«,. )— Пас) Ц „
эш,- д.ц ' —* ""’

(А.и?іршкарть ‚лимфу верхней и ниж-
ней ›ранццами уля 37")

  
 

жлщчше .т; на пошту-

' цз лврзиеще/шй
: „,машина-тп религ
ний ; тім," 7— шп чение :;
ла жимимивирующвм
*(1') лдршещгнии, иг-

ащдеугтаекна датам?
шу/ощш 1,1 "

    
 

  
    
  
 

   
  
     
  

Имешп .‚ш мм-
лт дграличения ?

    

”“’ “"“"“ “””" : мучил: тада мячами: перьимшай

мплкшдпт тиицкмм, чцми пврем ›-
мх при очередном щмеиг/ши нллрал-
лета тлгршищвтт на единицу

 
 

 
  
 

Дмчииглие л.д(і-і
шт.”,утммлмм “я
кажум самшмвющгй пробит—
гл ладрамелцлталраллемщ
мшамцлациднлша штата)

  

 
 
  
   
     
 
 
 
 

длщиглелце ‚чинно ‚ ‚
тора .::; .:":‘Цапдд му…, Если при
этом для таи или имт передний
граничные умрет: ле шлолляютсяддл.
чение А1} уменршают три жалкими тг
ламичтиц' та апарашы атгуттщтт)

  

‚имплант: ,?

 
    
    
 
         

!! жение пигме-
№ в лтдлш на-
правлении Если мт 5
щционлмй лщкл шИЁЩш/лгл

шву @

    
   
 

      
    

ушла лргучрущщ
жившим: шит:

ка стадии,;цвуую—
щей за длотм @,

        
     
   

«има ‚«вжари—
шш' лилиумшц ие— …
(п: @ превыше-

Лтг, вшей” ши

яш/шг : чм :!
рацишжи цим
„… делит: „‹ .?

 
   

!!шълл пишущих
утехам“: шаги

   

Имдют ли мита
праничеиия ?

    
     
 
   
   

штамм, ами ти—
! ив лопа пт ш
платил -

   
 
 

Кима лреушетгу/аци
шт, личика! м'лаш
@, ішцше суиници .’

 
  

 
     
     

Марлщаютая :йшуФ функции и мм не
фвуи ши.: маимцй „ми
жимелшдл (аля !” ‘М

лдйшем иммтлл

Ф и г. 6.3.7. Блок-схема вычислительного процесса на основе обобщенного гра-

пцвц-шпгп „м……
 pagebreak 
284 Глава 6

 

матрицы А представляют собой лишь аппроксимации ИХ'ИСТИННЫХ
значений, так как частные производные фигурирующих в задаче
функций вычисляются в точках, не являющихся допустимыми.
Поэтому в тех случаях, когда в ходе итерации из-за слишком гру—
бых нарушений ограничений не удается получить допустимую
точку с точностью до установленного ранее допуска, после опреде-
ленного числа итераций алгоритм вычисляет новый градиент и
уменьшает длину шага с тем, чтобы найти в результате допустимую
точку. Другая трудность, возникающая в случае нелинейнш; огра-
ничений, заключается в том, что поверхности линеаризованных
ограничений могут в какой-нибудь точке совпадать с граничной
поверхностью. Тогда матрица ААт становится вырожденной. Вы-

рожденность матрицы ААТ может быть обусловлена также допол—
нительным введением слишком большого числа ограничиізающих
поверхностей в имеющуюся уже систему активных ограничений,
так что локальное решение может оказатыя «избыточно обуслов-
ленным». Вырождение устраняется путем замены і—го диагональ-

ного элемента матрицы ААТ на единицу всякий раз, когда
этот элемент равняется нулю. Поскольку і-я составляющая век—
тора АА! (х) в таких случаях также равна нулю, параметр 7», ока-
зывае'кя равным нулю независимо от наличия и вида і-го ограни-
чения. Если перемещение в новом направлении не улучшает зна—
чение [(х) (или Р7і(х) =0), ищется новый градиент [(х) и
реализуется описанная выше операция проектирования 7 (х) на
подмножество активных огранИчений.

Пример 6.3.1. Обобщенный градиентный метод

Рассмотрим следующую задачу:
минимизировать [' (х) =4л1 _ хЁ — 12
при ограничениях
Н1(х)=25——хЁ——хё=0‚

32(х)=10х1—хі+10х‚—;ё›—34>0,
Е:;(х) =х1>01

84 (х) = хи > 0.
Фигурирующие в данной задаче функции изображены графически

на фиг. 6.0.1.
Начнем итерационный процесс с недопустимой (но являющейся

внутренней) точки х… =[2 411 и наложим нижние ограничения
(О 0) и произвольные верхние ограничения (10° 10“) на 1:1 и х, соот-
ветственно. Частные производные целевой функции и функций,
 pagebreak 
М етоды линейной аппроксимации 285

задающих нетривиальные ограничения, имеют СЛЕДУЮЩИЙ ВИД:
_д__г (х) = 4 анх)

 

дх—д— дм; : _ 2х”
ди (х) _ дн (х) _
—д‘х;—— —— — %„ _!З‘Т — -— 2,22,
_“? (’9 = 10 _ 2х, __ддй "“ = 10 _ 2х…

д):1 дх2

Значения частных производных в начальной точке (в приведенном
выше порядке) запишем в виде матрицы

4 _а`
_4 _в
6 2

Вычислим прежде всего Матрицу А (в точке х‘“’ = [2 417 атив-
ным является лишь ограничение Н, (х) =0), воспользовавшись
соотношением

, 1?) (й)
… ди,(х< ))(дщх )) . _ „,
аш=Ё'( дх; дх/ , :‚іг=1,...,п,
где п* —— суммарное число активных ограничений из числа ограни-
чений, записанных в исходной формулировке задачи в виде не—
равенств. и ограничений, имеющих по условию задачи вид равенств.
В рассматриваемом случае (при п* = 1)

А‹°>=аа*: =—4‹—4)+к—-8‹—8›1=8°

После этого вычисляется матрица АЬ, которая показывает,
какие приращения должны получить фигурирующиев задаче функ-
ции, задающие ограничения (в виде равенств и активных неравенств),
чтобы сошветствующие ограничения удовлетворялись при «старте» из

точки х…? = [2 417- , в рассматриваемом случае АЬ содержит всею
один элемент

1750) = __ 5,
так как значение И. (х) в точке х = [2 511 равняется пяти. Из фор-
мулы (6.3,7) следует, что
Ах : АЧАЬ.
Таким образом, Ах— = 1/80 (—- 5) = _— 0, 0625.
На первом шаге (/г = 1) вектор х… находится с помощью фор-
мулы (6. 3.9):
(а
х‹_1›_ _ „га) + (Ах)———— д__п__,д (х ’_) ,
1:9) = 2,00 _ о ‚60625 ('— 4)— -- 2, 25,

хг” = 4,00 —— 0,0625 (_ 8) = 4,50.
 pagebreak 
286 Г лава б

 

Последовательно реализуя шаги итерационного процесса, получаем
(числа округлены):

 

 

 

 

Перялт дт (к…) дм („(М, я

“1552“? “1 ' "’ Т _М— ”““> ”
1 2,250 4,500 4,500 —9,000 —з,к25.1о—' 0.08340—3
2 2,235 4,472 —4,472 —8,944 ——9,645›10_4 9,644›\0`6
3 2, 236 4,472 —4‚472 —8,944 —9‚302 - 10"9

 

После третьего Шага умение допуска для п, (7:00) оказывается
выполненным и значения независимых переменных последователь-
но смещаются на величину а (и, — 14), где ос =0‚005 (значение
этой константы можно выбирать произвольным образом по усмот—
рению пользователя), а и, и !„ (] = 1, 2) представляют собой верх—
ние и нижние предельные значения (границы) для ›:1 и ›‹2 соответ-
стыгнно. В рассматриваемом примере со ‹и, — Ь,) =0,005 - 10“ :
=5 - 103 как для к„ так и для хз, так что смещения текущих зна-
чений этих переменных имеют следуюший вид:

 

%(,3' + м х?) + Мэ ; (к) или ] (и + 6х)
2,235 + 0 4,472 7— 0 —23,05
2,236 —- 5 103 4,472 —- 0 1,99 10‘
2,136 … 0 4,472 + 5.105 4550107

 

Эти смещения используются при вычислении новых составляющих
градиента функции [ (х):

днк) ‚.`, [():], хз! “и х1+бху, ..., х„)—[(х)
дх] ‚" 6х, '

анх…) … 1,99. 104— (_ 23,05)

дх, " 5. 108 = 4›00'

д; (№) № _ 2,50. 10—7 _ (_ 23,05) :

дх” … 5 _ ю, _ 5,009 . №

(Старые значения составляющих градиент целевой функции заме—
няются на вновь вычисленные.) Следовательно, на шаге 4 (іг =4)
поиск осуществляется сравнительно большими перемещениями и

на Шаге 6 приводит к вектору х‘бі =[0 5,5901Т, для которого
и, (х) =_ 6,250, а 3, (х) =-— 9,348.
 pagebreak 
Методы линейной аппроксимации 287

 

5
д': .
6
№3“…
4 .
5 д‘“);

   

‘ т-іаш- *на/чалдах;
‘7 ’ ‚т, ’ Йщ-гб—дч; - а
’

о . ‚
0 1 _2 5 4 5 и,
Ф и г. П.6.З.і. Траектория оптимизационного поиска обобщенным градиентныи
методом.

Теперь, поскольку условие Ея (х) > 0 не удовлетворяется, на-
ряду с ограничением Нд =0 необходимо учитывать также и ограни-
чение, заданное функцпей 39 (х). При этом имеем

1350.102 1319.101 Ь 6,250
= 1319401 1,393 ' = 9,348’

45545.1018
": 6,113‹ 1014 '

На следующем шаге матрица А превращается в единичную матрич
цу. Для ряда последующих шагов итерационного процесса полу-
чаем

 

Номер шага іг хай) ”$“)

1,70 1,70
400 4,00

ОФФЧ
о
@
 pagebreak 
288 Г лава 6

 

На десятом шаге (іг = 10) матрица А, к сожалению, становится вы-

рожденной:
128 — 32
А = [_ 32 8] '

так что работа алгоритма преждевременно прекращается. Траек-
тория оптИМизационного поиска показана на фиг. П.6.3.1.

6.3.3. ОБОБЩЕННЫИ МЕТОД ДЭВИДОНА

Прежде всего изложим методы сопряженных направлений и
переменной метрики при наличии линейных ограничений, & затем
покажем, каким образом можно подойти к решению проблемы
согласования и учета нелинейных ограничений. В данном подраз-
деле в основном используются результаты Дэвидона [21], который
впервые сформулировал существо метода, результаты Голдфар-
ба [22‚ 23], проанализировавшего метод с использованием алгебры
матриц, а также работы Дэвиса [24114 Муртага и Сарджента [25],
которым удалось модифицировать метод Дэвидона и разработать
машинную программу, позволяющую реализовать предлагаемый
метод на ЭВМ. Хотя и предполагается, что на каждом этапе опти-
мизаЦионного процесса для определен“ направлений пробного
поиска работает алгоритм Дэвидона _— Флетчера —- Пауэлла или
алгоритм Бройдена, следует иметь в виду, что вместо них можно
успешно использовать почти любой из методов, описание которых
дано в гл. 3.

Дзвидон в своей первой статье по данному вопросу утверждал,
что его метод можно распространить на случай нелинейного про-
граммировани при линейных ограничениях как в виде равенств,
так и в виде неравенств путем понижения ранга матришя п… на
единицу для каждого активного ограничения и переопределения
п… с тем, чтобы каждая составляющая вектора х"‘+” =х“” +
+ Ах… удовлетворяла всем активным ограничениям [см. (З.4.1)].
Используя при этом подход, представленный соотношениями (6.3.2)
и (6.33), можно определть так называемую обобщенную проекти-
рующу/о матрицу. Обозначим через хм ортогональную проекцию

вектора х [26], связанную с данной матрицей 0:
хм : [3,Х, (6.3.10)

где матрица Р, определяется соотношением

|% = 1 _- АТ [А,ОАТг‘Ад. (6.3.11)
 pagebreak 
Методы линейной аппроксимации 289

 

Сравнивая это выражение с соотношениями (6.3.2) и (6.33), мы ви-
дим, что в последних 0 =1. Кроме того,

хш0(х—хм)=0.

^
Таким образом, Р, есть обобщенная проектирующая матрица, поз-
воляющая проектировать х на многообразие м в соответствии с
метрикой 0. Затем положим О =т|…‚ где п… —оценка обращенной
матрицы Гессе, описание каторой дано в разд. 3.4, посвяЩенном
оптимизации при огсутствии ограничений.

Напомним, что направление оптимизационного поиска в случае,
когда задача нелинейного программирования не содержит ограни-
чений, может быть найдено методом Дэнидона (см. разд. 3.4):

= — № №».

())г ..
Здесь пр есть 1] в точке х… при отсутствии ограничении. Если
имеется 1 активных ограничений (А, х =Ь), то, как уже установ
лено с помощью (6. 3. 4),

“’ = — тг ‹х‘”’›-

ОДИН ИЗ СПОСОбОВ КОМбИНИРОВаННОГО использования ПОНЯТИЯ ПРОЕК-
тирующей матрицы И метода ДЭВИДОНЗ ПОЗВОЛЯЕТ определить на—
правление ОПТИМИЗЗЦИОННОГО ПОИСК?! В виде

&‘”) = — пё”) ПЗМ‘ (Х“"Л = — пэт (х…), (6.31?)
где 13, задается соотношением (6.3.11) “ при 0 =ч‘о'”, а

№=цъд>іи= пё”—118"’А17(А,т|&"’А‚)"'А,пЬ”. (6.3.13)

В приняшх здесь обозначениях т") есть матрица и в точке х…
при 1 активных ограничениях имеющих место в точке х“). Напри-

мер, накладывая ограничение а,- х =Ь на целевую функцию задачи
без ограничений. с помощью (6.3.13) получаем
га) „(и
ЦБ ааТ
{”> „__ ЦБ > __Ц_- . (6.3.13…)
аіТпо’Ъ

Голдфарб показал, что в случае квадратичной целевой функции
п переменных при ! ограничениях в виде равенств использование

 

” Если определить $… с помощью соотношения а“” = _,!3; 1118" ті (Х…)Ъ

в котором предполагается, что проектирующая матрица проектирует шаг в усло—
виях соответствующей задачи без ограниъюний на ограничивающую поверхность
^

исходной задачи, то Р', запишется (по Голдфарбу) в виде

6; = | _ од} (А‚оА,Т)—1А‚.
 pagebreak 
290 Глава 5

 

для определения направлений оптимизационного поиска соотно-
шения (6.3.12) в комбинации с поэтапной линеаризацией обеспе-
чивает сходимость последовательности промежуточных решений
к оптимальному за (п — !) итераций. Матрица ч обновляется (кор-
ректируется) способом, предложенным Бройденом (алгоритм еди-
ничного понижения ранга); при этом следует иметь в виду, что эф-
фективиость рассматриваемого здеСь метода связана с тем, что
главная задача состоит не в нахождении проектирующей матрицы

‚. ‚`
Р, (или !>?) в явном виде на каждом этапе вычислителъной процеду-

ры, а в определении поправок к Р, по отношению к предыдущему
этапу.

Если имеется одно или несколько ограничений, которые в ходе
оптимизационного поиска в заданном направлении оказываются
нарушенными, то эти ограничения добавляются к совокупности
ограничений в виде равенств и учитываются при формировании
№). С другой стороны, ограничения, записанные в исходной фор-
мулировке задачи в виде неравенств, могут исключаться из систе-
мы активных ограничений, если направление оптимизационного
поиска оказывается таким, что эти ограничения из группы т огра-
ничений-неравенств вида

Втх>с

при этом более не нарушаются. Г олдфарб установил следующее со-
отношение. позволяющее исшкючать ограничение в виде неравен—
ства из группы, состоящей из ! активных ограничений:

Рт—яьітЬіРт—п
ьірт_,ь‚.т

Где Ь,- : [Ьд 17,2 д…], т. е. Ь, представляет собой строку матри-
Цы В,… соответствующую і-му ограничению. подлежащему исклю-
чению из совокупности активных ограничений, а В,… находится
с помощью (6.3.3) при исключении і-го ограничения в виде неравен-
ства из множества т ограничений-неравенств (являющихся на пре-
дыдущем шаге активными):

Р…_‚ = 1— в5,_1(в…_,в,т„_,)—'в…_1. (6.3615)

Теперь остается лишь ответить на следующий вопрос: как можно
определить, какое из ограничений в виде неравенств становится
активным в точке х…? Как уже отмечалось в разд. 6.3.1, это
позволяют сделать так называемые теневые параметры, т. е. состав—
ляющие вектора и, определение которого дано в связи с рассмотре-
нием соотношения (6.3.4);

и = (АжАитГ'Аті (х…)—

(!:) :

пы пЁ’” + ‚ (6.3.14)
 pagebreak 
Методы линейной аппроксимации 291

 

Отрицательное значение и, соответствует ограничению, которое
можно исключитъ из базисной совокупности ограничений, причем
для этого выбирается ограничение с наибольшим абсолютным зна-
чением и,. Поскольку из совокупности активных ограничений мож.
но исключить лишь ограничения в виде неравенств (ограничения,
записанные в виде равенств, всегда активны), можно избежать
вычисления и, ограничИВШись вычислением лишь вектора

П = <в,„в‚$г'в„ді (х…). (6.3.16)

Кроме того, хак отмечалось в разд. 6.3.1, существуют более эф-

Т _ _
фективные способы вычисления (ВМВ…) ‘ при заданнъш (В…„відгд '

и (В„…ВДЧ)", нежели прямой способ перемножения матрип с

последующим выполнением операции нахождения обратной матрицы.

Используя 113“, Р, и и, определение которых дано выше, можно
рассматривать метод Дэвидона как метод решения задач нелиней-
ного программирования при линейных ограничениях. Начальная
допустимая точка к“” предполагается известной; в противном слу-
чае для того, чтобы алгоритм начал работать, ее нужно отыскать.
Если к“” — внутренняя точка К и ограничения в Виде равенств

отсутствуют, пё… принимается равной |. Если х<°> лежит на !

линейно независимых гиперплоскостях (т. е. удовлетворяет ! огра-

ничениям в виде равенств), то ц?” находится путем !-кратного
применения (6.3.1За) при начальном условм пп (0) =!. Таким об-
разом, множество независимых ограничений в виде равенств оказы-
вается включенным в исходную совокупность базисныхограниче-
ний, и, следовательно, только ограничения вниде нераВенств либо
вводятся в базис, либо из него исключаются.

Предполагается, что на 11-м этапе ОПТИМИЗЭЦИОННОГО поиска мы
знаем х‘”),і(х“°)‚ р[ (‚@) и ТГ,”; будем также считать, что хи
принадлежит К и многообразию м, задаваемому пересечением !
линейно независимых гиперпласкостей, представляющих актив-
ные ограничения (базисную совокупность ограничений). Схема даль—
нейшего развития вычислительного процесса, предложенная Дэви-
сом, включает следующие операции:

1. Выделение активных ограничений из числа ограничений,

имеющих вид неравенств. Вычисляют 5… : —п$"’, 71° (х…) и с …>
мощью формулы (6.3.16) и. Если |]5‘”Ё||= () и и‚- >О при любом зна-
чении ]“, оптимум х* найден и работа алгоритма заканчивается;
в противном случае осуществляется переход к шагу &

2. Перестройка базиса ограничений. Из базисной совокупности
ограничений исключается то ограничение в виде неравенства, ко-
торое соответствует наибольшему по модулю отрицательному зна-

чению и,; эта операция выполняется с помошью формулы (6.3.14).
 pagebreak 
292 Глава 6

Вычисляется эш? =—п‘‚’°7і(х<’°); затем, как и в случае приме-
нения алгоритма проекции градиента (алгоритма Розена), убеж-
даются в том, что Вновь определенный вектор зі“) задает допусти-
мую (по отношению ко всем неактивным ограНИчениям) т0чку.
Если точка, задаваемая вектором №, не является допустимой,
используют соотношеНие (6.3.133) и прибавляют к базисной системе
ограничений те ограничения в виде неравенств, которые при этом
нарушаются. После этого с помощью формулы (6.3.12) находится
новое значение а“”. Эта процедура выполняется (от начала рассмат-
риваемого шага) столько раз, сколько необходимо для получения
допустимого направления. Если для некоторого іе справедливо ра-
венство || зЁзпуп || =(), возвращаются к шагу 1; в противном
случае переходят к шагу З.

3. Одномерный оптимизационный поиск. По схеме, описание
которой дано в разд. 3.4 и 2.6, реализуется одномерный оптимиза—
ционный поиск в допустимом направлении. Если при единичном
перемещении в процессе одномерного оптимизационного поиска
нарушается одно из ограничений, переходят к шагу 5. В против-
ном случае фиксируется точка, соответствующая наименьшему
значению [(х).

4. Переход к новой матрице. Если в процессе линейного опти-
мизационного поиска группа активных ограничений не меняется,
осуществляется переход от матрицы ПКР к Матрице ”[#-Н) с исполь-
зованием при этом либо метода Дэвидона —— Флетчера — Пауэлла,
либо метода Бройдена (см. разд. 3.4). Затем возвращаются к шагу \.

5. Формирование новой группы базисных ограничений. Группа
базисных ограничений расширяется за счет введения в нее нового
ограничения, а именно того, которое оказалось нарушенным на
шаге 3. Затем возвращаются к шагу 1.

Для определения направления оптимизационного поиска Муртаг

и Сарджент использовали проектирующую матрицу РЁ, т. е. пола-
гали

Ахив _„„,;;…„‹0…7‚„…‚=

— № [1 — №? ‹АтЪЮАЪ—‘Ад пБ’”7і №» =

= — №№ [71° (х…) —- АкТИЁЁ’].

где 115") Е(А‚т|Ъ’”А;Т)"А1т|о‘”$/і(х“°›) можно рассматривать как вектор,

составляющими которого являются ассоциированные с активными
ограничениями множители Лагранжа; с их помошью можно опреде-
лить, какие ограничения следует исключить из базиса. Выражение

[7/(х‹*’)—ЦБЮЦЪЫ1интерпретируется как разность между градиен-

том Дх) в точке хи” исоответствующим градиентом чёта?) в най-

денной стационарной точке.

П
 pagebreak 
Методы линейной аппроксимации 293

 

Алгоритм Муртага — Сарджента весьма похож на алгоритм Дэ-
виса. На іг—м этапе реализуются следующие шаги:

1. Вычисляется цЁЮ=МЁ*’А,ц8’”7і(х‘*’)‚ где МУ” — аппроксима-
ция (А‚т.‘*’А‚Т)—'. ‚

2. Вычисляется А “” = —- пё)” [71° (хм) — А1Тц$’°].

З. Вычисляется

; ›1

@= так ? ”’}
/| и >О т ’
‚'=1‚1…,! ”

где т„— і—й диагонаЛЬный элемент матрицы МО“.

4. Если “Ахши<е и 6<е‚ вычислительный прецесс заверша-
ется; в противном слуЧае осуществляется переход к следующему

шага!.
. Вносятся изменения в базисную группу ограничений (если
в этом имеется необходимость):

а) к базису добавляется некоторое ограничение. Если точка х‘”

оказывается на поверхности, связанной с новым базисным ограни-
Т

чением, то 31+1(х“°) = 0. Если же (Ах…) 7@,+1(х®)>0‚ то в сиг

стему базисных ограничений вводят ;… (х…), а затем возвращаютш

к шагу 1;

б) некоторое ограничение исключены из базиса. Если || АхщЦ<
<В, то выбранное і-е ограничение исключают из группы базис-
ных ограничений, а затем возвращаются к шагу 1.

При включении в базис нового ограничения перестройка матри-

Цы МЗ” осуществляется следующим образом:
М М
№. = “ ” .
мы м2!
где 1
м1] = Ап‘ + Ап'АшАо-‘АшАп‘ =

 

Мп = М; = _ АЁ1А1яАЁ'‚

М22 = АЕ' (скаляр),

Ап‘ = М?",

Ап = А‘; = АЩЁЮУЕцп (ход),
Ага = 7917-м (х…) 111979… (х…),
Ао = Ат — Амдй'А“ (скаляр).
 pagebreak 
294 Глава 6

 

11.
При исключении ограничения из базиса матрица м‘,’ заменяется
матрицей

МУЗ, = м11 — м„м5‘м„.

б. Осущестшіяется оптимизационный поиск в направлении про-
екции:

№ = — №8” ті ‹х‘*>› — Атт].

Параметр ?» подбирается так, чтобы значение і(х) уменьшалось,
а Вектор х оставался допустимым; при этом используется одношзр-
ный поиск.

7. Вычисляется А;… = 71° (хин…) — 71° ($”).

8. Перестраивается матрица ч при использовании метода Брон-
цена:

(Ахив _ ((РАЁЮ) (Ахав _ ЧЪЮАЕ‘Ю“
(Ах… __ чъгдддфдтщш)

Осуществляется проверка с тем, чтобы убедиться в положительной
определенности матрицы №№. Если „(№0 не является положитель-

но определенной, ц‘од" приравнИВается чё,”.
9. Перестраивается матрица МБ,”:

мэй—Н) : м;!» +
[МЪЫЫ (Ах‘ю _ 318052…” [МФА: (Ах… __ чё,”)Ав‘ЮЛТ
(№ — чЪ’”Ав“">ТАе“" + их“” — чЬЮАаФЧТА,’ [ММ (№ — чё"’^е"")1 '

Затем возвращаются к шагу 1.

Как обобщить метод Дэвидона на случай нелинейнш ограниче-
ний? Если ограничения локально линеаризованы, то выбранный
метод минимизации должен обеспечить возвращение из точки, не
являющейся допустимой, в допустимую область (как, например,
это имело место для х‘д’ на фиг. 6.3.3) и гарантировать, что при этом
значение ;” (х) действтельно улучшится. Приведенный ниже ал-
горитм такого обобщенного метода предложен Дэвисом [241 и осно-
Ван на результатах, полученных Розеном [14]. На фиг. 6.3.8 графи-
чески предстаВлены активное ограничение, заданное функцией
@, (х); два неактивных ограничения, заданных функциями ‚3, (х)
и 53 (х); линии ровней целевой функции! (х) в точке ‚№; плоскость,
касательная к (‚«/г» в точке к“"; плоскость, касательная кд, (хі’д)
в точке х‘” (последняя представляет собой линеаризованное огра—

№» = пз") +

+

ничение 5105”) =0). Активным нелинейным ограничением будем
считать ограничение, линейная аппроксимация которого являтя
активной в соответствии с соотношением (6.3.15). Вектор «возврата»
г (х…) соединяет недопустимую текущую точку с точкой, принад-
 pagebreak 
Методы линейной аппроксима ции 295

 

лежащей допустимой области:

г №) = в’ ‹ввт›—'ф<’°‚ (6.3.17)
где В — матрица, строки которой состоят из элементов, предсТав-
ляюших собой найденные в точке № значения частных производ-

    
     
 

Лг ниченное

, „ ” МСН“?
(" ‚ %ипш 3%

- - ?: 7і(:'1:")

   
  

Ллошг (.'/пд, каштілшая
и: :'(.т :: тачке « \

„(ым
Ф и г, 6.38. Метод Давидана, обобщенный на случай нелинейных ограничений.

ных активных ограничений в виде неравенств по каждой из пере—
мех-шых, а ф —-вектор-столбец‚ элементами которого являются аб—
солютные значения функций, задающих активные ограничения,
вычисленные в точках, лежащих на 50° в окрестности х“). Наконец,
вектор, задаЮЩий направление оптимизационного поиска 804,
есть проекция вектора — «№7! (х…) на пересечение всех активных
линейных ограничений и активных ограничений, полученных
из нелинейных ограничений с помошью линеаризации (последние
представляют собой гиперпласкости. касательные к соответствую`
щим нелиНейным ограничениям).

Метод, предложенный Дэвисом, имеет следующую структуру ":

Шаг !. По аналогии с шагом 1 алгоритма, используемого в слу-
Чае линейных ограничений, выявляются активные ограничения в

 

') Ограничения в виде равенств, по-видимому. также могут быть включены
в расширение; однако никаких специальных правил Дэвисом по этому поводу
указано не было.
 pagebreak 
296 Глава 6

 

виде неравенств путем рассмотрения линеаризованных (в окрест-
ности точки к"”) ограничений, заменяющих соответствующие не-
линейные ограничения.

Шаг 2. Поскольку при использовании аппроксимирующих функ-
ций на каждом шаге итерации происходит изменение базиса огра-
ничений, вычисляется матрица 119 для і активных линейных огра-
ничений в виде неравенств [вместо того, чтобы в ходе «согласова-
ния» активных линеаризованных ограничений приМенять для
Понижения и повышения ранга матрииы «; требующие больших

временных затрат соотношения (6.3.1За) и (6.3.191. Матрица п}?

вводится в память ЭВМ; затем понижается ранг дубликата 11$)
путем последовательном прИМенения соотношения (6.3.1321) для
каждого активного линеаризованного ограничения, в результате

чего формируется матрица 115“), где 1— суммарное число активных
ограничений. Наконец, находится
8‘” = — 115%? (кф)-

Шаг 3. Чтобы начать оптимизационный поиск в точке х<"+‘‚
осуществляется одномерное перемещение вдоль направления 500.
Это перемещение реализуется следующим образом. Длина шага №”
выбирается равной меньшему из чисел и. и @. где ее — удвоенное
перемещение в сторону минимума по алгоритму Ньютона, а В—
расстояние до ближайшего линеаризованного ограничения Вдоль 50°.
Данная процедура гарантирует, что минимизация превращается
в безусловную (т. е. в минимизацию при отсутствии ограничений)
и что нерациональный выбор длины шага будет при этом исключен.

Далее находится хг” =х("> -|—№>в<*° (фиг. 6.3.8) и осуществляет-
ся проверка с целые выяснения, не нарушается ли какое-либо
из нелинейных ограничений. Если какое-нибудь из ограниче-

ний, задаваемых функциями @, (хЁЁ’), нарушается, то по направ-

лению вектора г (х"‘*) производится перемещенпе из хі’” к допу-
стимой области. Чтобы избежать излишних операций, связанных
с вычислением значений @, (хдд), указанное выше перемещение
всегда осуществляется до точки пересечения г(х<*>) с плоскостью,

касательной к контуру [ (хдд), т. е. в точку ХЁ’. (Эта точки яв-
ляется Внутренней, так как она находится в области, лежащей меж-
ду плоскостью, касательной к контуру целевой функции [ (х…),

и ограничивающими поверхностями.) После установления отрезка

ь :; :;
хі’ — хё) проводится интерполяция с целью отыскания точки хё‘

на поверхности, определяющей ближайшее к хё'” ограничение с

ТОЧНОСТЬЮ ДО установленного ДОП уска.

ЕСЛИ точка ХЬЮ не удовлетворяет активным ограничивающим

условиям, то из точки ха” производится новое перемещение при
 pagebreak 
Методы линейной аппроксимации 297

 

сокращенной длине шага И, Таким образом, находится новая ТОЧ-

ка 1:2).

После отыскания граничной точки х?) производится проверка,
цель которой заключается в том, чтобы установить, существует ли

минимум на дуге, соединяющей х“) и хЗ’” (см. в этой связи шаг 4).

 

“ті

Ф__и г. 6.3.9. Экстраполяпия при поиске граничной точки в случае, когда нарушгъ
ется новое ограничение.

Если существование минимума установлено, производится уточне-
ние его положения путем надлежащей интерполяции. Эгот минимум
обозначим через х(*+1>.Если существование минимума установить

не удается, то из точки хз”) предпринимается шаг длиной А в на-
правлении 5$) и повторяется шаг 1, в результате чего определя-

ется точка хз“?! (фиг. 6..39).

Если в точке кз” оказывается нарушенным какое-либо другое

из нелинейных ограничений (на фиг. 6.3.9 этот момент проиллюст-
рирован на примере ограничения, заданного функЦией Ев (х)), гра-
ничная точка к““… определяется с помощью экстраполяции вдоль

ЛИНИИ, (соединяющей &;02) И непосредственно предшествующую ей

точкухзю (см. шаг 4). После этого осуществляется переходкшагу 5.
Шаг 4. Прекращение оптимизациох-п-юго поиска в окрестности
х"‘+" может иметь место при разных условиях. За исключением

случая, когда оказываются нарушенными т новых ограничений
(т>1)‚ поиск обычно прекращается, если оказывается, что
 pagebreak 
298 Г ‚шви 6

 

‚ т ‚
‚(Хаш)>і(х‹зщ) или 7 [(х3‹’°)$‹’”>0, так как минимум функции
НХ) находится на прямой хз‘”)—х$ю. При этом производится ин-
терполяция ‹: целью более точного определения положения миниму-

ма функпии Дх) на той прямой (точки ХБ”). После этого из точки
Таблица 6.8.1

Сравнение четырех меюлов

 

 

 

 

з……„ы ] м…… 523.5:„ъгвжггж'зе км::‚эажгж- „21°зз;;ъж::'г‚ь

10 а 5 120 0
б 12 0
в 8 0
г 7

11 а 5 109 114
6 94 111
в 10 22
г 9

18 а 11 712 805
6 657 794
в 227 421
г 124

1) В качестве начальной выбирается точка, лежащая ›: допустимой области.

 

Х?) предпринимается шаг В направлении КНЗИСКОРейШеГО спуска» К

ближайшей границе и находится точка хи"). Дэвисом устаношюно,

что для выпуклых функций-ограничений положению х‘и'“ можно

определить путем нахождения пересечения —7}(х$”)) и 50” в точке

х?) (не являющейся допустимой) с последующей интерполяпией или

экстраполяцией (для вогнутых ограничений) между точками ХБ”) и

хЁ". Данная процедура для двумерного случая иллюстрируется
на фиг. 6.3.10. Заметим, что при вогнутом ограничении ‚((#-Н) сле—
дует находить путем линейного поиска вдоль ——71°(Х2*’), так как

точки х?” и х?!” совпадают.

Если в процессе поиска минимума [(х) путем перемещения

вдоль линии Аю—хэи" значение {(х) не получается меньшим
"‘*'":хё")

[(Ё)], то полагают х

Шаг 5. Как только положение точки к“”… оказывается
установленным, по аналогии с шагом 5 оптимизационной процедуры
при линейных ограничениях к 115,” добавляются новые активные
линеаризованные ограничения, после чего возвращаются к шагу 1,
 pagebreak 
ттпбпв, климата:: ‚(:)-г

А'

   
  
    

    

" (:

 

в точке д‘

гш-г тс).- :

№,"! КВМ—
твлшал # На:.)
в точке ::"

6 ":

Ф и г. 6.3.10, Определение кф“).
 pagebreak 
300 Г лава б

 

Шаг 6. Если группа активных ограничений остается без изме—
нений, осуществляется переход от матрицы п?” к новой матрице
ч)“… по схеме, представленной шагом 4 оптимизационной про-
цедуры при линейных ограничениях.

Описанная выше процедура воспринимается пока лишь хак
«краСИВая абстракция». Поскольку относительно эффективности
метода Дзвпдона при нелинейных ограничениях изВестно очень

мало, мы предлагаем читателю ознакомиться с табл. 6,31, в кот0‹
рой проводится сравнение:

а) комбинации метода Дзвидона с МБП 1) (описание метода
см. в разд. 7.1.3);

6) комбинации метода Голдфарба с МБП;

в) метода Давидова _Дэвиса (описание метода дано выше);

г) метода Муртага и Сарджента (аналогичного мет0ду Дэвиса).

При этом анализировались результаты, полученные при рас-
смотрении задач 10, 11 и 18, приведенных в приложении А, а также
и ряда более простых задач.

Применительно к задачам, содержащим только линейные огра—
ничения (в таблице ссылки на такого рода задачи отсутствуют),
сочетание метода Голдфарба с МБП оказывается гораздо эффек-
тивнее сочетания метода Дэвидона и МБП; однако при решении
задач с нелинейными ограничениями эти комбинированные методы
почти равноценны. С точки зрения эффектИВности оба они значи-
тельно уступают методу Дэвидона — Дэвиса.

6.4. мвтод допустимых НАПРАВЛЕНИИ
(МЕТОД ЗАУГЕНДАИКА)

Как уже отмечалось выше, для каждой допустимой точки ход)
в А’ может существовать множество различных допустимых направ—
лений оптимиз’ационного поиска [27]. Сущность методов допусти-
мых направлений сводится к следующему: поиск начинается в
допустимой точке пространства решений и реализуется (при линеа—
ризованных ограничениях) по траектории, обеспечиваЮЩей улуч-
шение значений целевой функции и вместе с тем никогда не вы-
ходящей за пределы допустимой области. В этом смысле предло-
женный Розеном метод проекции градиент представляет собой одну
из модификаций метода допустимых направлений. Однако необходи`
мо обратитъ внимание на следующее: проекция градиента И (№")
на подмножество ограничений, содержащее х‹#›_ задает напраые
ние поиска, соответствующее (относительно евклидовой метрики)
направлению наискорейшего спуска для целевой функции, тогда

 

') МБП — метод барьерных поверхностей.
 pagebreak 
Методы линейной аппроксимации 301

 

как в методе Заутендайка используется другая метрика, а именно
метрика, определяемая соотношением

"Ах“: тах (]Ахц, ..., [А):„П.

Данная метрика приводит к тому, что в качестве допустимого вы-
бирается такое направление, которое обеспечивает наибольшую
минимюирующую поправку к значению Целевой функции без на-
рушения какого-либо из ограничений.

Метод Заутендайка позволяет оперировать как с линейными,
так и с нелинейными ограничениями; однако с его помощью не
удается решать задачи с ограничениями в виде равенств` Задача,
рассмотрению которой посвящен данный раздел, по существу пред-
ставляет собой задачу (6.1.1) без ограничений в виде равенств.
Линеаризация фигурирующих в этой задаче функций путем их
разложения в ряд Тейлора в окрестности точки к”” приводит
к следующей задаче:

минимизировать і(х®) + 7701…) (х — хи”), х Е Е ”,
при ограничениях

Е,(х®)+7Т3д(х®)(х—х…)>0, і: 1, р. (64.1)

Процедура Заутендайка устанавливает наиболее благоприят-
ные 1’ из возможных направлений оптимизационного поиска при
отправной точке х“? путем решения некоторой (связанной с исход-
ной задачей) подзадачи, а именно путем решения задачи (6.4.5),
структура которой указана ниже.

Перемещение из точки хо” в точку ›‹ , как обычно, задается
соотношением х< іг__+1)_х‹/г) + Ж…З (*). Подстановка в задаче (6.4.1)
вместо вектора х его текущего значения ха“… приводит к задаче

минимизации НХМ) „№№; [(х ("’)50”
при ограничеНИЯх

я, (х…) + ж‘ЮУ’Ых ““п“” > 0, г = 1, ‚ . . ‚ р. ‹6.4.2›

Поскольку НХ…) и @(х‘ю) >О являются константами, необходимые
и достаточные условия реализации перемещения из точки х… в
точку хм") в связи с решением задачи (64.2) [причем такого не-
ремещения, когда точка х‘н'” остается допустимой с точки зрения

‹й+1›

1’ В смысле получения наибольшей минимизирующей поправки :( анаЧению

[(х) при перемещении из точки х… в точку хи“… без нарушения какого-
либо из ограничений.
 pagebreak 
302 Г лава б

 

условий задачи (6.4.1)] имеют следующий вид:
\7Ті(х…) 50” <о (6.4.3)

птг‹(х"”)з"" >О. і= 1. р. (6.4.4)

Любой вектор з…, удовлетворЯЮщий неравенствам (6.4.3) и (6.4.4),
одновременно является вектором допустимого направления.
Метод Заутендайка выделяет допустимое направление, обеспе-
чивающее получение наибольшей минимизирующей поправки к
значению целевой функции [ (х) на шаге от точки х… к точке хи…)
путем решения следующей задачи линейного программирования:

минимизировать УТПХ‘”) з…, 8… Е Е",

при ограничениях
7Т5;‹х""›з"">0, і: 1, р. (6.4.5)

Решая задачу (6.4.5), мы определяем составляющие вектора допу-
стимого направления, вдоль которого следует перемешаться из
точки к“” в точку х“‘+”.

Каждый из этапов реализации метода Заутендайка имеет сле-
дующую алгоритмическую структуру:

1. Пусть х(*Р—некоторая допустимая точка задачи (6.0.1)‚
в которой отсу'гствуют, однако, ограничения в виде равенотв,

2. Вычисляютсн градиенты функции“ Дх) и функций 3, (х)
(і = 1, …, р) в точке х“? и решается задача линейного програм-
мирования (6.4.5), в результате чего находится допустимое направ-
ление ;(”). Решение задачи (6.4.5) находится с помощью любого
из алгоритмов линейного программирования.

3. Если УТНхид) 5(Ю<0‚ то определяется максимальная длина
шага М, осуществляемого в направлении &‘” без выхода за преде-
лы допустимой области задачи (6.0.1); ?»* получается из условия
А.“ = тах {Ы хи‘Ч— №0") Е !?}. Значение # может быть найдено ‹:

ПОМОЩЬЮ одномерного поиска В направлении З…, начиная ИЗ ТОЧКИ

хи“). Затем определяется такое значение №), довлетворяющее
условию 0 <?»… < ?ъ", для которого {(хф’ + ‚“{/иди) есть минималь—
ное значение целевой функции в направлении $…. Новая точка
определяется из хи“… = х‘ь’ + ””в"". Теперь возвращаются к шагу
2 с тем, чтобы начать оптимизационный поиск на (із + 1)-М этапе
вычислительного процесса`

4. Если 7Ті(х“")з'*’ =0, оптимизационный поиск заканчивает-
ся, так Как дальнейшее уменьшение значенияі (х) не представляется
возможным.

Заутендайком дано также описание модифицированном метода
допустимых направлений [28], в рассмотрении которого пока нет

И
 pagebreak 
М етды линейной аппроксимации 303

 

особой необходимости. Опубликованные сведения относительно ма-
шинных программ, которые позволяли бы реализовать метод Зау—
тендайка на ЭВМ, крайне бедны; тем не менее некоторые результа-
ты известны [28]. Рассмотренный выше метод Заутендайка по
сравнению с другими методами, применяемыми при аналогичной
постановке задачи нелинейного программирования, является более
«быстродействующим». Кроме того, он имеет то преимущество,
что позволяет оперировать как с линеиными, так и с нелинейными
ограничениями, имеющими вид неравенств. Однако нет достаточно
данных, доказывающих эффективность данного метода при реше-
нии задач с большим числом нелинейных ограничений.

6.5, метод ововщвнного приввдвнного
ГРАДИЕНТА (мот)

Алгоритм обобщенного приведенного градиента [30—321 пред-
ставляет собой модификацию алгоритма Вольфа [33], которая может
быть использована для решения задач при нелинейном характере
и целевой функции и ограничений. Структура данного метода пред-
полагает реализацию (по отношению к нелинейным функциям)
линейно-аппроксимирующих процедур; определение новых пере-
менных, ортогональных к некоторым из ограничений; приведение
градиента целевой функции к преобразованному таким способом
базису. (Вольфом подробно рассматривается связь метода приведен-
ного градиента в его первоначальной формулировке и симплексного
метода линейного программирования.) Хотя задача, решаемая ме-
тодом приведенного градиента, формируется в общем виде как за-
дача

минимизацни [ (х), х Е Е”,
при ограничениях
Нд(х)=0, !=1, ..., т, (6.5.1)
Ьі<хі<и‚, і=1‚...‚п,
ограничения в виде неравенств удается включить в оптимиза-
ционную схему путем вЫчитания из левых частей ограничений,
имеющих вид неравенств, неотрицательных ослабляющих перемен—
ных, что превращает ограничения-неравенотва в ограничения-ра-
венства вида
2
д:(х)=ёі(х)—Щ =0
при неограниченных предельных значениях переменных и„ т. е.
— со <%. < оо. (Переменные и, добавляются к л переменным
исходной задачи.)
Если в соответствии с принятым предположением выполняется
условие невырожденности, в структуре обобщенного алгоритма
 pagebreak 
304 Глава 6

 

приведенного градиента различают две системы переменных: т ба-
зисных (зависимых) переменных х; формируют подмножество [, а
(н ——т) небазисных (независимых) переменных хк образуют под-
множество К . При этом зависимые переменные неявным образом
определятся через независимые переменные; следователгто, [(х)
есть функция лишь (и —т) независимых переменных. Поясним
Используемые в данном разделе спеЦиальные обозначения:

 

 

 

 

 

 

 

 

 

 

 

 

”100
115 5 —(т ›‹ 1)-мерная матрица,
&… (Х)
дИ‚(х) ди1(х)
115 дх‘ дх’“ —(т ›‹ т)—мерная квадратная мат-
дх, 'ддт’ф ' ' Эл,; (х') рица («базиснат матрица),
дх, ' дх…
д д
711; = [ (31221 ;;:Ч— [1 ›‹ (п—т)1—мерная матрица,
71,1“ = [ д;)? 9%?- ———(1 >< т)-мерная матрица,
@ПХ) _ #00 «ПШ _ _ _ .
‚Щ— [ “%+! дх“ ] _ г [1 >< _(п т)] мерная матрица
(матрида приведенного градиента),
4х, 11:6,
ах, (1х… +1 ' ' ' ах„
дх = _ . . . . . . —[т><(п—т)]—мерная матрица.
К ах," ах…
%… ах,.
піИ1(х) №1…
[… дхт+1 ' ' ' дхн
—= ‚ . . . . . .. _тхп—т-меная матица,
"”‘К ли…… ди…… [ ( )] р Р
”„„„—+“, ах„

6.5‚1. ПРИВЕДЕННЫИ ГРАДИЕНТ

Поскольку ограничения в виде равенств отражают зависимость
между переменными задачи (6.5.1) лишь в неявкой форме, непосред—
ственное сокращение размерности этой задачи, вообще говоря,
неосуществимо. Другими словами, уравнениядадаюшие упомяну-
тые выше ограничения, не могут быть разрешены относительно
зависимых переменных с тем, чтобы их можно было путем соответ-
 pagebreak 
Методы линейной аппроксимации 305

 

ствующих подстановок исключить из структуры целевой функции
и, таким образом, выразить целевую функцию только через неза-
висимые переменные. Однако метод ограниченных вариаций поз
воляет сократить размерность задачи и делает возможным исполь—
зование приведенного градиента в качестве одного из критериев
при установлении оптимальностп. Чтобы проиллюстрировать эту
идею, рассмотрим частный случай задачи (6.5.1), предположив,
что целевая функция зависит всего от
двух переменных при единственном огра-
ничении в Виде равенства, & именно
рассмотрим следующую задачу:
минимизировать [ (х„ хд)

при ограничении

 

 

 

и(хь хз) = 0.
При бесконечно малых приращениях ›:1 Ф и г. 6.5.1. Допустимые пе—
и х! имеем ремещения в случае, когда
д,… дн!) минимизация} (х) осущест-
@; (х) = 11351 + (1х2, вляется при единственном
дх; дхн ограничении в виде равен-
Кроме того, ства 11 (х) = 0; А н в _- до.
днх) дп… ПУСТШЁ'ые точки, тогда как
: : точка не являекя допусти—
сіЩх) дх‘ ах! + дх 4х2 0, ‘…„Ь

Приведенные выше выражения линейны относительно их, и (1х3,
так что из выражения для (іі (х) либо ад, либо ах“ можно исклю-
чить. На фиг. 6.5.1 показано, что единственно допустимыми пере-
мещениями являются перемещения вдоль ограничения И (х„ х„) =
=` 0.

Решим уравнение дл (х) =0 относительно ‹іхд:

дд ( х) !дх,
ди (х)]дх,

Полученное решение подставим в выражение для (іі (х):

ді (Х) д! (х) дп (}:)/дх
'“ <*> = (т ——д„—; №) “*

6х2 = — ах,.

Отоюда получим следующее выражение для приведенного градиента:

анх) _ анх) днх) [дщхуг дн…
_ _ дх, дх,

Необходимым условием минимума [(х) является равенство нулю
дифференциала (#(х) (т. е. (#(х) =О). По аналогии со случаем
минимизации без ограничений можно записать это условие в виде

днк) _
% _0.
 pagebreak 
306 Г лава 6

 

Возвращаясь к общей формулировке задачи (6.5.1), выразим
обобщенный приведенный градиент через компоненты градиента
целевой фунюши, матрицу, обратную по отношению к базисной,
и якобиан для ограничений, имеющих вид равенств. Для 4! (х) по-
лучаем

т т
11; (Х) = Уккідхк + %, (11х1-
Путем перемножения матричных элементов нетрудно показать,

что приведенный градиент можно записать В виде

а ) Фк:
{,}; = №“ + 71; ??? . (6.5.2)

 

(Следует помнить, что такие производные, Как ах…+./11х‚„+2 или
дх…‚д/сіхд, обращатся в нуль, так как переменные х, (і =
= т + 1, …, п) являются независимыми.) Чтобы исключить из соотно—
шения (6.5.2) неудобную для дальнейшего анализа матрицу ахтіхк,
Заметим, что

 

0171, (х) = 75,31, (х) ахк + 71,Щ(х)1іх‚ = О, і: 1, .. . , т,
ап дп дн дк,
@@@—ЧИЖ щ)“ “‘—53")
так ЧТО
дк: дп " дн
—‚.—.,<—=—(д—.,) (т.) (6.5.36)

Подставляя (6.5.36) 3 (6.5.2), получаем для обобщенного приведен-
ного градиента

 

3::>=71кг—т(ёгт)"(%)- №

Заметим, что число составляющИх вектора приведенного гра-
диента равняется числу независимых переменных (по одной состав-
ляющей на каЖДую независимую переменную).

На фиг. 6.5.2 дано графическое представление приведенного
градиента для следующей задачи квадратичного программирования,
включающей одно ограничение в виде равенства:

минимизировпь [ (х) = х? + ;&
при ограничении
Н(х) = 2х1+ х,— 1 = 0_

Пусть х, есть незаВИсимая (небазисная) переменная, а х2 —зави—
симая (базисная) переменная. Частные производные функций
 pagebreak 
Методы линей ной ттроксиліации 307

 

___—___.

 
  
 
 
  

“:
Б
Значения
приведенная
грауиента
дГСШ)

 

д.1}

  
 

Уровни /1(ас)= 2-1.‘‚+ж2—/=0

1"(::)= 132+ :»; —3
Ф и г. 65,2. Приведенный градиент: условный минимум находится на линии
н (х) = 0 в точке х“ = [0,4 0,2]7 (в этой точке прИведенный градиент обращается

в нуль).
]“ (х) и И (х) имеют следующий вид:

И (Ю

 

дх! : 2х1! дх; _ 2353;
д?! (Х) _ дИ (х) _
т — 2, ———дх2 —— 1.

для обобщенного приведенного градиента получзем

аш) _ днк) _ днк) д…)г дых)
«іх, "' дх1 дх; дхд дх,

=2хд—2х3. 1 -2=2х1—4х‚.
 pagebreak 
308 Г лава 6

 

Перемещение из любой допустимой точки вдоль ограничения 11 (х):
=0 до тех пор, пока а; (х)/‹і›с1 не обратится в нуль, обеспечивает
минимизацию [ (х).

Можно интерпретировать приведенный градиент и другим обра-
зом, опираясь на понятие двойственной по отношению к (6.5.1)
задачи математического программирования 1). Нетрудно показать,
что условия Куна —— Таккера (см. подразд. 2.5.4) для двойствен-
ной по отношению к (65.1) задачи (если она является задачей вы-
пуклого программирования) имеют следующий вид:

 

 

(“|
щдх) — \: „(: = :, (6.5.58)
л.
7х‚1°(Х)—Ч „,8" = 0, (6.5.56)
2,- < 0, если х,- = […
г,>0, если х,‹=!]„ і=т+1, ..., п, (6.5.513)

2; = 0, если Ь, < х, < И„

где 2=[г„‚+1 2,1]. а \7=[010‚„].

Если положить 2__(‹іі(х)/41хк), то подстановка (6.5.56) в (6.5.5а)
приводит к (6.5.4). Таким образом, значения составляющих при-
веденного градиента служат ориентиром при отыскании оптималь-
ного вектора х (поиск состоит в отыскании точки, в которой при-
веденный грцдиент целевой функции обращается в нуль).

6.5.2. НАПРАВЛЕНИЕ ОПТИМИЗАЦИОННОГО ПОИСКА

Алгоритм обобщенного приведенного градиента начинает рабо-
ту с допустимой точки. Если же относительно условий рассматри—
ваемой задачи вектор х не является допустимым и, следовательно,
возникает необходимость вводить в рассмотрение (при записи огра-
ничений) искусственные переменные, то значения последних посте-
пенно сводят к нулю путем добавления к целевой функции штраф—
ного члена (см. гл. 7), что в итоге делает вектор ›‹ допустимым. С этой
целью можъю также использовать и сам алгоритм обобщенного
приведенного градиента, минимизируя (или максимизируя) значе-
ние каждой искусственной переменной (или суммы абсолютных
значений эгих переменных). Если приведенный градиент ни на одном
из этапов вычислительной процедуры не обращается в нуль, произ-

" В математическом программировании понятие двойственности отражает
то обстоятельство, что если существует допустимый оптимальный вектор х, являю—
щийся решением задачи минимизации (которую называют исходной), то Этот же
вектор является решением соответствующей задачи максимизации (которую на-
зывают двойственной).
 pagebreak 
Методы линейной аппроксимации 309

 

водится замена текущего вектора по Стандартной формуле
х0г+1› : хоч) .]. жж… (6 5 6)

где Ъ> 0, а п элементов вектор- -столбца А“?) задают направление
оптимизационного поиска по алгоритму обобщенного приведенного
градиента. При этом компоненты А„ соответствующие независи-
мым (небазисным) переменным, определяются способом. который
отличается от способа определения Аі для зависимых (базисных)
переменных. Начнем с обсуждения способа определения состав-
ляющих А„ соответствующих независимым переменным.

Индекс К, обозначающий подмножество независимых перемен-
ных, ниже всюду (за исключением случаев, когда окажется необ-
ходимым различать х, и хк) будет опускаться. Направления опти-
мизационного поиска А,— (] =т+ 1, ..., п), соответствующие
независимым переменным, определятся через значения состяз-
ляющих приведенного градиента следующим образом:

если ::(-”= 11,- и гш>0,
№ = 0 ’
] если х,- =Ь- и г, ’,<0

А5Ю= —г$ , если Ь,<х‘‹"’<и„

где г„ согласно приведенному выше определению [см. соотношения
(6.5.БВ)]‚ представляют собой составляющие приведенного гради-
ента (т. е. 2=аі(х)/‹іхк). Так, например‚т на графике, принеден-

ном на фиг. 6…‚52 в точке х °=[1——— 1]Т имеем АЁ°)=— 25°’=

= ——(‹іі><(х)/‹іх1) = —-6; следовательно, х… = 1 — 67ь а вточке х‘°` =

=[›——— 2Г имеем —г$° =9 и хЁ"=1—|—9?ь

Если ограничения линейны, то в силу (6.5.6) метод обобщенного
приведенного градиента совпадает с методом приведенного гради-
ента, предложенным Вольфом В соответствии с данным алгорит-
мом составляющие А“" при этом также обращаются в нуль когда
значение х, становится очень близким либо к нижнему предельному
значению [_,-‚ либо к верхнему предельному значению [],-; при этом
прилагательное «близкий» понимается в том смысле, что разница

между х, и Ь, (или О,) не превосходит некоторое произвольное
малое число в.

Ниже рассматриваются два других варианта. алгоритма обоб-
щенного приведенного градиента, с помощью которых можно выби-
::
рать АР для независимых переменных.

1. Симплекс—модификдция метода обобщенного приведенного градиен—
та. Пусть

2$"’|=тах|г‚('"[
 pagebreak 
310 Глава 6

 

по значениям }, для которых Ь; < ХЗ“) < и‚. Положим

А<’°’={ 0, если іфд
' —-2‹›’” если ‚'=1.

! 7
Если целевая функция и ограничения линейны, симплекс—модифи-
кация метода обобщенного приведенного градиента эквивалентна
симплексному методу линейного программирования. Симплекс-
модификация метода обобщенного приведенного градиента облада-
еттем достоинством, чтос ее помощью удается сократить количество
вычислительных операций, необходимш для определения на-
правлений оптимизационного поиска А“”, причем последние ока-
зываются независимыми от того, в каких единиЦах измеряются
составляющие вектора х.

2. Циклический вариант метала обобщенного приведенного гра-
циента. В рамках данного варианта составляющую вектора АФ
определяются по следующей схеме:

Номер | Ааа)
итерации ]

 

 

ит‹ д.

 

После выполнения п такого рода операций вычислительный цикл
повторяется. Рассматриваемая модификация метода обобщенного
приведенного градиента также «индифферентна» по отношению к
выбору единиц измерения составляющих вектора х.

Наконец, направления оптИМИзаЦИонного поиска для незави-
симых переменных можно (при желании) вводить в блок-схему алю
ритма обобщенного приведенного градиента и другими способами,
отличающимися от только что рассмотренных, например с помошью
метода сопряженных градиентов (см. подразд. 33.2), Вычислительные
эксперименты показывают, что, прежде чем говорить о преимуще-
ствах методов определения оптимизационных направлений, не сов-
падающих с симплекс-модификацией и Циклическим вариантом ме-
тода обобщенного приведенного градиента, необходимо вначале
накопить определенный опыт логического и экспериментального
характера.

Перейдем теперь к рассмотрению вопроса о выборе направлений
оптимизационного поиска для зависимых переменных, При этом
направляющий вектор Ах, для определения составляющих вектора
 pagebreak 
Методы линейной аппроксимации зп

 

х, входящих в подмножество х;, выбирается иначе, чем для неза-
висимых составляющих этого вектора, входящих в подмножество
хк. Мы знаем, что если ограничения линейны, то их можно разре-
шить относительно базисных (зависимых) переменных, выразив
последние в явном виде через независимые (небазисные) перемен-
ные. В случае же нелинейных ограничений сделать это не всегда
удается. Поэтому при наличии нелинейных ограничений вектор
направления оптимизационного поиска для подмножества х, опре-

деляется по существу с помощью линеаризации ограничений по
схеме, заданной соотношением (6.5.3а) или (6.5.36):

[… = _— (%)“ №№

ИЛИ В разностном виде

—1
(Ь) __ дих“”) дп №) „:
Ах, __( дх, _Щ— аще. (6.5.7)
Так, например, обращаясь к иллюстрации, приведенной на
фиг. 6.5.2, мы видим, что по отношению к точке х<°> перемещение

АЁЩ =— 6, и, следовательно, АЁ” =— (1) (2) (_— 6) = 12.

6.5.8. МЕТОД ОПТИМИЗАЦИОННОГО ПОИСКА
В ЗАДАННОМ НАПРАВЛЕНИИ С ЦЕЛЬЮ НАХОЖДЕНИЯ
ДОПУСТИМОИ ТОЧКИ

Опишем сначала процедуру завершения поиска длины шага,
уменьшающего Дх), с использованием как зависимых, так и не-
завухсимых переменных, а затем поясним, каким образом удае'гся
подобрать значения зависимых переменных так, чтобы текущее
значение [(х) получило дополнительную минимизирующую по-
правку при сохранении вектора х внутри или на границе допусти-
мой области. Прежде всего определим, какими должны быть зна.

чения №) в соотношении (6.5.6). Как обычно, значение целевой
функции в точке (х… + ?А…) минимизируется при помощи пара—
метра ?» на іг-м шаге (т. е. ?»”), значение которого определяется в
процессе одномерного дихотомического поиска. Значения 73,” ле-
жат в интервале, определяемом неравенствами 0 < %(,” < А,… где

 

 

Ът : тіп ”“]: же}: (6.5.8)
и для і = 1, ..., п имеют место соотношения
. . ‚‘”—1$ ‚ 0—10”
?»1 : шт {пил {.;—№1. А, <О} , т1п{—’Ь’(_—Юі— Аі >0}} ‚
№ } {71…00} Ааа]
7“: _ {тэх 7Т, (‚(@) Ат," А… и: " Аш]? '
 pagebreak 
312 Г лава 6

 

где №" — наибольшее из возможных значений А, для которого
переход в допустимую точку реализуется при улучшении значения
целевой функции { (х) без изменения подмножества базисных пере-
менных х„ которые использовались на р предыдущих итерациях.
Индекс Ре означает порядковый номер текущего шага, а индекс і —
порядковый номер итерации, связанной с ЖЗ. Величина 7»: выбирает-
ся с учетом данных, полученных на іе-м шаге. После выбора 2, путем
минимизации {(А) может обнаружиться, что разность

і—(х‘*+"› их“")

ОКЗЖЗКЯ меньше некоторого заранее ЗЭДВННОГО критического ЗНЭ-
чения. В ЭТОМ случае значение ›» МОЖНО постепенно увеличивать,
скажем ВДВОе, ДО тех пор, пока не будет ВЫПОЛНЯТЬСЯ условие

і ‹х‘”+ 1» — ! (№

их“”)
Таким путем от неудовлетворительного (слишком малого) выбора
Ж.… осуществляется переход К более оптимальным значениям ЭТОГО
параметра; однако при ЭТОМ возникают дополнительные трудности.

Абади и Гигоу проанализировали ряд других факторов, влияющих
на выбор Ъ. Оказалось, что в любом случае в каждом из направ—

лений А)) реализуется перемещение с шагом длиной Ж‘Ё’А‘ю, за
исключением тех ситуаций, когда для той или иной независимой
переменной граничное условие, Задаваемое предельным значением
Ь,- (или и,), не выполняется; в таких случаях граничным значением
соответствующей переменной становится ее значение на (іг + 1)- -м

& 1

шаге, т. е. х}+’.
Если Ж определяется дИхотомическим поиском, то, подставляя
найденное значение этого параметра в (6.5.6) и учитывая (6.5.7),

мы обнаруживаем, что некоторые из составляющих ху" оказыва-
ются недопустимыми (обозначим их через х, “”), причем такая си-
туация при нелинейных ограничениях вполне объяснима. В таких

случаях для нахождения допустимого вектора х‘і'н преобразуются
лишь базисные (зависимые) переменные Предположим, что в точке

(х‘кьи, ЮМ“) выполняется усіювие ЩхУЁ”, хт+п)э&0. Если огра-
ничения линеаризуются путем замены нелинейных функций усе—

ченным рядом Тейлора, можно определить Такой вектор х“‘+", для
коггорогоЬ(х$<ь+", х}"+")обращается в нуль, т. е.

,? —] 1 „11 1
Ь(Х;‹+|)‚ ХЬН ))=Ь(ХБЁ+)‚ Х; +))+

дЬ (х$‹+1);;’?+1))
дх]

>В.

+ (‚(Би-1) _ хУ‘ …) = 0
 pagebreak 
Методы линейной аппроксимпццц 313

 

откуда следует, что

х‘‚*+‘> _ ;?” = — (%)" 11(х5’ё+”, 25%"). (6.5.9)

С соотношением (6.5.9) связывают понятие «итерация методом Нью-
тона…. Построенный с помощью этого метода итерационный про-
цесс продолжается до тех пор, пока не будет получен один из при-
веденных ниже результатов.

Заметим, что если точка “%+", &'…) является допустимой в
пределах заданного интервала, как это показано, например, на фиг.

6,53 а, „;&—Н) превращается в ХЭМ”. (1) Если )*(ХУЁ'Н’, х(‚/2+”)<
<}(х52’, ХЗ”), где индекс і обозначает последний из допустимых те-

кущих векторов, то итерационный процесс по методу Ньютона за—
канчивается и оптимизационный поиск продолжают, беря в качестве

” ;:
отправного соотношение (6.5.6). (2) Если точка ХГ… является внут-

ренней или граничной и тем не менее”) ПхЁ'Н’, хБЁ+“)>і(х}?‚
х‘і’) или если итераЦИОнный процесс с помошью (6.5.9) не обеспечивает
сходимость за онределенное (фиксированное) число шагов (итера-
ций), то производится уменьшение (в некоторой заданной пропор—
ции, например вдвое или в десять раз) значения ?» и повторяется
итерация по схеме, вытекающей из соотношения (6.5.9). (3) Если
первые две из описанных выше ситуаций не реализуются и послед-
няя из найденных с помощью (6.5.9) точек не является ни внутрен-
ней, ни граничной, то вносятся надлежащие изменения в базис.

Отрезок прямой, соединяющий точку ‚((№ с точкой, полученной из
(6.5.9), пересекает поверхность параллелотропа. заданного входя—
щими в задачу (6.5.1) векторами Ь и и, в точке, Где одна из перемен-
ных (обозначим ее через х,) подмножества х, принимает либо свое
верхнее предельное значение П„ либо свое нижнее предельное
значение Ь„ Рассмотрим фиг. 6.5.3, 6; здесь в роли такой перемен-
ной х, выступает хз. Переменная х„ принимаЮщая свое граничное
значение, исключается из базиса и заменяется переменной ›‹8 из
подмножества хк. После этого применительно к новому набору
независимых переменных выполняется итерация по Ньютону.
Правила выбора переменной‚ заменяющей исключаемую из ба-
зиса переменную х„ могут быть различными. Значение переменной,
вводимой в базисный набор переменных, не должно Совпадать ‹:

” Если базис содержит ослабляющие переменные, появляющиеся иэ-за иа-
личия ограничений в виде неравенств, то вместо (65.9) используется более эффек-
тивное рекуррентное соотношение. описание структуры которого можно найти в
соотвектвующих публикациях (см цитируемую литературу).

2) При этом осуществляются также некторые дополнительные контрольно-
вычислительные тесты.
 pagebreak 
/1 (.2')=0

 
 
      
  
  

(“;.—'), ‘!!!ір 1),

    
  

4!
(“к“”); 1215”),

 

» (» 10…)
.::,“ЁЖ 42 :
‚щиту ге
""`:
:! т т
‚ 41 д,
Шлепостьиаттельнля "д'; Допустиудипя точки;,
:! [:(ас)=0 : точке :::… лри ловок давати:
ледгмвллои ага
гг, ‚1 ‚я,
а 6

Ф и г. 6.5.3. Оптимизационный поиск методом обобщенного прпаеденного граДИента и преобразование зависимых переменных.

Здесь хз —— зависимая переменная` а ;и и ‚т. — независимые переменные. Имеет место нелинейное ограничениеввншз рввенстнаід (х) —0.
и ниже требуется, чтобы выполнялись услцвия 0 $ ”і ‹ 100 (; = 1. 2. 3). На фиг. :! покяздно положение новой допустимой тачки. Нв фиг. &

представлена схема изиеиения базиса путем исключения из него х, и введения в базис переменной х..
 pagebreak 
Методы линейной аппроксимации 325

 

соответствующим граничным значением (Ь$ или (15). причем пред-
почтение отдается такой ситуации, когда это несовпадение оказы—
вается значительным,

Пусть

К’ —— совокупность индексов переменных из множества К, ко-
торые могут быть введены в базис в ходе итерационного процесса;

82, — г-я строка матрицы (дЬ/дх‚)—'‚ где г —- индекс переменной,
подлежащей иокточению из базиса;
дЬ/дхд—‚ё-й столбец Матрицы (дЬ/дх);
дл: = шіп {(хд _ Ь»), (“к " кд};
У, =(:ё"+2’——х$›ю) при допустимых хЁН'Ш и х}"’;
в —- произвольное малое число.
Тогда, если через 8 обозначить индекс переменной, подлежащей
включению в базис, то значение этого индекса определяется ИЗ
следующих критериев:
Критерий ]:
611 дн
|Е}, Й @, = [133% 6—х;
Если (65.10) не позвттяет определить переменную х„ например,
по той причине, что 99, (дЬ/дхэ) |< &, то для этой цели исполь-
зуется критерий, формулировка которого приводится ниже.
Критерий 2:
3) Если х, =Ь, (т. е. если х, принимает свое нижнее предель-
ное значение), то

9,

 

дп
9)“ Щ‚адч

 

|>е} . (6.5.10)

дн
52, д—хз—тах{

9!

 

дн дн }
Й' 9,ЩУ„>0 . (6.5.1153)
6) Если х, = 0, (т. 6. если х, принимает свое верхнее предель-
ное значение), то
ди ди ди }
9, ”д; _ тах{'9‚ Ё | @, ЖД <о . (6.5.116)
Если При выполнеНИИ ньютоновской итерации для определения х,
получается 71 =0, то используются некоторые другие критерии
поиска; подробное описание этих критериев можно найти у Абади и
Гигоу. Схема итераций по Ньютону может быть улучшена, если при
переходе от одного вычислительного этапа к другому не допускать
слишком больших приращений для элементов базисной матрицы.
Например, можно рассматривать отношение Ах] к норме Ак и в слу-

чаях, когда это отношение превышает некоторое заранее установ-
ленное критическое значение, исключать переменную х,- из базиса,
заменяя ее другой переменной по указанному выше правилу. В осо-
бых ситуациях, когда на первых итерациях все базисные пере—
менные являются ослабляющими, при реализации итерационной
 pagebreak 
316 Глава 6

 

процедуры по Ньютону находят практическое применение нект
рые специальные правила, позволяющпе избегать слишком боль-
ших изменений в Группе базисных переменных.

6.5.4, КРИТЕРИИ ЗАВЕРШЕНИЯ ВЫЧИСЛИТЕЛЬНОГО
ПРОЦЕССА

В экстремальной точке составляющие вектора А обращаются в
нуль. Первый тест, состоящий в исследовании на сходимость,
заключается в том, чтобы проверить, выполняется ли условие

1 .
{А}"’]<в|А}’|‚ =т + 1, .. ., 11, где в — некоторое малое число.
Второй тест состоит в проверке выполнения условия Г< Г…ах,
где

:: !? (& ь

Г: тах {М)(иі—ХРЪ Аі)(Ьі—ХЁ))Ъ
[‹ __ __
Ауди) Ауд<о

Ггпах —‹ некоторый (произвольным образом выбранный) параметр.

6.5.5. МЕТОДЫ СОКРАЩЕНИЯ ВРЕМЕНИ РЕАЛИЗАЦИИ
ВЫЧИСЛИТЕЛЫ'ЮГО ПРОЦЕССА

Вместо того чтобы заново вычислять (дЬ/дщГ1 каждый раз,
когда данная матрица должна использоваться в вычислительной

процедуре, оказывается возможным аппроксимировать (дЬ/дхі)"
с помощью метода, который впервые был предложен Билем. Пред-
положим, что в точке ХФ) матрица (ді1/дх‚)'| найдена. Тогда в со-
ответствии с методикой, предложенной Абади и Гигоу, на неко-
тором последующем 1—м шаге

дых“); “'ы? дых…) “' дих“”) " дых…) дих“”)
дх, “' дх, '— дх, дх, дх, '

Данная аппроксимация еще подлежит тщательному анализу; вме-
сте с тем можно утверждать, что она Выглядит весьма многообеща-
ющей. В тех случаях, когда приближение оказывается слишком гру-
бым, с помощью специальной машинной «подпроцедуры» удается
заново вычислить элементы матрицы, обратной по отношению к
базисной. Абади и Гигоу предлагают для определения погреш-
ностей, возникающих при аппроксимации, ряд соответствующих
тестов.

Оптимизационный поиск можно также осуществлять (только
внутри допустимой области) с помощью метода наискорейшего
спуска, находя при этом ряд следующих одна за другой точек
к"”, х"‘+”, ..., х“‘+т и перемещаясь в направлении хі’Н'т —- к“”.
 pagebreak 
Методы линейной аппроксимации 317

 

Основываясь на эмпирических данных, Абади и Гигоу рекомен-
дуют принимать р =2.

Более поздние машинные (переведенные на язык кодов) вариан—
ты алгоритма обобщенного приведенного градиента, ориентиро-
ванные, правда, на решение задач слинейными ограничениями,
можно найти в специализированной библиотеке \71М ЬіЬгагУ ')
по номенклатуре Е4 ЕВР РНПМАХ и ЕА ЕВЁ РН1МАС2. Имеются
сведения о том, что метод обобщенного приведенного градиента ус-
пешно применялся Вольфом при решении задач с нелинейными це-
левыми функциями при наличии от 200 до 300 линейных ограни-
чений и при числе переменных, равном 1000 [34]. Качество работы
машинной программы, составленной в 1969 г. на основе алгорит-
ма обобщенного приведенного градиента, проанализировано в гл. 9
путем рассмотрения ряда тестовых задач.

Пример 6.5.1. Метод обобщенного приведенного градиента

Рассмотрим следующую частную задачу:
минимизировать і(х) = 4х1 —— хЁ — 12
при ограничениях
ЩЩ=%—Ё—Ё=щ
3„(х) = 10х` —х? + 10х,—— хЁ— 34 >О,
Ев (х) = "1 > 0›

84 (х) : ха > 0-
Функции [(х), 111 (х), 32(х)‚ 3800 и 5400 графически изображены
на фиг. 6.0.1.

Поскольку начальная точка х<°> =[2 47 не является допусти—
мой и так как нетривиальным компонентом задачи является огра-
ничение 32 (х) > 0, мы вводим аддитивным способом искусствен—
ную переменную ›‹а в ограничение в виле равенства и вычитаем из
левой части ограничения & (х) > 0 ослабляющую переменную хд.
Частные производные целевой функции и функций, задающих огра-
ничения, по переменным х1 и ::3 имеют следующий вид:

 

ты›=4 %ш::_2№
дх, ' х2 '
дп (х) _ дп (х) _

Тй———4№: тЁ_——4%

№ш_ №щ_
1й—Ыю—ад _Ё__ю—л@

 

" Поступили в указанную библиотеку 9 мая 1968 г.
 pagebreak 
318 Глава 6

Итак, в задаче фигурируют четыре переменные х„ хд, хз и хд и два
ограничения в виде равенств, выраженные функцияМи &, (х) и
ви (х); следовательно, две переменные будут независимыми и две —_—
зависимыми. Начнем вычисления, рассматривая в качестве неза-
впсимых переменные х1 и хг, а в качестве зависимых (или базис-
ных) — переменные хз и Х4. Приступая к поиску допустимого ре-
шения, вычтем из { (х) величину Юбка и будем считать,

что —101°<х3<0 и 0<х4<10'°. Тогда №:4, №=8

дх, дх, ’
дій) ___ __ 10:5
01:3 '
Для формирования приведенного градиента нужны матрицы

[дЬ(х‘°’)/дх;]" и [дп(х(°’)/дхк]; другими словами, необходим якобиан,
вычишенный в к"” по кажлрму из подмножеств переменных:

 

дл! №) дн; („(Ш)

диод…) дхз дх; _ ‘ 0
дк: _ дам“”) девок“) _ 0 —1 '
дхз дхд

Из (6.5.4) для приведенного градиента получаем

дих“”) _ дих“”) дг‹х‘°°› _
т—[д—д—бгг 44 “81“

106 о1 0—1—4 _в_ 999 …
'[— 10=1 ‹; 2—[“`3'96'°—
—в‚ооооз . 10°].

Далее вычисляется норма приведенного градиента с тем, чтобы
проверить, не оказыва‘ется ли она ниже числового значения кри-
терия‚ определяющего условия завершения вычислительного цикла
при данной текущей точке и с учетом граничных значений перемен-
ных; выясняется, что норма градиента равняется 8,944 - 105, что
превышает значение упомянутого выше критерия.

После этого находятся Направления оптимизационного поиска
для независимых переменных; для этого определяются

(0)
№ = _- Ш = = 3,99996 . 105

дх,

(°)
А3” = _— ———д"" ’ = _ 8,00008 . 105.

По завершении этой вычислительной процедуры ищутся направ-
ления поиска для зависИМых переменных; используя (6.5.7), по-
 pagebreak 
Методы линейной аппроксимации 319

 

«» дих““) “ ди‹х<'”› «» _
А ”[Т] "№ А……

1 0 —4 ——8 —— 3,99996. 10’5 8,000 . 10“
=“ 0 __1 6 2 —8,00008›105 _“ 4,000-106'
Определив направления поиска, найдем ?», минимизирующее [(х)
[см. (6.5.6)1:

Этап поиски

 

 

 

Переменные
и целеввя ;(") '
функция 1 ' 2 ' последний

Х! 2 2,250 2, | 25 2,250
х? 4 4,500 4,250 4,500
ха _в —2,з42- кг" _2500 0
х. 6 . 8,500 7,250 8,500

] (х) м5- 105 —23‚250 24,997— 10? ——-2З‚250

Окончательное значение Ъ равняется 6,250 . 10`7.

Теперь используем последовательно (6.5.9). стремясь подобрать
значения зависимых переменных таким образом, чтобы вектор х
стал допустимым:

‚тса 0 1 0 ——0‚3125]_[0‚3125]
д, = 8,500 ’ о ——1 —о‚з125 ' 8,1875 '
Поскольку вектор хм=[2‚250 4,500 0,31% 8,18717 не был допу-
стимым, осуществляется поиск нового значения ж; в результате

выполнения пяти итераций методом Ньютона находим допусти-
мую точку:

 

х"’=[1‚568 4,748 0 4,1611’.

При этом и Х! и х, продолжают оставаться независимыми перемен-
ными, а ›‹а обращается в нуль.

Теперь переходим к вычислению составлящих нового реду-
цированного градиента и, следовательно, опять приступаем к вы-
полнению описанной выше процедуры. Последовательность значе-
ний составляющих вектора х указана на фиг. П.6.5.|. Приведенный
градиент вычисляется при этом еще только раз, а все остальные вы-
числительные операции проводятся с целью нахождения допусти-
мого вектора и определения момента завершения вычислительного
цикла. В общей сложности значения функций, задающих ограниче-
ния, вычислялись 103 раза, целевая функция 110 раз, & градиент
 pagebreak 
320 Глава 6

 

":
‚я“
5
№3“…
4
О
, * (д‘
5 а
‚

   

дтп): 1017529 Юл,- хё— 511 > а
, іі(17=25-.г‚'— „:= и

0
а 1 2 5 4 5 :,
Ф и г. П.6.5.1› Траектория поиска методом обобщенного приведенного
градиента

целевой функции 27 раз. При этом замена базисных переменных осу-
ществлялась дважды (фактически это сводилось к перенумерации
переменных).

 

ЗАДАЧИ 1)

6.1. Выполни’ге ЛИНеаризацию фигурирующих в задачах 6.17,
6.22, 6428 и 6.29 целевых функиий и ограничений в окредтности вы-
бранной точки. Для одномерных и двумерных задач изобразите
графически исходные целевые функции и их линейные аппроксимации.

6.2. Можете ли вы линеаризовать целевую функцию задачи 6.20?

6.3. Проверьте, выполняются ли для задач 6.17, 6.18, 6.20,
6.23, 6.28 и 6.29 условия, гарантирующие сходимость к оптимальному
решению (см. стр. 242—243).

6.4. Выполните два этапа алгоритма Гриффицэ и Стюарта для
задачи, приведенной в примере 6.2.1 (используя вычислительную
процедуру, приведенную в связи ‹: рассмотрением примера 6.1.1).
Для получения допустимого вектора х либо воспользуйтесь

" Ряд задач, имеющих отношение к содержанию данной главы, можно найти
также в конце гл. 7 и в приложении А.
 pagebreak 
Мг тоды линейной аппроксимации 32|

 

машинной программой для алгоритма Линейного программирования,
либо выполните все вычисления вручную.

6.5. Повторите задачу 6.4 применительно к условиям задачи
6.25.

6.6. Составьте машинную программу, реализующую алгоритм
ПОП Н. Решите задачу, приведенную в примере 6.2.1. Ответьте на
следующие вопросы:

а) Значения каких параметров необходимо задать (из рекомен—
дуемого набора), чтобы получить искомое решение?

6) Каким образом сравниваются значения производных, получен—
ные численным методом, с соответствующими значениями этих
производных, найденными в аналптическом виде?

в) Какие трудности возникают при решении рассматриваемой
вами задачи и как они выглядят по сравнению с трудностями, опи-
санными в разд. 6.1.3?

г) Какие усовершенствования алгоритма могли бы вы предло—
жить?

6.7. Составьте матрицу приращений, структура которой приве-
дена на фиг. 6.1.3, необходимую при использовании алгоритма ПОП,
для задачи, приведенной в примере 6.1.1 (за исключением сюлб-
цов с порядковым номером ] > п + 1 и строк с порядковым номе—
ром ! > п + т + 2). Положите 6, = 0,001. Вычислите также
погрешности за счет линеаризации. '

6.8. Найдите проекцию градиента целевой функции

{(х) = 5х1 — 3:52 + 6:53

на (‚\11 —х2)-плоскость (данная плоскость соответствует ограниче-
нию хз = О). Изобразите графически 7} (х) и найденную вами проек—
цию градиента на (х1 ——х$)-плоскость.

6.9. Повторите задачу 6.8, взяв в качестве целевой функции

і(х) = 2х? + хё + 2х5.

При этом вычислите градиент этой функции в точке (1, —1‚1) и
спроектируйте его на (;:1 —х2)-плоскость.

6.10. Предложите процедуру Минимизации, основанную на
Методе проекции градиента, с тем чтобы найти минимум функции

{(х) = х? + хЁ + хЁ — 2х1):а
при ограничении
Ь1(х) = 2х1 +х2—4 = О
И
Н$(х) = 5х1—х3—8 : 0.

Реализуйте практически три этапа предложенной вами процедуры.
На каждом этапе укажите составляющие градиента целевой функции,
структуру проектирующей матрицы, составляющие вектора неза-
висимых переменных и значение і(х).
 pagebreak 
322 Глава 6

 

6.11. Определите проекцию градиента в точке х = [1 Пт для
следующей задачи:

минимизировать {(х) = 5х? — 3х3

при ограничениях
х, > 0,

х, > 0.
6.12. Определите проекции градиента целевой функции
Нк) : х? + хЁ + 1% —— 2х1):а -— 2х1х3 — 2х2):з

на ограничения
И1(х)= 2хд+х„—6 =0,

32(х)=х1—х3—8>0
ИЗ ТОЧКИ
х=п 1 пт.

6.13. Должни ли проектирующая матрица быть обязательно по-
ложительно определенной?

6.14. Покажите, что соотношение (6.3.11) справедливо и для 0606—
щенной проектирующей матрицы.

6.15. Докажите, что при исключении ограничения в виде нера-
венства из группы активных ограничений правомерно использо-
вать соотношение (6.3.14).

6.16. Подготовьте машинную программу, реализующую алго-
ритм, предложенный Дэвисом (см. подразд. 6.3.3).'Вначале составь-
те вариант программы, пригодный для решения задач с линейными
ограниченнуіми, а затем видоизмените подготовленную вами про-
грамму применительно к условиям нелинейных ограничений. Каким
образом вы считаете возможным эффективно учитывать в ходе вы-
числений ограничения в виде равенств?

6.17. Рассмотрите следующую задачу (вытекающую из мате-
матической модели фунщионирования сушильного аппарата):

минимизировать {(х) = 0,0064х11ехр (- 0,184х?‘3х‚ — 1)]
при ограничениях

31(х) = 1,2 . 1018 _ (3000 + х1)х%’х‚>0‚
& (х) = 4,1 _ ехр (0,184х'3'3х2) > 0,

где хд— скорость газа, а х2— глубина ванны. Начиная поиск из точки
х = [31000 0,34517, покажите, что локильный оптимум соответ-
 pagebreak 
Методы линейной аппроксимации 323

 

ствуетточке х* = [31800 0,3421Т. Насколько строго в этой точке
удовлетворяются условия, представленные указанными выше огра-
ничениями? Является ли локальный минимум истинным минимумом?
Является ли локальный минимум глобальным миним№0м?;(См. гл. 2.)
Можно ли прийти в ту же точку х*, выбрав в качестве отправной

точку х…) = [О 01Т? Точку х"” = [1 НТ?
6.18. Суммарные затраты, связанные с сооружением ректифи-
кационной колонны, можно записать в виде

С=С0А№+05НА№+С1+Са+Сь+Сі+сх, (3)

где С — суммарНЫе затраты, долл;

С„ _— стоимость одною квадратного метра горизонтального
перекрытия монолитными плитами, долл/футд;

А _- площадь поперечного сечения колонны, фут“;

№ — число монолитных плит (равняется числу горизонтальных
перекрытий), М…П—минимальное число горизонталь-
ных перекрытий (монолитншх плит);

С‚ _ удельные затраты, связанные с сооружением фермы,
долл/футз;

Н — расстояние между горизонтальными перекрьггиями (меж—
ду монолитными плитами), фут;

С, —стоимость (плюс затраты на монтаж) подающею насоса
(насоса накачки), долл;

Са —-стоимость (плюс затраты на монтаж) систеМЫ насосов,
обеспечивающих ректификационный процесс, долл;

С„ — стоимость (плюс затраты на монтаж) насоса откачки низ-
ких фракций, долл;

С, — стоимость (плюс затраты на монтаж) насоса, обеспечи-
вающего повторную перегонку промежуточных фракций,
долл;

С,с — другие фиксированные затраты, долл.

Задача заключается в минимизации суммарных затрат при за-
даннъхх спецификщионных характеристиках выходного продукта
и пропускной способности ректификационной колонны, а также при
фиксированных стоимостных характеристиках, относящихся к
функционированию всех видов Насосных установок (т. е. С„ С„
С, и С„ фиксированы). После подбора строительного материаЛа
Становятся фиксированными Ср, С5 и С‚.

Переменные, описывающие технологический процесс, связаны
двумя (установленными эмпирически) соотношениями:

% = [1 — Ф;…іп/МГ (%)… ' (6)

А = И ‹Ь + 0)“. (в)
 pagebreak 
324 Глава 6

   

Дистиллат

детшшж

Для простоты положим ос = 6 = 1; тогда
!. _ 1 __Ь_ ,
Т _ [1—‹№……/№›М 0 >… ' (6)
А = К(Ь + 13). (в’)

Некоторые Из типовых ректификационных колонн характеризуіш‘ся
следующими значениями указанных выше параметров:

С„ = 30, С„ = 8000,

С, = 10, ?= 1500,

Н = 2, В = 1000,

С; = 4000, №…… = 5,

[,
С,; = 3000, '5' = 1,
_ _ 1 ч- фут'

С„ — 2000, _ т № .

Затраты на перекачку, обеспечИВающую повторную перегонку, Вы-
ражаются формулой

сд = 5000 + 0,71… (г)

а) Опредемште подходящее решение для этого процесса, т. е.
значения независимых переменных. Какие из переменных являются
зависимыми?

6) Определите минимальные суммарные затраты и найдите соот-
ветствующие им числовые значения переменных.

6.19. Майлендер [351 показал, что сформулированную Бокоом
[361 задачу, заключающуюся в минимизации

, (Х) : до + “мх: + (1%; а0іх1>х1
 pagebreak 
Методы линейной аппроксимиции 825

при ограничениях

5
0 < (151361 -|- (2 01,49) 16; < дд, і= 1, 2, 3,
і=2

х, >О, 1,2 < „ < 2,4, 20,0 < ха < 60, 9.0 < ;, < 9,3,
6,5 < хь < 7,0,

можно преобразовать в задачу линейном) пёстраммирования с по-
мощью подстановок у, = х1хі ($ = 2, 3, 4, ) и И = х,. При этом
получается следующая задача линейного программирования:

5
минимизировать ; (у) =% + Вашу,
1=1

при ограничениях
5

0<21Щіуі<ьь 3:1: 2, 3,
‚=

у,— >0, і= 1.5,
ув— 1,2 у1>0‚ 2,4у1—уъ>0.
уз — 20‚0ук >О, 60,051. _а >О.
у. — 9,0% > 0, 9.3% — у. > 0,
1/5 — 6.5511 >О, 7,0у1—уь >0‹
Используя меюд нелинейного программирования (НЛП) для
исходной задачи, подтвердите оптимальность решения, полученно-

м с помощью линейного программирования, а именно убедитесь,
чю

,; = 5 280 344,9,
91 = 4,53743, „ = 10,88983, уд = 272,24584,

у, = 42,19811, % = 31,76202‚

Т, е. если вернуться К ИСХОДНЫМ ПерЕМЕННЫМ, ТО будем ИМЕТЬ
‚‹ = _ 5 280 344,9,

151 = 4,53743, х2 = 2,40000, х:! = 60,00000,
х, = 9,30000, хь = 7,00000.

Интересно отметить, что исходная нелинейная задача не являет-
ся выпуклой: допустимая область невыпукла, целевая функция
также не является выпуклой. Тем не менее полученная в результате
указанной выше замены переменных линейная задача (эквивалент-
ная исходной) оказывается выпуклой.
 pagebreak 
326 Г лава 6

Ниже указаны значения фигурирующих в задаче постоянных
коэффициентов:

„… = _ в 720 288,795, а23 = 129492

аш = = 150 512,524, аи = 10 236,8839,

„„ = _ 156,695, а„ = 13 176,7859,

а… = _ 476 470,319, а31 = = 326 669,5059,
„„ = _ 729 482,825, „„ = 7390,6840,

ац = = 145 421,4004, ‹:33 = — 27, 8987,

а… = 2931,1506, а„ = 16 5430759,
и„ = _ 40,4279, а„ = 30 988,1459,
а" = 5 106,1920, 5, = _ 24 345,0,
а„= 15 711,3600, ь, = 2940000
„„ = = 155 01 1,1055, 5, = 294000‚0,
% = 4 360,5834, 5, = 277 200,0.

6.20. Найдите минимальное значение интеграла

|
дх) = 05 №

при ограничении
1

“1 + (%)?” ах = 4.

0

6.21. Определите максимальное и минимальное расстояния от
начала координат кривой:

52;" + 6% + 51% = 8.
6.22. Найдите максимальное значение функции
?(х) = 20,21 -— 46,383:1 + 59,4%2 + 16,30х1хд +

+ 8,34% + 4,21%

на ограничивающей окружности ‹: радиусом, равным 3. Какова
структура вектора х?

6.23. Фирма, выпускающая химическую продукцию, продает
три вида продукции. Эюй фирмой установлено, что функция дохо-
да имеет вид Г = 10х + 4,41;2 + 22, где х, у и : представляют собой
месячные нормы выработки продукции первого, второго и третьею
вида соответственно. На основе анализа графиков распределения
уровней спроса на выпускаемую продуКЦию фирмой выявлены сле-
дующие предельные условия норм выработки упомянутых выше видов
 pagebreak 
Методы лингйной аппрдкшмации 327

 

продукции:
х > 2,
\
Т 22 + у2 > 3.
Кроме того, фирма должна иметь в виду, что объемы имеющихся
в наличии сырьевых материалов ограничены; это приводит к сле—

ДУЮЩИМ ограничениям, которые должны учитываться ПРИ СОСТЗВ-
ЛЕНИН ПРОИЗВОДСТВеННОГО графика:

х+4у+Бг<З2,
х+3у+2г<29.

Составьте наиболее рациональный для данной фирмы производ-
ственный график и определите максимальное значение функции СУМ-
марного дохода фирмы.

6 24. Минимизируйте половину квадрата расстояния от точки х— —

=[2 3 —11Т до тетраэдра, заданного соотношениями
ш=—х1——х2—х3+3>0
х„ 1:2, хз} 0.

Примечание. ЦеЛевая функция имеет вид

…) =%[‹х—2)* + @ —з›*+ ‹г+ №1.

6.25. При определении условий химического равновесия стал-
киваются со следующей задачей:

 

минимизировать Г (х) = дхі и), + іпР _|— м

 

‚!
2 т
іх!
при ограничениях
х1+222+2168+х5+х1п= 2,
х4+2хь+хв+х7 : 1,
хз+х1+хв+2хв+ххо= 1-
Пусть Р = 750, а ш,. имеет следующие значения:
! ' ш! „ ! “’!
\ ——10‚021 6 —18‚918
2 —21,096 7 —-28,032
3 ——37,986 8 —14,640
4 — 9,846 9 —30‚594
5 —28, 653 10 —26‚\ 1 1

Определите х* и {(х’“).
 pagebreak 
328 Глава 6

 

6,26. Система, состоящая из трех последовательно соединенных
теплообменников (см. схему на стр. 329), реализует обычный поэтап-
ный процесс теплообмена без повторнъхх циклов. Обозначения для
температур, характеризующих каждый из этапов теплообмена, при-
ведены на схеме (предполагается, что температуры измеряются по
шкале Фаренгейта). Процесс теплообмена осуществляется следу-
ющимпростым способом: холодная жидкость нагревается в каждом
из теплообменников горячей жидкостью, поток которой перпенди—
кулярен потоку нагреваемой жидкости. Допустим, что каждый из
теплообменников можно описать следующей стационарной макромо-
делью :

№„ (Т„ _ т,…) = и„А„ (… _ т„›.

Предположим, что скорости всех потоков одинаковы и разнятся
‘У, & также будем считать, что теплоемкость жидкости в любом узле
системы постоянна и равна Ср. Задача заключается в определении
площади поверхности теплообмена А для каждою из теплообменни-
ков, так чтобы суммарная площадь, обеспечивающая теплообмен в
системе, была минимальной. Ниже приводятся входные (исходные)
данные для фигур ирующих в приведенной модели постоянных коэф-
фициенюв:

т., = 100 °1=, и = 120 БЕТ/ч . (фут)2 . °Р,
тз = 500 °Р, и2 = 80 БЕТ/ч . (фут? . °Р,
г„ = воот, и& = 40 БЕТ/ч - (фут)2 . °Р.
1,1 = 400 °Р,
:… = 600 °Р,

№„ = 10° ввтгг.

(Примечание. Данная задача нередко решается с помощью динами-
ческого программирования)
6.27. Минимизируйте

__ 2 1 3
„’Ч— х1+0‚5 + х,+.0‚2 + „34-05

при ограничениях
4х1 + 7:62 + 3х3 < 10,

3х1 + 4х1 + 5х3 < 8,
хь ха, хв>0.

6.28. Определит глобальный минимум и глобальный максимум

функции
[(х) = ::2 віп х, — 4х1
 pagebreak 
Методы линейной аппроксимации 329

 

при ограничениях
Е1(х) : хд 5іпх„ —х?— х, = 0,
82 (Х) : "1 > 0:
Ба (Х) : "2 > 0,
84 (х) = 151 < 4‚
Ев (х) = хи < 4.

(Примечание. Приведенная здесь целевая функция имеет несколько
минимумов и максимумов.)
6.29. Ощаедеіште минимум целевой функции

НХ) = х? + 1% —13х1 + 15%
при ограничении

(%+ хд)2—4(х1`—х‚)=0.
(Примечание. Данная целевая функция имеет два локальных ми-
нимума.)

{” #3!
тяжёлая” \ „ммм…,
—7Ё7 , д 73 —)›
[и 132

 

ЛИТЕРАТУРА

(ШШШ К. Е., Зіешагі К. А., Маладетгп! $011, 7, 379 (1961).

Стіазз Н., Соорег !.., .]. А$ос. Сотрш‘ег Мат., 12, 71 (1965).

1015011 Р. А., АСМ ЗЮМАР \ЯогКзЬор, ШМ вага Ргосеззіп; ВЫ., Липе 14—‹
5, 1966.

Зтіш Н. Ч., А Ргосевз Ор‘сітіиаііоп Ргоегагп іог Ыопііпеаг Зуэіетзг РОР 11,

!ВМ Степ. Рговгаш ЬіЬпгу 7090 НЭ 1ВМ 0021, 1965.

Ёшаг’с Р. В., ЗЮМАР \\!огКзіюр оп Ыопііпеаг Рговгагпшіпв, УокК‘сошп Неівмз,
. У.. 1967.

“твои К. В., РЬ. В. Віззег’саііоп. Натаха Нпіш Огайцаіе $с1юоі оі Вцзі-

пезв Агітіпізігаііоп, Возіоп, 1963.

Веаіе & М. 1… Мцшегісаі Меійоёз, іп: Мопііпеаг Ргодгагптіпц, АЬасііе З.,

ед., 1піегзсіепсе РцЫ., М. У., 1967.

(ігачеэ 6. Ш., \Иъіпзіоп А. В., Ппіч. Саш. Шезіегп Мапацегпепі 5сі. 1п5і.

Рярег 108, 1.05 Апве1е5‚ Зе {. 1966.

Ргяпк М., \Уоп‘е Р‚‚ Маси Кез. Ьоеізіів апт., 3, 95 (1956).

Вагпез 6. К.. М. 5. ТЬезіз, Ппіш оі Техаз, Ацэііп. Тех.. 1967.

БЬЁЁШ С. “!„ Зіечепз “[ Р., !пф Еле. Сінгт. Рюеезз Везівп Веоеіор.‚ 4, 16

).
. РгізсЬ Ц., тие Мціііріе Метод іог Ьіпеаг Ртоуашгпіпд, Мет. Ппіч. Зосіа-
іоіюп 1п5і., 0510, Осі. 1955.

г‘.°$°9°.".°>9‘:‘*9’!°:"

‚__-‚_
ю
 pagebreak 
330 Г лава 6

 

13. 2оц’сепаіік О., Меіпоаэ оі РеазіЫе Вігесііош, Е1зечіег РцЫ. СО., Ашзіепіаш,
1960.

14. Козел ]. В., 1.800. !ті. Аррі. Май., 8, 181 (1960); 9, 514 (1961).

15. Нозеп !. В., Мы:… В. Р., Схгадіепъ Ргоіесііоп— 6Р90, $1таге Рговгагп
7090-Н2-34306Р90.

16. Мипадь В. А., Загдепі В. “1. Н., СЬар. 14 111: Орп'шіиайощ Р1еіс11ег К., ей.,
Асааетіс Ргезз, Ьопйоп, 1969.

17. НоцэеЬоШег А. $., ТЬе Т11еогу оі Мабгісез іп Ыытегіса1 Апа1узіз‚ В1аі5<1е11
РцЫ. Сом, Шаііпат, Маз„ 1964, р. 8.

18. Кі'шиі Н. Р., Кге11е “’., Ыоп1іпеаг Ргоёгагпгпіпг, В1аіэде11 Риы. СО., \УаННаш,
Маззч 1966.

19, Пеіспег К., ]. [ш. Мат. Арр1., 5, 2 (1969).

20. Сгозз К. Е., АЕС Вос. К-1746, Мау 30, 1968.

21. Вачігіоп …. С., АЕС Вос. АЫЬ-БЭЭО (геи.), 1959.

22. ОоШіагЬ В., Р11. Б. Візкгіа’сіоп, Ргіпсеіоп ит., Ргіпсеіоп, М. .1., 1966.

23. 60165311) 11, Ьарідпз Т…, !гиі. Еле. Едет. Ритіатепіаів, 7, 142 (1968).

24. Вачіез В., ТЬе Цзе оі Вачіаоп‘з Меіпоа іп Мопііпеаг Ргоегатшіпе, 1С! Ц‹1.
Кер1.М$ВН/68/110, Аше. 1968; Вос. ывэ-ззгзз {гот СР$Т1, Бргіпвііеіа,
1/8.

251 Мцгіавп В. А., Багеепі 12. “1. Н.. СЬар. 14 іп: Оріішішііоп, РіеісЬег Е., е‹1.,
Асааетіс Ргеэз, Ьопдоп, 1969.

26. Нопзепоійег А. З., Т11е ТЬеогу оі Маіп‘сез іп Ышпеп'са1 Апаіузіз, Б1аі$йе|1
РцЬ1.Со.‚ Шпинат, Мазз., 1964, р. 10.

27. Хоціепаіік О., Метоаз оі РеязіЫе Вітесііопэ, Е1зечіег РЦЫ. СО., Ашзіегёаш,
1960.

28. 20Ціетііі1< С., $!АМ .]. Сопіті, 4, 194 (1966).

29. ШоНе Р., Кесепі Вече.]ортепіэ іп ЫопНпеаг Ргодшштіпв, капа Согр. Еері.
124014912, 1962.

30. АЬаШе ]., Сагрепііег ]., 6ёпёга1і2аііоп ‹іе 1а шёН'юае дц агайіеп‘с гёаш'і сТе
“Ыіе аи саз ‹1е сопігаіпіез поп1іпёаіге5, Рюс. 1РОК$ Сет.; СЬар. 4 111: Ори-
шітііоп, Р1е1с11ег к., её., Асадетіс Ргезз, Ьопаоп, 1969.

31. Рапге Р., Ниага Р., Кач. Ргапс ЕесЬегсЬе ОрегаііопчНе, 9, 167 (1965).

32. АЬааіе ]., Сшідоц ]., Огаёіепъ гёдиіі дёпёгаіізе’, Е1ес1гісі’сё ‹1е Ргапсе Ыоіе
Ні 069/02, Аргі| 15, 1969,

33. “іоііе Р., А’аіісев Ат. Мат. Зоо., 9 (4), 308 (1962); Мейюдз 01 Моп1іпеаг
Рговгаттіпа, іп: Весепъ Аёчапсез іп МаШетаііса] Ртоегатшіпд, Ога-
Че5 & Т…, 11/0110 Р., газ., Мсбгаш-НШ, М. 80,1963, рр. 76—77.

34. КППіі Н. Р., итетептепзіогвс/шпд, 12, 1 (1968).

35. Муіапаег 1111. С., Сатриіе/ !., 8, 391 (1965).

36. Вох М. ]., Сотриіеі ]., 8, 42 (1965).

ДОПОЛНИТЕЛЬНАЯ ЛИТЕРАТУРА

ОБЩИЕ ВОПРОСЫ

АЬааіе .1., Мцшегіса! Ехрегітепіз “ть Пте ОКС! МеПчогі, іп: 1п1ееег апё Моп1і-
певг Рюггаштпіпе, АЬааіе .! ., ей., Мот] Но11апс1 Риы. СО., Ашзіепіаш, 1970.

ВеПтоге М., ОгеепЬегд Н. 1 ., .]апп‘з .1. .1 ., 6епега112ес1 РепаНу-іппсііоп Сопсеріэ
іп МаШетаіісЫ Оріітіш’сіоп, Оретііопз Кез, 18, 193 (1970). {

Сагрепііег .1., АЬаёіе ]., бёпе’га1іза’сіоп ае 1а тёН-юёе [11.1 згааіепъ гёаиіі де ШоПе
аи саз (із сопігаіп1е5 попііпёаігеэ, Рюс. 1РОВ$ Сонди, СатЬгідев, Май.,
Аид. 29 — Зері. 2, 1966.

СЬашез А., Соорег Ш. “’., Мопііпеаг Роше: 01 Авіасепі Ехігеше Роіпі Меіпойз
іп [‚іпеаг Рювгаттіпд, Есопотеіііса, 26, 132 (1957).

Вачіез В., Зоте Ргасііса] Ме11юс15 оі Оріітіиа’сіоп: Ыоіез іог Ъ11е МАТО Эпштег
 pagebreak 
Методы линейной аппроксимации 33|

 

5с1юоі, оп 1пте5ег апа ЫопНПеаг Ргоггаттіпд, Асааегпіс Ргеэз, М. У., `Тцпе
18—20, 19691

Вачіез В., Кечіеш 01 Сппзігаіпеа Оріішіиаііоп, Сіеагіпвноцзе іог Редеги] 5сіеп1і-
ііс апа Тесппісгді [піогтаііощ Восцгпепі М 69-36898. $ер1. 30, 1968.

Веппізд. В., Маінетаіісаі Ргодгаттіп; апті Е1есігіса1 Меішогіщ МП, Сат—
Ьгіава Ма55., 1959.

Рацгё Р., Нцапі Р., Ке'зоіиііоп с\е ргоегаттеэ ша…ётаіічиеэ & іопсііоп поп1і-
пёаіге рат Ца шёыюсіе (111 нгааіепі гёдціі, Еги. Ргапс. Кгсіъегсде Орегаііопе/іе,
№ 36, 167 (1965).

пекин К., С1еагіпгъоцзе Гог Редеги] 5сіепШіс апа ТесЬпісаі 1піогта$іоп‚ Боси-
тепъ Ы 69-37016, Зері. 30, 1968.

Огіііііп Ц. Е., Зіешагі К. А., А Ыопііпеаг Рюегаттіпе ТесЬпічце іог 0р1іті2а-
ііоп ог Сопііпцоцз Ргосеззіпг Зузіешз, Мападетет‘ 8011, 7, 379 (1961).

К1еіпЬоЬш К., Еіп Уегіапгеп шг арргохітаіічеп Ъбзипд чоп Кончехеп Ргоггат-
теп, РЬ. |). аі5зегіаііоп, Нпіч. 01 2цгіс11, 1966

Ьеуііоп Е. З., Ро1уа1< В‚ Т., Сопзігаіпекі Міпітігаііоп Метнодз, ПЗЗК Сдтри-
шпона! Мат. аті Мат. РИу5., 6, 1 (1966).

Цозеп ]. В., ТЬе Скгадіепі Ргоіесііоп Метод іог ЫопНпеаг Ргоегатгпіпд, Рагі 1,

.]. Зпс. 1па‚ Аррі. Мат., 8, 181 (1960); Ран П, 9, 514 (1961); 1ВМ 5Ьаге
Ргозгат 1399.

“10119. Р‘, Ментоаз оі Мопііпеаг Ргодгашшіпа іп: ЫопПпеаг Ргодгатшіпд, АЬа-
‹ііе Л., еф, Мог… Но11апс1 РЦЫ. (101, Ашзіегааш, 1967.
Ъоціешііік &, Метоаз оі РеазіЫе Вігесііопз, Ашегісап Еіэечіег, М. У.. 1960.

СХОДИМОСТЬ АЛГОРИТМОВ

ТорКіэ 1) М„ \іеіпон А. Е., Оп Н'ле Сопчегвепсе оі Зоте РеазіЫе Вігесііоп Аще-
гіШтз іог Ыоп1іпеаг Рговгаттіпг, .]. $1АМ Сопігод, 5, 268 (1967).

2ап3ші11 Ш. 1.‚ Сопчегдепсе Ооппііпопз іот Ыопііпеаг Ртодгапп'піпе Ащогішшз,
Маладетет ЗЫ., 16, 1 (1969).

ДРУГИЕ МЕТОДЫ НЕЛИНЕЙНОГО ПРОГРАММИРОВАНИЯ
ПРИ НАЛИЧИИ ОГРАНИЧЕНИЙ, ИСПОЛЬЗУЮЩИЕ ЛИНЕАРИЗАЦИЮ

СЬепсу Е. Ш., Ооіазіеіп А. А., Мемопъ Метод іог Сопчех Ртодгагптіпд апа
ТсЬеЬусЬеН Арргохіта’сіоп, Миттал! Май… 4. 253 (1959).

Ве Цепшэ 1… У., ЫопНпеаг Рагтіоп Ргоёэаштіпд, 51ОМАР \УоШзЬор оп Моп-
Нпеаг Ргодгаттіпг, [ВМ Согрегаііоп, огкіошп НеівЩз, М. Ж, 1968.

ВіВеНа С. Ш., Зіеуепз \У. Р., Рюсезэ ОрСітіиаііоп Ъу Ыоп1іпеаг Ртоегаттіпе.
11111. Ела, спе…. Ргосезэ Веэідп Веуе1ор., 4, 16 (1965).

612155 Н., Соорег 1… Зечцепііаі ЗеагсЬ: А Метод іог 501111113 Сопзігаіпыі Орііті-
:аііоп РгоЫетз, .]. АСМ, 12, 71 (1965).

(Згауез (3. “У., ШЬіпзсоп А. В., ТЬе Арріісаііоп 01 & Моп1іпеаг Рговгаттіпе А1-
догітш [о а Зесопа Огаег Кергезепіаііоп 01 [Не РгоЫегп, Ппічг. 01 СаНіогпіа
аі Ьоз Апее1е5, Шезтегп Манагетепі Зсі. 1п51. Рарег 108, Зерг. 1966 (АВБМ 196).

НагПеу Н. О., НосКіпЕ К. К., Сопчех Рговгатшіп; Ьу Тапшъпііа] Арртохітаііоп,
Мападетепі 8011, 9, 600 (1963).

НагЫеу Н. О., ес а1., Сопуех; А Сотрціег Ргоетшп {ог 501х611; Сопуех Рюн-
ЁЭПЁ, Тесіш. Кер. № 23, Техаз А апа М Опіщ Со11е3е 51311011, Теха5, 1и1у

НіПеагу Н. К., ТЬе Тапдепі ЗеагсЬ Мепюа 01 Сопзтгаіпеа Міпішіиаііоп, Н. 5.
Ыауа1 Розгвгааца‘ге $сЬооі Теспп. Цері. Кез. Рарег 59, Магсп 1966 (АВ 632121).
 pagebreak 
332 Глава 6

 

№№ 1. Е., ТЬе Сцтпц-ріапе Метод іог Зоічіпе Сопчех Ргонтагпз, ]. Бас. !ті.
ррі. Май., 8, 703 (1960); Метод оі Огааіепіз, СЬар. 6 іп: 0 іітіиаііоп
Тесйпічиез МШ Арріісаііопз, Ьеіітапп О., ей., Асааетіс Ртез5, Ы. ., 1962.
Кйпіі 11—3051?) ё'бйе Виоріех МеШод іп Мопііпеаг Ргоггашшіпд, ]. ЗММ Сотка],
. ).

Мсбш'ге 5. “!., НосКіпв К. К., Натеу Н. 0… ЗрЬегісаі Ргоегатгпіпе: А Сопчех
Ргоегашгпіпе АіеогіШгп, ТесЬп. Кер. № 5, 1115$. оі 5Саіізііс5, Техаз А апа
М ит., Ооііеде $$аііоп, Техаз, Осі. 1968.

Міеіе А., Нпапд Н. У., Неійетап ]. С‹, Зечиепііа1 ОгайіепЪ-геэіогаііоп АіеогіШш
іог Міпішіиаііоп оі Сопэігаіпеа Рцпсііопэ— Опііпагу аті Сопіцгаіе Счга-
гііеп! Меыюаз, .і. Оріітігдііоп ТЬеогу Арм., 4, 213 (1969)

Міііз В. Н., Ехіепаіпг Метоп'з Метод [о Зузіетз оі 1печца1іііе5, Ргос. 6111 [П—
іегп4 Зушр. оп Мат. Ргошатшіпе, Ргіпсеіоп, М. Л., Ане. 1967.

Мц2е1е К. А., А Ргонгат іот 0р$іта100піго1 оі Ыоп1іпеаг Рюсеззез, !ВМ Зу-
зшпз ]., 1. 2 (1962).

РіпзКеі 1. $., ТЬе Апегпапсе МеШоа (іог Зоішіоп оі РюЫешз іп ЫопНпеаг Рю-
шатшіпе), Аиіатаііс Кетоіе Сапіуоі, 25, 280 (1964).

$Ьаппо В. Р., Ап Ассеіегаіег] Огааіепі Ргоіесііоп Метод іот Ьіпеагіу Сопзігаіпед
Мопііпеа: Езіішаііоп, 81АМ ]. Аррі. Май., 18. 322 (1970;
 pagebreak 
Глава ?

ПРОЦЕДУРЫ минимиздции при НАличии ОГРАНИЧЕНИЙ!
мвтоды штрдфных функции

В публикациях по нелинейному программированию методы
штрафных функций представлены в различных вариантах, которые,
однако, имеют одну общую черту: во всех этих методах осуществля-
ется преобразование задачи нелинейного программирования при на—
личии ограничений либо в одну (эквивалентную исходной) задачу
без ограничений, либо в эквивалентную последовательность задач
без ограничений Пусть, например, мы хотим найти минимум функ-

ЦИИ
„Х) : (351 '- 3)’ + (Х? _ 2?

при ограничении
Мк) =х1+х2—4=0.

Прибавим № (х) к целевой функции і (х), в результате чею получим
новую целевую функцию

Р 00 = (161 —- 3? + (& -— 2)2 + (361 + 152 _ 4)”:

значения которой будем считать свободными от каких—либо ограни-
чений [№ (х) здесь выступает в роли «штрафа»1. В процессе миними-
зации Р (х) «штрафная добавка) к [‘ (х) способствует тому, чтобы Век-
тор ›‹ в некоторой степени удовлетворял исходному ограничивающему
усповию(п(х)=0). Совершенно очевидно, что, пока условие }; (х) = О
удовлетворяется (в пределах установленного допуска), значение
штрафного члена пренебрежимо мало, и Р (х*) —› і(х*) при х —› х'.
Преимущество, которое мы получаем за счет перехода от задачи ми-
нимизации при наличии ограничений к задаче минимизации в от-
сутствие ограничений, состоит в том, что в последнем случае мини-
мизация может осуществляться с помощью юраздц более простых
(по сравнению с первым случаем) алгоритмов. При использовании
методов штрафных функций получается максимальный оптимизи-
РУЮЩИЙ Эффект за счет постоянного компромисса между необхо-
димостью удовлетворения ограничений и процессом минимизаЦИи
? (х), который достшается путем присвоения надлежащих весов це-
левой функции и функциям, задающим ограничения. На фиг. 7.0.1
Графически представлена преобразованная дешевая функция. по-
лученная путем добавления к Дх) штрафной функции (с весовым
коэффициентом, равным единице).
 pagebreak 
334 Глава 7

 

г, а

”@= (13—572 + (.71'2—2)2

 

Й!=1')=1', + 12—11=0

“а
5 6
5 Р(:с)= (‹2',—д‘)2+ (ш,—2)2+ (“%%-41.

 

Ф и г. 7.0.1.

и вв графическое Представленне исходной задачи: 6 — уровни штрафной функции.

Методы штрафных функций можно разделить на два класса:
1) параметрические методы и 2) непараметрические методы. Пара—
метрические методы характеризуются наличием одною или несколь—
ких надлежащим образом подобранных параметров, входящих в
структуру штрафной функции (которая строится с помощью функ-
ций—ограничений) в качестве весовых коэффициентов. К числу ти-
 pagebreak 
Методы штрафных функций 335

 

пичных параметрических методов относится метод последователь-
ной безусловной минимизации (МПБМ), предложенный Физика и
Мак-Кормиком [1 ], а также метод Зангвилла [2]. С другой стороны,
в непараметрических методах, таких, как «метод центров» Гуарда
[3] и предложенный Фиакко и Мак-Кормиком непараметрический
МПБМ [4], целевая функция рассматривается как функция, зада-
ющая дополнительное искусственное ограничение, постепенно «уп-
лотняемое» по мере получения информации в ходе решения задачи.

Параметрические методы распадаются на три категории:
1) методы внутренней точки; 2) методы внешней точки и 3) комби—
нированные методы. При использовании методов внутренней точки
уровень целевой функции удерживается в отдалении от границы
допустимой области (т. е. точка х… постоянно находится внутри до-
пустимой области) с помощью штрафной функции. Мет0ды внешней
точки (такие, как методы Зангвилла, Петрижковского [Б]) и метод
Фиакко И Мак-Кормика [6], наоборот, генерируют последователь-
ность точек, которые выходят за пределы допустимой области, но
дают в пределе допустимое решение. Штрафная функция не позво-
ляет вектору х слишком удаляться от границы допустимой области.
В комбинированных методах (использование которых особенно
необходимо в случае, когда ограничения имеют вид равенств) в
ходе минимизации одни из ограничивающих условий удовлетворяют-
ся, а другие не удовлетворяются; однако все условия в пределах
заданного допуска оказываются удовлетворенными при достижении
исходного решения. МПБМ является комбинированным методом.
Для полноты классификационной картины отметим, что в работе
[6] перечислены и кратко описаны непараметрические методы внеш-
ней точки. Хороший исторический обзор большинства методов
штрафных функций можно найти в монографии ФиаккоиМак-Кор—
мика [6].

Итак, в основу методов штрафных функций в области нелинейно-
го программирования положена идея преобразования общей не-
линейной задачи (2.2.1) — (2.2.3) в последовательность задач без
ограничений путем добавления к целевой функции одной или не-
скольких функций, задающих ограничения, с тем, чтбы ограни—
чения, как таковые, в задаче оптимизации не фигурировали. Фор-
мально преобразование задачи, представленной соотношениями
(2.2.1) _- (2.2.3), в задачу минимизации без ограничений осуще-
ствляется путем перехода от (2.2.1) —- (2.2.3) к задаче минимизации

Роб“, р"*’›=г(х"*’›+ Ё РЁ")Н(Щ(Х®))+ Ё рЁЫ6(3,(х®)). (7.0.1)
і=1 і=т+1

Будем называть РФ;“), р‘“) обобщенной присоединенной функцией'

или же просто штрафной функцией. В формуле (7.0.1) рЁ—Ы>0

)

 

” Иногда Р (к…, р…) называют расширенной функцией.— Прим. перев.
 pagebreak 
336 Глаац7

 

представляют собой весовые коэффициенты, И (п, (код)) и 6 (3,- (хш)) яв-

ляются функционалами соответствённо !д— (х‘ю) и ;, (х‘ю) [эти фух—ШЦИо-
налы выбираются с учетом ряда конкретных требований (см. ниже)],
& іг = 0, 1, есть число завершенных этапов вычислительного опти—
мизационного процесса.

Типичными требованиями, из которых исходят при выборе фух-ш-
Ционала 6(3‚-(х’г)), являются следующие:

1. 6 (вд(х))—› + оо при 35(х)—›0+‚ для чего необходимо, чтобы
точка, определяемая вектором х, всегда была внутренней, т. е. чтобы
{х]3,(х)>0(і=т+ Ъ …, р)}-

2. 62(3,(х))—›О при 3,(х)—›0“`. При таком выборе функционала
О оперируют только с внешними 'ючками: {х15,(х)<0}.

3- 63(Еі(х))>0 ПРИ 8$(Х)<0 “ 64(Еі(х)) =.0 “1… Е;(х)>0'
При таком выборе функционалаб не заботятся о том, чтобы ограни—
чивающие условия удовлетворялись на промежуточных этапах вы-
числительного процесса, хотя, естественно, требуют, ч'юбы эти ус-
ловия удовлетворялись в точке, определяющей искомое решение.

случае когда ограничения имеют вид равенств, как правило,
требуют, чтобы Н (и, (х)) —› 0 при пд (х ) —› 0. При этом обы'чно
полагают Н (;и (х)) = пё (х).

При любом (из указанных выше) выборе функпионалов НО:! (х))

и (КЕ; (х)) требуют, чтобы

пт Ё рё’г’ащхш» = 0,

11—м» і=т+1

1іт Ё рёищых‘т» = 0, (7.0.2)
!:

».» і=1
НШ ' Р (Х…, 9…) _ [ 0:02)“ : 0,
[1—ти

Другими словами, влияние входящих в Р (х…, 90”) функций-ог-_
раничений на значение данной присоединенной функции постепенно
по мере развития процесса оптимизационного поиска ослабевает, а
в пределе полнеетью исчезает, так что последовательность проме-
жуточных значений Р (Х“), №1) сходится к тому же значению, что
и соответствующая последовательность значений НХМ), и, следо-
вательно, экстремум Р (х) совпадает с экстремумом [ (х).

В данной главе будет проведено краткое обсуждение некоторых
вариантов методики штрафных функций, а затем дано несколыю
более детальное описание метода последовательной безусловной
минимртзации.
 pagebreak 
Методы штрафных функций 337

 

7.1. МЕТОДЫ ШТРАФНЫХ ФУНКЦИИ СПЕЦИАЛЬНОЙ
СТРУКТУРЫ

7.1]. ИСПОЛЬЗОВАНИЕ МНОЖИТЕЛЕИ ЛАГРАНЖА

Методы, основанные на использовании множителей Лагранжа,
относятся к категории параметрических ме'юдов штрафных функ-
ций, поскольку для них характерно то, что функции-ограничения
вводятся в структуру модифицированной целевой функции сов-
местное некоторым переменным параметром. Чтобы обобщить ме—
тод множителей Лагранжа, ограничения в виде неравенств следует
преобразовать в ограничения, имеющие видравенств, путем введения
надлежащих оспабляющих переменных (на каждое ограничение-
неравенство по одной ослабляющей переменной) Задача нелиней-
ною программирования в общей постановке [см соотношения
(2.21) — (2.2.З)] принимает при этом следующий вид:

минимизировать [(х), х Е Е",
при ограничениях

Ьі(х)=0, і=1,...‚т,
2 . (7-14)
@,(х)—ш=0, :=т+1‚
Если вычесть 0% из & (х) ([ : т -|— 1, …, р), то можно гаранти—

ровать, что ограничивающее условие, имеющее в Исходной постанов-
ке задачи вид неравенства, действительно выполняется. Тогда мож—
но определить обычным образом функцию Лагранжа

"1 #7
Р(х‚ (0) = [(х) + 23 щих) + 2 ш,.ш, (х) —и%1, (7.1.2)
г=1 і=т+1
где о), (і = 1, ‚ р) _ неотрицательные и не зависящие от х
весовые коэффициенты, которые можно отождествить с множителями
Лагранжа. Для того чтобы х" было решением общей задачи нели-
нейного программирования (2. 2. 1) — (2 2. 3), необходимо и доста-
точно [81,чтобы: ]) функция } (х*) была выпуклой. 2) в окрестности
х“ ограничения задачи были выпуклы и 3) в точке Х* удовлетворя-
лась следующая система уравнений [определяющая стационарное
решение (7.1.2)]:

 

 

дР .

дітч=0 при1=1,….‚п‚
@= 0 при і==1, р, (7.1.3)
да;?) =2шд=0 при і=т+1, ..., р,

ші>0я і=1.-...‚р.
 pagebreak 
338 Глава 7

 

Короче говоря, условный минимумі (х) имеет место в стационар-
ной 'ючке для Р (х, св, У) и, в частности, в седловой 'ючке (х, ‹0, У)-
пространства, так что задача с ограничениями превращается в за—
дачу определения седловой точки в отсутствие ограничений.

Пример 7.1.1. Использование множителей Лагранжа
Рассмотрим в качестве примера следующую задачу:

минимизировать у = №№, х Е Е",
при ограничении

 

 

 

 

31(х): 25 — ЁЁ — хЁ > 0. (а)
Надлежащая минимизации присоединенная функция имеет вид
Р (х, ш) = лаха — ш,. (25 — х? — хЁ— 0%). (б)
Необходимые условия существования экстремума:
дР
дх! = хе —— 2ш‚х1 = 0,
др
а», = х1 = 2ш1х2 = 0,
др (В)
д—щ- = 25—хЁ—хЁ—1Ё’ = 0,
(31°
до} = 20$), = 0.

Совместные решения уравнений (в) при (1), = 0 и ш1 ;& 0 приведены
в табл. П.7.1.1.
Таблица П.7.1.1

Решение задачи (а) с помощью метода множителей Лагранжа

 

 

 

 

 

 

‹» ‘ х, х, Точка в, [ (х) Примечание
0 0 О Е 5 0 Селдовия точка
+З,54 —З,54 В 0 —12,5 Минимум
05 { —з,54 { +354 А 0 42,5 Минимум
_0 5 {+ 3,54 { +354 В 0 +125 Максимум
’ —З‚54 —3,54 С 0 +125 Максимум

 

Векторы х* являются стационарными решениями задачи (а). Заме—
тим, что решения при ті > 0 являются минимумами, при ш,. < 0 —
максимумамщ а при 0), = 0 — седловой точкой задачи (а). Функ-
ции, фигурирующие в задаче (а), представлены графически на
 pagebreak 
Методы штрафных функций 339

 

Ф и Г. П›7_1.1.

фиг. П.7.1.1. Уровни целевой функции (гиперболы) изображены
пунктирными кривыми, а допустимая область заштрихована. Эта
область ограничена окружностью 31 (х) = 0. Точки А и В соответ—
ствуют двум (указанным в табл. П.7. 1.1) минимумам, точки В и С _—
двум (также указанным в табл. П.7.1.1) максимумам, & Е является
седловой точкой .целевой функпии 7 (х).

 

Метод множителей Лагранжа интенсивно изучался многими спе-
циалистами (см. список литературы, приведенный в конце главы).
Этот метод может оказаться непригодным в случае невыпуклых за-
дач, для решения которых успешно применяются другие методы
штрафных функций. Ме'юд множителей Лагранжа мало эффективен
в случае задач нелинейного программирования большой размернос-
ти, поскольку совместное решение системы уравнений, аналогич-
ной (в) в примере П.7.1.1‚ требует применения численных методов, и
соответствующие вычислительные процедуры реализовать не легче,
чем алгоритмы оптимизации. Более того, многократно повторяемые
процедуры решения упомянутых выше уравнений должны быть
 pagebreak 
340 Г лава 7

 

вылелены из общей программы. Для данного метода и соответствую-
щих вычислительных процедур было составлено несколько машин-
ных программ, но ни одна из них не оказалась достаточно эффектив-
ной при решении задачи нелинейного программирования общего
вида.

7.1.2. МЕТОД РОЗЕНБРОКА ДЛЯ РЕШЕНИЯ ЗАДАЧ
ОПТИМИЗАЦИИ ПРИ НАЛИЧИИ ОГРАНИЧЕНИЙ

Задача минимизации НХ), ›: Е Е",

при ограничениях
@,(х)>0, і= 1, ... . р, (7.1.4)

была преобразована Розенброком таким образом, Ч'Ю оказался
применимым для ее решения метод, описание которою дано в
разд. 4.3. Решение задачи (7.1.4) эквивалентно определению мини—
мума не связанной никакими ограничениями присоединенной функ-
дни

‚7
Рок“! %) =1°(Х"“)П и,.‹хш>)д,.‹х®)‚ (7-15)

[=]
где?!, = О при3д(х®)<0 и ‘Ц, =1 при ;, (х(“))>0(і= 1, . .. , р).
Таким образом, присоединенная функция, определяемая соотно-
шением (7.1.5), вне допустимой области обращается в нуль. Пред—
полагается, что в каждой точке допустимой области целевая функция
принимает отрицателшое значение, т. е. ([ (х) < 0| х Е !?}. Если бы
в некоторых или даже во всех точках х Е 12 значения ПХ) ока-
зались положительными, мы могли бы вычесть из [ (х) болЬЩое по—

стоянное число [( ‚ так что имело бы место условие [ (х) = [[ (х) _—
_К] < 0. Ясно, что характер задачи (минимизировать і(х)) при
этом остался бы прежним. При решении сформулированной выше
задачи численный оптимизационный поиск может начинаться не
толъко с внутренней точки к“”, но также и с точки, слегка выходя-
щей за пределы допустимой области. Для минимизации Р (х) ис"-
пользуется разработанная Розенброком процедура безусловной
минимизации в том виде, в каком она представлена в разд. 4.3. После-
довательность точек х…), х“), …, №). получаемая при этом, явля—
ется допустимой.

Чтобы увидеть взаимосвязь между функпией (7.1.5) и присоеди-
ненной функцией типа (7.0.1), требуется лишь прологарифмировать
правую и левую части (7.1.5), изменив предварительно их знаки и
перейдя от минимизации к максимизации. В результате придем к
задаче максимизации

іпк—Р‹х""›1= 1п1—і‹Х"")1+ Ё (111%) + Ё … №"). (7.1.6)
і=1

!=!
 pagebreak 
Метды штрафных функций 34]

 

[Умножение (7.1.5) на —1 необходимо по той причине, что Ра“”)

и [(х‹"’) здесь являются отрицательными величинами,] Совершенно
очевидно, что минимизация і(х)<0 эквивалентна максимизации

0
111 [—і(х)]>0. Поскольку 2 1.1%, на любой стадии вычислтель-
1=1
ного процесса является константой (хотя значение этой константы,
возмож`но, и не полностью конкретизировано), можно положить р, =
= 1 и считать, что 1п &(х‘ю) = 6(3_‹(х(”’)) (і = 1, …, р), в резуль-
тате чего соответствие между (7.1.5) и (7.0.1) оказывается установ—
ленным.

Вычислительная практика с применением машинных программ,
построенных на основе метода Розенброка, показывает, что этот
метод не позволяет оперировать ограничениями в виде равенств и
не представляется удовлетворительным для решения задач, содер-
жащих нелинейные ограничения в виде неравенств (см. гл. 9).

7.1.3. МЕТОД ВНУТРЕННЕЙ ТОЧКИ [ОБЪЕДИНЕНИЕ
МЕТОДА БАРЬЕРНЫХ ПОВЕРХНОСТЕЙ
И МЕТОДА ДЭВИДОНА)

Бокс, Дэвис и Свен [9] объединили метод Дэвидона с предложен-
ным Кэрролом [10] методом барьерных поверхностей (МБП), по-
строив таким образом своеобразный параметрический метод внутрен-
ней точки, позволяющий эффективно решать задачи нелинейного
программирования при наличии ограничений. Метод Кэррола осно-
вывался на использовании штрафной функиии вида

Р(х‚ г) = і (х) + ’Ё "" (7,1.7)
і=і

 

Е: (Х) ’

где г — параметр, значения которою убывают с каждым циклом, а
ш, (і : 1, р) — положительные весовые коэффипиенты (ве-
са). При приближении к границе изнутри, т. е. как только &. (х) —›
—› 0, «штраф» становится большим. Соотношение (7.1.7) преобра-
зует задачу нелинейного программирования при наличии ограниче-
ний в задачу без ограничений с гораздо более сложной (по сравнению
с исходной задачей) структурой, но зато характеризующуюсн на-
личием весьма сильных барьеров вдоль гранины допустимой области.

Построив штрафную функцию и определив внутреннюю точку,
приступаем к реализации пропедуры минимизации Р (х, г) при за-
данном начальном значении #0). Тогда конечная для первого этапа
ВЫчислительной процедуры точка х становится исходной (старто-
вой) точкой для минимизации фушщии Р при уменьшенном значении
Г и т. д. Завершающий этап минимизации реализуется при очень
Малом значении г, так что результирующая точка х с точностью до
 pagebreak 
342 Г лава 7

установленного допуска может (если требуется) оказаться либо на
одной из ограничивающих поверхностей, либо сразу на нескольких
поверхностях, заданных ограничениями задачи. На каждом этапе
безусловной минимизации Бокс, Дэвис и Свен использовали метод
ДЭВИДОНа — Флетчера — Пауэлла. Доказательство корректности
данного подхода приведено в подразд. 7.2.2.

На эффективность МБП существенно влияют и выбор началь-
ного значения г (НО)), и метод сокращения значений г в ходе мини-
мизации, и выбор весовых коэффициентов. Если в Р (х‚г)значение
#“) выбирается слишком малым, на начальной стадии процесса ми—
нимизации мы придем к минимуму функции ['(х), который вряд ли
окажется вблизи условного минимума в точке х*.Следовательно‚
движение вдоль траектории, которая должна привести к к“, будет
связано со значительными временнь'тми затратами. С другой стороны,
если значение № слишком велико, то на первых этапах вычисли-
тельного процесса текущая точка неизбежно окажется слишком да-
леко за пределами допустимых границ и поиск из—за необходимости
возврата в пределы допустимой области также окажется весьма за-
тяжным. Бокс, Дэвис и Свен [91 считают, что на начальной стадии
оптимизационного процесса угол между 7/7 (х…!) и 7Р‚(х<°’,
№3) должен быть острым, а значение г должно увеличиваться или
уменьшаться путем умножения или деления начального значения
этого параметра на некоторое число до тех пор, пока угол между
71° (х‘т) и 7Р (кш), год) не станет тупым. Кроме того, должно
выполняться условие #“) > 104. (На практике упомянутые выше
авторы чаще всего просто полагают Н°) : 50.) Они рекомендуют
также при переходе от одного этапа вычислительном процесса к
последующему умножать текущее значение г на 0,1 (или на число,
лежащее в интервале огг 0,02 до 0,1), что обеспечивает постепенное
уменьшение этого параметра. Фиакко и Мак-Кормик (1963 г.)
предъявляютк выбору г несколько иные требования; подробное об-
суждение их рекомендаций содержится в подразд. 7.2.1.

Относительно ш, рекомендации Бокса, Дэвиса и Свена сводятся
к следующему: значения (в должны выбираться с таким расчетом,
чтобы все слагаемые в (7 1 7) пооле надлежащего масштабирования
оказывались по возможности величинами одною порядка Данными
авторами разработан эмпирический метод «подгонки» значений
сед, основанный на том, что ші для часто нарушаемых ограничений
слишком малы и, следовательно, в этих случаях значения 0), следует
увеличивать.

' Дэвис [11] считает, что в случае, когда ограни'еравенства
приводят к Р-функциям вида

…

Р1=і(х)+ігёш

 

@ …, (7.1.83)
 pagebreak 
Методы штрафных функций 343

 

 

__ т со;
а_нх) на; 5%) , (7.1.86)

т
Р8 = [(х) + 122 со, 103 [— & (х)], іг>0‚ (7.1.8в)
!=]
0), следует полагать равными нулю до тех пор, пока не окажется
нарушенным хотя бы одно из ограничений. Для активных ограни-
чений ш,. полагаются равными единице. В качестве значения & Дэ-
вис рекомендует брать значение множителя Лагранжа, ассоции-
рованного ‹: первым из нарушенных ограничений. Так, например, в
приведенном выше выражении для Р1 (применительно к активным
ограничениям &. (х) > 0)

е? (к) [771' (Х) яе (х)]
іг = —‚——— , (7.1.9)
7 21 (Х) 73: (Х)

где значения градиентов [(х) и {(х) вычислены в последней из
текущих допустимых точек. Вместо того чтобы вычислять із, для каж-
дого дополнительного ограничения и пересматривать значения [г, на
каждом этапе вычислительного процесса, представляется целесооб-
разным (эта идея также принадлежит Дэвису) величину із, опре-
деленную с помощью (7.1.9), при переходе от одною этапа ите—
рационною процесса к следующему уменьшать путем умножения на
Число, лежащее в интервале от 10—2 до 104. Если задача содержит
ограничения в виде равенства, то (по Дэвису) к Р—функции (вида
Р], Р2 или РЗ) добавляется выражение, соответствующее второму
слагаемому в правой части (7.0.2).

Фиакко и Мак-Кормик. используя МПБМ, полагали все 03, рав-
ными единице, хотя и обсуждали в своей книге (см. список литера-
туры в конце данной главы) другие варианты выбора весовых коэф-
фициентов, Некоторые результаты, полученные при решении проб-
ных задач путем комбинированного применения МБП и метода
Дзвидона, приведены в табл. 9.3.4.

7.1.4. МЕТОД ВЕИСМАНА

Вейсман [12] разработал структуру комплексного метода (из-
вестного под названием «МИНИМАГЫ, позволяющего реализовать
в рамках одной машинной программы сразу три алгорИтма, а Именно
алгоритм прямого поиска, предложенный Хуком и Дживсом, ал-
горитм случайного поиска и алгоритм, основанный на использова-

нии штрафной функции. Штрафная функция строится следующим об-
разом;

Р (х, ') = ПХ) + Ё бипвНХ). (7.1.10)

'=1
 pagebreak 
344 Г лава 7

 

где 5‘. = (1 — и,) равняется нулю, если ограничивающие условия
удовлеТВОРЯЮтся‚ и единице, если ограничения оказываются на—
рушенными. При этом ограничения в виде равенств преобразуются
в ограничения-неравенства, т. е. записыватся в виде

Еі(х)=№і(х)|—5і<0‚

где в, — величина допуска, ассоциированного с соответствующим
исходным ограничением в виде равенства.

Минимизация Р осуществляется методом Хука и Дживса для не—
которой поэтапно возрастающей последовательности значений г‘.
Поиск заканчивается либо когда оказываются удовлетворенными
все ограничивающие условия, либо когда абсолюгная разность меж-
ду значениями & (х) в начале и конце поиска оказывается меньше
некоторого заранее установленного доверительного числа (например,

10'4 . Вейсман выби ал начальные значения 7 так, чтобы
к
‚(а, = 0,02
#51 (хш’) ! (хш’) ›

где р* —— число ограничений. В конце каждого этапа значения г?“
для каждого нарушенного (на іг-м этапе) ограничения умножаются
на 8; полученное в результате новое значение 7 используется на
(із + 1)-м этапе. `

В конце каждого этапа оптимизационного поиска метадом Хука
и Дживса реализуе'юя, кроме того, случайный (рандомизирован-
ный) поиск. Пространство Е" делится на 10 гиперсфер с центром в
точке х, оказавшейся наиболее предпочтительной в результате поис-
ка методом Хука и Дживса. В и случайно выбранных точках внутри
каждой гиперсферы (число п задается заранее) находятся значения
целевой функции. и, если попадается точка, дающая минимизирую-
щую поправку менее 10% предыдущего значения { (х) (т. е. значе-
ния )* (х), найденного в предыдущей точке х), поиск методом Хукз и
Дживса повторяется. На следующем (Ь + 1)-м этапе стартовой
(исходной) является точка, в которой значение )* (х) оказывается
наименьшим среди всех значений, полученных на предыдущих
!г этапах оптимизационного поиска по любому из упомянутых выше
алгоритмов.

7.1.5. ДРУГИЕ МЕТОДЫ ШТРАФНЫХ ФУНКЦИЙ

1. Метод компенсирующих констант (МКК) ". Фиакко и Мак-Кор
мик в работе [13] описали метод, в структуре которого с неравенства-
ми можно обращаться так же, как и с равенствами, за счет исполь-
зования положительных ослабляющих констант (примерно в том же

 

1) Этот метод представляет собой одну из модификаций метода внешней точки.
 pagebreak 
М етоды штрафных функций 345

 

смысле, в каком это делалось в связи с рассмотрением (7.1.1)). Эгот
ме'юд предполагает использование штрафной функиии

р
№ г‘”, с) = дх) + №)“ 2 [@.-(№) чт, (7.1.11)
і=т+1

где с, > О‚ Штрафная функция т'акого вида достигает экстремума
в результате последовательных перемещений в направлении иско-
мой тОЧки со стороиы недопустимой области и имеет то преимущест-
во, что поиск допустимой точки в начале вычислительного про-
цесса можно не проводить. Относительно эффективности исполы
зования такого рода штрафной функции вряд ли можно сделать
достаточно аргументированное заключение. так как «эксперимен-

тальных» данных по этому вопросу явно недостаточно.
24 Метод внутренней точки. Фиакко и Мак-Кормик [131 пред-
ложили другой вид шрафной функции в рамках алгоритма внут-

ренней точки:

Р (Х…, хш—Ь) : [’с (‚(Ф—!)) _ ‚* “((Ил—1 + 2 [31 (‚(Нет—|_ (7112)

Ограничения в виде равенств могут быть включены в схему алго-
ритма по аналогии с (7.0.1). Функция (7.1.12), однако, исследована
еще недостаточно.

3. Метод центров (разновидность метода внутренней точки).
Гуард [14] описал алгоритм оптимизации, основанный на исполь-
зовании следующей модификации целевой функции:

Р‹х"*’‚ №") = [! (%*—") ——і(Х"")1 Пя; №). (7.1.13)

Несмотря на то что функция'(7.1.13) не является выпуклой, Гуарду
удалось доказать, что получаемый на 12-м этапе локальный оптимум
является также глобальным оптимумом целевой функции. Следует,
однако, заметить, что метод центров на практике недостаточно хо-
рошо зарекомендовал себя, поэтому логика построения вычислитель-
ной процедуры и подробное описание метода центров на языке ма—
шинной программы здесь не приводятся (читатель может обратить-
ся по этому вопросу к оригинальному источнику).

7.2. МЕтод послвдовмвльнои ввзусловнои
минимизщии (КОМБИНИРОВАННЫЙ мвтод
ШТРАФНЫХ ФУНКЦИИ)

Алгоритм нелинейного программирования, называемый сокра—

1 ‹,
щенно МПБМ ’(метод последовательной безусловном минимизации),
является обобщением метода барьерных поверхностей, кторый

 

1>Этот алгоритм разработан в одном из научно-исслодовательских уч еждений
США (Кезеагсн Апаіузіз Стр., МсЬеап, Уд.). р
 pagebreak 
346 Г лава 7

 

был предложен Кэрролом [15]. Физика и Мак-Кормик [161раз-
вили уют метод, доказали его эффективность и распространили
его алгоритмическую структуру на случай, когда среди ограниче-
ний задачи имеют место ограничения в виде равенств. Соответ-
ствующие машинные программы имеются в Корпорации по научным
исследованиям и разработкам (США), а также в лабораториях бал-
листических исследований (США) [17]. Алгоритм МПБМ разработан
для решения задачи нелинейного программирования вида (2.2.1) —
(2.2.3), в которой {(х) и & (х) ($ = т + 1, …, р) могут быть не-
линейными функциями независимых переменных, & ні (х) (і =
= !, ..., т) должны быть линейными функциями независимых
переменных. При таких условиях гарантируется сходимость после-
довательности промежуточных решений к оптИМальному решению
задачи нелинейного программирования.

В основном МПБМ сводится к следующему: ищется решение неко-
торой последовательности задач без ограничений, причем в пределе
находится минимум исходнойзадачи нелинейногопрограммирования.
В переложенном на язык машинных программ варианте МПБМ,
относящемся к 1967 г., задача нелинейного программирования преоб-
разуется в последовательность задач без ограничений путем построе-
ния Р-функции следующего вида:

1

_. т и
рок“”. г<”’›=і‹х“”›+‹г‘*’› " }; п%‹х“*’)+г"” }: _… ‚ 0.2.1)
:=1 і=т+1 81 (Х )

где значения весовых коэффициентов г положительны и образуют
монотонно убывающую последовательность {г\ "… > г… > >
> 0]. На фиг, 7.2.1 графически представлена Рфункция, являю—
щаяся частным случаем (7.2.1), а именно

Р(х)=(4х,—хё—12)+г( ' 34+тіг+ъё)*

Ю::1 — х? + 101:% —хЁ —

для трех различных значений г; в этом случае целевую функцию
исходной задачи нелинейного программирования и функпии, за-
дающие ограничения, легко выделить путем почленного сопостав-
ления данной Р-функции с (7.2.1). Пунктирной кривой изображена
траектория поиска минимума Р (х, г).

Заметим, что вначале Фиакко и Мак-Кормик предпочитали
задавать О-функционал ограничений-неравенств в виде своего рода
«барьера», который в задачах минимизации добавлялся к целевой
функции, а в задачах максимизации вычитался из )* (х). Этот функ—
ционал имел следующий вид:

и д |
6‹в‹х")›=\ _.

:, в: №)
 pagebreak 
110 2.0 6 11,0 . 5,1; м
Ф нг. 7.2.1. Уровни Р-фушщии.
 pagebreak 
348 Г лава 7

 

Как только хотя бы одна из функций;, (хаб)) —› О внутри допустимой
области, @@(ХФ1))—› оо; отсюда и происходит понятие «барьер».
При уменьшении №) влияние барьера уменьшается и точку х удает—
ся приблизить к границе, ассоциированной ‹: ограничениями—нера-
венствами.

Как уже отмечалось выше, можно выбрать О—функционал иным
способом, например в виде

№» = Ё шт ‹0‚ @ №№

:=!

сш (х"")) = —Ё 1п‹в‚-‹х“”»= Ё 1п——

1%)
:=1 і=1 Е (х )

Перелож‘енный на язык машинных пр`ограмм в 1970 г. вариант
МПБМ основывался на использовании штрафной функции

, 17
Р(х®‚ ‚“”> = {(х)—|_ (‘Ю Ё пы ‚(”)—‚® 2 1п 3, (х…). (7.2.121)
[=\ і=т+і

Как в этом варианте МПБМ, так и в варианте, описание которого
приведено выше, функционал Н (11 (х<’г>)) представлял собой просто
сумму квадратов п; (х),1'а1‹ что при г<>—› 0 ограничивающие ус-
ловия в виде равенств удовлетворялись с непрерывно возрастающей
точностью. Хотя каждое из ограничений в виде равенства можно в
принципе разбить на два неравенства и затем иметь дело с неравен-
ствами, на практике такой прием оказывался весьма неудовлетвори-
тельным — он в значительной степени замедляет оптимизационный
поиск и порождает тенденцию к преждевременному прекращению
вычислительного процесса

Процедура минимизации функций (7.2.1) и 57.2.1а) начинается
свнутренней (или граничной) точки, т. е. сточки х…), в которой все
ограничивающие условия в виде неравенств удовлетворены. После
вычисления №) точка х“) определяется путем минимизации Р (х,
№). Затем вычисляется г… и путем минимизации Р (х, г…) нахо-
дится точка х“) и т. д.

При выполнении описанной выше процедуры возникает ряд по—
мех. Во-первых, ассоциированная с Р-функцией матрица Гессе
по мере приближения к экстремуму начинает вести себя все хуже;
поэтому направления оптимизационного поиска могут в этих ус-
ловиях стать ошибочными. Во-вторых, скорость сходимости зависит
от начального выбора № и от способа редуцирования данного па-
раметра, Наконец, данные относительно «топологии» [ (х) и Р (х,“ г)
в большинстве случаев при переходе от одного этапа вычислений к
другому оказываются обесцененными (даже в тех случаях, когда
алгоритм предполагает выполнение экстраполяции того или иного
вида).
 pagebreak 
Методы штрафных функций 349

 

7.2.1. МЕТОДИКА ОПРЕДЕЛЕНИЯ ПАРАМЕТРА Г

В первых вариантах МПБМ в качестве весового коэффициента

пе “‘ „? ‹ю ‹ю—ч.
ред 2 ‚(х ) исполЬЗовался множитель (г )

і=|

показал Фиакко (1966 г.) путем сравнения Р-функции и ‚‘(х) вбли—

, поскольку, как

 

Ф и г. 72.2. Траектория минимума функции
Р(х‚ !“”) = (4х‘ + х,) + :(”) (# + ‚+) .
2

”1
зи экстремума при очень малых г, вектор х в окрестности искомого
минимума Р(х‚ г) можно представить в виде некоторого подинома

по г'” (фиг. 7.2.2). В последующих вариантах МПБМ для Суммы

т
2 них“”) использовался весовой коэффициент (г“)Г'. Весовой коэф-
{:|
фициент для той компоненты Р-функции, которая обусловлена на-
личием ограничений-неравенств, в обоих вариантах выбирался рав—

ным ‚@.

Фиакко и Мак-Кормик предложили три способа выбора началь—
ного значения №:

а) #0) = 1. (72.2)

6) Выбирается такое значение №), которое минимизирует норму
градиента Р-функуши [т. е. функции Р (Х…), №3) относительно г], что
дает

— 77! №) тк №)
11 71? ‹х“"› ||”

‚ (7.2.3)
 pagebreak 
350 Глава 7

 

где ХШ)

р

_внутренняя допустимая точка, К(х‘о’) = 2 1/31 (х)‘°’,
і=т+і

712 (х‘°’)—- вектор-столбец, составленный из вычисленных в точке

х…) первых частных производных К(х) по х. Мы видим, что при

построении К(хш’) учитываются только ограничения, которые имеют
вид неравенств.

5) Значение Н°) выбирается так, чтобы минимизировать превы-
шение функции Р (х, ‚(Ф) относительно его минимального зна—
чения (эту величшіу называют метрически взвешенным градиентом

Р- -;функции) при этом #03 задается следующим соотношением 1’:

Т 0) (0) —1 (0) Ч.
«»: 7 № №№ ›] тк )
г {уТК‹х‘°’›№к‹х“”›г‘ук‹х<°’›} ’ (7'2'4)

где 7“К(х(°))—- —-матрица Гессе для К( (х): Ё 1/3, (х), вычисленная
і=1

в точке ха”. Соотношение (7.2.4) может быть применено лишь в том
случае, когда 71? (х(°))эЬ0‚ так что ‚‘О’фо. При слишком больших
значениях ‚(О) минимизационный процесс начИНается во внутренних точ-
ках, лежащих слишком далеко от границы допустимой области,
тогда как при слишком малых #0) начальное решение оказывается
чрезмерно близким к границе, задаваемой ограничениями задачи.
В обоих случаях, для того чтобы оказаться в нужном месте допус-
ТИМОЙ области, приходится тратить дополнительное машинное время.

Из указанных выше трех способов задания № наиболее удобным
с практической точки зрения оказывается первый (в большинстве
машинных программ, составленных на основе МПБМ, полагают
‚(°) = 1); именно этот вариант рассматривается в гл, 9. Однако,
чтобы достичь при решении задачи наибольшей течности, пред-
почтение следует отдать выражению (7.2.4), хотя расход машинного
времени из-за слишком больших начальных значений г…) будет при
этом бёльшим. Соотношение (7.2.3) применяется в тех случаи,
когда отсутствуют данные о вторых частных производных функции
К по х. Если в результате вычислений по формуле (7.2.3) или по
формуле (7.2.4) окажегся, что № < 0, оптимизационный поиск
начинается в точке ХФ) одним из методов, описанных в г.п. 3. При
этом #01 вычисляется в каждой новой точке хдд, пока не будет по-
лучено положительное значение #0) (в этом случае оптимизационный
поиск предолжается с помощью МПБМ) или пока не будет достигнут
безусловный минимум целевой функции задачи (2. 2. 1) — (2.2.3)
В последнем случае х* есть внутренняя точка, и поиск, таким обра-

” Этим соотношением ‚(°) задается точно, если Р-функция является квад-
ратичной.
 pagebreak 
Методы штрафных функций 351

 

зом, заканчивается. Фиакко и Мак-Кормиком экспериментально было
показано. что после определения ‚(°) одним из указанных выше
способов эффективность алгоритма не изменится в значительной
степени, если последовательность г"), г“), …, г… индуцировать
простым соотношением № = гт—Ч/с, где с > 1 есть константа
(обычно полагают :: = 4). Такой простой способ определения каж-
дого последующего значения № в ходе итерационного процесса
существенно упрощает процедуру эктраполяции, описание которой

дано в подразд. 7.2.3.

7.2.2. УСЛОВИЯ СХОДИМОСТИ МПБМ

Можно доказать, что при определенных условиях последова—
тельность безусловных минимумов Р (х, №) будет стремиться к
решению задачи нелинейного программирования (2.2.1) — (2.2.3) по
мере приближения к нулю значений г…. Существенным является ус-
ловие выпуклости Р—функции. Условия сходимости (ср. их с условия-
ми, перечисленными на стр. 242—243) выглядят следующим образом:

Условие 1. Объединение множества, содержащего все точки х,
удовлетворяющие ограНИчивающим условиям в виде равенств

Р:, (х) = О (і = 1, …, т), и множества $*, содержащего все точки
х, удовлетворяющие ограничивающим условиям ;, (х) >О (і =
=т+ 1, ..., р), должно быть непустым. дРУгими словами,

задача должна иметь допустимую область,

Условие 2. Функции НХ), … (х), ..., и… (х), Ет+1(х)‚ ..., Е„ (х)
должны быть дважды непрерывно дифференЦИруемыми, если
возникает необходимость применять метод, основанный на исполь-
зовании вторых производных (см. подразд. 7.2.3, шаг 3).

Условие 3. Для любого конечного :; и любого г“) > 0 множество
точек х, удовлетворяющих неравенству

т
мх) + (г“дг‘” 2 и? (х) < 4
і=1
и принадлежащих множеству 8“, должно быть ограниченным.

Условие 4. Целевая функция {(х) должна быть выпуклой, а
функции Р:, (Х) (і = 1, ..., т) должны быть линейными (точ—
нее, сумма Еп? (х) должна быть выпуклой).

Условиед. Функции & (х) (і = т + 1, ..., р) должны быть во-
гнутыми.

Условие &‘ . Матрица Гессе для Р-функции относительно х (т. е.
матрица, сос'гавленная из вторых частных производных Р-функции
по независимым переменным) не должна обращаться в нуль ни для
Одной из точек, принадлежащих множеству $*.

Выполнение условий 1—6 полностью гарантирует сходимость
к решению задачи нелинейного программирования, представленной
соотношениями (2.2.1) ——(2.2.3); однако сходимость может иметь
место даже и тогда. когда эти условия полностью не выполняются.
 pagebreak 
352 Глава 7

 

Опираясь на условия 1—6, Фиакко и Мак-Кормик доказали
следующую теорему сходимости:

Теорема 1 (сходимость для исходной задачи)

Если задача нелинейного программирования удовлепшоряет ус—
ловиям 1—6, то:

а) каждая функция Р(х, г…) имеет минимум в некоторой точ-
ке иги”) множества 6“ и

б) Ы)… Р(х(г"”)‚ гф’) = шіпі (х) = [ (х*)‚ т. е. последовательность

: чо

безусловных минимумов Р(х(г(’”), ‚@) стремится к решению і(х*)
исходной задачи нелинейного программирования при іе—› оо.

Кроме того, при выполнении условий 1—6 Р-функция есть вы-
пуклая функция в 8*.

С задачей нелинейного программирования (2.2.1) -— (2.2.3) ассо-
циированы две двойственные задачи: одна из них относится к слу-
чаю, когда функции Р:, (Х) (і = 1, ..., т) нелинейны, а ЦРУГая —
к случаю, когда эти функции линейны. Если функЦии и, (х) нели-
нейны, то нелинейную задачу (2.2.1) —— (2.2.3) необходимо (путем
записи каждого из равенств в Виде двух неравенств) переформули-
ровать следующим образом:

Задача А:

шшимизировать Дх), х & Е”,
при ограничениях
л%‹х)>о‚ і=1‚…т‚

3‚(х)>0, і=т+1‚...,р.
двойственной по отношению к задаче А является задача А’:

(7.2.5)

максимизировать Е(х, ц, …) =і(х)— Ё иіддх) +Ё шт.??(х)

Г=т+1 і=1
при ограничениях
7:5 (Х. н, и) = 0, (7.2.6)
иі>0, і=т+1‚...,р,
ш‚>0, і=1,...‚т,

где 7х5 (х, ц, ш) ес'і'ь вектор, составляющими которого являются
первые частные производныеЕ (х, ц, и;) по независимым переменным.
Следует иметь в виду следующее: когда функции Л‘ (х) нелинейны,
нет гарантии того, что решение задачи А’ совпадает с [ (х*)‚ т. е. с
решечием задачи А. (Опыт говорит о том, что это весьма маловеро-
ятно.
 pagebreak 
Методы штрафных функций 353

 

Если функции 11, (х) линейны, задача А можт быть представ-
лена в эквивалентной форме В:
Задача В:

минимизировать } (х), х Е Е”,
при ограничениях

Щ(х)>0‚ і=1,...‚ т,
*Щ(Х)>0‚ і=1‚ …, т. (7.2.7)
Ея(7‹)>0‚ і=т+1,...‚р.

Задача, двойственная по отношеНИЮ к задаче В, формулируется
следующим образом:
Задача В’:

[’
максимизировать Е (х, ц, ш, ш')=/‘(Х)-— 2 “15100"?
і=т+1
+ 21101!!! (Х) ‘— 21 шт; (х)
!= ‘=
при ограничениях
7‚Е(х, ц, ш, ш’) = 0,

ид>о‚ і=т+1‚р‚

_ (7,2.8)
Ш,)О, !=1‚...,т‚

ш2>о‚ і=1‚т.

Двойственная задача 8' имеет решение в некоторой точке (х', 1.1“,
ш*, и”), где В (х*‚ “*, “"', и”) = і(х*), т. е. совпадает с решением
задачи В. Фиакко и Мак—Кормик доказали следующую теорему
сходимости применительно к условиям двойственной задачи:

Теорема 2 (сходимость для двойственной задачи)
ри выполнении условий (1—6) МПБМ генерирует точки
{х(г"'›), и (г…), …И”), “"(ГщП; являющиеся допустимыми и обла-
дающие следующим свойством:

‚13…50: (№), 11 (А”), и(г‘”), ш’(г""))=1°(Х*)-

Таким образом. наряду с решением задачи А (или В), которую
мы называем исходной, алгоритм, основанный на МПБМ, генери-
рует также последовательность точек, приводящую к решению задачи
А’ (или В')‚ двойственной по отношению к А (или В). Поскольку [ (нд)
есть максимальное значение Е (х, ц, ш, ш’), то, как только условия
1—6 оказываются выполненными, имеет место следующее неравен-
ство:

В (к а“”), и №), и (№), ш' (№» < :* (х*› < Р (х «‘*’». (7.2.9)
 pagebreak 
354 Г лава 7

 

Неравенство (7,2.9) можно использовмь [если задача удовлетво-
ряет условиям (1—6)1 для определении! момента, когда в процессе
реализации вычислительного процесса на ЭВМ сходимость после-
довательности промежуточных решенпй к решению исходной задачи
нелинейного программирования оказывается практически достиг-
нутой.

7.2‚3. ВЫЧИСЛИТЕЛЬНАЯ ПРОЦЕДУРА

В общем случае вычислительный алгоритм реализует следующие
шаги (фиг. 7.2.3)”:

Шаг 1. Пользователь выбирает точку ХФ), принадлежащую
множеству 8* (т. е. такую точку х<°>‚ для которой Е: (х‘т)> 0,
і= т + 1, …, р). Другими словами, начальная точка должна
быть внутренней точкой (в соответствии с определением, приве-
денным в гл. 2). Поскольку Р-функция может иметь несколько ми-
нимумов, то, начиная поиске точки, не являющейся внутренней.
можно прийти к минимуму, не являющемуся допустимым. Если
требуемая внутренняя точка неизвестна, ее можно найти повторным
применением метода МПБМ. В варианте МПБМ, относящемся к
1967 г., фиксировалось первое нарушенное ограничение›неравен-
ство, причем функция, соответствующая этому ограничению, рассмат-
ривалась как временная Целевая функция и с помощью МПБМ ми-
ннмизировалось отрицательное значение этой функции при учете
совокупности удовлетворенных ограничивающих условий в виде
неравенств. Как только все эти ограничивающие условия оказы-
ВШОТСЯ удовлетворенными, упомянутое выше выделенное ограниче-
ние переводится в разряд обычных ограничений и процедура пов-
теряется относительно другого нарушенного ограничения, т. е. фик-
сируется новая временная целевая функция. В варианте МПБМ,
относящемся к 1970 г., для определения внутренней точки осу-
ществлялась минимизация взятой с отрицательным знаком-суммы
ВСЕХ @] (Х), ДЛЯ КОТОрЫХ СООТВВТСТВУЮЦЦ/іе ограничения ОКЗЗЫВЗЛИСЬ
нарушенными. В обоих из указанных выше вариантах МПБМ
ограничивающие условия в виде равенств удовлетворяются лишь на
заключителъном этапе решения ИСХОЦНОЙ задачи.

Следует отметить, что если оказываются нарушенными сразу
несколько ограничений с высокой «степенью» нелинейности, то оп-
ределение допустимой начальной (стартовой) точки может потре-
бовать значительных временньіхх затрат. Поэтому всякий раз, когда
допустимую начальную точку удается «увидеть» без дополнительных
вычислений, следует именно с нее и начинать итерационный процесс.

') Фиг 7.2.3 позволяет провести сравнение траектории последовательностн
минимумов Р (х, г), найденных ‹: помощью МПБМ, с траекторией поиска, получен—
ной проективным методом.
 pagebreak 
Методы штрафных функций 35

 

Шаг 2. После определения стартовой течки в соответствии с ал-
горитмом находится положение минимума Р—функции [определенной
формулами (7.2.1) или (7.2.1а)] для текущего значения №. Вероят-
но, ббльшая часть машинного времени потребуется на отыскание с
помощью МПБМ последовательности внутренних точек, миними-
зирующих Р-фунКЦию для каждого значения №)! Направление

  

Дипустимая

  

 

“:

Ф и г. 7,2.3. Сравнение траектории оптимудзационного поиска, полученной ме’ю-
дом штрафных функций, с траекторией минимизации, найденной проективным
методом.

:; (х) › 0 — нелинейное ограничение в виде неравенства. Стрелками изображена
траектория. полученная проективиым методом: точками изображена траектория. получен-
ная методом штрафных функций.

оптимизационного поиска находится с помощью описанного в
разд. 3.3 метода Ньютона путем предварительного умножения гра-
диента функции Р (х, №3) на матрицу, являющуюся обратной по
отношению к матрице вторых частных производных Р (х, №) по
незавпсимым переменным, или (как альтернативный вариант) с
помошью метода Бройдена (см. подразд. 3.4.1), аппроксимирующего
[\72Р (х, ‚„„„—1,

&’” = 4721996”, гщ)]_'17Р(х…, №) (7.2.10)
ИЛИ

5аг) : _ ““рок“”, ‚…; (7.2.1021)

Длина шага, как обычно, определяется путем минимизации моди-
фицированной Р—функции. Как только направление поиска оказы—
вается установленным, в рамках МПБМ производится поиск ме-
ТОдом Фибоначчи с тем, чтобы определить положение минимума
 pagebreak 
356 Г лава 7

 

Р (х, №) на расстоянии Ахщ от ха?) в направлении поиска [тогда
как в структуре метода НЛП предполагается сочетание поиска и
экстраполяции (подгонкиП для того, чтобы перейти к минимизаЦИи
методом линейной аппроксимации.

Применение метода Ньютона сопряжено с определенной «опас-
ностью», поскольку поведение матрицы, обратной к матрице Гессе
для Р-ф нкции, может оказаться весьма неудовлетворительным.
Мюррэй 18] показал. что даже в случае задач с хорошо выбранными
масштабами для переменных, матрица Г ессе дляР (х, :…) ведет себя
неудовлетворительно. Новая информация, полученная на том или
ином этапе вычислительного процесса, может оказаться недостаточ-
ной для того, чтобы скомпенсировать увеличение погрешности в
информации, полученной на предыдущем этапе.

Флетчер и Мак—Канн [191 рассмотрели отношение наибольшего
из собственных значений матрицы Г ессе для Р—функции к наимены
шему собственному значению этой матрицы в качестве некоторого
критерия; ими было установлено, что применение метода Ньютона
приводит к неудовлетворительному поведению матрицы Гессе, тогда
как метод Дзвидона — Флетчера —Паузлла приводит хотя и к
приближенной‚ но удовлетворительно ведущей себя матрице, обрат-
ной по отношению к матрице Гессе для Р-функции. Флетчером и
Мак-Канномпредложенаопределеннаястратегия ускорения процесса
минимизации [ (х) путем использования наряду с г собствен—
ных значений Р (х, г) для выявления на каждом этапе вычислитель-
ного процесса (когда значение г уменьшается) наиболее удовлетво-
рительной структуры матриц, задающих направление оптимиза-
ционного поиска. Как показало решение пяти пробншк (тестовых)
задач, включая задачи 10, 11 и 18, приведенные в приложении А,
экстраполяция позволяет сократить (по сравнению с метадом Нью-
тона) количество вычислителъных операций (определение направ-
ления поиска + линейный поиск) на 15—50%.

Из-за необходимости приведения (в рамках МПБМ) матрицы
Гессе для Р—функции к регулярному виду (если эта матрица не яв—
ляется положительно определенной) берется Направление поиска,
совпадающего с отрицательным градиентом, т. е. матрииа‚ обратная
к матрице Гессе для Р-функции. подагается равной едшхИчной мат-
рице.

Хотя Фиакко и Мак-Кормик утверждают, что практическое при-
менение методов «первых производных» и метод Дэвидона при ми—
нимизации Р-функции не было в такой же степени успешным, как
использование метода Ньютона, Уортман [171 считает, что миними-
зация методом Дзвидона — Флетчера — Пауэлла требует наимень—
ших затрат времени. В табл. 7.2.1 приведены некоторые результаты,
полученные Уортманом для задачи 18 из приложения А с помощью
различных минимизационных подпрограмм. Метод Ньютона имел
при этом структуру‚ описание которой дано в гл. 3, если не считзть,
 pagebreak 
Методы штрафных функций 357

 

что, когда УЯР не был положительно определенным, р*Р заменя-
лось на единичную матрицу !, т. е. направление поиска осуществ-
лялось вдоль отрицательного градиента. Небольшие отличия имели
место между МПБМ и методом НЛП в отношении условий завер-
шения вычислительных операций; однако в целом эти ме'юды рав—
ноценны.

Таблица 7.2.1

Сравнение различных методов поиски при минимизации Р-функции задачи 18,
приведенной в приложении А

 

 

Метод
Мпа дзви_до- Мете Мета Х в
МПБМ ]) НыотоЪа ФЁ-гче- Пауэл}: и дані:
ра — Пау-
алла
і(х*) 32,3519 32,8488 32,8488 82,3488 32.3526
Полное число этапов 455 1363
Одиомерный линейный
поиск (число шаюв) 92 88 272 7164
Количество вычислений
значений целевой функ-
ции 292 1086 27 987 37 485
Количество вычислений
значений Р-функции 487 1331 27 458 34 054
Время, мин 1,14 0,73 4,71 4,72

 

1) Физика и Мак-Кормнк.

 

В методе Хука и Дживса вычислительный этап состоит из струк-
турно—аналитического и по необходимости моделирующего поиска.
В методе Пауэлла на каждом этапе находится линеаризованный ми-
нимум в п независимых направлениях, и не исключается возмож—
ность того, что на каком-либо из этапов реализуется поиск в «состав-
ном» направлении (см. гл. 4). За исключением случаев применения
методов Хука и Дживса, составляющие вектора х определялщь с

точностью до 104—40"4 от их истинных значений (см. в этой связи
приложение А). Во всех случаях все ограничивающие условия в
виде неравенств были полностью удовлетворены. Как метод Дэви-
дона _ Флетчера — Пауэлла, так и метод Ньютона позволили
найти минимум целевой функции быстро и с большой степенью точ—
ности.

В одном из своих исследований Табак 1201 приводит данные от-
носительно временных затрат при минимизации Р-функцпи на
ИБМ 360/91, Эти данные содержатся в табл. 7.2.2. Они относятся к
следующей задаче:
 pagebreak 
358 Г лава 7

 

минимизировать НХ) = 0х1 + х, + хб
при ограничениях

(2х3 _ 1) „3 + (2хё— 1)хё>о‚

1:1 [4хЁхЁ (4хЁхЁ _ 2х3 — 2х3 + 1) + х: + хЁ] + 1 — 215,2 (лах4 +
+ хдхд) > 0.
2х1хЁХЁ №163 —- 1) 1% + (2хЁ —— 1) 16%] + 2х2х4х9 (хех. + хм“) — хз —

— хЁ — 4х8х4х„х„ > 0,
хЗдпіп < хз < хЗд'паху

Хз.…іп < х„ < Хэд…
ха < хинах,
755 < хб.шах‹

Тестовые решения задач 1, 2, 4, 5 и 11 из приложения А (соот-
ветствующие результаты приведены в табл. 7.2.3) показывают, что

 

 

 

 

Таблица 7.2.2
Мииимипция Р-фуикции различными методами
м…… №№ м…… №№

Ньютона 1,40 Бройдена 6,63
Проекции приведенного

градиента 2, 10 Флешера — Ривса 7.66
Проективный Ньютона —-

Пирсона 2,93 Пирсона 2 32,24
Пирсона 3 6,13 Наискорейшего спуска 57,53

 

перечисленные методы минимизации с применением машинной про-
граММЫ «МПБМ-1970» в грубом приближении эквивалентны, если
используется аналитическая запись частных производных, но оказы-
ваются малоэффективными в условиях поиска без использования
производных в их аналитической записи (т. е в условиях «чистого»
поиска).

Завершение поиска минимшхьного значения Р-функции в МПВМ
определяется на каждом этапе вычислительного процесса одним из
трех критериев сходимости; выбор критерия осуществляется поль-
зователем. Работа программы заканчивается, если выполняется
одно из следующих условий:

а) [УТР (Хаг). ‚(А» [7313 (х…, ‚(&…—1 7Р (Хок), г…) |< &
 pagebreak 
Методы штрафных функций 359

 

Другими словами [см. соотношение (7.2.10П, останов имеет
место, если

#)
”“_Ыіщдке, і=1,п.

_ (;;—1) _р <::)
6) №№"), г<’”›№‹х<’”‚ А’”)! 'пР №, г*‘›|<”————————<х >„ "‘ ’.
Данный критерий останавливает минимизаиъионный поиск, если

аг) (»› (::—1) іе—п _ (12) №)
№№Ы<№э 1=1‚.—-‚п-

дР(х(’”, ‚(т) , .
В __ __
) | дх! < в, ъ— 1, .

где вертикальные линии показывают, что берется абсолютное зна—
чение величины дР/дх,. Критерий «а» использовался исключительно

..,п.

Таблицд 742.3

Временные затраты 1) на решение некоторых заддч нелинейного программпроваиия
‹: помощью МПБМ (1970 .)

2
1]?

 

Номер задачи 11

 

 

 

 

 

 

!
Критерий останова?) 1 ‘ 2

   

Методы минимизации

Ныо'юна с производ-
ными в аналитиче-

ской записи 0.53 0,67 0,76 0,68 2,05 2,27 0,99 1,33 0,98
Бройденя 0,56 1,01 0,85 0,88 4,39 4,80 1,01 1,30 1,65
Только вычисление

значений функций,
Фиакко и Мак-Кор-
мик 0,94 1,23 Решение найтя не удалось 3,40.

| | 1 1 [

1) Основное время машинной обработки данных в секундах нв СВС 6600
7) См. подразд. 7.2.3 (шаг 5).

 

 

в связи с решением задач, рассматриваемых в гл. 9 (при & = 104).
В табл. 7.2.4 приведены некоторые данные применительно к усло—
виям задачи 1 из приложения А; эти данные позволяют провести

сравнение эффективности сформулированных выше критериев ос-
танова.

Шаг 3. В МПБМ вектор х"*+1> задается соотношением
х(гг+!› : Хаг; + №504),

Где 5… определяется либо формулой (7.2.10), Либо (7.2.10а). Чтобы
Избежать манипулирования с точками, леЖАЩими вне допустимой
области, необходимо располагать некоторым методом выявления
 pagebreak 
360 Глава 7

 

ситуаций, когда оказывается нарушенным то или иное ограниче-
ние в виде неравенства.

Шаг 4. Рассмотрим теперь ускорение процесса поиска решения
путем экстраполяции. Без акселерационного шага МПБМ обес—
печивает сходимость к условному экстремуму слишком медленно

Тдб/цща 7.2.4

Результаты применения МПБМ (1970 г.) при различных критериях останова
в связи с решением задачи 1 из приложения А1)

 

Останов пря „и……шдции Осинов по завершении всего минимизационного процесса 3)
2
Р-функцни ) Критерий 1 ! Критерий 2 | Критерий :;

 

Метод Ньютона

Критерий а 0,529 (32) 0,670 (38) 0,606 (38)
Критерий ‹) 0,703 (106) 0,832 (129) 0,815 (129)
Критерий : 0,604 (93) 0,884 (127) 0,785 (127)
Метод Бройдена Критерий 1 Критерий 2 Критерий 8
Критерий в 0,568 (49) 1,013 (64) 0,967 (64)
Критерий 6 0,729 (49) 1,190 (61) 0,955 (61)
Критерий в 0,597 (49) 0,974 (04) 1,112 (64)
Только вычисление зна,
чеиий функции Критерий 1 Критерий 2 Критерий 3
Критерий 11 0,944 (112) 1,234 (146) 1,231 (164)
Критерий 6 1,316 (187) 1,679 (223) 1,462 (214)
Критерий в 0,703 (58) 1,002 (91) 1,051 (91)

 

1) Чистое машинное время в секунддх; в скобках указано число птислнтельинх этапов.
2) См. подразд. 7.2.3 [шаг 2).
3) Оч, подразл, 7.2.3 (шаг 5).

 

(так как вбЛИзи границы процесс минимизации проходит медленно).
Именно для преодоления этой трудности используется прием по-
следовательного уменьшения весового коэффициент г с тем, чтобы
получить последовательность минимумов Р (х, год) и соотве'пчгтвую`
щих значений Х…. После этого по трем точкам х“…д х… и
№“… можно найти приближеннъхй экстремум. Данная процедура
оказывается эффективной при решении многих задач, но становится
явно неудовлетворительной при сильном «сгущении» текущих точек.

После того как удается отыскать несколько минимумов функции,
Р (х…, д’”), МПБМ экстраполирует значения составляющих векто—
ра ›‹ путем их представления в виде полинома по степеням %.
(Если функция Р (х…, г…) строго выпукла, то для каждого г‘”
существует только один минимум Р (хдд, №0). Экстраполяционнью
ПРОЦЕДУРЫ, основанные на использовании ДВУХ ИЛИ трех ПОСЛЭДО'
вательных значений х, соответствующих минимальным значениям
 pagebreak 
М етоды штрафных функций 361

 

Р-функции, называются процедурами первого и второго прибли-
жений соответственно (фиг. 7. 2 4).

Укажем, что Фиакко и Мак—Кормик доказали, что траектория,
проходящая через точки х (г“д) (каждая из которых является ре-
шением подзадачи безусловной минимизации Р (х, г…», прибли-

Р(.т"‚’ г‘”)

   

[,да-‚г "’»

приближение

0 ! 2 б 1: 5 б 7 .7:

Ф и г. 7.2.4. Метод экстраполяции для уско ения оптимизационного поиска с по-
мощью М БМ.

зительно линейна по (‚…У/: при г… —› 0 (т. е. для малых значе—
ний г…):

№”)… (0) + „(№№ (72-11)
И

х(’—ш)_)…х(0)+а< {%))/, (7.2.12)

где и — некоторая константа, & х (0) —— значение х (НЮ) при г”) +
—› 0. Таким образом, приближение первого порядка к решению за-
дачи нелинейного программирования находится путем решения урав-
нений (7.2.11) и (7.2.12) относительно х (0), в результате чего
имеем

х (0),_‚ … № (7113)

ДЛЯ ПОЛУЧЕНИЯ ЭКСТРЗПОЛЯЦИОННЫХ ОЦЕНОК ВО ВТОРОМ приближении
полагаем

х ‹г‘”) = ›‹ «» + а1‹г"°>›"' + аз №).
<›<›‹ ?>

.(д_:›>=.…‚..,<г;›>/„№.

(7.2.14)
 pagebreak 
362 Г лава 7

 

Разрешив (7.2.14) относитльно х (0), получаем
№№ х‹г‘*’)—‹с+с‘^›х‹г:”/с›+с'/*х‹г"”/ся) _ (№15)
‹е—і›‹е^—1›
Соотношения (7.2.13) и (7.2.15) используются в МПБМ для уско-
рения процесса оптимизационного поиска и. следовательно, для ако-
номии машинного времени.

Шаг 5. Итак, тесты на сходимость выполнены. Алгоритм со-
держит три критерия завершения оптимизационного поиска (вы-
бор критерия предоставляется пользователю). Машинная программа
реализует останов (прекращение итерационного процесса), если
удовлетворяется один из следующих критериев:

1)
і‹х(г"”» _ 1_ „‹
Е‹х‹г”"›‚ не"”). ши"”), ит…» " °’
где функция Е определена в подразд. 7.2.2.
2)

;)
‚ад 1

_ е.
[=… +1 емко…» < °

[Следует заметить, что этот критерий не содержит члена, который
позволял бы проверить, удовлетворяются ли условия 111 (х (пт)) =
=О, і= 1, ..., т.]

3)

Значение [(х') в первом прибли№Ь _ 1 < 6
В (х (№„ .. №). … №). …» №» "’

где 60 — некоторая константа, значение которой выбирается поль-
зователем, Критерии 1 и 3 являются логическим развитием (7.2.9).
Значения целевых функций исходной и двойственной задач при
уменьшении №) обнаруживают тенденцию к совпадению (по край-
ней мере в задачах с линейными ограничениями в виде равенств),
& функции Е и Р стремятся к [(х"). Вычисления заканчиваются,
если выполняется выбрах’іный критерий. В противном случае ал-
горитм реализует переход к шагу 6. Ряд результатов применительно
к условиям задачи 1 из приложения А (с использованием критериев
1—3) приведен в табл. 7.2.4; в гл. 9 критерий 1 применяется при
реализации вычислительных процедур.

Шаг 6. Как отмечалось выше, машинная программа обеспечи-
вает уменьшение значения №).

Шаг 7. Машинная программа обеспечивает приближенное вы-
числение минимума Р—функции для уменьшенного значения №) с
помощью экстраполяционных формул, приведенных в связи с
описанием шага 4.

Шаг 8. Исходя из результата, полученного на шаге 7, программа
реализует переход к шагу 3, и итерационный процесс продолжается
в установленном выше порядке.
 pagebreak 
Методы штрафныяс функций 363

 

В варианте МПБМ, относящемся к 1967 г., кроме задания ие-
левой функциии ограничений, выраженных через независимые пе-
ременные, от пользователя требовалось также ввести в программу
аналитжеские выражения первых и вторых частных производных
[(х) и функций, задающих ограничения, по независимым перемен-
ным задачи. В варианте МПБМ 1970 г. пользователю предоставляет-
ся возможность определить программным способом приближенные
значения вторых частных производных с помощью разностных
соотношений, содержащих аналитическое представление первых
частных производных; эта особенность машинной программы не
была, однако, в достаточной степени опробована. Кроме того, МПБМ
1970 г позволяет применять алгоритм Бройдена с использованием
аналитической записи первых частных производных или метод
оптпмизационного поиска, в котором частные производные вообще
не используются. Пользователь должен также задать начальный
вектор х. который не обязательно является допустимым, & также
заранее установить значения некоторых из фигурирующих в про-
грамме параметров и констант.

 

Пример 7.2.1. Метод последовательной безусловной минимиза-
ции (МПБМ)

Рассмотрим задачу, которая уже решалась в предыдущей главе
(здесь она будет решена с помощью МПБМ):
минимизировать і(х) = 4х1 — хЁ — 12
при ограничениях
И1(х)=25—хЁ—хё= 0,

32(х)=10х1—х%+10х2—хЁ—34>0,
3300 : ’Я >(»
8400 : х2>0.

Функции )* (х), и, (х), 32 (х), 33 (х) и 34 (х) изображены графически
на фиг. 6.0.1.

НаЧНем оптимизационный поиск с точки х<°> : [1 117, в кото-
рой [ (Х“) = _ 9; однако, поскольку точка хю) является внешней,
в соответствиис МПБМ определим прежде всего внутреннюю точку
х (не являющуюся допустимой по отношению к ограничению 11. (х) =
= О) путем минимизации —— 32 (х) при ограничениях 33 (х) > 0 и
Е,; (Х) > 0, которые не должны при этом нарушаться. Построим
НеРВую из вспомогатеЛьных Р-функций в виде

4
1

Р, =_Ев(х)+72 ЕЦХ)
[:.—З

 

=—‹10х‚—хі+ 10х„_хё_з4) +

+ ‹1›(%+—„‘‚—). (а)
 pagebreak 
364 Г лава 7

 

В точке х‘о) = [1 пт имеем—3,(х) = 16 и [(1/х,)+(1/х2)1=2, так
что Р’( х‘щ)=18. Присоединенная (расширенная) целевая функция
(которая подлежит максимизации) двойственной задачи Имеет сле-
дующий вид:

 

4
1
Е=—3‚(х)—г2 ЕАК) =14. (б)
інЗ

Минимизация функции Р’ выполняеТся методом Ньютона
(см. разл, 3.3). Для частных производных функции Р‘ имеем

д‘" ==10+2х1—1

дх, „[
дР’ 1
дхв
дЕР2 '

 

 

=—10+2х2— „
2

=2+—,

Таким образом, направление поиска И длина шага В случае МИНИ-

мизации Р' задаются соотношением
_ 4 0 —' ——9 225
_ яр' ‘ Р’ =.— = ’ . в
т 1 7 [о 4 [_9] [225] (›
Шаг длиной 2,25 реализуется вдоль каждой оси координат, в ре—
зультате чего получаем внутренний вектор х следующего видах

 

 

: 3 25
(0) (0) ,
х = х 5 = . г
+ [3.25 0
Для этого вектора удовлетворяются все ограничивающие условия в
виде неравенств, 3 [(х) = =- 20,25.
Построим теперь основную 1Р—функцию:
__”10‘) !
Р—ПХН`" 1/7 + (; + хе + пох1—х3+юх2—х3—з4)' …

В точке х = [3,25 3,251Т при г = 1 эта функция принимает значение
529.716. Подлежащая максимизации целевая функция двойствен-
ной задачи имеет вид

| 2
Е: [(х)—‚(_+Т+ 10х1=х21+10х2—хЁ—34 )+2т1щ

и принимает в точке х = [3,25 3,25 1Т значение 1047,72.
 pagebreak 
М етоды штрафных функций 865

 

Вычислим прежде ВСБГО частные ПРОИЗВОДНЫЕ Р-функции В точке
х = [3,25 3,251’:

 

 

др дтр _ дяр _

152,‘ = —46,505‚ дх, _ 69,084, № _ 84,525,
др дяр _ д*Р _

7,52— = _- 57,006, дх; _ 69,084, @ _ 84,525.

Матрица Г ессе для функции Р не является положительно опре.
деленной, так как при положительном значении определяющего
элемента

с!еі 69,084 84,525
84,525 69,084

Поэтому составляющие вектора, определяющего направление поис-
ка, направлены вдоль составляющих отрицательного градиента
функции Р. Вектор х…і’ изменяется следующим образом:

х : х…), + Ахо»,
и для начального шага теперь имеем

49,755 = 3,25 + 46,505
60,256 3,25 57,006 ’

Далее процесс минимизации Р-фунщин реализуется методом Фи-
боначчи; поиск продолжается до тех пор, пока не будет достигнут
точка х = [3,516 35777 (в действительности результш'ы поиска
оказываются вычисленными с точностью до пятого десятичного

 

знака).
Теперь ВНОВЬ ВЫЧИСЛИМ частные ПРОИЗВОДНЫЕ Р-фуНКЦИИ:
др дар __ дяр _
79},— = 6,119, 3х? ›— 99,613, № _ 100,628,
др апр тр _
'ы;— = 2,160, 6х3 : 101,024, №1— —- 100,628.

При этом матрица Гессе для функции Р опять не является положи-
тельно определенной, так как

еі 99,613 100,628
100,628 101,024

Таким образом, поиск методом Фибоначчи вновь реализуется в на—
правлении отрицательного градиента; этот поиск осуществляется
до тех пор, пока не будет достигнута точка х = 12,137 4,7021Т.
Минимизация функции Р продолжается следующим образом. В точке
 pagebreak 
366 Г лава 7

 

  
 

‚12°
5
‚10
)#
‚№
4
“4.390
3 > , ’
2
! я!:пЬШд—ау'ч- 7012—15-31: 3 0
; іі!=:)=25—аг,‘—х‚’=0
0 , ,
а 1 2 .7 4 5 .и,

Ф и г. П.7.2.1. Траектория оптимизационного поиска с помощью МПБМ (чиола
означают порядковый номер вычислительного этапа].

х, для которой матрица Гессе для Р-функции положителъно опре—
делена, используется соотношение (7.2.10).

После 23 итераций вдоль соответствующих направлений опти-
мизационного поиска значение параметра г (начальное значение г =
= 1) начинают вчетверо уменьшать. Значения переменных х1 и
х2, а также функцийі (х), Р (х, г) и Е (х, 7), вычисленные при умень—
шении г, приведены ниже:

 

 

 

 

13353 Ваш) і‹х› Р‹х.г› х. ”в 11.09

13 1 42,990 41,593 49,400 1,150 4,918 _1,01.10-1
23 1/4 49,270 —З1,807 40,959 1,073 4,909 4153.10“
33 1/16 —З2‚065 41,902 41,547 1,037 4,904 4,2910-1
42 1/64 ——З2,0Н —31,948 —-31‚788 1,019 4.902 —6,З4—Ю_2
51 1/256 41,997 41,970 41,995 1,010 4,900 _з,17.10-2
55 11024 41,993 41,944 41,944 1,000 4,899 ———1,58_10“2

62 1/4096 41,993 —31,987 —31.969 1,004 4,899 43410“3
68 1/16384 41,992 41,990 —31,981 1,002 4,899 495.10—з
 pagebreak 
Методы штрафных функций 367

 

Отметим, что имеет место типичная сх0димость функций Р и В к
минимальному значениюфункции [ (х). Обратим также внимание на
верхнюю границу, определяемую функцией Р, и нижнюю границу.
задаваемую функцией Е. Колщество вычислений, связанных с
получением оценок указанных выше функций и их частнъхх произ—
водных, на разных этапах оказывается различным и варьируется
от 11 на первом этапе до 4 на последнгм этапе (число вычислений
упомянутого характера зависит, разумеется, от требуемой точности
результатов вычислений при Одномерном поиске). Траектория
оптимизационного поиска показана на фиг. 1172.1.

 

 

ЗАДАЧИ 1)

7.1. Рассмотрите следующую задачу:

минимизировать [(х) = х? + 6х1 + хЁ + 9
при ограничениях

@(х): х,>0‚ (і: 1, 2).
Пусть минимизация осуществляется с помощью МПБМ, начиная

из точки х(°) : {1 0,517.

а) Вычислите 71°), используя соотношения (7.2.2)—(7.2.4). Ка-
кой способ задания №, с вашей точки зрения, является наиболее
предпечтительным?

б) Пестройте функцию Р (х, ‚‹о›)_

в) Найдите х… и і (х…) спомощью любой оптимизационной про-
цедурыв рамках МПБМ. Каким образом можно Избежать опасности
выхода за пределы допустимой области?

г) Реализуйте некоторую последовательность этапов оптими—
зационного процесса.

д) Какие из шести условий, сформулированных в подразд. 7.2.2,
выполняются для рассматриваемой задачи?

е) Выполните проверку на сходимость на каждом из вычисли-
тельных циклов, используя критерии останова, сформулированные
в разд. 7.2. Удовлетворяются ли критерии останова, если Р-функция
выпуклая?

7.2. Можно ли сформулировать задачу, двойственную по оггн0‹
шению к задаче 7.1? При положительном ответе сформулируйте
соответствующую двойственную задачу и реализуйте несколько
ИТерационных циклов при ее решении. Исследуйте тенденции, ко-
торые обнаруживают решения исх0дной и двойственной задач,
и проверьте, выполняются ли неравеНства (7.2.9).

_“—

1 …
) РЯД задач, имеющих отношение к содержанию даннои Главы, МОЖНО найти
также в конце нь 6 и в приложении А.
 pagebreak 
368 Глава 7

 

7.3. Повторите пункты задачи 7.1 применителъно к условиям
следующих задач:

&) минимизировать і(х) = 16% + хЁ
при ограничении

%! (Х) = х? + хЁ— 9х2 + 4,25 = 0;
б) минимизировать [(х) = ея. _|_ еж,

при ограничениях
их) =хЁ+хЁ—9 =0‚
$100: х1+х2"'1>0‚
32 (х) = 351 > 0,
33 (Х) : 162 > 0-
7.4. Прокомментируйте структурзхые особенности Р-функций,
построенных для решения следующеи задачи:

минимизировать )* (х)
при ограничениях

81(Х)>0‚ і=1‚2‚...‚т‚

начиная с допустимой стартовой (Начальной) точки. УпомянУтые
выше Р-функции имеют следующий вид:

1

(‚е) _ т 1
&) Р(х‚ х )— [(№№—Дх) +;1`Гш ‚

т
аг ие) игл !:
6) Р‹х*› =і(х ›—г 2 №№”).
с=1
Какие преимущества имеют эти функции по сравнению с (7.2.1)?
Какие неудобства возникают при их использовании?

7.5. Изобразите графически уровни штрафной функции Физк-
ко—Мак-Кормика для следующей двумерной задачи:

минимизировать {(х) = ()с1 — 3)2 + (::.2 — 2)2

при ограничении
п(х)=;‹:1 +х3—4=0.

Используйте различные значения параметра г.

7.6. Задача оптимального размещения в трехмерном простран—
стве единицы оборудования игносительно конфигурации, уже со-
держащей (п— 1) фиксированных (в смысле дислокации) единиц
оборудования, формулируется следующим образом:

минимизировать

3 = Ё 0! [(хъі —- 1602 + (752) '°* хи)“ + (953; _ #6517“,
(=!
 pagebreak 
Методы штрафных функций 369

где 5 — суммарные затраты, х1‚ х„ ха — координаты местонахож-

дения новой единины оборудования относительно «нулевой тэч`

ки», х… х‚‚›‚ хз,- _ координаты уже имеющегося оборудования
Ограничения имеют вид

3х1+3х3< <80 и 3:1, хе, хз>0

Значения с, и х,; указаны в приведенной ниже таблице:

 

! | “1 } "1/ ’ "2/ 1 "431
1 1 О 0 0
2 [ 10 0 0
3 1 10 Ю 0
4 1 0 10 0
Б 1 О 0 10
6 1 10 0 10
7 1 10 10 10
8 1 О Ю 10

 

а) Покажите‚ что 8 _выпуклая функция. (Замечание. Апгебраи-
ческая сумма выпуклых функций есть также выпуклая функция,
поэтому требуется лишь убедиться в том, что [():1 — ад2 + (::2 — “92 +

2 Ч: .. ..
+ (хэ— аз) ] представляет собои выпуклую функцию. Используите
в ходе доказательства неравенство Коши —Шварца

ПёддЁЮТЪЁа

И соотношение (241), прибавив к правой и левой его частям

622 х,- +(1—9)32 у,. Можно также воспользоваться свойствами
і=1 г=1
«а» и «б», ассоциированными с (2.4.2).)

6) Покажите, что функция, эадающая ограничение, является
выпуклой.

в) Докажите, что для рассматриваемой задачи выполняются
условия 1—6, сформулированные в подразд. 7.2.2.

г) Постройте Р-функцию.

д) Покажите, что для №) = 100 при стартовой (начальной)
точке ХШ) = [0 2 017 и 8— = 86 540 первый этап оптимизационного
поиска вдоль градиента функции Р (х) приводит в точку х… =

==,!1 03 1,03 1‚т031,для которой Р (х) = 97, 237 и 8 (х)= 82,782.

е) Каким должно быть очередное значение 7?
 pagebreak 
370 Г лава 7

 

ж) Сколько потребуется итераций для того, чтобы понизить
значения составляющих вектора \7Р (х) до числа, меньшего 104?
104?

3) Покажите, что решение рассматриваемой задачи имеет сле-
дующий вид:

х*=[1/3 1/3 “317, Р(х)=71,817, 8(х)=71,816.

7.7. Проверьте, удовлетворяют ли задачи 6.17, 6.18, 6.20, 6.25
и 6.27 условиям сходимости МПБМ.

7.8. Рассмотрите следующую задачу:

минимизировать {(х) = (х1 — 2)‘ —|— (хя— 1) “

ПРИ ограничениях А
2

в1‹х)=——ЁЬ—хё+1>о‚
п„(х)=х‚—-2х2+1=0.

а) Постройте Р-функцию Фиакко—Мак-Кормика при г =
= 0,04. Изобразите построенную Р-функцию графически (если смо—
жете найти надлежащий способ графического изображения уровня
этой функции).

6) Определите направление оптимизационного поиска из на-
чальной внутренней точки ХФ) = [07489 0,548511.

в) Найдите вектор х….

г) Может ли одна Из точек х“) оказаться вне допустимой об-
ласти? Ответ поясните.

7.9. Преобразуйте задачи, указанные в упражнении 7.7, в за-
дачи минимизации путем использования надлежащих Р-функций.

7.10. Сравните (для некоторого числа итераций) скорость мини-
мизационного процесса для задачи, приведенной в подразд. 7.2.1,
со скоростью минимизации, если в качестве обобщенной присоеди—
ненной функции (вместо рассмотренной в подразд. 7.2.1) взять
следующие функции:

1

а) Р №, г‘”) =1°(Х) + 7; ; и;. №) — № 7% ; т, №) —
— 01“;

б) функцию, фигурирующую в (7.2.1а).

Придайте константе с некоторое кенкретное значение.

7.1]. Сравните Р-функцию, изображенную графичкки на
фиг. 7.2.1, с Р-функциями, упомянутыми в упражнении 7.10. На-
чертите Линии уровней этих Р-фунщий при таких же значениях
х1 и х„ как в случае, проиллюстрированном на фиг. 72.1. Ответьте
для каждого из вариантов выбора Р-функции на следующие во-
просы:
 pagebreak 
Методы штрафных функций 371

 

а) Сохраняется ли разрывность на границе области внутрен.
них точек?

6) Как повлияет на траекторию поиска выбор стартовой (на-
чальной) точки? По-прежнему ли необх0димо выбирать в качестве
стартовой (начальной) внутреннюю точку?

7.12. Рассмотрите следующую задачу:
минимизировать НХ) = 4х1 — хЁ— 12
при ограничениях

81… = 1015—х? +10хя—хЁ—З4>О‚
82(Х):х1>07
Ев(х)=х2>01

выбрав в качестве начальной точку к“” = [2 41Т.
Изобразите графически уровни {(х) в области

0<Х1<6,
0<х2<6

(пусть это будет график А). Наложите на полученное вами графи—
ческое изображение кривую, заданную уравнением 31 (х) = 0.
Начертите уровни постоянных значений для функции (7.1.7) при
с)! = 1 и значениях г, равных 100, 1, 104, 10“1 (т. е. требуется
начертить четыре графити: В1, В2, ВЗ, В4), Для каждого значения
7 миНИМизируйте Р (х, г), начав оптимизационный поиск в точке х<°>
и используя алгоритм Дэвидона — Флетчера — Пауэлла. Изобра—
зите графически траектории поиска отдельно для случаев В1, В2
и ВЗ и наложите графики этих траекторий на график А.

Какие выводы можно сделать относительно выбора тд”?

7.13. Мощность, потребляемая миксером-нагревателем промыш-
ленного назначения, выражается формулой

Р = 2,63 - 1045$“? (—Ч3
60

где Ь — диаметр импеллера, фут; п — скорооть вращения импел-
лера, об/мин; р. — вязкость; в —- удельный вес; а Р —— эмпиричес-
кое выражение.

Для чисел Рейнольдса “, превышающих 150, Р = (р/З750тй)°'°5‚
тогда как для чисел Рейнольдса, меньших 150, 1" =
= 33,3/<з7505пь2/д)°-75.

Определите минимальную мощность, требуемую для функцио-
нирования миксера, вмещающего 6000 галлонов жидкости, удель-
ный вес которой равняется 0,8, а вязкость — 200.

№

1 .
) Числа Реинольдса выражаются через днаметр импедлера, скорость враще-
ния импедлера, удельный Вес перемешиваемой жидкости и ее вязкость.
 pagebreak 
872 Глава 7

Исходньш данные. Для простоты будем считать, что зазор между
импеллером и внутренней поверхностью бака, в которую заливает-
ся жщкость, равняется 8 дюймам. Число Рейнольдса определяется
по формуле
__ атеми

Р

Стоимость бака находится из расчета 100 долл на 1 фунт металла.
в толщина стенки бака должна быть не менее 0,25 дюйма при вы-
соте до 6 футов и не менее 0,375 дюйма при высоте, превышающей
6 футов. Ежегодные расходы, связанные с обслуживанием и капи-
тальным ремонтом миксера, составляют 25% СТОИМОСТИ бака; за-
траты на энергоснабжение 0,01 долл за ! кВт-ч. Суммарное время
эксплуатации миксера в течение года составляет 6000 ч.

7.14. Разработка оптимальной модели функционирования хими-
ческою завода сопряжена с необходимостью решения следующей
задачи:

максимизировать

дх>=№№№чщ

Ке

Где
2 = 0,3% —— 0,02х1 _— 0,03);2 _ 0,01% + 0,006861,

5=И1+ув+ув+уд+у5+у6,
"“ : ув—Одуд,
Ц: (З—ХЬ—у5)хв‚

ПРИ ограничениях

х_хзш %% = ,
х2—”Ву=——°‘Ё+”——і*“;2№=о‚
—х8у8+2-%Ё_23_ЁД_№=0,
…%- г “32“ = ‚

— —+1‚Бі{;і=о‚

 

0,1у„‹1 — ха) —ув „ №45 ___„Ёу, = 0,

где
01 = 5,9755 . 10° . е—Ш'іо'лхмет'

02 = 2,5962 ‘ 10п . е—15‹10'/‹х.+4ео›’
сэ = 9,6283 . 1015 . е“2о"°’/(Х.+4во>_
 pagebreak 
М втоды штафных функций 373

 

7.15‚ Галлер и Г отас [211 сформулировали следующую задачу
нелинейного программирования, связанную с проблемой оптими-
зации затрат на эксплуатацию фильтровальной установки (подроб-
ности, относящиеся к постановке задачи, см. в работе 1211):

минимизировать
24: $7 : % 117 :: літх 2
Г(Х)=(—%Ш+"`%7Ь+дй—” +с2пх1+
9
свпхіхд хз 053 Х 8,34 Х 365 Х 358031 + ')
+ Т + 2сдх1 + _дв + „да) + 2,65р
при ограничениях
Х [ 43 560 ($ + "В) ]'/п
1 = “"‘“— '

пО
1 (314+ хэш…“ _ ‚_ = 0
($ _'_ ‚69018062 + “0,67 (х1)0‚25 ” '
0 < хз < 48,
3 < хв < 10,
шах{10‚ (№№} < ус! < 100.
Найдите минимум Г (х) и определите х*‚ основываясь на следующих
данных:
с1 = 80, К1 = 0,219,
02 = 4, 17 = 1,
св= 10, Р = 1,
ед = 53, $ = 1,
„5 = 3,2 _ 104, р = 07,
сб = 5,55, п = 3,14159,
с‚ = 0,01, 1,1 = 200,
[„ = 30.

7.16. Клейн и Климпел в работе [22] описали задачу нелиней-
ного программирования, связанную с попском оптимального реше-
ния относительно выбора мест для строительства промышленных
предприятий и определения размера этих предприятий в каждом
из выбранных мест; предполагается, что речь Идет о выработке
решения для некоторого заранее установленного интервала вре-
мени. Основной и оборотный капитал можно записать в следующем
виде:

Основной капитал = а0 + 1118“,
Оборотный капитал : 170 + !71Р + 1738“.
 pagebreak 
374 Г лава 7

 

Здесь $ —— размер предприятия, Р — проектная мощность пред-
приятия (объем продукции, выпускаемой за год), ад, 1)… а„ [71 и 172 —
известные константы, опредеЛяемые эмпирическим способом.

Затраты в течение года (переменная величина) определяются
с помощью следующей формулы:

Затраты = Р (01 + 028 + СЗЗ“).

Предполагается, что при заданном пункте отправления и фик-
сированном пункте назначения транспортные расходы пропорцио-
нальны объему перевозок.

Целевой функцией является чистый дисконтированный капитал
(ЧДК), т. е. сумма дисконтированных капиталовложений; при эгюм
норма дисконтпрования полагается равной 10%.

Предполагается, что движение всех денежных средств, за исклю-
чением вкладов на капитальное строительство, происходит в течение
года равномерно; оборотный капитал учитывается (либо со зна-
ком плюс, либо со знаком минус) дискретно в начале каждого года‚
а Основной капитал учитывается (со знаком плюс) лишь в начале
планового периода (т. е. в начале «нулевого» года).

В непрерывном представлении коэффициенты дисконтирования
выглядят следующим образом:

1. Для одновременных вкладов

і = ечу,
где ! —— процентная ставка на размещенный капитал, у —— длитель—
ность периода в годах.

2. Для равномерно (во времени) реализуемых вкладов

г—1
Ри = %— е "‘.

Переменная 11 может принимать как положительные (после на-
чала отсчета времени), так и отрицательные значения (до начала
отсчета); в конце года‚ являющегося началом отсчета времени,
у = 0.

Поскольку цены и статьи дохода Клейном и Климпелом не рас-
сматривались, максимизация ЧДК эквивалентна минимизации се-
бестоимости.

Обозначим через Рщ объем продукиищ доставленной с і—го пред—
приятия ([ = 1, 2, 3, 4) на рынок сбыта ] (] = 1, 2, 3) втечение іе-го
года (із = 0, 1, 2, 3). Пусть 8, и 8, представляют собой соответствен-
но размер і-го промышленного предприятия и переменную, прини—
мающую значение 0 или 1 в зависимости от того, равняется или не
равняется нулю ведичина 81. Обозначим через Мой уровень спро-
са в 1—м пункте сбыта в іг-м году, Накенец, для удобства обозначим
через Р.… суммарный объем продукции, выпускаемой і—м предприя-
тием в !г-м году.
 pagebreak 
Таблица А
Чистый дискшпировапшый капитал

______________________________________________———_——————
1. дела основного капитала (предприятие № 1)

 

 

 

 

 

 

 

 

Коэффициент
Гэд Основной капитал 'дисиинтирова- Дисконтнрованннй основной капитал
‚ ННП
0 (1967) 0,7 5, + 1,5 395 10517 \ —0,7302 5, _ 1,5775 $$$
?. Доля оборотного капитала (предприяше № 1)
К
5212“ ово…ыиммыл „2165311 диштнжжжжжжт№

_______________________._______—_——————

0 0,4 5, + 0.2 р… + 0,05 з'д'е 1,000 _.0,4 3, _ 0.2 р… _ 0,05 59-5

1 0,2 (Р… _ Р…) 0,9048 —0, 1810 Р…2 + 01310 р…

2 02 (Р… _— Р…) 0.8187 —0‚ 1637 р…, + 0,1-637 Р…,

3 +04 51 _ 0,2 р…, _ 0,05 33-е 0,7408 +0,2903 31 + 11,1482 Р…в + 00370 3%“
________________________________________——_——
3' “:? ЁЁЁЙЁЁЁЪЁЁЁЖЗ“УЗЕЁЁЬЁЁЪЁЪЩЁЁЁЁЁЁ; ”"' "

Г ПЁЁЁ' ] Амортизация“ другие затраты
№
1 р… 0,4667 5, + 1,0 59-6 0,03 5, + 0.0151 + 0.05 39-45 + 0,07 5‘,“ + 0,1 р… _ 0,005 Р…з, +
“‘ 014 131015143'55
2 Р… 011673, + 0,25 $?“ 0,03 $, _ 0.01 $, + 0,05 3%45 + 0,07 32.6 + 0,005 р… — 0,0048 17…23, +
__ 0,38 р…згМё
з Р…З 0,1166 5, + 0,25 3316 0,03 $, + 0,01 3, _- 0,05 39,45 + 0,07 з'і—б + 00903 Р…, _

__ 0,0045 Р„„з, + 0,361 Р…З,

____________________________________._________—__
 pagebreak 
П родолжение табл. А

 

6. Результаты шісионтнрования затрат (предприте № 1)”

 

 

 

 

Коэффн-
Год „&&&;н- Результаты дисконтирования при норме дисконтиравания. ранней 10%
рования
1 0,9516 0,1983 3, + 0.0049 5, _— 0024755“5 + 0, 4221 53»6 _— 0,0495 Р… + 0.0025 Р…з1 _ 01979 13101370155
2 0,861! 0.0348 5, + 00045 5, 410224 5%“, + 00720 59-6 — 0,0425 Р… + 00020 Р№$д _0‚1702 Р№$Г°Ы
3 07791 00315 $, + 0.0041 3, _ 00203 3545 + 0.0651 59.6 _— 0,0366 Р… + 0,0017 13,0331 _ 0,1463 р…,зі'л55
4. Учет транспортных раскидав (при перевозках с предприятия № 1)
…… „5211111355; т„‚„…„,‚,……№ №№… №°№°33312н1°03°№ №………„_
ния
1 09516 0,8 Р… + 0.5 Р… —— 0,396 р… + 0.247 !>…
2 0,861! 0,7 РШ + 0,45 Р… — 0,313 Р122 _ 0,201 РШ
3 0,7791 0. в Р,25 + 0, 4 Р… _ 0,243 Р123 _ 0.162Р133

1) Приведенные здесь результаты получены с помощью мтдов так называемых наклонных и юрнэот'альиых шщонтнрующнх сечения.
 pagebreak 
Таблица Б

 

2

Целевая функция

 

шах :

_ 0.5753 3, _ 1.0313 3%“ _— о,оввв Р… _ 0,0597 Р…, _ 0,0522 Р…, + .

+ 0.0135 5, _ 0,0074 33145 + 0.0025 Р…з, + 0,0020 13,0251 +
+ 0.0017 Р…з, __ 0,1979 Р101$г№ _ 0.1702 Р…згд“ —

— 0,1403 Р,.„зг0—55 _ 0,396 Р… _ 0,247 р… _ 0313 Р… _

_ 0.202 РШ — 0243 Р… _ 0, 162 р… _- 0,3423 3, — 0.8920 536 _

— 0.0535 Р… _ 0.0597 Р… _— 0,0522 р...„ + 0,0135 3, — 0.0309 52-45 +
+ 0.0025 р…в, + 0.0020 Р…З, + 0.0017 р…з, _ 0,2227р…5;°—55 _—
_— 0.1914 Р…з;°'55 __ о, 1645 Рдда${°'55 _ 0, 396 Р… _ 0,495 Р… _-

_— 0‚з1з р… _ 0,448 р… _ 0,243 Р… _- 0,405 Рява _— 0‚з164 $; _—

_ 1,2987 53,6 _ 0.0942 Р… _— 0.0819 Ра„ -— 0,0712 ры. — 0,0539 3%“ +
+ 0,0030 Р„„З, + 00026 Р,…‚зЗ + 00022 Р,.„з, _— 0,2227 Р„,$3°°'55 +
… 0.1914 Р№$3_°*55 — 0.1645 Р….ЗЗ'О'ББ _ 0,247 Р… _ 0.495 Р… _

__ 0,202 Р… _ 0,443 РЗ“ _ 0.162 Р… _ 0,405 РЗ“ __ 0.2441 Б, _

_— 1,з707 5346 _ 00577 р…_ 00504 р.,.‚г 0,0440 р… + 0.0020 р…з4 +
+ 0.0017 ”„484 + 0.0015 Ршв. _ 0,1484 Р„‚$;°-55 _

_— 0‚127в Р.„‚$;°›55 — 0.1097 Р…$;°155 _ 0495 Р.… __ 0,099 Р… _.

__ о_о4о р… _ 0,448 Р… —0‚090 Р… —- 0040 Р… —— 0,405 Р.… —
_— 0,088 Р.№ — 0,041 Р№

 

Таблица В

 

Константы

 

(1) $1+$д+$3+5д=10 (2) ‚31114475111"'Раіі’і'р411=1
(3) Р11г'Р91я“Рзп"Рап°4 “) Р11з+рпв+рз1з+рпа=5
(5) Р191+Ряз1"рви”рш=2 (6) Р,„+Р„‚+Р3„›—Р„‚=3
(7) Р125+Р9ш*‘рваэ+р4вз=2 (8) Р1з1+Р231+Р331’—Р431=4
(9) Р139"Р2314+Р332+Р439=3 (Ю) Р1ав+разэ+рзги“рдзз=2

‹…
‹…
117)
(20)

 

 

 

 

Р… _ 54 < 0 (12) 17104 — 31 < 0 (13) Рюз — 31 < 0
Рт1—52<0 (15)Р202_51<0 (16) Р203_32<0
Р301—$а<0 (18) Рво9_53<0 (19) рзоя—33<0
Р… — 54 < 0 (21) Рш _ 54 < 0 (22) Риз -— 3. < 0
 pagebreak 
‹ пз Глава 7

 

Задача нелинейного программирования заключается в том,
чтобы определить $, и Р…“

максимизирующие 2 ЧДК (с учетом транспортных расходов)
‹
при ограНИчениях

2 рта = Мот,
;
3120, Ріііг >0‹

В табл. А показан способ определения ЧДК для предприятия
№ 1; для других предприятий ЧДК находится аналогичным обра—
зом. В табл. Б приведена полная структура целевой функции, а в
табл. В указаны 22 ограничения: ОДНО ограничение в виде равенст-
ва, лимитирующее полную производственную мощность предприя-
тия (10 миллионов фунтов в год), девять равенств, обусловленных
требованием полного удовлетворения спроса на трех рынках сбыта
в течение года, и 12 неравенств, ограничивающих превышение
парциальных производственных мощностей рассматриваемого
предприятия. Кроме того, следует иметь в виду условия неотрица-
тельности для всех переменных (число переменных равняется 40).
Таким образом, рассматриваемая задача содержит 10 ограничений
в виде равенств и 52 ограничения в виде неравенств.

ЛИТЕРАТУРА

1. Ріассо А. У., МсСогтісК @. Р.‚1\10п1іпеаг Ргоегатшіпе, “11'1еу, М. У., 1968.

2. Евпашт \У. 11, Мапаветеп! За., 13, 344 (1967).

3. Ниагкі Р., Кезош‘сіоп ае ргоегаттез таше'таіічцез & сопігаіпіез поп1іпёаіге5
рат 1а тёшоде дез сепігез, Ноге Е1есіг1'сііё ‹іе Ггапсе, НК 5690/3/317, 1964;
см. также ТЬе Метод оі Сепіегз іп: Соцгзе А., МопНпеаг Ргоегашшіпд, Могін
НоНапсі РЦЫ. СО., Атзіегйаш, 1965.

4. Ріассо А. У., МсСогтісЪі С:. Р., Орегаііопз Евы, 16, 820 (1968)‚

5. Ріеігщйошэйі Т., Арр1ісаііоп оі 111е Зтее е51 Везсепі Ме’токі 10 Сопсаче Рго-
впишите, Ртос. 1Р1Р5 Солана, МцпісЬ, от] НоПапа РЦЫ. Со1, Атэіегдаш,
1962.

6, Ріассо А. У., МсСогтіск @. Р., !. Зое. !ті. Аррі. Май., 15, 505 (1967).

71 Ріассо А. У., Р11. 1). Віэзегіаііощ ЫотіЬшеэіегп ит., Ечапзіоп, Ш., 1967.

В. Вебппіз 3. В„ МаіЬетаНса] Ргоегатз апа Е1ес1гіса1 Ыеішогйз, \УПеу, М. У.,
19 9.

9. Вох М‚ Л., Вачіез 11, Эшапп \У. Н., Ыоп1іпеат Оріітіиаііоп ТесЬпі цев,

1С1 Моповгарй оі Маіпетаіісз анд Зіаіізіісз, № 5, ОХіуег анд Воуй Ш.,
Ьопдоп, 1969.

10. Сагго] С, Ш., Оретііопз дез., 9, 169 (1961).

11. Вачіез В., Зоте Ргасііса] МеіЬодз [ог Оріітіиа‘сіоп, Ыоіез іог Ше ЫАТО Эшп-
тег 51211001 оп 1п1еаег апкі Мопііпеаг Ргоегатшіпе, Зцпе 8—20. 1969.

12. \Пеізтап З., РЬ. [). Віззегіаііоп, Ппіч. оі РіНзЬцгф, Ра., 1968.

13. Ріассо А. У., МсСогтіск @. Р., $1АМ !. Арт, мат., 15, 505 (1967).

14. Ниага Р., р‚ 209 іп: Ыоп1іпеаг Ргоагаттіпе, АЬайіе Л., ей., Мог… Но11апа
РцЬ1., Атэйегёат, 1967.
 pagebreak 
М поди штрафных функций 379

 

15. Сапо11 С. Ш., Орегап'опз Кез… 9, 169 (1961): РЬ. 1). Віззегіаііоп, 1п51. ог Рарег
СЬетізігу, Арр1еіоп, 111/15… 1959.

16. Ёіассо А. У., МсСоппіск Ст, Р., Мапаввтепг ЗЫ., 10, 360, 601 (1964); 12, 816
(1966).

17. Шогітап .1. В., ВНЬ 1958 (ЫЬРЦОО), Зап. 1969.

18. Мцггау Ш., Ргос. 6111 1п1егп. Зушр. оп Магнетаіісш Ртоегатгпіпд, Ргіпсеіоп,
М. д., 1967.

19. Р1е1с11ег К., МсСапп А. Р., СЬар. 13 111: Оріітіиаііощ Р1еіс11ег К., ей., Асикіе-
гпіс Ргезз, Ьопаоп, 1969.

20. ТаЬаК В., [ЕЕЕ Тгапз. Аиіотаііс Сопітд АС", 572 (1969).

21. (ЁаПег “(376 $., 60135 Н. В., !. Запіі. Епд. Віц, Ат. Зао. Сіш'! Едет, ЗА],
1 з (19 ).

22. К1еіп М., Кіітре] 12. К., !. !тіиз. Еще., 18, 90 (1967).

ДОПОЛНИТЕЛЬНАЯ ЛИТЕРАТУРА
методы множитвлви ЛАГРАНЖА

Аггош К. Л., Нцпш'си !.., Огайіепі Меіпоаз іог Сопзйгаіпекі Оріішіиайоп, ]. Оре-
!аііапз Кез. Эт., 5, 258 (1957).

Вапі У., Сктеепзіасіі .|. Ь„ А. Моаіііыі Метоп Метод іог Оріітіиаііоп №1111
Ечпаіііу Сопэітаіпк, іп: Оріітіиайіоп, Р`1е1с11ег К., ед., Асааешіс Ргезз,
Ыпдоп, 1969.

00…99]. $„ Оп Ьаегапде Ми1іір11‘егз апс! 1печиа1іііез, ]. Орегаііолз Кез. Зоо., 9,

5 (1961).

Ечегеі’: Н., 6епега1іге11 Ьаегапее Мці’сірНег Меіпойз іог 501111115 РгоЫетз оі Оріі-
ша] Аііосаііоп оі Ке5оцтсез, Орегаііопз Еж, 11, 399 (1969).

Раш .1. Е… Ъаагапее Мц111р1іег5 апа Ыопсопчех Ргоегатз, Кез. Апа1узі$ Согр.
Тес11п. Рарег КАС-ТР-ЗЗБ, Меч. 1968; Ьаегапве МЦ11ір1іег5 апа Моп1іпеаг
Ргоагаттіпд, .]. Мат. Апаіувіз Арр!., 19, 141 (1967).

Кіеіп В., Вігесі Цзе оі Ехігетаі Ргіпсіріез іп 501х411; Сегіаіп Ор’гітіиіпв РгоЫешз
1пчо1чіп9 1печца11'11е5, .] . Орегап'ппэ Кез. Зоо., 3, 169 (1955).

Кн]… 1-1. “!., ТцсКег А. №., ЫопНпеаг Рговгаштіпд, Ргос. 2пс1 Вегкыеу Зушр.
оп Маш. 5131151. РгоЬ.‚ Ппіч. Саіііогпіа Ргезз, Вег1‹е1еу, Са1іі.‚ 1951, р. 481.

ТаКаЬазЬі 1., УагіаЫе Бератасіоп Ргіпсір1е іп Маійешаііса] Ртовгатшіпд,
]. Орехагіопз Кез. .!арап, 1/01. 6 (1964).

Ешап, .]. Орг. Тпеогу апа Арр1.‚ 6, 150 (1970).

МПБМ

ВгасКеп ]„ МсСогтіск &. Р., $е1ес1ед Арр1іса’гіоп5 0$ ЫопНпеаг Ргоегаштіпа,
Ші1еу, М. У.. 1968.

Ріассо А. У., МсСогтіск 6. Р., Ыоп1іпеаг Ргоегашшіпе: Зечцепіігп Цпсопзігаі-
пед Міпітіиаііоп ТесЬпіццез, \УіЬу, М. У., 1968.

Ьоо’сэта Р. А‚‚ Ьовагііпшіс Ргоетагпшіпе: А Ме11юс1 01 $о1чіпв Мопппеат Ргохгаш-
шіпе РгоЫетз, Рттрз Кез. Нет., 22, 329 (1967); Сопзігаіпед Оріішішііоп
чіа Репаііу Рипсііопз, Рпітрз Кез. Кері.‚ 23, 408 (1968).

Ротеп1а1е Т., А Мех» МеШші Гог 501чіпе Сошііііопеа Махіша РюЫешз, .]. мат.
А_па!у$і3 Арр!.‚ 10, 216 (1965).

5с1пп11 1„ А., Ап 1п1е3га1еа АрргоасЬ іо $1гцсіцга1 Апа1у$15 апс1 ЗупЁЬезіз,
А1АА .1., З, 1104 (1964).

ДРУГИЕ МЕТОДЫ

А11гап К. К, ЗоЬпзеп 8. Е. ]., Сотри!” !., 13, 171 (1970).
Ве11тоге М., &геепЬегд Н. Л„ Лагщ'з .]. ]., Оре], дез., 17, 229 (1969).
 pagebreak 
380 ‚ Глава 7

 

РЫсЬег Н., МсСапп А. Р., Ассе1егаііоп ТесЬпічцез іог Ыопііпеаг Ргоегаштіпд,
іп: 0рііші2аііоп, Ріе‘сспег К., ей., Асааешіс Ргеэз, Ъошіоп, 1969.

Наагіюіі Р. С., Вцуз 1. В., Сотрш‘ег ./., 13, 78 (1970).

Ниагд Р., Кезоіц‘сіоп оі МаіЬетаіісаі Ргоегаштіщ; ті’т ЫопііпеагСопзігаіпіз
Ьу іЬе Метод оі Сепіегз, іп: Моп11'пеаг Ргодгаттіпе, АЬайіе д., ед., №№
НоНапсі РцЫ. СО.. Ашвіегдагп, 1967.

КеНеу Н. ]., ВепЬаш “7. &., .ХоЬпзоп 1. 1… №еаі1еу Р. О.. Ап Ассе1ега‘сеа Сна-
&іеп! Меыюа іог Рагаше’сег Оріішіъаііоп шт; Мопііпеаг Сопэігаіпіз, .]. Авт:-
лапша! за., 13, 166 (1966).

Котайк ]., ОзЬогпе М_ П., Куан В. М.. А №№ Меіпоё {от Сопзігаіпей Оріішіиа-
ііоп РгоЫетз. Орегагіипз Евг., 17, 973 (1969).

!.азйоп Ь. Э., Ап Етсіет Аідогііпт [ог Міпітіиіпе Ваггіег апп Репаііу Рцпсіі-
опз, ТесЬп.Мешогатіцт№ 210, Орегаііопз Кез. Верагі.‚ Сазе Шезіет Це-
зете ит., Вес. 1970.

Ъоошпа ?. А., Воцпаагу Ргорегііез оі Репаііу Рцпсііопз іот Сопзігаіпеа Міпіті-
иаііощ Маі. Теспп. іпіогт. Зетісе, Восишепі [“О—33412, 1970.

МОГГЁЁОП ВЁЗВ" Оріітіиаііоп Ьу Ьеаэі Эчцаге5‚ ЗИМ ]„ Митегісаі Апаіузіз, Б.

(19 .

Мцггау “’., ёопзігаіпесі Оріітіиа’сіоп, Ыаі. РНуз. ЪаЬ. Кері. № МА 79, Авг. 1969.

Мцггау “і„ ВеЬачіог оі Неззіап Маігісез оі Ваггіег аті Репаиу Рцпсііопз Агізіпд
іп Оріішіиііоп, №11. рпу5‚ !.аЬ. Кері. № НА 77, Аргіі 1969,

Рошен М. .1. В., А МеіЬосі іог Мопііпеаг Сопзігаіпіз іп Міпішіиаііоп РгоЫетв,
іп: Оріітіиаііоп, Ріеіспег К., ей., Асааетіс Ргезз, Ьопдоп, 1969.

Запиши]… Е., Ьагке 5’сер бтайіепі Метоаз, СЬар. 8 іп: Оріішіщаііощ Ріеісйе;
И., её., Асааетіс Ргезз, Ьопдоп, 1969.

Зіайап Л. М., МсВопаШ .|. Р., ОРТ1РАС: ТЬе Везіепетз Оріішіъа‘сіоп РгоЫет
Зоічег, 2 001$, МсМаэіег Ппіщ МесЬ. Епдіпеегіпв 0ерагі.‚ Нвтіііоп, от.,
Санада, Осі. 1969.
 pagebreak 
Глава 8

ПРОЦЕДУРЫ МИНИМИЗАЦИИ ПРИ НАЛИЧИИ ОГРАНИЧЕНИЙ:
МЕТОД СКОЛЬЗЯЩЕГО ДОПУСКА

Напомним, что в общей. постановке задача нелинейного програм-
мирования формулируется следующим образом:

минимизировать і(х)‚ х (5 Е",

при ограничениях
т(х)=0, і=1,…‚т‚

8і(х)>0' ъ=т+1, ---'› Р.
где функции Дх), Л, (х) и 3, (х) могут быть как линейными, так и
нелинейными ". При практической реализации на ЭВМ многих

мегодов нелинейного программирования значительная доля машин-
ного времени тратится на то, чтобы обеспечить строгое выполнение

требований допустимости. Алгоритм скользящего 2) допуска [11
позволяет улучшить значения целевой функции как за счет инфор-
мации, получаемой в допустимых точках пространства решений,
так и за счет информации, которую удается получить при прохож-
дении через некоторые точки, лежащие вне допустимой области,
но являющиеся близкими к допустимым; для краткости будем на-
зывать их почти допустимыми точками. Интервалы, в пределах
которых точки можі-ю считать почти допустимыми, в ходе оптими-
зационного поиска постепенно сокращаются, так что в пределе
(по мере приближения к искомому решению задачи нелинейного
программирования) в системе соотношений (8.0.1) учитываются
только допустимые точки х. При такой стратегии оптимизационною
поиска задачу (8,0.1) можно заменить более простой (но имеющей
то же самое решение) задачей

минимизации ((х), х 6 Е",
при ограничении

(8.0.1)

Ф“) _ Т (х) > 0, (8.0.2)

Где ФО” —— значение критерия скользящего допуска на іа-м этапе
ПОИСКЗ [этот критерий определяется соотношениями (8.1.01, а Т (х)

 

” Как уже отмечалось в разд. 2.1, при линейной структуре всех фигурирую—
щих в (8.0.1) функций мы имеем дело с задачей линейного программирования.

2) Иногда говорят ‹иежесткога допуска».
 pagebreak 
382 Г лава 8

представляет собой положительно определенный функционал над
множеством всех функций, задающих ограничения (как в виде ра-
венств, так и в виде неравенств) в задаче (8.0.1). Функционал Т (х)
является мерой степени нарушения ограничений рассматриваемой
задачи [определение Т(х) дано с помощью соотношения (8.1.5)
в разд. 8.1]. В разд. 8.2 приводится стратегия алгоритма. Разд. 8.3
посвящен описанию процедуры определения необходимой совокуп-
ности как допустимъхх, так и почти допустимых точек, а в разд. 8.4
обсуждается вычислительная процедура в начале оптимизационного
поиска. Отметим, что хотя при решении задач безусловной миними-
зации используется так называемый метод деформируемого много-
гранника, предложенный Нелдером и Мидом (см. разд. 4.2), так как
он оказывается исключительно эффективным, при решении
задачи безусловной минимизации можно применять и другие
методы, не связанные со стратегией скользящего допуска. Таким
образом, метод Нелдера и Мида можно заменить любым другим
методом определения безусловного минимума, если при этом га-
рантируется надлежащая степень эффективности вычислительных
процедур. Получаемая при этом последовательность векторов х

будет просто представлять собой последовательность точек в Б”,
а не вершины специально построенного многогранники.

8.1. ОПРЕДЕЛЕНИЕ Ф, Т(х)
И ПОЧТИ ДОПУСТИМЫХ ТОЧЕК

З.Н. КРИТЕРИИ ДОПУСКА Ф

В качестве критерия допуска Ф выбирается положительно опре-
деленная убывающая функция координат точек, являющитя вер-
шинами дефорьшруемого многогранника в Е", т. е. Фш) =Ф®(х$"’,
ХЗ", …, ‚&., хдд). Функция Ф служит критерием допуска для
нарушения ограничений решаемой задачи на протяжении всего
процесса оптимизационного поиска и, кроме того, является кри-
терием, позволяющим определить момент прекращенИя процедуры
оптимизации. Варианты конкретного выбора 0) многочисленны;
здесь мы рассмотрим лишь одну из возможностей, представив функ-
цию Ф в следующем виде:

(и _ ‹!е—п т_+1 '+ а»
Ф _тіпФ ‚ ‚__… 2:1]хф— +2,"
(8.1.1)
ФФ) =2(т+ …,
где
: —— величина, характеризующая размер исхоцного много-
гранника;
 pagebreak 
Метод скользящего допуска 383

 

т _— число ограничений в виде равенств;
х‘д'” —— вектор, задающий положение і-й вершины многогран—
ника в Е";
г = (и —— т) — число степеней свободы целевой функ-
ции {(х) в задаче (8.0.1);
х‘ЁЮ—вектор, задающий положение вершины, которая со-
ответствует «центру тяжести» рассматриваемого много-
гранника при п = ! [см. соотношение (4.2.1)!;

13 = 0, 1, —— индекс, указывающий число пол-
ностью законченных этапов вычислительного про-
цесса;

Ф‘Ь'Щ — значение Ф на (іг —— 1)—м этапе оптимизационного поис-
ка

Обозначим второй член в фигурных скобках соотношения (8.1.1)
через Б“”, т. е. положим

1 г+|
е<**'=—”:і1 вихгю—хгын=

[=]

г 1 л ‘
= %? {Ё 2 ‹хЕ-‘і’ — №№} ". (8.1.2)
…=1/=1

Где я?? (] = 1, ..., п) -— координаты і-й вершины нежесткого мно—
гогранника в Е”. Заметим, что 6… представляет собой среднее рас-
сюяние от точек худ) (і = 1, г + 1) до центра тяжести #6222
выбранного многогранники в Е . Чтобы понять поведение функции

Ф“). необходимо прежде всего рассмотреть величину 6. Очевидно,
что 6 зависит от размеров упомянутого выше многогранника, ко-
торые могут оставаться неизменными, увеличиваться или умень-
шаться в зависимости от того, какая из четырех описанных в

разд. 42 операций используется для перехода от х?” х хг”). Та—
ким образом, Ф… ведет себя как положительно определенная убы-

ваюшая функция х, хотя 6… может в ходе оптимизационного поис-
ка либо возрастать, либо убывать, а по мере приближения к опти-

Мальной точке и Б“”, и Ф… устремляются к нулю, т. е. образуется
последовательность

ФЮ’ > Ф… > … > Ф… > 0. (8.1.3)

Если при использовании метода Нелдера и Мида улучшение
значений і (х) с помощью (4.2.2) оказывается невозможным, вер-
шины деформируемого многогранника постепенно приближают к
той вершине, которая сответствует наименьшему значению целевой
функции. В пределе имеет место полное вырождение деформируе-
мого многогранники в точку, соответствующую стационарному
 pagebreak 
384 Глава 8

 

значению [ (х). Таким образом, по мере приближения к стационар—

ному значению [(х) величина Б””, определяемая соотношением
(8.1.2). постепенно уменьшается, так как среднее расстояние между
вершинами многогранника и его центром тяжести сокращается до

нуля Поскольку на іе-м этапе оптимизационного поиска Ф… пола-

гается равной наименьшему из значений либо Фи“), Либо в…,
величина Ф“) также уменьшается и в пределе имеем
1ігп Ф“) = 0. (8.1 .4)

!чх'

8.12, КРИТЕРИИ Т(х) КАК «МЕРА» СТЕПЕНИ НАРУШЕНИЯ
ОГРАНИЧЕНИЙ

Рассмотрим теперь функЦионзл Т(х) над множеством ограни-
чений задачи (8.0.1):

т р Ч.
Т(х) = +[3 „г… + 2 №? (х)] ‚ (8.1.5)

!=; і=т+1
где и, —— оператор Хевисайда, обладающий следующим свойством:
ид == 0 при 9, (х) > 0 и и,. = 1 при 3, (х) < 0. Таким образом,
функционал Т (х) представляет собой взятый с положительным
знаком квадратный корень из суммы квадратов функций, задающих
полную совокупность нарушенных ограничений задачи (8.0.1). За-

метим, что Т(х) >О при любом х Е Е". В частности, обратим

’“
внимание на то, что если сумма 2 &? (х) является выпуклой, а фун—
1:1

кции ;, (х) (і = т + 1, …, р) вогнуты, то Т(х) есть выпуклая
функция, обладающая глобальным минимумом Т(х) = 0 для лю-
бого допустимого вектора х, т. е. для любого {хм, (х) = 0,
3, (х) > О (і = 1, …, р)}. Кроме того, Т (х) > 0 для любого век-
тора х, не являющегося допустимым. Для заданного х… 6 Е“
вычисленное с помощью формулы (8.1.5) значение Т (х) можно ис-
пользовать для различения допустИмых и недопустимых точек.
Если Т (х<*>) = 0, то ючка х… допустима; если Т (х) > 0, то точ-
ка х… не является допустимой. При этом существенным является
следующее обстоятельство: если значение Т(хщ) мало, то это
означает, что точка х“) расположена отностельно недалеко от гра-
ницы допустимой области; при большом же значении Т (х…) 'ючка
ХШ лежит на значительном расстоянии от границы допустимой
области.
 pagebreak 
Метод скользящего допуска 385

 

8.1.3. ПОЧТИ ДОПУСТИМЫЕ ТОЧКИ
(КВАЗИДОПУСТИМОСТЬ)

Почти допустимыми точками называются такие точки х Е Е",
которые не являются допустимыми, но в то же время почтидопу-
стимы в указанном ниже смысле. Чтобы установить четкое различие
между допустимыми, почти допустимыми и недопустимыми точками,
рассмотрим значение Ф на !г-м этапе оптимизационного поиска, т. е.

значение Ф в точке х“) 6 Е“. Г оворят, что вектор х… является:
1) допустимым, если Т(х“”) =0;
2) почти допустимым, если 0<Т(х“") <Фщ;

3) недопустимым, если Т(х®)>Ф"°.

Таким образом, область КВаЗИДОПУСТИМОС'ГИ определяется СОШНО—
шением

Ф“) -——Т(х) >О. (8.1.6)

Любое перемещение из точки х… в точку х‘Ы'" называется допус-
тимым, если ТОНН") =0, почти допустимым, если 0<Т(х“‘+") <
$030". и недопустимым, если Т(х“+”)>Ф‘*’. Отметим, что значе-
ние Ф на (іг +1)-м этапе оптимизационъюго поиска находится толь-

ко после того, как определяется, что точка х"‘+" является либо до
пустимой, либо почти допустимой.

8.2. СТРАТЕГИЯ АЛГОРИТМА СКОЛЬЗЯЩЕГО ДОПУСКА

В этом разделе мы покажем, что задачу нелинейного програм-
мирования в общей формулировке (8.0.1) можно заменить более
простой задачей минимизации і (х) при единственном «укрупненном»
ограничении в виде неравенства, & именно задачей следующей струк-
туры:
минимизировать ;“ (х), х Е Е”,

при ограничении
Фш _ Т (х) > 0, (8.2.1)

Поиск методом деформируемого многогранника (т. е. методом Нел-
дера и Мида) удобен и эффективен, хотя и не относится к числу
основных методов при минимизации [(х) в отсутствие ограниче-
ний, т. е. когда ограничение в (8.2.1) не является активным. Однако
этот метод используется и для минимизации Т (х) (см. разд. 8.3)
при ограничении, фигурирующем в (8.2.1), если это ограничение
активно. Общая схема работы алгоритма выглядит следующим об—
разом: по мере развития оптимизационного поиска уменьшается
 pagebreak 
386 Глава 8

 

значение Ф…, что приводит к сужению области квазидопусти-
мости, и процедура минимизации [ (х) отделяется от этапов, служащих
для выполнения ограничения, указанного в (8.2.1). При заданном

Ф… в точке х"‘+'› имеет место один из следующих вариантов:
1) Т(х‘*+“) < Ф‘”. В этом случае точка х‘н’” является либо до-

пустимой, либо почти допустимой; соответствующее перемещение
можно считать разрешенным.

2) Т(х"°+'))>Ф®. В этом случае точка ха”… классифицируется
как недопустимая; необходимо отыскать вместо к"…) другуюточку,
которая либо лежала бы ближе к границе допустимой области, либо
принадлежала допустимой области. Один из способов перемещения
точки х“… в сторону допустимой области состоит в уменьшении
значения Т (МН”) в соответствии с (8.1.5) до тех пор, пока не будет

выполнено условие Т (х‘Ё'Н’) < Фа”.
Чтобы убедиться в том, что решение задачи (8.2.1) эквивалент-
но решению задачи (8.0.1), достаточно проанализировать поведе-

ние Ф…. Поскольку Ф… есть положительно определения невоз-

растающая функция, так что Ф‘М = 0 лишь в том случяе, когда
дальнейшее улучшение значения [ (х) для задачи (8.2.1) невозмож-
но, область квазидопустимости, определяемая соотношением (8.1.6),
постепенно уменьшается по мере того, как оптимизационный поиск
приближает нас к решению задачи (8.2.1). В пределе, когда все

вершины х)” (і = 1, ..., г + 1) деформируемого многогранники

в Е" стягиваются в одну точку х*, Ф* = 0 и условию (8.1.6) могут
удовлетворять лишь допустимые точки х, т. е. точки {хм, (х) =
= 0, 3, (х) > 0 ($ = 1, …, р)). Другими словами, если Ф… = 0,
то, поскольку Т (х) не может принимать отрицательных значений,
единственно возможным значением Т(х) является Т (х) = 0, что
эквивалентно требованию, чтобы были удовлетворены все ограни-
чивающие условия в задаче (8.0.1).

Поскольку критерий допустимости Ф есть положительно опре-
деленная невозрастающая функция над последовательностью точек
х…. х…, …, х“), ..., х*, которые генерируются в ходе оптими—
зационного поиска, а также в силу того, что Ф не зависит ни от і (х),
ни от функций, задающих ограничения задачи, и в пределе Ф“ = 0,
сходимость алгоритма гарантируется по следующим причинам:

1. Невозрастающее поведение критерия допустимости обеспе-
чивается самим способом построения Ф [см. формулу (8.1.01. Если
бы функция Ф могла неограниченно возрастать, появилась бы воз-
можность улучшать значение Нх), все более удаляясь от границы
допустимой области.

2. Когда решением задачи (8.0.1) является внутренняя точт<а
(при отсутствии ограничений в виде равенств), сходимость алго-
ритма гарантируется в силу свойства деформируемого многогран-
 pagebreak 
Метод скол изящно допудка 387

 

ника вырождаться в точку лишь при достижении оптимума )‹ (х) в за-
даче (8.0.1). При этих обстоятельствах Т (х) не влияеч` на сходи-
мость алгоритма, так как на заключительных этапах поиска точки
х?" (і = 1, …, г + 1) являются внутренними и, таким образом,
Т (х)”) = 0, откуда следует, что в (8.1.6) ограничивающие условия
в виде неравенств удовлетворяются для любых х?” и задача (8.0.1)
не содержит активных ограничений.

3. Когда оптимум задачи (8.011) достигается в точке, не являю-
щейся внутренней [либо потому, что х* является граничной том:»
кой, либо потому, что задача (8.0.1) содержит только ограничения
в виде равенств], сходимость гараншруется за счет условия (8.1.6),

т. е. в силу того, что @” —— Т (х) >О. Деформируемый многогранник

не начнет вырождаться В ТОЧКУ ДО тех пор, пока не будет найдено

такое улучшенное значение [ (худ), для которого Ф… — ’Г (х‘Ё’) >

> 0.
Пусть х _вершины деформируемого многогранника, такие, что

Ф‘”—Т(х1*›) >О, а [(хій’) — наилучшее значение і(х)‚ полученное

на іг-м этапе оптимизационного поиска. Обозначим через х)”… вер-

ШИНЫ, полученные путем построения точек, симметричных ТОЧ-

КЗМ ХХ” ОТНОСИТЕЛЬНО центра ТЯЖеСТИ многогранники, так чтобы

Ф‘и—Т(хЁ-"+")>О. Если {(хё’г+")>;°(х$’°) для любого симмет-

#
ричного преобразования относительно центра тяжести, Ф‘ ’ будет
убывать вследствие сжатия элементов многогранники. Таким образом,

значения Ф‘ю уменьшаются, и х)” должны удовлетворять ограничи-
вающим условиям задачи (8.0.1) с постоянно возрастающей точнос-

тью, пока оптимизационный поиск не прекратится из—за того, что
окажется выполненным условие Ф… < в.

С другой стороны если і(х1‹*+")<і(х$'°)‚ то значение Фш’ ие
уменьшится. поскольку никаких сжатий многогранники не будет
иметь места, и х),” заменяется на более подходящую вершину. По-
строение симметричных (относительно центра тяжести) точек и рас-
тяжение элементов деформируемого многогранники осуществляют—
СЯ в ходе поиска допустимой или почти допустимой точки [для ко—

торойі(х‘д”+") <1°(х‘‚"’)] столько раз, сколько это необходимо.
Таким образом, преждевременное прекращение поиска в окрест-
ности нелокального оптимума не имеет места, так как дефОрмируе-
мый многогранник не вырождается в точку, если существует та-
кой вектор ХЁН'”, для которою Ф… — Т (ХЁНЦ) > О и [ (;&-”“) <
< Г (Х* :1: з).

Одно из преимуществ стратегии скользящего допуска, нашед-
шее отражение в структуре задачи (8.2.1), заключается в том, что
степень нарушения ограничений, содержащихся в задаче (8.0.1),

!:
Ё)
 pagebreak 
388 Г лава 8

 

по мере приближения к искомому решению этой задачи постепенно
уменьшается. Поскольку на первых этапах поиска ограничения
задачи (как в виде равенств, так и в виде неравенств) должны удов-
летворЯться весьма приблизительно и лишь при поиске непосред-
ственно в окрестности искомого решения задачи (8.2.1) требуется
бс'шьшая точность, полный объем вычислений в процессе оптими—
зации по сравнению с другими методами существенно сокращается.

Другим преимуществом стратегии скользящего допуска явля—

ется то, что оказывается удобным использовать Ф… в качестве
критерия окончания процесса поиска. Во всех возникающих на
практике ситуациях оптимизационный поиск достаточно продол-

жать до тех пор, пока Ф… не станет меньше некоторого произволь-
ным образом выбранного положительного числа в. На заключитель-

ных этапах поиска ФП” является также мерой среднего расстояния
от вершин деформируемого многогранника х),” ([ = 1, …, г + 1)
до его центра тяжести Х),“ЁЮ. Если Ф… < э, ю значительное число

вершин х)” содержится внутри гипосферы радиуса в. (Если бы

последний ИЗ рассматриваемых МНОГОГраННИКОВ был ПРЗВИЛЬНЫМ,

внутрь гиперсферы радиуса & попали бы все вершины х)”; в силу же

тою, что многогранник является неправильным, некоторые из
вершин выходят за пределы упомянутой гиперсферы.) Таким об—

разом, если Ф… < в, не исключается возможность того, что зна—
чение [ (х) не удастся улучшить без дальнейшего уменьшения раз-
меров деформируемого многогранники. Отсюда, в частности, сле-

дует, что замена & —› 28 в точке х)”, соответствующей наилучшему

значению і (х) (т. е. в точке ХЭ”), не приведет к улучшению целевой
функции. Следовательно, к моменту прекращения оптимизацион-
ного поиска Выполняется следующее условие:

№“) < ! (х* :Ь в). (8.2.2)

Поскольку условие (8.1.6) удовлетворяется при любом перемеще-
нии в пространстве решений, если Ф“) <&, то условие е—
— Т (х)”) > 0, очевидно, также выполняется, и мы имеем

ТЫ”) = [Ё %… + Ё и,. (х) 3%… ", < в. (8.2.3)
{=\ :=‚т+я

Из соотношения (8.2.3) следует, что при прекращении поиска сум-
марное значение функций, ассоциированных с нарушенными ограниче-
ниями, не превышает 8. Само собой разумеется! что и значение каж-
дой отдельно взятой функции, ассоциированной с тем или иным
из нарушенных ограничений, также не МОжет превысить &.
 pagebreak 
Метод скользящего допуски 889

 

Пример 8.2.1. Стратегия скользящего допуска
Рассмотрим следующую задачу:

минимизировать [(х) = х? + хг, х 6 Е”,
при ограничении (а)
и, (х) = х? + хЁ—9х2 + 4,25 = 0.

Уровни целевой функции [(х) и геометрическое меСто точек, для
которых 111 (х) = 0, показаны на фиг. П.8.2.1. Решением задачи

 

Ф и г. П.8.2.1‘ Минимизация при наличии ограничений ‹: помощью алгоритма
скользящего допуска.

(а) является точка х* = [0 0,517, в которой ? (х*) = 0,25 и И, (х*) =:
= 0. В соответствии с методом скользящего допуска задача (а)
преобразуется в задачу

минимизировать {(х) = х? + хё, х 6 Е",
при ограничении (@
ФФ) _- Т (х) > 0,
Где Т (х) = [(хЁ + хЁ— 9х2 + 4,25)2]`/*. Заметим, что в рассматривае—

мом примере г = (п —— …) = 1, так что при отыскании минимума
Г (х) можно использовать г + 1 = 2 вершин. Однако в силу того,
 pagebreak 
390 Г лава 8

 

что методика интерполяции (см. разд. 8.3.2) требует три опорные
точки, число вершин ‹; всегда должно удовлетворять условию :; > 3.
Именно поэтому в данном примере рассматриваются три вершины
деформируемого многогранники. При десяти переменных и пяти
ограничениях будет использовано только пять вершин.

Для иллюстрации работы алгоритма сколюящего допуска ниже при-
водится подробное описание вычислтельных операций на первых
двух этапах решения задачи (6). В качестве начального выбирается

вектор х‘°’=[4 4,517, а величина, характеризующая размер исходного
многогранники, і=1 (при этом мы будем иметь многогранник с

единичными ребрами и центром тяжести в точке х‘ш). В силу (8.1.1)
при != 1 и т = 1 имеем Фю’ = 4. Вершины исходного многогран-
ника расположены в точках х)”) = [3,592 4,0921Т, х?” = [4,558 4,3511Т
и хёш=|3,85 5,061Т. Для соответствующих значений [(х) имеем
пхі“) = 29,64, [(ХЁП’) =- 40,4 и №9”) = 40,4.

НУЛЕВОИ ЭТАП ОПТИМИЗАЦИОННОГО ПОИСКА (іі == 0)

Вершина, соответствуЮЩая наименьшему (на данном этапе) зна-

чению [(х), находится в точке х)… = х)… [в этой точке )*(хіщ) = 29,64],
а вершина, соответствующая наибольшему (на данном этапе) значео
нию [(х), находится в точке хЁ?’ = (°) [в этой точке НХ?) = 40.4].
Значение Т (х) = [(х? + хЁ— 9х2 + 4,25)2]'/* в точке х)… равняется
ТЫ…) = 2,65, и, поскольку Фа” — Т (х$°)) > 0, неравенство (8.1.6)
удовлетворяется и точка х$°’ может рассматриваться как почти до-
пустимая. Нет никакой необходимости в том, чтобы неравенство (8.1.6)
удовлетворялось для двух других вершин, поскольку в процессе
оптимизации эти верштш будут заменены другими вершинами
с улучшенными значениями [(х). Согласно (4.2.1), центр тяжести

для оставшихся вершин находится в точке х,?” = [4,07 4,2211. В соот-
ветствии с (4.2.2) при ос =1 точка, симметричная точке ХЯ” относи-
телы-ю хі‘”. задается вектором хЁ” = [4,28 3,3711.

В точке х?” функционал Т(х) принимает значение Т(х_5;"’) = 3,75.
Поскольку Ф‘°’—— Т(хё°’)>0, точка кг;” является почти допустимой;

при этом ;” (хз…) = 29,6. Вследствие того что і(х$°’)<і(х$°))‚ соглас—
но (4.2.3), при ? =2 следующий шаг состоит в выпшшении опера—

ции растяжения, что дает ХЁ” = [4,49 2,5211; в этой точке Т(х$‚'”) =
=8. Поскольку Ф‘°›——Т(х‘5°’)<0, точка ХЁ” не является почти до
пустимой и поэтому отбрасывается. Таким образом, минимизация Т (х)

начинается из точки хё‘” и продоткается до тех пор, пока не будет
удовлетворено неравенство (8.1.6).
 pagebreak 
Метод скол ьзящего допуска 39|

.… ___—__———————4

Получающаяся в результате минимизации Т(х) нова?! вершина
хі?’ задается вектором х? = [3,32 2,4017, для которого Т(хб‘щ) = 0,59,
и, следовательно, точка хёо’ почти допустима. Теперь нетрудно убе-
диться, что в почти допустимой точке хЁ” функция { (хёо’) =? 16,8- ПО"

скольку і(хё°))<і(х5°’), точка ХБ?) = ХЕ“) заменяется на каш. на ЭТОМ
нулевой этап (&= 0) оптимизационного поиска заканчивается— Как

(11
показано на фиг. П.8.2.1, вершина хЁ—Ё’ отождествляется с ТОЧКОЙ х —

ПЕРВЫЙ ЭТАП ОПТИМИЗАЦИОННОГО ПОИСКА (12 # 1)

Вершинами деформируемого многогранника в начале первого

([в = 1) этана оптимизационного поиска являются точку Хи —
=[з‚592 4,09217, хё°›= [4,558 4,351? и х… = [3‚ 32 2,40! . Обра—
тим внимание на то, что при переходе от этапа к этапу ПРОИСХОДИТ
замена Только одной вершины многограннищ. С помощью формулы
(8.1.1) для критерия допуска получяем Ф… =0‚745. Вершины, В К°-
торых [(х) принимаеч` наибольшее и наименьшее (на данном

[, РЭ „ ХФ) :
этапе) Значения, Находятся сООТВеТсТВеНнО В точках Х}. = Хі ,

=х… [при этом имеем ПХЗ") = 16,8 и Т(х}1’)=0,59[. ПОШОЛЪКУ
Ф"’—Т(х1”)>0, неравенство (8.1.6) оказывается выполнВННШ‘д И
поиск продолжается. Центр тяжести находится в течие хр =
= [3,45, 3,29[Т.»Симметричное отображение точки ХЬ“ = ХЭ” ОТНОСИ—
тельно точки х.?) дает точку хё“ = [2,34 212311: в которой Т(ХЁ“) =

=5,50. В силу того что Ф‘”——Т(х2”)<0, точка хё“ не является
Допустимой; поэтому осуществляется минимизация Т(х). исходя ИЗ

точки хё".

В новой точке хё“ = [3,1 2.117 имеем Т(хё" =0,64. ПдСКОЛЪКУ
Ф—Т(хё‚“) >О, производится вычисление [(х) в точке хё“. Нетруд—
но убедиться, что [ (Хён) = 14,01. В силу того что [ (хё`))</с “1% В
соответствии с (4.2.3) выполняется операция растяжения, в резудь-

тате чего получаем хё” = [2,75 0917. В этой точке Т(хё”) =4‚5. ПО"

скольку точка х?) не является допустимой, производится …;ниыжза—
.
ция Т(х) при стартовой точке хь“ и находится новая точка Хе =

=[2,92 1,9011, в которой Т(хё“) = 0,71, так что эта [1013215| ““:)“
Кё“ оказывается почти допустимой. В силу того что і(хё")41°(х1 ),

… о „ _
х„ = х`2`замгняется на хЁ’; на этом первыи этап (12 = 1) ОПТИМИЗЗ

циоъшого поиска заканчивается. Точка х?) отождествилнет!?я (СМ-
фиг. П.8.2.1) с точкой х….
Вычислительная процедура, выполняемая по схеме. про…“!ю'

стрированной для первых двух (Ь = 0 и & == 1) этапов ОПТИМИЗд'
 pagebreak 
392 Глава 8

 

ционного поиска, повторяется на последующих этапах іг : 2, 3, ...;
при этом на каждом этапе вершина, соответствующая наибольшему
значению і (х), заменяется на новую вершину, получаемую путем
выполнения соответствующих операций по методу Нелдера и Мила.
Эти операции повторяются до тех пор, пока найденное с помощью
(81.1) значение Ф… не будет удовлетворять условию @” < в,
где в _— заранее выбранное число. При выполнении указанного вы-
ше условия оптимизационный поиск заканчивается.

Подробно каждый шаг алгоритма скользящего допуска описан
в разд. 8.4, где содержится также блок-схема алгоритма.

8.3. ПРОЦЕДУРА ОТЫСКАНИЯ ДОПУСТИМЫХ
И ПОЧТИ ДОПУСТИМЫХ ТОЧЕК

В предыдущем разделе было установлено, что в процессе опти-
мизационного поиска при улучшеНИИ значений целевой функции
і (х) используются только допустимые или почти допустимые точки.
Если какая-либо точка х… окаЁывае'гся с точки зрения критерия Ф
недопустимой, необходимо определить другую точку, которую мож-
но было бы квалифицировать либо как допустимую, либо как почти
допустимую. Отыскание либо допустимой, либо почти допустимой
точки осуществляется за счет минимизации Т (х<*)) над множеством
всех точек пространства решейий; при эгом процесс минимизации
Т (№”) продолжается до тех пор, пока не окажется выполненным
неравенство (8.1.6).

Для минимтшции Т(х) методом Нелдера и Миди необходимо
построить новый многогранник в окрестности недопустимой точки
хо”. Чтобы не возникло путаницы, будем обозначать вершшщ мно—
гогранников, рассматриваемых в связи с процедурой улучшения зна-
чения {(х), через хг)“ = 1, . . . . г+ 1), а вершины многогранников,
рассматриваеМых при отыскании допустимых или почти допустимых

точек путем минщшзации Т(х)‚—— через хг)“ : 1, .. . , п + 1). По
следовательностъ векторов‚ генерируемых в процессе минимизации

Т(х)‚ для каждого недопустимо… вектора хЁ-“будет, таким образом,

^‹0› ^… ^‹з› _
представляться последователыюстью х‚- , х, , . х,- (: = 1,

, п —|- 1), где индекс 5 обозначает число полностью завершенных

этапов процесса минимизации Т(х). В любой процедуре мршнмиза-
ции Т(х) в качестве начальной всегда берется точка :?“ = ХЗ"), где
х$’—недопустимая точка на !г-м этапе процесса минимизации [(х).
Последняя вершина посл'едовательности %…, ЁЁ", , ЁЁ” считается

достигнутой в том случае, когда для некоторого х!” выполняется
 pagebreak 
Метод скользящего допуска 893

 

„ „
условие Т(хЁ5’) <Ф‘т. При этом недопустимая вершина х?” заменя-
ется ДОПУСТИМОЙ или почти допустимой вершиной ХЕ”, для которой

Ф… — Т (худ) > 0, где х?” = хЁБ’.

Процедура отыскания допустимых или почти допустимых точек
будет описана в подразд. 8.33, а до этого рассмотрим:

1) метод получения (и + 1) вершин исходного многогранники
в Е" (подразд. 8.3.1);

2) метод интерполяции между внутренними и внешними точ-
ками (подразд. 8.3.2).

8.3.1. МЕТОД ПОЛУЧЕНИЯ (п + !) ВЕРШИН ИСХОДНОГО
МНОГОГРАННИКА

^
Пусть х<°> = х‘Ё’ —— недопустимая точка в Е”. Чтобы приступить

к поиску в связи с минимизацией значения Т (х) методом Нелдера

и Мида, требуется задать (п + 1) исходншх точек х?” (і:
=1, ..., п +1), которые могут (либо не могут) образовывать
правилъный многогранник в Е". Эти (п + 1) вершин должны
быть выбраны таким образом, чтобы п вшторов, соответствующих
любому подмножеству п вершин, были линейно независимы.
На практике всегда оказывается наиболее удобным строить

„
правильный многогранник, беря в качестве базовой точки х…).

Вершины исходного многогранника в В" [число вершин, как уже
отмечалось, равняется (п + … находятся с помошью соотношения

х{°’=х‘°’+в‚‚ і=1‚...‚п+1, (8.3.1)
где [),—вектор—столбец, составляющими которого являются эле-
менты і-го столбца [п ›‹ (п +1)]-мерной матрицы. Определение
этой матрицы дано в разд. 4.2

Траектория поиска, получаемая путем минимизации Т (х) ме—
“Годом Нелдера и Мида, зависит от размера и ориентации исходного
многогранника в пространстве решений. В случае когда размеры
многогранника малы по сравнению ‹: раЗМерами допустимой об-
ласти, траектория поиска почти не зависит от ориентации этого мно-
гогранника в Е". При малых значениях ! траектория поиска
(по крайней мере на первых этапах поискг) мало отличается от тра-
ектории, получаемой методом наискорейшего спуска.

Чтобы проиллюстрироватъ влияние размеров многогранники на
ход оптимизационного поиска на начальных этапах, рассмотрим со-
Вокупность ограничений (8.3.2), которые графически представлены
 pagebreak 
394 Г лава 8

 

на фиг. 8.3.1:
810059— хЁ—хё >О, (8.3.2)
35 (Х), 33 (Х) : хи хи >О.

Допустимая область указана здесь штрихами по ее периметру.

В любой точке допустимой области Т (х) =0, тогда как в любой
точке, лежащей вне допустимой области, Т (х) > О. Уровни Т (х) =

      
 

@
`,`)
`:
*? \
\
\
` \
”"живи \

Ф и г. 8.3.1‚ Влияние размеров исходного деформируемого многогранника на ход
минимизации Т (х).

= 12, ’Г (х) = 9,5 и Т (х) =4, вых0дяЩ’ие за пределы указанной
допустимой области, показаны на фиг. 8.3.1 пунктирными кривы-
ми‚ На фиг. 8:3.1 изображены также два разносторонних тре-
угольника, имеющих общую вершину в недопустимой точке х… =
=[1‚2 3.411, в которой ТЫ”) = 4. Если применить методы
Неллера и Мила, то потребуется всего один этап для того, чтобы

установить допустимую точку х…, начав с рассмотрения большею
из упомянутых двух треуголънилюв. Если начать рассмотрение

А
с менъшего треугольника, то допустимую точку х“) удастся опре-
делить лишь по завершении трех угапов. Направление наискорей-
шего спуска для Т (х) в точке хК’г’ задается вектором & =
=\—— 0,4 0,917. (Это направление также показано на фиг. 8‚3‚1.)
Чем менъше размеры исходного многогранника, тем ближе проходит
траектория поиска к траектории наискорейшего спуска. Чтобы
предтвратить возможность осцилляции с пересечением границы
допустимой области, весьма желательна Такая ситуация, когда
 pagebreak 
Метод скользящего допуска 395
№

траектория поиска при минимизации Т (х) не слишком
ляется от траектории наискорейшего спуска для Т (х).

В алгоритме скользящего допуска величина, характеризующая
размер исходного многогранники, при минхдмизации Т … на іг-м
этапе определяется с помощью эмпирическои формулы

‘ = 0,05 Фай (8.3.3)

где Ф… —значение критерия допуска, вычисленное & помощью
(8.1.1) на 13-м ЭТапе. Следует помнить. что размеры многогранника
используемого при минимизации ПХ), фиксируются в Начале этой
вычислительной процедуры И СОКРЗЩЗЮ’ГСЯ только, когда векторы
х не приводят к улучшению значения Нх).

На первых этапах поиска почти допустимые точки ‚(‹/в)
ложены дальше от границы допустимой области, нежели на этапах
завершающих оптимизационный процесс. На фиг. 8.3.1 Множесты')
точек, для которых Т (х) = 0, образует допустимую облас… 3 №0.
жество точек, для которых 0< Т(х) <Фш). Образует квазидо-

пустимую область. Квазидопустимая область при Ф… ‚`.—_ 1 пред-
ставлена на фиг. 8.3.1 узкой полосой, обрамляющей дспустимую
областъ. Следует отметить, что эта полоса вслучае линейныХ ограни—
чений оказывается более широкой, чем в случае нелинейных огра-

ничений.

Сильно уда-

распо—

832. МЕТОД ИНТЕРПОЛЯЦИИ МЕЖДУ ВНУТРЕННИМИ
И ВНЕШНИМИ ТОЧКАМИ

В случае когда задача (8.0.1) содержит только ОГРЩ-шчения в
виде неравенств, метод Нелдера и Мида может оказаться неэф.
фективным. Проиллюстрируем это, рассмотрев следующУю задачу:

минимизировать [ (х) = — х1 — х,

при огранИчениях
31(х):9—хЁ—ХЁ>0‚

8.3.4
ых), ваши.. х2>0. ‘ >
На фиг, 8.3.2 допустимая область задачи (8.3.4) показана заштри-
хованной кромкой на внутренней пограничной части контура,

заданного уравнениями {‚(х) =0(і = 1, 2. 3). а УРОВНИ целевой
функции } (х) изображены наклонными пунктирными ЛИНиями. до.
пустим, что на іг—м этапе поиСка вершины многогранника фактиче-
ски треуголъника), рассматриваемого в связи с минимизацией ‚= (х).
находятся в точках х‘і'” =[0‚7 0,711, х!” = [1 2,717 и ® :
= [2,5 1,817 (фиг. 8.32). В этих точках 7 (х) принимаег соответст-
венно значения )*(хію) = -— 1,4, Г (хз”) = _ 3›7 И ‚ (ХЕР) = — 4,3.

іг
Симметричное отображение точки Х‹|› относительно центра тяжести
 pagebreak 
396 Глава 8

 

точек х… и х?) (соответствующая процедура обсуждалась в

разд. 4.2) дает точку х?) =[2‚8 3,8]Т, лежащую вне допустимой
области.

В результате безусловной минимизации Т (х) методом Нелдера
и Миди находится допустимая точка х“) = [1,15 2,151]. (фиг. 8.3.2).

 

0 1 2 б 4 5.13

Фи 1х 8.3‚2. Пример «выброса» при нарушенных ограничениях (метод Нелдера
и Мида).

Траектория поиска, в результате которого удалось найти точку
хз, представлена пунктирной ломаной линией 0, 1, 2, 3. Поскольку
точка х?) находилась на относительно большом расстоянии от гра`

^
ницы допустимой области, точка х<3> оказалась глубоко внутри до—
пустимой области задачи (8. 3.4)

После замены к“” на х‘з’ (последнюю точку для удобства будем
также обозначать через хЁ’) получаем Дх?) = -— 3,3. Заметим, од-
нако, что вершине х? теперь Соответствует наибольшее [по сравне-
нию со значениями ЮНХ) в двух других вершинах] значение ‚(х).
Действительно, [(хз )= — 3. 3, тогда как [’ (х…) = — 3, 7 и [’ (ХЭМ):
= ——43. Отсюда следует, что точка х'5’д подлежит симметричному
отображению относительно центра тяжести точек х… и ХЁЮ, в ре—
зультате чего получается новая точка, лежащая вне допустимой
области. Такого рода осцилляция относительно границът допуст-
мой области может продолжаться достаточно долго без существен-
 pagebreak 
Метод скользящего допуска 397

 

ного улучшения значения [(х). Чтобы в какой-то мере исправить
ситуацию (которая, как правило, возникает при решении задач,
содержащих только ограничения-неравенства), по отношению к
внутренним и внешним точкам осуществляется квадратичная ин-
терполяпия, с помощью которои находится точка х, лежа—
щая вблизи от границы, заданной нарушенными ограничениями.
На фиг. 8.3.2 нарушенным является ограничение, задаваемое функ-
цией @, (х).

^

‚.
_.1 в 1.7
Пусть х(31 —внутренняя точка. а х“ ›— ближаишая к неи внеш-

няя точка, найденная путем минимизации Т(х). Если вновь обратитъ-
„ ^
ся к фиг. 8.3.2, то нетрудно убедиться, что х“) = х‘з’ = [1,15 21511,

^ А
а. к“” = х‘2’ = [2,35 2,911. Любая точка на отрезке между точка-
ми х‘” и х‘Ы’ задается соотношением
^ „ ‚.
х = х“) + ””$ при 0 < А.“) < №, (8.3.5)
п " ^ ‘/. А
где А‘“ =[ “ (х}"“——х}*’)“] есть расстояние от точки х‘” до точки
і=1
^ ^ „ „
х‘з—“‚ а з=(х““"—х‘”)/Ъ* представляет собой единичный вектор
“(&—1) ^… » 2 ‚`
в направлении х —х . Пусть 2(х) =2 3,- (х), где р—суммар-

[=!

ное число ограничений в виде неравенств, оказавшихся нарушенны-
ми в точке ;((547. Вычислим 2 (х) в точках ;(”. ;(“) + 0,573; и 365") =

= ;(… + А‘Ёи положим 21= 2 @@), г„= 2 (;(… + 0,575) и г: =
=2(1^‹“_"). Таким образом, 21, 22 и 23 представляют собой значения
Е(х) в трех одинаково отстоящих ЦРУГ от дрУга точках, располо-
9— ;&"). Желательно найти такую точку

женных вдоль вектора х‘

„ „

х*‚ в которой 2(х*) почти не отличается от нуля. Такая точка опре›
деляется соотношением

‚@ = ;… + (№) и;, (8.3.6)

411

где о: =:1 —— 222 + 23, а В =Зг1 — 422 + 23. Соотношение (8.3.6)
можно получить, записывая приближение 2 (х) ‹: точностью до вто—
рого порядка в интервале, определяемом 73. При этом рассматри-

ваются только положительные вещественные корни (|З2 _ 80421)"'.
В примере, проиллюстрированном на фиг. 8.3.2 2(х)= (9—

—хЁ—хЁ)2‚ ;;“) =|1,15 2,151Т и $3") = [2,3 2,59]7. Следователъ-
но, и = 1,37, &= [0,837 0,548? и х…+0.51.*8=[1,72 2,531’. При
этом пшлучаем 21 = 2 (;(…) = 9,3, 22 = 2 (х… + 0.5135) = 0,36 и
 pagebreak 
398 Глава 8

 

г& = 2 ({“—”) = 22. Отсюда следует, что 0$ = 30,6 и В = 48.8.
С помощью формулы (8.3.6) находим

„‚ 1,15 0,835 1,68
= . 0,47 1,37 = .
х 12 15 + Х 0,548 2,50

Значение 2 (х) в точке х“ равняется 2(х*) =0‚005‚ и, следова-

9

тельно, точка х* может рассматриваться по существу как гранич-
^
ная точка. В чрезмерно точном определении положения х* нет ни-

какой необходимости. Если значение Т (Х“) в точке х*, найденное
с помощью (8.1.5), не удовлетворяет требованию допустимости

(8.1.6), то осуществляется переход к новой точке х* путем переме-

щения вдоль 3 по направлению и х“); при этом процедура пошаго-
вого перемещения в указанном направлении продолжается до тех

пор, пока не будет выполнеію условие Т (х*) < Ф….

8.3.3. ПРОЦЕДУРА НАХОЖДЕНИЯ ДОПУС’ГИМЫХ
И ПОЧТИ ДОПУСТИМЫХ ТОЧЕК

Процедура, в результате которой удается получить либо допу—
стимую, либо почти допустимую точку. вытлядит следующим об-
разом:

1. Пусть х…) =х5’” есть недопустимая точка в Е", Ф“) — зна-

чение критерия допустимости, найденное с помощью соотношения
(8.1.1) на 13-м этапе процедуры оптимизационного поиска. Пусть

1:0,05 Ф… есть параметр размера исходного многогранника, ас-

социированного с минимизацией Т (х), начиная из точки х…). С по-
мощью процедуры, описание которой дано в подразд. 8.3.1, и
определяют (п —|— 1) вершин х,… ($ = 1, .. ., п +1), требуемых для
выполнения начального шага в связи с минимизацией Т (х). С по-
мощью соотношения (8 1 5) вычисляется значение Т (х) в каждой

из (я _|— 1) вершин, т. е. находится Т (ХР)) при і =1, …, п +1.
2. При ос =1 8 =0, 5 и у :? с помошью процедуры Нелдера
иМида минимизируется Т [}(х). В конце каждою 3-го этапа наи-

меньшее из значений Т(х‚° )( і =1, .., п +1), т.е.Т(х15›)‚
сравнивается с Ф….
3. Если Т(х$")>Ф“"‚ найденная точка является либо допусти-

мой, либо почти допустим^ой. Если Т(х15’)>0, недопустимая точка

(# ) (11)

^!
х; заменяется на точку х?)- , при этом точка х; = х)” окажется ли-
 pagebreak 
Метод скол ьэящгго допуска 399

 

бо допустимой, либо почти допустимой и минимизация Т(х) закан—

чивается. Если же ТЫ”) =0 и т =0, переходят к шагу 7, описа—
ние которою дано ниже.

4. Если Т(х$”)>Ф"”‚ вычисляется величина

№: „—+1 {2 \Т‹хъ*’›—т‹х‘:’+г›1°} ‚

и=1
где Т(Х(ЁД_2)—значение Т (х) в центре тяжести многогранника на
3-м этапе минимизации Т.(х)

5 Если А“’>10' 7, возвращаются к шагу 2 и продолжается
минимизация Т(х) на (5+ 1)- м этапе.

6. Если ‹Д‘” < 10"7 , деформируемый многогранник близок к вы-
рождению в точку, тогда как допустимую (или почти допустимую)
точку так и не удалось найти. При А… < 10—7 и при наличии боль-
шого числа нелинейных ограничений (как в виде равенств, так и в
виде неравенств), формирующих структуру Т(х) и, следователь-

но, определяющих значения Т (х) в вершинах %?), в ходе выпол-

нения процедуры Нелдера и Миди могут возникнуть серьезные за-
труднения. В этом случае Т (х) оказывается весьма сложной функ-

цией в недопустимой области Е". Пу сть х" есть вершина, соот-

ветствующая наименьшему значению ХГ (х), найденному с помощью
процедуры Нелдера и Мида Вместо того чтобы прекратить поиск

В точке ХЁЗ ›, ПО'ГЭрЯВ ВОЗМОЖНОСТЬ определения ДОПУСТИМОЙ ИЛИ ПОЧ'

ти допустимой точки, алгоритм продолжает работу. реализуя поиск
вдоль каждого из направлений, параллельных осям координат,
и осуществляется поиск минимума Т (х) по следующей схеме. Пусть

‚-(] =1, ... _ п) _точки, соответствующие наименьшим среди
всех значений ’Г(х), найденным на траекториях, параллельных

осям координат. Начиная из ХБ”, определяется х1‚ соответствую-

щее минимальному значению Т(х) при перемещении в направле-
нии параллельном координатной оси х1; затем, начиная из х],
определяется х; и т д. Этот процесс продолжается до тех пор, пока

не будут определены х, для всех п значений индекса ;. Используе-
мая при этом методика заключается в определении такого интерва-
ла !… который содержал бы точку с минимальным значением ’Г (х)
в выбранном направлении. После этого осуществляется одномер—
ный поиск методом золотого сечения [21.Этот поиск продолжается

до тех пор, пока длина интервала, содержащего точку х,-‚ не умень-
шится до 0,01 ФО”. Цель такого одномерного поиска состоит в том,
 pagebreak 
400 Глава &

 

чтобы найти новую точку, не совпадающую с 3:5”, и повторить вы-

числительные операции, начиная с шага 1, при больших размерах
исходного многогранника. -

В конце каждого одномерного поиска в направлениях, парал-
лельных осям координат, производится проверка с целью выясне

"а
ния, выполняется ли для нового значения Т (х;) условие Т (х,) <

<Фш. Если это условие выполняется, х?” заменяется на хг и

процедура минимизации Т (х) заканчивается. Если после прове-
дения поиска в каждом из координатных направлений допустимую
(или почти допустимую) течку определить все же не удалось, алго-
ритм реализует переход к шагу 1 и все операции вновь повторяют—
ся по схеме, предусмотренной методом Нелдера и Мила. При этом

в качестве начальной вновь выбирается точка хд, т. е. точка, в ко-
торой Т (х) принимает минимальное значение в ходе перемещения
в направлении. параллельном п—й оси координат. Если в резуль-
тате треккратного выполнения всей процедуры от шага ] др шага 6
допустимую или почти допустимую точку найти не удается, мини-
мизационный поиск прекращается и квалифицируется как безре-
зультативный.

7. Если ТЫ”) : ТЫ,”) = 0, то, прежде чем вернуться к проце-
дуре минимизации {(х), осуществляется интерполяция, описание ко-

торой дано в подразд. 5.4.2. В результате интерполяции добиваются

…
того, чтобы точка х?” = х?” не была слишком удалена от границ,

задаваемых теми ограничениями, которые были нарушены непосред—

^
ственно перед тем, как была найдена точка щ….

8.4. НАЧАЛО И ОКОНЧАНИЕ ПОИСКА

В данном разделе приводится описание процедуры начала поис-
ка с целью минимизации Нх). Напомним, что при минимизации
Т (х) использовались все (п + 1) вершин многогранника, где и—
суммарное число переменных (как независимых, так и зависимых)
задачи (8.0.1), тогда как при минимизации {(х) рассматриваются
лишь (г + 1) вершин, где г =(п —т) есть число «степеней сво-
боды» целевой функции. Еслит =0 [т. е. если задача (8.0.1) не со-
держит ограничений в виде равенств], то г = п, и при поиске ми-
нимума { (х) мы имеем такое же число степеней свободы, как и при
минимизации Т (х).

Приступая к поиску минимума целевой функции ;“ (х) с помощью
алгоритма скользящего допуска, мы должны знать начальную точ-

ку к“”, [, Ф…) и г. Для того чтобы поиск минимума )* (х) был начат
при правильном выборе размеров деформируемого многогранника,
 pagebreak 
Метод скользящего допуска 401

 

 

параметр : должен быть задан как функция интервала ожидаемых
вариаций переменных х рассматриваемой задачи. Как Правило,
оказываются известными нижняя И верхняя Границы изменения х;
теща для оценки наиболее рационального значения : можно вос-
пользоваться следующей формулой:

і=тіп{[—0‚;2—Ё «],—дд], «],—ц), ((а,—ы}, (8.4.1)

и:!

где (11, — Ь,) _ разность Между верхним и —нижним предельными
значениями, которые может принимать переменная х,. Таким об-
разом, если и, и Ь, (і = 1, …, п) известны, установить подходящее
исходное значение ! удается относительно легко.

В рамках рассматриваемого алгоритма локальные минимумы
исключаются проще, если исходный многогранник охватывает весь-
ма большую область пространства решений. Стратегия алгоритма
не зависит ни от локальных свойств )* (х), ни от сочетаний харак-
теристик і (х) и функций, задающих ограничения (с противополож-
ной ситуацией сталкиваются, например, При использовании ме’юдов
проекции градиента). На каждом этапе оптимизационного поиска
методом скользящего допуска информация, необходимая для реа-
лизации… очередного перемещения в ПроСтранстве решений. ПОЛУ-
чается за сче'х` рассмотрения (! + 1) вершин деформируемого мно-

гогранника в Е". Таким образом, алгоритм скользящего допуска
имеет весьма важное преимущество, которое ЗЗКЛЮЧаеТсЯ в том,
что в самом начале поиска удается получить существенный объем ин-
формации относительно і (х) за счет рассмотрения большого числа

вершин деформируемого многогРанника. При этом увеличивается

_ ла
вероятность того, что некоторые из наиденных ХР будут соответст-

вовать локальному оптимуму, лучшему ЛЮбОГО дРУГОГО локально-
го оптимума. Практика решения задач‚ характеризующихся нали—
чием многочислені-хых локальных оптимумов, подтверждает Эф-
фективность алгоритма скользящего ЦОПуска при исключении ИЗ
рассмотрения побочных локальных ОПТИМУМОВ— Разумеется, НИ-
какая из реализуемых на ЭВМ внЧИШИТЫЬНЫХ процедур не мо-
жет гарантировать глобальность найденного экстремума при ре-
шении задачи, целевая функция которой обладает множеством ло-
Кальных экстремумов.

Представляется также целесообразным ВЫбИраТЬ В качестве
точки к“”, относительно которой строится исходный многогранник,
допустимую или почти допустимую ТОЧКУ- ЁСЛИ ИСХОДНЫЙ МНОГО-
Гранник строить относительно точки. ЛЗЖЗЩЕИ Далеко за пределами
допустимой области, то придется произведить замену г +1 вер-
шин на другие вершины, распОдоженные ближе к границе допу-
стимой области
 pagebreak 
диким „"::„х, .г ‚
майл", л,?‘(і- : " “ф … …

‚… ‘ММИИ‘ №14
алитнив котята с’ауоржцтш . № пеш,“

«ммм шлмнллпэ „ши…
Лх,“ "!“”
Лшшжитв а:. „"’

Дичшиит‘ ‘на: 13";

м „

тмин… „13: ас,.

(» `
т:, ›‹ф’“ Лилимиэщтпи тц“ ……

впредшщть ю‘”. …

ш_
'г-г' “(”и

ад Адил”
„"‘. =№0°53 вы")
713$!1)‘ ф!!! .;
„клкмштбцтд ты"") М
чтоби “#55451”? ’
Лимит ’ы)“

“) :]
гг: 34?‘ ?
дичимить д.:" „$) …

лишними“ т: .), тик
_ «тли Пища“;
… „, Лмлжшм „: эс”
тем ) ‹ пдд „

Мицмшп'і Пыщ)

№13; манги тд” ›‹ м::"; г

‘:{ТМИЫММ Лмижитв
: ” и ,"

5
их“"): під"

»] … Лмажшпь

:… «: ‚ - «аятнщ;

‚., … … …
„щ…… „_,. ‚ещ «…>

мииимшишщ (1… ‚так
…да. тнг? 271073, "”
Лможигт $:?

Бычшлйгйд “’;(агш

‚……
ад„" «:'5‘, тт" › и:”іы

 

длрешши/т 12”. д‘“, 17,5 ‹х,‘“— ::“;‚1,

Ф и г. 8.4.1. Блок-схема алгоритма скользящего допуска
 pagebreak 
Метод скользящего допуска 403

 

Процедура отыскания вершин х}… ($ = 1, ‚ 7 +1) реализует.
ся по следующей схеме. С помощью (8.1.1) вычисляется Фт) = 2 (т +
+ 1)! и находится значение Т(х) в исходной точке хш’. Если
Т(х(°’)<Ф(°)‚ то х‘щ является либо допустимой, либо почти допусти—

мой точкой, и исходные вершины хЁо’ (і = 1, . .. , г+ 1) находятся
с помощью процедуры, описание которой дано в подразд. 8.3.1.

Если Т(х(°’)>Ф(°’, то Т(х) минимизируется до тех пор, пока не бу-
дет найдена допустимая или почти допустимая точка х; именно эта
точка и выбирается в качестве базовой при построении исходного
многогранника.

Работа алгоритма заканчивается при двух обстоятельствах:

1. Когда Фш) < в. В этом случае поиск считается завершенным
и квалифицируется как успешный (именно такая ситуация возни-
кает в подавляющем большинстве случаев).

2. Когда с помощью процедуры, описание которой приведено
в разд. 8.3, не удается найти допустимую или почти допустимую
точку. В этом случае поиск заканчивается, производится замена
стартовой точки хю) и/или осуществляется переход к другому на-
бору значений параметров со, 5, т, ! и 8. В обычных условиях реко-
мендуется принимать ос = 1, 6 =0,5‚ \; =2 и е ==10‘5.

На фиг. 8.4.1 представлена блок—схема, дающая общее пред-
ставление о логической схеме алгоритма скользящего допуска.
Снисок соответствуюцшх машинных команд на языке ФОРТРАН
приведен в приложении Б.

 

Пример 8.4.1. Метод скользящего допуска
В качестве примера рассмотрим следующую задачу:

минимизировать )“ (х) =4х1 _ хЁ — 12
при ограничениях
п1(х)=25—х%—хё=о,
д„(х) = 10х, _ хЁ+10х„— хё— з4>о,
83 (х) = 151 >01
831“) = 152 >О—

іслевая функпия и ограничения этой задачи изображены гра-
фически на фиг. 6.0.1 и П.8.4.1. В качестве начальной (стартовой)
точки возьмем недопустимую точку хЪО’ = [1 Пт, & начальную ве-
личину параметра размера многогранника положим равным !=

=0‚30. Тогда. согласие (8.1.1), Мя критерия допуска на старте
будем иметь

Ф<°’=2‹т+ т=2 ><(1 + 1) ><о‚зо= 1,20.
 pagebreak 
404 Глава 8

 

“а
‚л

5 ‚

. \О

, №“,
4
о

_; ‚№№

 
  

!
7 › ; ад“” у{:1=/0.г‚-.тд.‘+П1'г—1Ё-б но

,! МШ- 25— :::,іхд- П
в і 2 з 4 5 $,
Ф и г. П.8.4.1. Траектории поиска с помощью алгоритма скользящего допуска

(ЧИСЛЕ УКЗЗЫПЗЮТ ПОРЯДКОВЫЭ номера этапов ОПТИМИЗЗЦИОННОГО процесса).

В точке хЬ'” =[1 ПТ значения функций, задающих нарушенные
ограничения, таковы:

Щ (хш’) = 23 и 32 (х‘щ) = _— 16,

так что значение Т (кБт), вычишенное с помощью соотношения
(8.1.5), равняется

Т (хз“) = №3)и + (_ 16) Х 21% = 28,02.

Мы вщим, что Т(х8°’)>Ф(_°’. Следовательно, на первом цик-
ле работы алгоритма осуществляется поиск почти дапустимого
вектора.

Чтобы начать процедуру минимизации Т (х), построим равно-
сторонний треугольник, каждая сторона которого равняется 0,06:

Вершина ;: ;:
1 1 ‚000 1 ‚000
2 1,057 1 ‚0 1 5
3 1,015 1,057
 pagebreak 
Метод скользящего допуска 405

Теперь методом деформируемого многогранника (обсужпение
данного метода см. в разд. 442) осуществляется минимизацпя

Т (х) = [и? (х) + №5 (х) + №5 (х) + №3 (кпд
где иі—оператор Хевисайда. В результате получается после-
довательность вершин, указанных Б приведенной ниже таблице:

Удивлетворяются лн ограничивмощие
усмвия в виде неравенств?
Новая

 

 

вершина ;: ;:

№ (3 да 66 ! е. &?
4 1,110 1,110 Нет Да Да
5 1,072 1,221 » » »
6 1,243 1,381 » » »
7 1,253 1,683 › » »
8 1,600 2,154 » » »
7 1,794 2,993 Да » »
8 1,426 1,918 Нет » ›
9 2,584 4,356 Да » »

 

(Напомним, что и, = 0, если соответствующее ограничивающее

условие удовлетворено.) В точке хз” удовлетворяются все ограни-

чения-неравенства, так что единственным нарушенным ограниче-

нием в этой точке является ограничение ?: (хЪЩ) =0,648‹ Отсюда
следует, что
т (хз“) = 0,648 < Ф‘с" и хз" = хз”.
Теперь алгоритм переключается на минимизаЦИю целевой функ-

ции [ (х)\ В точке ХБ" =[2,584 4,3561Т имеем [(хЪ”) =2,063. Да-
лее строится новый симплекс при сдедующих координатах вершин:

Новая вершина | х, | х,
0 2,584 4,356
1 2,559 4,331
2 2,617 4,347
3 2,574 4,389

На этом этапе оптимизационного поиска значение критерия допу-
1
ска Ф‘ ), найденное с помощью (8.1.1), равняется

Ф") = шігц1,20; 0,0447} =о‚0447, т. е.
 pagebreak 
406 Г лава 8

 

Ф… < Т(х 'в”). Следовательно, необходимо вновь перейти к поиску

почти допустимой точки, начиная ‹: ХБ” = х51’=[2,574 4,3891Т.
Все последующие этапы поиска в точности воспроизводят опи—
санные выше процедуры, и мы их подробно не рассматриваем. Ре—

Таблица ПВА.!

 

 

 

 

 

Этап х, , х, › [(х) Ф ”1 (х)
1 2,574 4,389 —2о,966 447.10—2 —8,94‹ 04
2 2,600 4,274 —19,867 7.1310—3 —з,01- 0—2
3 2,599 4,270 —19,836 6,33-10’З 6,68-10‘3
4 2,578 4,284 _20,041 1,2210*3 —6,74- 0—4
5 2,549 4,301 —2о,029 6,33. 10'3 633.104
6 2,457 4,355 41,1147 63810“3 —2‚06‹ о—4
7 2,278 4,451 722,703 6,33.11гз —5,42‹ 0—3
8 1,814 4,659 —26‚457 6,22›10"3 ——6,05‹ 0—3
9 1,059 4,886 ——31,636 6,33›10"3 4,79. 0—3
10 1,015 4,896 —31,916 6,3310'3 ——З,64›10_3
11 1,015 4,896 431,916 6,33-10‘З 43,6410—3
12 1,003 4,898 ——31,988 6,3340'3 _1,77. 0—3
13 1,003 4,898 —31,983 6,33‹1О`3 —1,77.10—3
14 1,003 4,898 —31‚983 6,36 10“3 _1,77.10—3
15 1,002 4,899 _з1,989 2.24.10—3 _2,03_ 0—4
16 1,001 4,899 —з1,993 1,11 . 10—3 …1‚4з› 10—3
17 1,001 4,899 _э1‚992 2,43.1о—4 _7,о1- 0—4
18 1,001 4,899 _31,991 2,43104 6,5910—5
19 1,001 4,898 _31,991 3195-10—5 7,69 0—5
20 1,001 4,898 —з1,992 395.10“5 4,34 10—5
21 1,001 4,898 41992 319540 5 _з‚50‹ 0—5
22 1,001 4,898 —31,992 1,0910—5 4,50 0—5
23 1,001 4,969 41,992 832-1043 5.53.10—6

зультаты, полученные в ходе оптимизационного поиска с помощью
алгоритма скользящего допуска, приведены в табл. П.8.4.1 (эти ре-
зультаты округлены до третьего десятичного знака). Мы видим,
что на десяти последних этапах минимизируюшие поправки для
х и ‚‘ (х) незначительны. Однако в результате реализации этих эта-
пов достигается более строгое выполнение ограничения-равенства.
Траектория поиска изображена на фиг, П‚8.4.1, Следует обратить
внимание на то, как в процессе поиска происходит постепенный пе-
реход к точкам, обеспечивающим более строгое выполнение услр-
вия #11 (х) =0.
 pagebreak 
Метод скользящего допуска 407

 

8.5. МЕТОДЫ РЕШЕНИЯ ЗАДАЧ НЕЛИНЕЙНОГО
ПРОГРАММИРОВАНИЯ С ЗОНАЛЬНОЙ
НЕОПРЕДЕЛЕННОСТЬЮ

Известны примеры задач нелинейного программирования, в ка
торых целевая функция и, возможно, некоторые из ограничений
В некоторых зонах (или областях) Е" не определены. Чтобы не до-
пустить в таких случаях преждевременного прекращения поиска,
необходимо переформулировать задачу, введя запрет на те векто—
ры х, для которых хотя бы одна из функпий } (х), и,. (х) и Е; (х) од-
нозначно не определена или теряет физический смысл. Для иллю-
страции этой идеи рассмотрим следующую задачу:

МИнИМИзировать [(х) =(хЁ +х3 _ 4х2 —— 45)"' +

+ [111 ": (хг _ 2)“ Х Е Е".
при ограничении
д,… : 64—х3—хё>о. (8.5.1)

Поскольку квадратный корень из отрицательного числа и лога-
рифм отрицательного числа не имеют смысла, целевая функция
задачи (8.5.1) не определена в точках, для которых

(х%+хё_4х‚—45)<о‚ х1<0‹или(х2—2)<0.

В области, показанной на фиг. 8.5.1 заштрихованной кромжой по
внутренней стороне контура, образованного дугой окружности, кото-
рая задается уравнением @, (х) = х? + хЁ — 4х2 —- 45 = 0, и отрезка-
ми прямых, описываемых уравнениями ‚%(Х) = хд =() и ддх) :
=_- хг —- 2 = 0, все функции, фигурирующие в задаче (8.5.1), опреде—
лены. Обратим впимание на то, что значительная часть допусти-
мой области, ' определяемая условием @! (х) > 0, по указанным
выше причинам исключается из рассмотрения. Другими приме-
рами, в которых некоторые из функций, фигурирующпх в форму-
лировке задачи, зонально не определены, являются задачи 4, 9 и
17 в приложении А.

Если алгоритм скользящего допуска используется для решения
Задачи нелинейного программирования в общей постановке, то эту
задачу необходимо привести к такому виду, когда заведомо устраня—
ется возможность манипулирования с точками х, лежащими за
пределами области определения рассматриваемой задачи, Один из
способов устранения из рассмотрения зон, в которых задача не
определена,заключается в надлежащей замене переменных На-
пример, замена переменных х1 и х% в задаче (8.5.1) по формулам

х1 = 7 +е2‘,

Где 2 — новый вектор, приводит к следуюшей задаче:
 pagebreak 
408 Глава 8

 

 

шато

      
 

адлаатд ол !: ения
зауаіирй’іі)

о 2 4 б а и:,
Ф и г. 8.51. Графическое изображение области определения для задачи (8.5,1).

минимизировать [‘ (2) = (в”1 + 14е’д + ггг!“ + Пп (8 + в“) ещ”,
: Е Е",
при ограничении
31(2) = 11—14521 —— ещ — 4е’я _ ед: > 0,

где [(и) определена теперь для любого вектора 2. В результате
преобразования (8.51) в (8.5.2) формулировка задачи оказывается
полностью корректной и допускает применение алгоритма сколь-
зящего допуска в его обычном виде. После того как будет найдено
оптимальное решение :* задачи (8.5.2), значение х* нетрудно вы—
числить, используя соотношения, с помошью которых производи-
лась замена переменных.

Когда в некоторых зонах области изменения х не определена
лишь целевая функция, для каждою члена в выражении для Дх),
приводящего к неопределенности в указанном выше смысле, необ
ходимо ввести вспомогательное ограничение в виде неравенства

8р+і(х)і Ы,- ‹х›—Ф‘*’ » і = р + 1, . . . ‚ р + 4, (8.5.3)
где Д.… (х) — і-я компонента в структуре целевой функции, за Счет
которой [ (х) теряет определенность в отдельных зонах Е”, 3 ‹; -—
 pagebreak 
Метод окользлщего допуска 409

 

число таких компонент в выражении для [(х). Дополнительные
ограничения Вида (8.5.3) добавляются к ;) исходным ограничениям
задачи нелинейного программирования, и «уточненная» задача
решается обычным способом. Путем вычитания Ф… из Р,… (х)
(і : р + 1, ..., ;] +11) мы исключаем из рассмотрения те векторы
;;, для которых Рич (х) < 0 в случаях, когда выполнятся усло-
вие (8.1.6). Таким образом мы добиваемся того, чтобы неравен-
ство (8.1.6) выполнялось лишь при условии Р„“ (х) >О (і=
= 11 +1. р +4)-

Переходя к более подробному рассмотренню, допустим вначале,
что одна из компонент Р,…(х) в текущей точке х такая, что
_В… (х) >О, т. е. Р,… (х)< 0. Поскольку по определению Ф… >О,
из (8.5.3) следует, что д‚‚+;(х) =Р„+;(х)—-Ф®<0‚ т, е. в теку-
щей точке х функция 9„+‚-(х) принимает отрицательное значение.
Предположим, кроме того, что для всех остальных ограничений
Ид(х)=0(і= 1, ..., т), д,(х)>0 (і==т+ 1, . р+і—1, ‚)+
+ і—— 1, ..., р + 4). Тогда будем иметь Т(х) = + [(— Р`‚‚+;(х)—
——Ф"”)2]‘/я= Р„+д(х) +Ф‘“. Поскольку Т(х)>Ф“”, условие (8.1.6)
не вылолняется, и, следовательно, необходимо мш-ШМизировать Т(х)
до тех пор, пока не будет выполняться условие Р,…(х) >О.

В силу определения Т(х) очевидно, что для любой компоненты

Р‚‚+,-‚ удовлетворяющей условию 0<Р„+‚-(х)<Ф(Ы‚ неравенство
(8.1.6) выполняется даже в том случае. когда дд+і(х)<0. При
1‹`‚‚+,-(х) >Фо" имеет место неравенство 3„+,-(х)>0‚ что никак не
сказывается на поведении Т (х). Аналогичные рассуждения спра-
ведливы и теща, когда в точке х оказываются нарушенными сразу
несколько ограничений в виде равенств и/или в виде неравенств,
так как в структуру Т(Х) входят все нарушаемые ограничения.
Добавление к исходным ограничениям общей задачи нелинейного
программирования (8.0.1) ограничений (8.5.3) приводит к следую-
щему выражению для Т (х):

пд 9 11+! Ч:
т‹х›=+[іё1нг‹х›+і_>д+„и.ег‹х›] . (8.5.4)

Формула (8.1.5) используется при определении Т (х) в тех слу-
чаях, когда все функции, фигурирующие в формулировке задачи
(8.0.1), определены для всех значений х 6 Е"; в случае же, когда
некоторые из упомянутых выше функций зонально не определены
(т. е. определены не для всех х 6 Е”), следует использовать фор-
мулу (8.5.4).

Чтобы проиллюстрировать описанную выше процедуру, преоб-
разуем задачу (8.5.1) в следующую задачу:

минимизировать [(х) = (х? + хЁ — 4х2 — 45) ” + [111 х1 (х2 — ?)]2

(8.5.5)
 pagebreak 
410 Глава 8

при ограничениях
3100 = 64—хЁ—хё>0‚
ых) = ‚%+ х3_4х‚_-45—Ф“” >О,
Е:: (Х) = "1 " ФО?) > 0,

ых) = х2—2—Фш>0.

Функции Е, (х) (і =1, 2, 3, 4) определены для любого х Е Е":
однако, поскольку вычисление [ (х) возможно лишь при выполне-
нии неравенства (8.1.6), отрицательные значения (х? + ХЁ — 4х9 ——
— 45), х‘ и (;(2 —— 2) оказываются недопустимыми. Путем исполь-
зования рассмотренной вычислительной схемы были успешно ре-
шены, в частности, задачи 4. 9 и 17 из приложения А.

Следует, однако, еще раз отметить, что описанная выше про-
цедура оказывается неприменимой в случае, котла эоналыю

(т. е. для некоторых х Е Е") не определены одновременно и целе-
вая функция, и функции, задающие ограничения задачи.

ЛИТЕРАТУРА

1. Рачіапі В., Нігпгпе1Ыап В. М., Оригинал; дез., 17 (1969).
2. \Уііде Б. Л., Орііпшгп ЗееКіпд Ме…одз, Ргепіісе-На", Шо., Епдіешооа Сііііз,
М. д., 1962, р. 32.
 pagebreak 
Глава 9

ОЦЕНКА ЭФФЕКТИВНОСТИ МЕТОДОВ НЕЛИНЕПНОГО
ПРОГРАММИРОВАНИЯ ПРИ НАЛИЧИИ ОГРАНИЧЕНИЙ

Целесообразность выбора того или иного из рассмотренных вы—
ше алгоритмов в целях его практического использования опре—
деляется эффективностью этого алгоритма при решении конкрет-
ного класса задач нелинейного программирования с помощью ЭВМ.
Как и следовало ожидать, ни один из алгоритмов нелинейного
программирования, рассмотрению которых посвящены гл. 6—8,
не может считаться наилучшим по сравнению с другими алгорит—
мами при решении любых задач нелинейного программирования
и при любых обстоятельствах. Прежде чем перейти к оцениванию
эффективности конкретных алгоритмов нелинейного программи-
рования при наличии ограничений, рассмотрим вопрос относитель-
но критериев, которые следует иметь при этом в виду. После
обсуждения используемых критериев эффективности приводятся
результаты сравнительного анализа различных алгоритмов. Нако-
нец, излагаются некоторые обшие соображеНИЯ 14 Выводы, которые
могут послужить своего рода ориентиром для тех, кто намерен
применять алгоритмы нелинейного программирования на прак-
тике.

9.1. КРИТЕРИИ, ИСПОЛЬЗУЕМЫЕ ПРИ ОЦЕНКЕ
ЭФФЕКТИВНОСТИ АЛГОРИТМОВ НЕЛИНЕЙНОГО
ПРОГРАММИРОВАН ИЯ

На вопрос о том, какой из критериев оценки нелинейного
программирования наилучший, можно дать лишь «комплексный»
(т. е. развернутый) ответ. Ответ на этот вопрос в значительной
степени зависит от того, к какому классу (или типу) относится
рассматриваемая задача. от глубины предварительного анализа
структурных особенностей задачи и от осведомленности пользо-
вателя относительно конфигурации и размеров допустимой об-
ластм, ассоциированной с решаемой задачей. К числу важных
критериев, используемых при оценивании «качества» того или ино-
го алгоритма. относятся следующие:

1) время, необходимое для реализации серии вычислительных
Процедур (число операций и время их выполнения);
 pagebreak 
412 Глава 9

 

2) степень сложности задачи (размерность, число ограниче-
ний в виде неравенств, число ограничений в виде равенств);

3) точность решения по отношению к оптимальному значению
х* и (или) по отношению к Мк“), &(х*), 3(х*) и 7і(х*);

4) простота практического использования алгоритма (время,
необходимое для ввода исходных данных и записи функций в па-
мять ЭВМ);

5) простота машинной программы, реализующей рассматри-
ваемый алгоритм.

Наконец, важное требование, предъявляемое к алгоритму не-
линейного программирования, заключается в том, чтобы

6) он позволял решать задачи, которые представляют практиче-
ский интерес (нельзя считать, что какой-либо из алгоритмов окажет`
ся эффективным при решении любой задачи, и требовать, чтобы
он решал «патологические» задачи,т. ет задачи, которые специально
«подобраны», чтобы создать трудности для данного алгоритма).

Следует отметить, что указанные выше критерии носят гло-
бальный, & не «локальный» характер в том смысле, что они отно-
сятся ко всем этапам процесса оптимизации (начиная с первою
и кончая последним), а не к каким-либо отдельным этапам оптя`
мизационного поиска,

Наиболее широко используемыми критериями при оценивании
относительной эффективности машинных программ. предназна—
ченных для решения задач нелинейного программирования, являют-
ся количество вычислений значений функций, требуемое для полу-
чения оптимального решения той или иной тестовой задачи с за-
данной степенью точности, и (или) затраты машинного времени,
сопряженные с решением рассматриваемой тестовой задачи. Коли—
чество вычислений значений функций показывает, сколько раз воз-
никает необходимость в определении числовых значений целевой
функции и (или) той или иной функции из совокупности функций,
задающих ограничения задачи (а также числовых значений произ-
водных упомянутых выше функций), прежде чем будет найдено
решение расшатриваемой задачи нелинейного программирования.
Этот критерий является менее значимым в тех случаях, когда за-
дача содержит большое число ограничений при сравнительно не-
большом числе переменных, так как временные затраты, требуе-
мые для определения точки, в которой следует вычислить значения
‚° (х) и (или) и, (х) и 3, (х), нередко в несколько раз превышают
временные затраты, связанные с нахождением самих значений ука—
занных выше функций.

Таким образом, машинное время, требуемое для выполнения
последовательности процедур оптИМиэации‚ Является наиболее
часто используемым критерием, ПОЭВОЛЯЮЩИМ сравнивать эффек‹
тивность различных алгоритмов нелинейного программирования.
Вопрос о затратах машинного времени при использовании про-
 pagebreak 
Нелинейное программирование при наличии ограничений 413

 

грамм, реализующих различные вычислительные алгоритмы, ис-
следовался Стоккером 11], Хольцманом [2191 Колвиллом [3].
Поскольку разныеЭВМ имеют различные характеристики и не0ди-
наковое быстродействие, разработаны стандартные таймерчпро-
граммы для перерасчета временных затрат при переходе от одного
типа ЭВМ к другому. В результате можно проводить сравнение
значений времени по единой (приведенной) шкале, которую

Таблица 9.1.1
Машинное время, требуемое для реализации стандартной таймер-программы

 

 

Автор Тип ЭВМ Программа Время, ‹:

Абади КВМ 7094 МОПГ 63,0

СВС 6400 МОПГ (модифициро- 20,5

ванный)

Боас Оптим 1 19,7
Колвилл [ВМ 360/50 ПОП 11 168.0
Дэвис Еп311'511 Е1ес1гіс КВЁЭ Разн. 362,0
Кефарт [ВМ 7094 ОГМОП 128.2
Мак-Кормик МПБМ 599,0
Хольцман ПВМ 360/50 140,0
Стоккер СВС 6600 22,0

 

называют шкалой стандартизированного машинного времени.
Типичная стандартная таймер-программа, составленная на язы-
ке ФОРТРАН Колвиллом (см_ приложение Г ), сводится к прос-
тому десятикратному повторению операции инверсии по отношению
к матрице размерности 40 >< 40. В табл. 9.1.1 приведены вре-
менные затраты по реализации таймер-программщ указанные
временные характеристики для различных типов ЭВМ заимство-
ваны у различных авторов (Колвилл, Дэвис, Стоккер и др.).
Необходимо, однако, пшчеркнуть, что сравнительные оценки
стандартизированных временных затрат нельзя считать достаточ-
но точными показателями при оценивании эффективносш различ-
ных машинных программ. Оказывается, что при решении одной и
той же тестовой задачи на различных ЭВМ в оценках стандарти-
зированных временных затрат имеют место значительные расхож—
дения. Для иллюстрации в табл. 9.1.2 дано сравнение стандар-
тиэированных временных затрат при решении тестовых задач
10, 11, 15 и 19 из приложения А (с помощью метода МПБМ); со-
держащиеся в этой таблице данные заимствованы у Колвилла и
Стоккера (оба автора пользовались одной и той же программой).
Данные, приведенные в табл. 91.2, показывают, что сравнение
 pagebreak 
414 Г лава 9

 

эффективности машинных программ на основе оценок затрат мг-
шинного времени по приведенной (стандартизированной) шкал.-
вводит в некоторой степени в заблуждение, «Корректной» стан—
дартной таймер—программой могла бы быть лишь такая программа,
в которой принимались бы в расчет полиморфные факторы вычис—
лительной логики, структурные и емкостные характеристики па—
мяти ЭВМ,конфигурационныеи временные характеристики вычис—
лительного комплекса (центрального процессора и периферийных
устройств), объем распечатываемой информации и т. д.. имею—

Таблица 9.1.2

Сравнение стандартизироваиных временных затрат при решении задач 10,
Н, 15 и 19 приложения А

 

Номер задачи

Метод
Ю Н 15 |%
Колвилла 0,0162 0,028? 0,151] 0,238
Сюккера 0,127 0,048 0,253 0,719

 

щие место в различных типах ЭВМ и разных видах программного
обеспечения.

Чистое машинное время”, требуемое для решений той или
иной задачи, существенно зависит от того, с какой точностью нуж-
но определить оптимальное решение, а также от величины допуска
при выполнении ограничивающих условий на этапах, непосред—
ственно предшествующих завершению оптимизационного поиска.
Чтобы критерий, на основании которого производится сравне-
ние эффективности используемых при программировании алго-
ритмов, «работал» однозначно, при решении тестовой задачи необ-
ходимо стремиться к достижению одной и то'й же степени точности.
Вообще говоря, не исключено, что машинная программа, поз-
воляющая решить задачу быстро, но в грубом приближении,
окажется предпочтительнее какой-либо другой машинной про-
граммы, с помощью которой та же самая задача решается гораздо
дольше, хотя и с большей точностью определения оптимальных
значений х и {(х) и (или) выполнения ограничивающих условий
и, (х) = 0 и 5, (х) > 0. К сожалению, критерии останова. исполь-
зуемые в разных программах, различны, и, следовательно, точ-
ность решения одной и той же задачи с помощью разных программ
также оказывается неодинаковой. В разд. 93 вместо попытки
унифицировать критерии завершения работы программы (унифи-

‘) «Чистое» машинное время не включает время на подготовку, считывание и
распечатку, время задержки данных в системе раздыения времени в периферий-
ном контуре и т. п.
 pagebreak 
Нелинейное программироёание при наличии ограничений 415

 

кация такого рода сильно отразилась бы на всей схеме вычисли-
тельного процесса) проводится сравнение программ другим спо-
собом (по методике, предложенной автором данной книги).

Другим важным критерием, используемым при сравнении ма—
шинных программ. является показатель, характеризующий сте-
пень простоты (или сложности) подготовки задачи к решению поль—
зователем. Хотя этот аспект анализа и носит в известной степени
качественный характер, два существенных фактора, влияющих
на решение вопроса о целесообразности использования той или
иной программы, требуют особого рассмотрения. Один из них ——
это фактор. обусловленный возможностью возникновения ошибок
в процессе подготовки данных человеком («вручную»). Програм-
мы. требующие выполнения громоздких и трудных подготовитель-
ных операций, более подвержены влиянию ошибок человека, не-
жели программы, подготовительные операции для которых просты.
Другой фактор является чисто экономическим. Затраты, свя-
заннъте с решением Задачи математического программирования,
складываются из затрат на подготовительные операции и стоимости
матинного времени, расходуемого на решение задачи. Таким образом,
решение задачи с использованием менее эффективной программы,
которая, Однако, не требует больших трудозатрат на подготови-
тельном этапе, может обойтись дешевле, нежели решение той же
самой задачи с помощью высокоэффективной программы требую-
щей большого объема подготовительных работ. Такого рода эко-
номические расчеты с трудом поддаются сравнению, поскольку
упомянутые выше расходы сильно варьируются в зависимости от
конкретной ситуации; тем не менее экономические соображения
представляются весьМа существенными.

Некоторые машинные программы содержат большое число па-
раметров, удачный выбор которых повышает эффективность при-
меняемого алгоритма. Все упомянутые выше разработчики про-
грамм предлагают придавать входящим в программы параметрам
и константам их средние значения; однако при этом максимально
возможная эффективность программы при решении той или иной
конкретной задачи может оказаться недостигнутой. В некото-
рых программах содержится настолько большое число перемен-
ных параметров, что в итоге определяющий программу вычисли-
тельный алгоритм можно рассматривать как функцию некото—
рого набора параметров. Если программа оказывается малоэффек-
тивной при каком-либо конкретном наборе значений параметров,
ее можно подправить путем перех0да к другому набору значений
этих параметров. Наличием чрезвычайно большого числа подоб—
ных параметров особенно отличается ПОП 11.

Необходимость учета всех упомянутых выше факторов в опре-
деленной степени затрудняет интерпретацию результатов оцени`
вания эффективности алгоритмов путем решения тестовых задач.
 pagebreak 
416 Глава 9

 

В частности. оказывается, что эффективность того или иного ал-
горитма, оцениваемая на основе требуемого машинного времени
при решении тестовых задач (и в несколько меньшей степени _
оценка, основанная на количестве тестовых задач, решенных с
помощью рассматриваемого алгоритма), является в значительно
большей степени качественной, чем это представляется на первый
взгляд.

Учитывая изложенные выше соображения, проведем анализ
эффективности различных алгоритмов нелинейного программиро-
вания, исходя из следующих критериев. Первый и наиболее важ‹
ный критерий сводится к ответу на вопрос: удается ли вообще ре-
тить с помощью рассматриваемой программы поставденную зада-
чу? Этот критерий выбран потому, что для пользователя наиболее
ценным качеством машинной программы является ее способность
обеспечивать решение самых разнообразных задач нелинейного
программирования. Вторым критерием является требуемое
количество машинного времени. Наконец, используется и третий
критерий, характеризующий трудоемкость подготовительных про-
цедур, осуществляемых вручную на этапе, предшествующем реа-
лизации той или иной программы на ЭВМ. Этот критерий приоб
ретает весьма важное значение при сравнении временных затрат
на подготовительном этапе применительно к схеме оптимизации мето-
дами прямого поиска с соответствующими временнь’хми затратами
в случае, когда используются методы, требующие знания анали-
тического вида частных производных.

9.2. СРАВНЕНИЕ НЕКОТОРЫХ АЛГОРИТМОВ
НЕЛИНЕИНОГО ПРОГРАММИРОВАНИЯ
ПРИ НАЛИЧИИ ОГРАНИЧЕНИЙ:
ДВУМЕРНЫЕ ЗАДАЧИ

Чтобы проиллюстрировать поведение траектории поиска эк-
стремума задачи нелинейного программирования при наличии
ограничений в двумерном пространстве, с помощью множествен-
ной регрессии была построена целевая функция специальной струк-
туры (табл. 9.2.1). Эта функция в заданном интервале значений
двух независимых переменных имеет один пик и одну седловую
точку. Рассмотрен ряд конкретных задач, каждая из которых сво—
дится к максимизации целевой функции при наличии некоторого
множества ограничений-неравенств‚ приведенных в табл. 9.2.2.
Пять таких задач, конкретизированных путем выбора под-
множества ограничений-неравенств, приведены в табл. 9.2.3. 3
целевая функция. ограничения и соответствующие траектории,

» ц - чТ
исходящие из недопустимои начальнои точки х…) = [90 101 ‚ изоб-
 pagebreak 
ПЛМ атм
„„/дара…

Но— лол !!

лгаршпм
ЯЛ

..--“

#10957)

———› ЛЛ

 

алгоритм ммшщт
№
мрт

-›—› НЛ” №№ МЛЛГ
..…. ММёЩ-М
№:! ;да/ш
Ф и г. 9.2.2. Задача 2‚
 pagebreak 
418 Глава 9

 

ражены графически на фиг. 9.2.1—9.2.5. Пик целевой функ-
ции находится в точке с координатами яс1 =81‚154841 и хи =
=69‚135588; в этой точке целевая функция принимает значение
61,9059345. Условный максимум находится в точке с координата-
ми х1 = 75,000000 и хз = 65,000000; в этой точке значение це-
левой функции равняется 58,9034360,

Таблица 9.2. !
Целевая функция

НХ) = 3. + В. (Х.) + В: И)‘ + 5.031)“ + 3. (ХШ + В. (11) + 87 (х,) (х,) + 3. (ХШ %) +
+ Б„ (х,» ‹х‚› + 8… ‹хо‘ ‹… + В.. от* + в,. и.), + в,. ‹х‚›* + В… [771373] +
+ Бы Ш)’ (х,)“ + вы (%)а “д' + Вп (Хо' (ХШ + Н.. (Х.) (Х.)' + 5.901) (х,)“ +
+ в„{ехр [0.0005 (‚кд (им}

 

 

в, = 75,1968666677 в": 02564581253
3, = _ 3,8112755343 в“ = _о,ооз4604озо
в, :. 0‚|269366345 в…: 0,0000135139
в4 : … 0.0020567665 314 = —2з,1ов44з4908
в.., : 0,0000103450 в…: —о‚ооооозгз75
в° : _63306567613 5… = _ 0,0000000063
в, = 0,0302344793 в„= 0,0000000007
вв =_—о‚001281з448 вп: 0,0003405462
в„ = 0,0000352559 в.,: ——0,0000016638
в10 = _о,оооооог2вв в…, = —2‚8673112392

Задача 3 (фиг. 9.2.3) позволяет наглядно представить ряд ти-
пичных характеристик машинных программ, к обсуждению кото—
рых мы и переходим.

]. Алгоритм скользящего допуска. Каждый из векторов, изоб—
раженных на фиг. 9.2.3, соединяет следующие одна за другой наи-
лучшие точки, генерируемые в процессе оптимизационного поис-
ка. Напомним, что в методе скользящего допуска используется
симплекс с („ + 1) вершинами, где я —— число независимых пере`
менных. Следовательно, на каждом этапе поиска наилучшей точ-
кой является та вершина рассматриваемого на данном этапе сим-
плекса, в которой целевая функция принимает наибольшее (по от-
ношению к остальным вершинам) значение.

Поскольку начальная точка не является допустимой, програм-
ма реализует поиск новой точки. удовлетворяющей исходному
критерию допуска. Этот шаг поиска изображен графически пер-
вым вектором, проведенным из точки с координатами ::1 = 90,0 и
х, = 10,0 в точку с координатами х1 =68‚787 и х2 = 31,213.
Следует отметить, что поиск точки, удовлетворяющей критерию
допуска, реализуется по наикратчайщему пути вблизи границы
допустимой области. Тот факт, что траектория поиска, кроме того,
 pagebreak 
‚,и

‚„ '

3.

‚ .
‹ хам,...

г, 9.2.3. Задача

Фи
 pagebreak 
420 Г лава 9

Таблица 9.2.2

Ограничения—нерпеистю, используемые для построения мумерннх моделей
при заданной целевой функции (см. табл. 9.2.1)

 

е. (к): „, >О

81001 хй>0

& (х): 95,0 _ х, > 0

34 (х): 75,0 _— хд > О
55 (х): хр:й —— 700,0 > 0
36 (х): 75,0 — $, > 0

87 (х): 65,0 — 12 > 0

х в

88001 х.. — 5,0 {ЧЁ} >О

дд (х): (х„— 50,0)“ — 5,0 (х, — 55.0) > 0
810 (х): "1 “ 54›0 >О

30,0
Е„ (Х): т- (::в — 45,0) — (‚$1 — 45,0) > 0

40,0
810001 11 — 35.0 — т (::я — 40,0) >0

перпендикулярна линиям уровней целевой функции, является
простой случайностью.

Четыре последующих шага в процессе оптимизационного поис-
ка имеют длину, превышающую линейный размер допустимой об—
ласти, так как длина ребра первоначального симплекса прини-
малась равной пяти единицам. Если бы размеры исходного СИМ›
плекса были меньше указанных выше, траектория поиска про—
ходила бы ближе к границе, определяемой ограничением 9, и,
следовательно, затраты машинного времени были бы более зна-
чительными.

Пять первых шагов оптимизационного поиска позвол51ют
определить точку вблизи оптимума; однако окончательная сходи-

Таб/шци 9.2.3

Варианты двумерных задач нелинейного программирования при
наличии ограничений

 

Номер задачи ФЁЗЗЁЕ' , Номера огрвничений
1 9.2.1 1, 2, 3, 4, 5
2 92.2 5, 6, 7, 8
3 9.2.3 5, 6, 7, 8, 9
4 92,4 5, 6, 7, 8, 9, 10
5 9.2.5 5, 6, 7, 8, 9, 11, 12
 pagebreak 
Нелинейное программирование при наличии ограничений 421

 

мость к оптимальному решению достигается лишь в ходе реали-
зации дополнительных 39 итерационных этапов, что объясняется
постепенным уменьшением размеров симплекса па завершаю-
щих стадиях вычислптельного процесса. (Чтобы избежать чрез-
мерной громоздкости графического изображения, на фиг. 9.2.3

Иша

‚«‹-цьц-щ

13

до 70 до 90.1,

 

0—0—0/70/7 !! ....... ‚... №
" "" "'/1” № штамм №№:»
_ …

№7511 „..…. ”0,7?”

Ф и г. 9.2.5. Задача 5.

эти 39 шагов. работы алгоритма не представлены.) Вектор х осцил-
лирует в окрестности точки, лежащей на расстоянии около пяти
единиц от оптпмума; процесс осцилляции продолжается до тех пор,
пока размеры симплекса не уменьшатся до такой степени, когда
станет возможным получение дополнительных минимизирующих
поправок к значению целевой функции (т. е. дальнейшее переме—
щение в направлении к искомой оптимальной точке).

2. Алгоритм НЛП. Каждый из векторов, формирующих траек-
торию алгоритма, соединяет следующие одна за другой точки,
получаемые в ходе оптимизационного поиска. На пяти первых
шагах от исходной точки реализуются перемещения по алгорит-
му наискорейшего спуска, поскольку получаемые при этом точ—
ки лежат далеко за пределами допустимой области. Шестой шаг,
предпринимаемый из точки, лежащей вне допустимой области,
 pagebreak 
422 Г лава 9

 

переводит траекторию поиска внутрь допустимой области и осу—
ществляется по алгоритму линейного программирования. Все по-
следующие Шаги реализуются методом линейного программиро-
вания. Перемещения с помощью линейного программирования
производятся вдоль ограничивающих поверхностей (отметим, 13
частности. что последние шаги реализуются вдоль ограничении
9 и .

3.7)МПБМ (вариант, относящийся к 1967 г.). При использова-
нии МПБМ вначале осуществляется поиск внутренней точки; схе-
ма поиска выглядит следующим образом. При заданной началь-
ной точке нарушаются ограничения 7 и 8; поэтому с помощью
МПБМ прежде всего минимизируется взятая со знаком Минус фун-
кция, задающая ограничения 7 (при этом должны удовлетворяться
ограничивающие условия 5, 6 и 9), после чего минимизируется
взятая со знаком минус функция, задающая ограничение 8 (при
этом должны удовлетворяться ограничивающие условия 5, 6, 7
и 9). В результате получается внутренняя точка, лежащая в
окрестности точки с координатами 361 = 31 и х, = 48. Таким обра-
зом, первые два вектора. соединяющие первоначальную недопус-
тимую стартовую точку с внутренней (допустимой) точкой, полу-
чатся в результате большого числа итерационных этапов (на
рисунке микроструктура итерационного процесса не представ-
лена).

Завершающая часть оптимизационного поиска сводится и ре-
шению девяти сопутствующих подзадач (см, описание МПБМ в
гл. 8), в результате чего обеспечивается сходимость к условному
экстремуму. являющемуся решением исходной задачи. Заключи-
тельные шаги поиска для удобства показаны на фиг. 9.2.3 всгруп-
пированнсм виде. При использовании варианта МПБМ, отно—
сящегося к 1967 г}, вид траектории оптимизационного поиска за—
висит от порядка рассмотрения ограничений, тогда как в варианте
МПБМ, относящемся к 1970 г.. такая зависимость не имеет мес-
та, так как алгоритм минимизирует сразу сумму всех функций,
ассоциированных с нарушенными ограничениями. Интересно ат-
метить, что МПБМ-1970 в случае задачи 1 заканчивает работу воз-
ле седловой точки; попытки применить данный метод для решения
других задач оказались безуспешными.

4. Алгоритм Розенброка. За исключением первого вектора тра-
ектории поиска, который просто соединяет исходную точкус внут-
ренней (допустимой) точкой решаемой задачи, каждый из после-
дующих векторов, получаемых с помощью алгоритма Розенброка,
ассоциируется с новой минимизирующей поправкой к пред'
шествующему значению целевой функции. Машинная программа
обеспечивает поиск допустимой начальной точки путем максими-
зации суммы значений функций. задающих нарушенные ограни-
чения (в результате последовательной минимизации эта сумма
 pagebreak 
Нелинейное программирование при наличии ограничений 423

 

обращается в нуль); другими словами, все ограничивающие усло-
вия оказываются выполненными Для простоты на фиг. 9.2.3
показан лишь вектор, соединяющий исходную точку с первой из
допустимых точек рассматриваемой задачи. Посколы4у в направ-
лении поиска допустимой точки методом Розенброка длина пер-
воначального шага полагается равной одной десятой исходного
значения каждой из незавпсимых переменных, длина каждого из
шагов на началъной стадии поиска составляла девять единиц в
направлении ›‹1 и одну единицу в направлении хз. Так как при этом
значения функций, задающих нарушенные ограничения, улуч-
шались, поиск продолжался почти в одном и том же направлении
(длина каждого из шагов в направлении х1 значительно превыша-
ла длину каждого из шагов в направлении хя).

Дальнейший поиск оптимаЛЬной точки при старте из первой
допустимой точки включал дополнительно 136 этапов, по за-
вершении которых вычислительный процесс заканчивался. Точ-
ка, полученная в результате реализации первых шести этапов,
оказалась весьма близкой к усповно-оптимальной точке х1=

= [74,72669 64,9913617. На фиг. 9.2.3 микроструктура рабагы алгорит-
ма на протяжении 130 этапов не представлена. (Интересно отме-
тить, что алгоритм Розенброка при решении задач 1. 2 и 5 при-
вел к седловой точке, а в условиях задачи 4 оказался не всесто-
янии определить допустимую точку.)

5. ПОП 11. Наиболее примечательной особенностью ПОП 11 яв-
ляется то, что оптимизационный поиск осуществляется при малой
длине шага. Линейно программирующая стадия ПОП П генери-
ровала траекторию поиска, проходящую почти вдоль ограниче-
ний 9 и 7. (На фиг. 9.2.3 точки, попадающие на ограничивающую
поверхность 9, не показаны, так как они расположены слишком
близко друг от друга.),

6. Алгоритм ОГМОП (вариант, разработанный фирмой ‹Юньон
Карбайд»). Машинная программа‚ реализующая этот алгоритм.
оказалась не в состоянии решить задачу 3. При решении зада-

чи 1 была найдена точка х = [13,8 50,6]Т‚ лежащая неподалеку
от седловой точки. В процессе решения задач 2—5 на одной из
стадий оптимизационного поиска после выполнения операции про-
ектирования частные производные функций, задающих ограниче
ния, оказывались равными нулю.

7. Алгоритм МОПГ. Метод обобщенного приведенного градиен-
та относится к числу методов, индуцирующнх траекторию поис-
ка, проходящую весьма близко к ограничивающей поверхности,
которая определяется ограничением в виде неравенства. В силу
этого обстоятельства при решении задачи 3 «останов» имеет место
не при достижении глобального оптимума, а при «попадаНИИ»
в локальный оптимум. лежащий в окрестности точки с координа—
тами ›с1 = 12 и х, = 53. Следует отметить, что результат поиска
 pagebreak 
424 Г лава 9

 

зависит от стартовой точки. При решении задачи 4 глобальный
оптимум был достигнут при заданной стартовой точке по той при-
чине, что локальный (неглобальный) оптимум и седловая точка
задачи оказались вне допустимой области из-за наЛИчия ограни-
чения 10.

9.3. СРАВНЕНИЕ НЕКОТОРЫХ АЛГОРИТМОВ
ОПТИМИЗАЦИИ ПРИ НАЛИЧИИ ОГРАНИЧЕНИЙ
В СЛУЧАЕ БОЛЕЕ СЛОЖНЫХ ЗАДАЧ

Для оценки эффективности некоторых алгоритмов нелинейно-
го программирования при наличии ограничений как с вычисли-
тельной, так и с других точек зрения Стоккер [1] применял эти
адгоритмы при решении тестовшк задач на ЭВМ СВС 6600. Кол-
вилл [3] исследовал еще болъшее(по сравнению со Стоккером) чис-

 

 

Таблица 9,8.1
Ограничвния в виде Ограничения в виде равенств
пере венств
нелинейные ' линейные ] отсутствуют
Нелинейные А1 Ві С1
Линейные А2 В2 1)
Отсутствуют А3 С2 Е

 

ло алюритмов, хотя и приводит меньше подробностей относительно
их достоинств. В допшнение к результатам Стоккера и Колвилла
приведем в данном разделе результаты, которые не были опуб—
ликованы. Большинство тесговых задач, содержащихся в при-
ложении А, заимствовано из опубликованных источников; осталь-
ные тестовые задачи приложения А подготовлены нами специаль-
но. Некоторые из этих задач можно считать типичными задачами
нелинейного программирования в том смысле, что они (или их
аналоги) часто встречаются при решении конкретных практиче—
ских проблем. Эги тестовые задачи предсгавляют различные груп—
пы (классы) задач нелинейного программирования, т. е. это зада-
чи с различными типами входяших в них функций, с разными
структурными характеристиками, с неодинаковой степенью слож—
ности и разлщннм количеством независимых переменных.
Практически во всех рассматриваемых задачах целевые фун-
кции нелинейны. Системы Же ограничений варьируются: наибо-
лее тривиальными являются системы ограничений, состоящие
из одних лишь линейных ограничений в виде неравенств, а наи-
более полными (в структурно-аналитическом отношении)—си-
 pagebreak 
Таблица 9.3.2

Классификация машинных программ, предложенная Конвишюи

 

Производные и форм их
представления

Ссылка на раздел
(подраздел)

 

Методы прямого поиска (МПП)
Оптим (фирма «Мобил Ойл»)
Последовательный поиск

(фирма «Гласс и Купер»)
Комбинированный поиск
Розенброка

Отсутствуют
)

)
)

Клингмапа и Хнммельблау Аналитическая запись

Симплексный поиск (фирма
«Шелл Дивелопмент»)

Проб

Метод скользящего дЬпускаі)

Мелкошаговые градиентные ме—
тоды (МГМ)

ПОП/Збо (ШМ)

Рикошет (Гринштадт)

П ог амми «Карбайш

оРмёп

Метод аппроксимирующею
программирования

Подъем ‹: уклонением (фир—
ма ‹Шыл-Дивелопмеит»).

НЛП 2)

Крупношаювые градиентные ме-
тоды (КГМ)

МОПГ“)

Метод допустимых направ-
ленийПВМ)

Сочвтание метода Дэвидона
‹: МБП

Выпуклое программирование
ЦВМ, Франция)

Меюд сопряженных гради-
ентов (Голдфарб)

Проективный метод 0 пере-
менной метрикой (Муртаг)“’

Метод проекции градиента
(‹Шелл Дивелопиенть)

Улучшенный ме'юд проекции
градиента (инс'гитут Пас-
каля)

Модифицированный ме'юд
приведенном градиента
(институт Паскаля)

Моднфицнрованный метод
допустимых направлений

Методы вторых производных
(МВП) (1ВМ, ФРГ)
Гаусси—Нытоиа— Кэролла
МПБМ

Солвера

Отсутствуют

»
»

Числовые значення
Аналитическая запись
Числовые значения

Аналитическая запись
Числовые значения

)

Аналитическая запись

Аналитическая ›запись

То же
)

›

Аналитическая запись
или ЧИСЛОВЫЕЗНЗЧЁНИЯ

Аналитическая запись

4.5.2
6 1)

4.5.1
7.1.2

!. Ассоз. Сот иіег
Маш., 11,4000 64)

61)
8.1

6.1.2
], ЗИМ Аррі. Мат.,
14,3(1966)

6.3.2
6.1.1

6.2

6.3.3
6.3.3
6.3. 1

6.4
5.3

Р.“
—-ю

‘) Ссьшки на опубликованные работы ш, в конце указанной мин,
21 В обзоп Колвнтш (1968 г,) не включен.
 pagebreak 
426 Г лава 9

 

стемы, содержащие нелинейные ограничения как в Виде равенств,
так и в виде неравенств. В табл. 9.3‚1 представлена своего рода
классификационная схема, согласно которой задачи нелинейного
программирования в зависимости от типа системы ограничений
делятся на пять основных классов. Последовательносгь А, В, С, В
и Е (и индексы подклассов 1. 2 и 3) соответствует порядку умень-
шения сложности задачи, хотя и не исключено, что задача с един-
ственным нелинейным ограничением в виде равенства (класс А)
окажется менее сложной, нежелп задача, садержащая линейные
ограничения в виде равенств и нелинейные ограничения в виде
неравенств (класс В).

Таблица 9.3.3

Среднее стандартнзированное праця при использовании программ
классов А, в. С, |) и БП

 

Номер задачи Категория (тип) 2)

 

 

‘"”"тжение … К”… [ мпп \ мгм кгм мвп
[5 А2 0,179 0,060 0,049 —-
19 В? —— 0,305 0,148 0,238
7 С 1 0, 089 0, 054 0, 033 ——
” С1 0,295 0,017 0,023 0,019
14 С] — _- — —
18 С! — 0,326 0,220 0,151
10 В 0, 384 0, 055 0. 027 0, 023
8 Е 0.026 0,049 0,025 0,025

1) Зяиитоваио у Колвнлла (1938),
?)сМ. табл. 9.31

 

Колвилл собрал данные об эффектииости более тридцати различ-
ных машинных программ, предназначенных для решения задач
нелинейного программирования; он проанализировал «работу>>
этих программ для восьми стандартных тестовых задач, а именно
задач 7, 8, 10, 11, 14, 15, 18 и 19, приведенных в приложе-
нии А. Анализ проводился методом «коллективъшх усилий», пред-
полагающим участие в испытаниях программ нескольких специ—
алистов. Каждый из участников испытаний должен был решит
совокупность тестовых задач, выбирая по своему усмотрению
метод решения, машинную программу и тип ЭВМ. Колвилл сгруп-
пировал все программы таким образом, что получилось чегыре
больших класса; классификация Колвмлла приведена в табл. 9.3.2.
Эффективность каждого из этих классов можно оценит, с единой
точки зрения, взяв за основу среднее стандартизированное время,
требуемое для решения каждой из тестовых задач (табл. 9.3.8).
 pagebreak 
Нелинейное программирование при наличии играничгний 427

 

Поскольку многие из машинных программ оказались слишком
неэффективными при решении тех или иных задач и не учитывался
такой показатель, как число случаев, когда задача в установлен-
ное время не была решена, а усш'шия распечатки и останова были
в разных испытаниях раздичными (не говоря уже о том, что име-
ли место и дРугие трудности в установлении оценочных показа-
телей !>), среднее стандартизированное время представляет собой
ЛИШЬ грубую характеристику эффективности каждой из групп
алгоритмов. В работе Колвилла отсутствуют данные о среднем
стандартизированнсм времени, которое тратится на решение за-
дачи 14, так как в этом случае имеет место большое число локаль-
ных оптимумов. Кроме того, Колвшіл не приводит данных отно-
сительно того, удается ли решить методом прямого поиска задачи
18 и 19‹ Как и следовало ожидать (см, табл. 9.3.3), метод пря-
мого поиска (МПП) оказывается наиболее медленно деЙСТВУЮЩИМ, а
крупношаговые градиентные методы (КГМ) и методьивторых произ-
водных» (МВП) — наиболее быстродействующими. Некоторое уди-
вление вызывает тот факт, что мелкошаговые градиентные методы
(МГМ) работают так же быстро, как и КГМ и МВП.

Время, расходуемое на выполнение подготовительных опера—
ций, представляет собой другой существенный критерий эффек-
тивности машинной программы, предназначенной для решения
задач нелинейного программирования. Соответствующие данные
для типов программ, перечисленных в табл. 9.3.2, приведены
в табл. 9.3.4. Указанные в табл. 9.3.4 временнь’хе затраты на
выполнение подготовитеЛЬных операций в известной степени оце-
ненн по минимуму и не включают затрат времени, требуемых для
ознакомления с самой программой (т. &. предполагается, что поль-
зователю структура программъ1 известна), а также возможные по-
тери времени в тех случаях, когда подготовительные операции
приходится выполнять заново из-за неполадок в работе программы
при первых ее «испытаниях». Временнь‘1е затраты, связанные с
выполнением подготовительных операций пользователями, кото-
рые не знакомы ‹: МПБМ, ПОП П и алгоритмом НЛП, оказывают-
ся в 2—5 раз выше соответствующих оценочных данных, приве-
денных в табл. 9.3.4. Представляется маловероятным, чтобы
сценки временнЫх затрат для методов, основанных на исполь-
зовании аналитической записи вторых производных (например,
МПБМ), оказались справедливыми и для других задач, посколь-
ку, например, в задаче с девятью нелинейными ограничениями
(при десяти переменных) требовалось бы вычислить (причем без
ошибок) 100 первых частных производных и 550 вторых частных
производных За исключением тех случаев. когда большинство
частных производных равно нулю или является константами, на

 

1)См. разд Б,! Н 9.1.
 pagebreak 
428 Глава 9

 

 

Выполнение этих операций потребуется определенное время.
С другой стороны, если использовать дополнительную программу
«символического типа», время, требуемое на вычисление произ-
водных, возможно, удалось бы сократить. Следует отметить, что

Таблица 9.3.4

Время (в часах), расходуемое на подготовительные операции при решении
тестовых задач с помощью некоторых из алтаритмов, приведенных втабл. 9.3.1

 

Номер задачи [см. приложение А)

 

 

 

Алгоритм 2022,11;
7 | в | 10 | 11 | м | 15 ] 18 ! 19

Сколёзяшею допус- 0 0,3 0,1 0,5 0,1 0,4 0,1 0,5 0,5

кг )
Оптим “) 0 1,5 0,1 1,0 1,0 2,0 — — —
ПОП 360 *) Ч 1,0 0,5 2,0 1,0 2,0 2,0 2,0 2,0
МАП *) Ч —— 1,0 -— _— — _ —- —
НЛП 1) А 1,5 1,0 1,0 0,8 1,5 1,3 1,2 0,8
огмоп 1) А _ 0,5 0,5 0,4 1,5 1,2 0,7 2,0
ОГМОП ”) Ч 6,0 3,0 5,0 4,0 -— 6,0 4,0 6,0
МОПГ 1) (1970) А- 6,0 0,4 1,0 1,0 1,0 1,5 1,0 3,5
МОПГ *) А 5,0 1,5 2,0 2,0 — 4,0 2,0 4,0
Дэвидона — МБП 3) А 6,0 1,0 2,0 3,0 — _- 4,0 4,0
Минимал 11) 0 0,8 0,5 1,5 1,0 — 1,0 — 1,0
мпвм (1967) А а) 4,0 1) 1,5 1) 3,5 2) 4,0 %) _ _ 6,0 2› 3.0 *)
Розеиброка 1) 0 0,3 — 0,8 0,8 — — — —
Проективный ‹: пе- А 6,0 2,0 2,0 3,0 -— — 3,0 4.0

ременной метри-

кой 2)
Куранта *) А 4,0 1,0 3,0 2,0 — 3,0 2,0 4,0

1) Неопубликованные данные.
2) Заимпвоваио у Колвилля [1968 г.)

31Требуется вычисление вторых частных производных.
Обозначения: А —— аналитическая зап ись, Ч __ числовые значения, 0 ›— производные не нс-
пользуются.

 

у малоопытного специалиста лишъ. программа скользящего до-
пуска не отнимает много времени в процессе подготовки задачи
к решению на ЭВМ; в этом случае требуется перенести на перфо-
носитепи лишь данные относительно целевой функции, ограни-
чений и стартовой точки ХФ).

Стоккер оценил эффектииость тех же самых программ, что и
в работе Колвилла; кроме того, Стоккер получил соответствующие
данные для алгоритма НЛП и адгоритма скользящего допуска.

В табл. 9.3.5 указано стандартизированное время для раз-

ЛИЧНЫХ ТИПОВ программ и разных задач (ИЗ числа задач, приве-
 pagebreak 
Таблица 9.3.5
Огаидярггиаированиое время, требуете при решении восьми тестовых задач с помощью различных алгоритмов

 

Номер Задачи (см, приложение А)

 

 

 

А“”"ш РЁЩЭ’Ё 7 | в ! 10 11“ › 1401 15 10 19
Оптим 4.5 0,142° 0,010° 0,100” 0,014” 0,250“ в, с е, 0 е. с
поп 300" 0.1 0,044 0,011 0,037 0,010 0,007 0090 0,100 0,313
поп 11“ 0,1 0,078 0,135 с е с ; е ;
МАП" 0.1 г 0,086
нлп“ 0.2 0,073 0,638 0,074 0.110 ,; 0,353 4,15 2,52
Проекции градиента” 0.3.1 ; 0,040 0,0127 !“ ; ; г 00930
огмоп” 0.3.2 0,094 0,002 0,023 0,010 0,031 0.049 0.686 0.328
огмогп‘ 0.3.2 0 е 0,104 ; е в 0.589
мопг 0970)" 0.5 0,022 0,010 0,008 0,000 0,008 0.084 0,010
мопг (1970)‘ 0.5 0,170 0,072 0,009 г в 0,415 0.242 0.132
дэвндона _- мвп" 7.1.3 0,022 0,000 0,039 0,015 і : 0,384 0,272
 pagebreak 
Продолжение табл. 9.3.5

 

Номер зшчи (см. приложение А7

 

 

 

Ал о " Номер
.- рит ”““"“ 7 в 10 п п) и а) 15 из 19

Минимал” 7.1.4 0,118 0,087 0,412 0.103 е 0,184 в 0.875
Метод центровь 7.115 0,186
МП 1968

БМ ( 1) ) 7.2 0,016 0.028 [ 0.151 0.238

4 712 [ 0,082 0, 127 0.048 ; 1 2,53 0,719
МПБМ 0970)” 7.2 г 0.159

Резенброка

» 4.3.6 0,424 0,358 ; г е ;

‚1 7.1.2 0,045 0,032 е 0,078 1‘ 7 е
Скользящего допуска‘ 83 0,193 0,023 0,344 0,121 1,31 0,214 22,8 6,45
Проективный ‹: переменной метри-

коид 6.3.3 0,025 0,010 0000 0.000 ? 0.574 0,002
Курзнта” 0,036 0,004 0,026 0,025 0,072 0,380 0,209

 

 

 

 

 

Обои ачения

а— при допустимом иачяльном векторе: Ві СоНШе А. Е., А Сошратапуе Зішіу оп Ноп1іпеаг_ Рю гаттіпв 'Соаез, 1ВМ НАД всі, Сепіег Пері.
320-2949, .!цпе 1968, 5црр1ешеп1, 1969; : —ие опубликовцно; а—51ОсКег [>. С., М. & тпезіэ Пип], :) Теха5, Аизііп, Тех., 1969: е— не позволяет
найти решение задачи: [ _ к длиной задаче алгоритм неприменим; Е —- решение не получено вследртвие ошибок при вычисдеини “Зоизюдцых; Ь—
ныттап А. О., Ссшрагяыче Апаі 51$ 01 Ыопііпеаг Ргодгвттіпд Оодев ИШ! Ще “’еізтппп АідогіНпп. ЗНСС Кери 113. Ппш. 01 іМ5Ьцг3Ь, рт.
зЬщь, Ра„ Мои 1969; !—Рвчіаш 1). А1, РН. 1). Шэзегіаііоп, Ппш. ог Техяз, Ацзііп. Тех,. 1969; і—останов при погрешности 1% в ПХ) изза слиш—
ком большого времени, требуемого для вычислений…
 pagebreak 
Нелинейние программирование при наличии ограничений 431

 

ценных в приложении А). Содержащиеся в таблице данные заим-
ствованы у Колвилла и Стоккера, а также взяты из некоторых
неопубликованных источников. Следует обратить внимание на то,
что данные, взятые из разных источников, не всегда оказывают-
ся одинаковыми. Тот факт, что та или иная ячейка таблицы у Кол-
вилла оказывается незаполненной, как правило, означает, что
алгоритм не смог справиться с решением соответствующей задачи
(по крайней мере решение задачи не известно, хотя попытка ре—
шить эту задачу и имела место). На длительность подготовитель-
ных процедур оказывают влияние все факторы, о которых шла
речь в разд. 9.1, так что практически невозможно сделать ка-
кой—либо общий вывод относительно эффективности рассмотрен-
ных алгоритмов, даже располагая данными, представленными в
табл. 9.3.5. Однако можно утверждать (по крайней мере в результа-
те предварительного озна комления с приведенными выше результата—
ми), что для выявления возможностей практического использова-
ния метода скользящего допуска, ПОП, алгоритма НЛП, метода
МОПГ, проективного метода с переменной метрикой, метода Куран-
та и МПБМ требуется проведение дополнительных исследований.

С этой целью Стоккер провел глубокий анализ эффективности
пяти указанных выше алгоритмов, применяя их при решении
пятнадцати тестовых задач; результаты анализа (вместе с данны—
ми, относящимися к двум другим алгоритмам и пяти дополнитель-
ным тестовым задачам) приведены в табл. 9.3.6. Таким образом,
табл. 9,3.6 содержит операционные характеристики (время,
решения) семи машинных программ, полученные путем анализа
их возможностей в связи с решением 20 тестовых задач. Вначале
обсудим (разд. 9,3.1) рабочие характеристики некоторых машин—
ных программ, полученные при решении задач, представляющих
наибольший практический интерес, & затем (разд. 9.3.2) под-
ведем итоги относительно возможностей каждой программы в от-
цельности.

9.3.1. РАБОЧИЕ ХАРАКТЕРИСТИКИ АЛГОРИТМОВ НЕЛИНЕИНОГО
ПРОГРАММИРОВАНИЯ, ПОЛУЧЕННЫЕ ПРИ РЕШЕНИИ ЗАДАЧ,
ПРЕДСТАВЛЯЮЩИХ ОСОБЫЙ ИНТЕРЕС

Задача 111). Данную задачу, характеризующуюся квадратич-
ной целевой функцией и содержащую шесть квадратичных ограч
ничений в виде неравенств при пяти независимых переменных (знат
чения которых могут меняться в пределах фиксированных интерт
валов), удается решить с помощью любой из рассмотренных выше
машинных программ, за исключением ПОП Н. Алгоритм Розен-
брока оказался нев состоянии обеспечить такую же точность, какая

 

]) Рассматриваемые здесь задачи приведены в приложении А.
 pagebreak 
Машинное время (в секундах). расходуемое при решении задач нелинейного

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

известных
А В
‚ .931
Класс (см фиг ) … | М 131 | 132 |
Номер задачи (см: прило-
жение А) 20 15 5 13" : 4" в 19
Число переменных | 24 ` З | 3 12 ‘ 2 | 10 | 45 ] 16 1
Число ограничений в виде
равенств
линейных 2 2 1 4 1 3 12 8
нелинейных 12 4 1 3
Число ограничений в виде
Неравенств
линейных
нелинейных 6 1
Верхняя и нижняя грани—
цы 24 12 3 16 10 45 32
Время, ‹:
МОПГ (1969—1970) 4,98’ 9,14 1,21 1,06 1,45 1: 2,92
Скользящий допуск 511 4,71 0,84 с 0,43 27,9 с 142
нлп е 7,76 0,33 0.07 5,371 55,4
МПБМ (1968) : : а ] 0,51 2,44 29,4 15.6
МПБМ (1970), лучшие 0,22
варианты
ПОП П : : с : і і :' і
Розеиброка : : с : 4,52 і і [
ОГМОП :: е г с 5, 18 1, 15 е 13,06

(6,63)

Машинное время указаио применительно ›‹ ЭВМ СВС 6600 (спидартизироваиное время 22.0 с).
исктчениеи задачи 20) нелинейные: Незапшшениые ячейки означают. что соответствующая задача

ОбРЗиачекия
а.— получено нелрпусшиое решение (ограничивающие условия не удовлетворены): # -— в скобках
лепной сходимости; # — ограничивающие условия надлежащим образом не удовлетворены; е —— ре—
экстремум; И — получены отрицательные значения аргумента логарифмической целевой функции;
слишком большими трудностями: іг — не способен обеспечить решение (возможно, пз-за ошибок.

в
 pagebreak 
Таблица 9. 3.6

программирования рязли-дной пепени сложности с помдщью некотрых
алгоритм0в

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

С ]) Е
| 01 _
з 7 9 11” 12 14 16 18” 18“ 10 17 2 в
| 2 | з | 4 | 5 5 6 | 9 | 15 5 5 10 2 4

 

 

 

 

 

 

 

 

 

з
3 14 1 6 35 4 13 5
! 4 6 5 10 10 1 15 10 5 20 0 8
3 3,83 г {3,57 г е 5,38 2,25 1,54 0,35! 0,99 1,59
6,51
0,34 4,23 3,63 2,67 103,3 29,1 59,6 с 72,1 7,58 2,92“ 0,86 0.50
(13.9)
5 1,60 2,31 4,88 е 91,4 1,62 и 0,1814,о4
(0,64) (84,1)
0,82 6 ‚' 1,05 13 1 ; 5,58 2,79 1,32 0,11 1,80
(6,71) 1,99
12,66 (2,98) 76,0
0,63 1,72 с е в г е с 0,65 в 3,93
1,31 0,52 г 1,71 с е с е с, 11 0,21 0,70
(3,00) `
е 17,37 2,30 г е г е 2,08 4,52 г
2

Классы задач приведены в порядке уменьшения сложности (и- А до 13. Все целевые функции (за
указанным в левой колонке методом ие решалась.

указано время, расходуемое при старте из недопустимой точки; с — решение не получено из-яв мед-
щенпе отсутствует (пе получаю): [ —— дли задачи и; в — ддстигается ие глобальный, “ локальный
1— К данной задаче ддГориТМ Не применим; ]— вычисление вторых ПРОИЗВОДНЫХ СОПРЯ)К9К0 С°

допускаемых при вычислении вторых производных); [_ птиосится к 1970 г.
 pagebreak 
434 Глава 9

 

достигается при использовании других машинных программ. Это
объясняется тем, что оптимизационный поиск методом Розенброка
на последних этапах вычислительного процесса прекращается в
силу слишком медленного изменения минимизирующих поправок
к текущим значениям целевой функции в ходе перемещений вдоль
ограничений в окрестности оптимума. ПОП 11 приводит к мини-
муму, лежащему ниже минимальных значений целевой функции,
получаемых другими методами. Однако точка, соответствующая
экстремуму, находится за пределами допустимой области. Алго-
ритм скользяшего допуска, алгоритм НЛП, МПБМ. алгоритм
Розенброка и метод МОПГ приводят к оптимальному решению за-
дачи при старте из точки, не являющейся допустимой.

Задаяа 7. Это типична’я задача из категории решаемых с по-
мощью ПОП 11. Фигурирующие в ней функциональные связи обра—
зуют «самосогласованную» модель, легко описываемую на языке
команд программы. Интересующиеся способом построения моде-
лей такого типа, и в частности данной модели, могут обратиться
к работе [4].

Аналитический вид фигурирующих в задаче фунгщий в явном
Виде не определен, так что нахождение частных производных
этих функций оказывается весьма затруднительным. На Выпол-
нение подготовительных работ при решении задачи 7 с помощью
алгоритма НЛП уходит 1,5 ч; чтобы получить аналитпческую
запись вторых частных производных, требуется дополнительно 2,5 ч;
таким образом, суммарные временнЫе затраты при подготовке
задачи к решению спомощью МПБМ составляют 4 ч. Тем не менее
неоднократные попытки найти решение задачи 7 с применением
МПБМ заканчивались неудачей: программа прекращала работу
в условиях, когда имела место «сходимость» к ошибочному реше-
нию. Эти неудачи, безусловно, объясняются ошибками, допус-
каемыми при отыскании вручную вторых частных производных
целевой функции и функций, задающих ограничения, по неза-
висимым переменным. Помимо отмеченных выше, значительные
временнь’ю затраты сопряжены с безуспешными попытйами уста-
новить источник неполадок. Следует отметить, что методы прямо-
го поиска, метод скользящего допуска, алгоритм Розенброка и
ПОП 11, не требующие вычисления частных производных фигури—
рующих в задаче функций, характеризуются гораздо меньшими
затратами времени на подготовительные операции. Эти затраты
при использовании любого из указанных методов составляют при-
близительно 15 мин.

Задача 18. Эта задача, являющаяся двойственной по отношению
к задаче 10, содержит 15 независимых переменных. Она характе-
ризуется кубической целевой функцией при пяти кубических огра-
ничениях. Для значений всех 15 переменных установлены ниж-
ние границы. Эту задачу удалось решить лишь с помощью алго-
 pagebreak 
Задачи нелинейнаго программирования 435

 

ритмов МОПГ, НЛП и МПБМ, которые позволяют определить
максимальное значение целевой функции при старте как из допус-
тимой точки, так и из точки, не являющейся допустимой. При ре-
шении задачи 18 преимущества МПБМ и алгоритма МОПГ менее
очевидны. Отметим, однако, что данная задача обладает такой
структурой целевой функции и такими ограничениями, при ко-
торых вычисление частных производных не представляет особой
трудности. На подготовительные операции при использовании
МПБМ требуется всего 30 мин. Оказалось, что алгоритм сколь—
зяшего допуска обеспечивает очень медленную сходимость к опти-
мальному решению, приводя к чрезвычайно большим затратам ма-
шинного времени. При этом, несмотря на то что оптимальное ре-
шение целевой функшш впроцессе поиска было почти установлено,
вектор х. соответствующу1й наилучшему из найденных значений
[(х), значительно отличался от оптимального вектора х, полу-
ченного с помощью алгоритма НЛП и с помощью МПБМ. Алгорит
мы Розенброка, ОГМОП и ПОП 11 оказались не в состоянии обе-
спечить сходимость к искомому решению.

Задача 12. Эта задача представляет собой модель функциони-
рования гипотетического целлюлозно—бумажного комбината. Она
обладает существенно нелинейной целевой функцией, характери-
зующейся сложной зависимостью от пяти независимых перемен—
ных, значения которых ограничены как снизу, так и сверху.
Задача содержит три линейных ограничения в виде равенств
и 35 нелинейных ограничений, записанных в виде неравенств. Ре-
Шить эту задачу удалось лишь с помощью алгоритмов скользяще-
го допуска и НЛП (разумеется, с применением ЭВМ). Прямой по-
иск, реализованный в рамках алгоритма Розенброка, привел к
преждевременному останову из-за чрезвычайно медленного пере-
мещения вдоль одного из ограничений, в результате чего скорость
увелпчения значений целевой функции была явно недостаточной.
Программа ПОП 11 не справилась с решением задачи по не сов-
сем понятным причинам. Неоднократные попытки решить задачу
12, используя МПБМ, также не привели к желаемому результату
из-за невыявленных ошибок допущенных при вычислении 315 ча-
стных производных. Задача 12 по степени сложности целевой функ—
ции и функций, задаюших ограничения, напоминает задачу 7.
Мы вновь подчеркиваем то обстоятельство, что в процессе нахож-
дения вручную аналитических выражений частных производных
целевой функции и функций, задающих ограничения, по незави-
симым переменным не исключены ошибки. Хотя сравнение за-
трат машинного времени при использовании алгоритмов скользя-
щего допуска и НЛП показывает, что вычислительная зффетив-
ность алгоритма НЛП выше вычислительной эффективности
алгоритма скользящего допуска, следует иметь в виду, что машин—
ная программа, составленная на основе метода НЛП, требует
 pagebreak 
436 Глава 9

 

нескольких часов предварительной подготовки задачи к решению на
ЭВМ, тогда как временные затраты на выполнение подготови-
тельных операций при использовании алгоритма скользящего
допуска“ составляют менее 30 мин.

Задача 1. Это простейшая из задач, относящихся к классу В.
Она характеризуется квадратичной целевой функцией двух не-
зависимых переменных и содержит одно линейное ограничение в
виде равенства и одно нелинейное ограничение в виде неравенства.
Напомним, что алгоритмы Розенброка и ПОП 11 не могут опери—
ровать непосредственно с ограничениями, записанными в виде
равенств. Однако, как уже отмечалось выше, ограничения в
виде равенств можно включить в систему ограничений задачи в
преобразованием виде. т. е. после замены равенства !1,(х)=0
(і = 1, …, т) на два неравенства

”і(х)>_Ёд””і(х)<Ё.-э і=1‚...‚т.

Ограничения, записанные в таком виде, поддаются адекватному
учету при использовании программы Розенброка и ПОП 11, если
пользователем установлены верхняя и нижняя границы измене-
ния функций Р:! (х), т. е. если заданы значения —5‚ и Е,.
Указанный выше способ обращения с ограничениями в виде
равенств пытались применить в рамках алгоритма Розенброка

и ПОП 11 для решения задачи 1; при этом полагали %, = 104, так
как ограничивающие условия для значений И, (х), имеющие вид

— Ю“" < Ь, (х) < 10". вполне удовлетворительны, С решением
задачи 1 программа Розенброка справилась успешно, хотя найден-
ное при этом оптимальное решение несколько отличается от
более точного решения, полученного методами скользяшего допус-
ка, НЛП, ОГМОП, МОПГ и с помощью МПБМ. Кроме того, сле—
дует отметить, что машинное время,требуемое для решения задачи
1 на основе алгоритма Розенброка. сильно отличается от затрат
машинного времени, имеющих место при решении этой задачи
другпми (эффективными в условиях рассматриваемой задачи)
методами. Отметим также, что ПОП 11 не обеспечил сходимости
и строго оптимальному решению, а в точке, соответствующей ми—
нимуму, функция в ограничении-равенстве принимала значение
10;1 (вместо нуля).

Задача 4. Эта задача (так же. как и задача 6) представляет ст
бой пример оптимизации химического состава жидкой смеси, ко-
торая должна находиться в состоянии химического равновесия.
Смесь химических компонентов, поддерживаемая при постоянной
температуре и при постоянном давлении, достигает состояния
химического равновесия одновременно с уменьшением значения
целевой функции (т. е. свободной энергии жидкой смеси) до мини-
мума. Нелинейная целевая функция характеризуется логариф-
 pagebreak 
Задачи нелинейного програмирования 437

 

мической зависимостью от десяти независимых переменных при
наличии трех линейных ограничений в виде равенсгв; нижней
границей для каждой из независимых переменных является нуль.

Поскольку и алгоритм НЛП, и алгоритм скользящего
допуска не исключат некоторых отклонений текущего век-
тора х от его допустимых значений, возникает вероятность того,
что независимые переменные задачи 4 примут в ходе итерацион-
ного процесса оггршательные значения. Это в свою очередь может
привести к тому, что некоторые из натуральных логарифмов в вы-
ражении для целевой фунхции потеряют смысл и. таким образом,
оптимизационный поиск может оборваться. При решении задачи
11 алгоритм скользящего допуска никогда не приводил к отрица-
тельным значениям никакой из десяти независимых перемен-
ных; поэтому именно с помощью этого алгоритма и была решена
рассматриваемая задача (см. приложение А). Поиск же методом
НЛП был преждевременно прерван, как только значение одной из
независимых переменных стало отрицательным.

Чтобы преодолеть такого рода трудность, независимые пере-
менные были «переопределены». Обозначим новые переменные че—

рез х,. Формула перехода от х, к х, имела следующий вид:
х,:іпхд ]=1,..‚‚1О.

Переопределенная таким способом задача (т. е. задача, сформу-
лированная через новые переменные) приведена в приложении А
(см. задачу 43). Следует отметить, что задача 4а содержит три нед
линейных ограничения в виде равенств вместо трех линейных ог-
раничений-равенств исходной задачи и, следовательно, с полным
основанием может быть отнесена к классу А.

После перехода к новым переменным алгоритм НЛП оказался
в состоянии решить задачу 4; в результате получилось прибЛИЗи-
тельно такое же оптимальное значение целевой функции, как и
в случае применения МПБМ и алгоритма МОПГ. Соответствую-
щий оптимальном решению вектор х, найденный Брэккеном и
Мак- Кормиком [5%] (которые тоже использовали МПБМ), был в
точности воспроизведен с помощью программы МОПГ. Однако
соответствующие оптимальному решению векторы х, полученные
с помощью алгортмов скользяшего допуска, НЛП и ОГМОП,
несколько отличались от вектора х, полученного упомянутыми
выше авторами (см. приложение А). Отсюда следует сделать вы-
вод, что целеная функция задачи 4 обладает своего рода «широко-
полосным» минимумом (т. е. в точке экстремума кривизна функции
выражена весьма слабо)_

Задача 6. Задача 6 также связана с проблемой поиска условий
химического равновесия. Однако эта задача содержит 45 незавш
симщ переменных и 16 линейных ограНИчений в виде равенств.
 pagebreak 
438 Г ‚шва 9

 

Таким образом, ее размерность значительно выше размерности
задачи 4. Из используемых для решения задачи 6 четырех алго-
ритмов (скользящий допуск, НЛП, ОГМОП и МПБМ) три первых
столкнулись с трудностью, связанной с появлением отрицатель-
ных значений выражений, стоящих под знаком логарифма (как и
в задаче 4). Предпринималась попытка перейти к новым незави-
симым переменным при использовании алгоритма НЛП (как и
при решении задачи 4), а также вводились дополнительные ог-
раничения в связи с применением алгоритма скользящего допус-
ка (описание этого приема см. в разд. 8.6). Оказалось, что успеш—
ное решение рассматриваемой задачи достигается лишь с помошью
МПБМ, хотя получаемая при этом оптимальная точка х и не сов-
падает с оптимальной точкой, найденной Джонсом (формулировка
задачи 6 принадлежит именно Джонсу); все эти решения ука-
заны (для сравнения) в приложении А. Кроме того, следует отме—
тить, что найденный Джонсом оптимальный вектор х не удовлет-
воряет ограничивающим условиям, записанным в виде равенств.
Минимальное значение целевой функции Джонсом не указано;
однако, подставляя полученные им оптимальные значения неза-
висимых переменных в выражение для целевой функции, мы по-
лучаем і(х*) : — 79,108, Минимальное значение і(х*), найден-
ное с помощью МПБМ, равняется — 1910,446, т. е. является по
отношению к результату, полученному Джонсом, существенно
улучшенным. Это значение і(х*) определено при старте из трех
точек: а) из точки хм = 10—1; 6) из точки хдд = 10710; в) из опти-
мальной точки, полученной Джонсом.

Для решения задачи 6 ни алгоритм Розенброка, ни ПОП 11
не применялись.

Задача 5. Данная задача характеризуется квадратичной целе-
вой функцией трех независимых переменных и содержит одно
нелинейное ограничение в виде равенства и одно линейное ограни-
чение также в виде равенства. Каждая из независимых перемен—
ных может принимать лишь положительные значения. Таким
образом, задача 5 относится к классу А. Для решения задач
нелинейного программирования при нелинейных ограничениях,
записанных в виде равенств, педходят лишь алгоритмы скользящего
допуска, ОГП, МОПГ и НЛП. Именно эти четыре алгоритма
и оказались в состоянии обеспечить решение задачи 5.

МПБМ не смог обеспечить решение данной задачи в том смыс-
ле, что он приводит в точку, где ограничивающие условия в виде
равенств с требуемой точностью не выполняются (см, приложе-
ние А). Несколько дальнейших попыток удовлетворить ограни-
чениям—равенствам с большей точностью также не увенчались ус-
пехом. Неспособность МПБМ обеспечить решение задачи 5 была
неожиданной; однако при использовании МПБМ сходимость к
оптимальному решению задачи нелинейного программирования
 pagebreak 
Задачи нелинейнаго программирования 439

 

при ограничениях в ВИДе равенств, вообще говоря, и не гаран-
тируется (см. гл. 7).

Алгоритм Розенброка и ПОП П применялись для решения
задачи 5 после преобразования ограничений-равенств в ограни-
чения, имеющие вид неравенств (см. задачу 1). Ни один из этих
алгоритмов не смог обеспечить сходимость к оптимальному реше-
нию. Алгоритм Розенброка прекратил работу в условиях, когда
минимизационный процесс стал протекать крайне медленно (при-
чем в стационарном режиме). ПОП Н обеспечил сходимость к зна-
чению целевой функции, лежащему ниже оптимальных значений
і (х), полученных в случае применения алгоритмов скользящего
допуска и НЛП; Однако при этом ограничения-равенства оказа-
лись нарушенными.

Задача 20. Целевая функция данной задачи линейна, а число
нвависимых переменных равняется 24. Задача содержит двензд-
цать нелинейных ограничений в виде равенств, два линейных ог-
раничения, также имеющих вид равенств, и шесть нелинейных
ограничений в виде неравенств. Независимые переменные могут
принимать только положительные значения. Из всех задач, при-
веденных в приложении А, данная задача, возможно, является
наиболее трудной. Никаких попыток применить алгоритм Розен-
брока или ПОП 11 для решения задачи 20 не предпринималось.

Алгоритмы скользящего допуска, НЛП, ОГМОП и МПБМ ока-
зались в состоянии улучшить значение целевой функции по сравне›
нию со значением [(х) в стартовой точке; однако сходимость
к решению задачи была достигнута лишь при использовании ал-
горитмов скользяшего допуска и МОПГ (1970). Ни алгоритм НЛП, ни
МПБМ сх0димость к искомому решению обеспечить не смогли и
предолжали «осциллировать» относительно некоторой наилучшей
из текущих точек, которую они смогли определить, пока не было
исчерпано отведенное на решение задачи машинное время. Более
того, наилучшие решения, полученные с помощью алгоритмов
НЛП и МПБМ, оказались менее точными, нежели решения, по-
лученные с помощью алгоритма скользящего допуска и МОПГ.
Кроме того, решение, найденное с помощью МПБМ, не удовлетвт
ряло ограничениям-равенствам с достаточной степенью точности.

9.32. ОЦЕНКА ЭФФЕКТИВНОСТИ АЛГОРИТМОВ
НЕЛИНЕИНОГО ПРОГРАММИРОВАНИЯ НА ОСНОВЕ АНАЛИЗА
РЕЗУЛЬТАТОВ ИХ ПРИМЕНЕНИЯ ПРИ РЕШЕНИИ ТЕСТОВЫХ
ЗАДАЧ

В данном разделе дается характеристика каждого из рассмот-
ренных выше алгоритмов нелинейного программирования с уче—
том всех данных, полученных в ходе применения этих алгорит-
мов для решения тестовых задач, перечисленных в табл. 9.3.5.
 pagebreak 
440 Глава 9

1. МОПГ, вариант 1969 г_ С точки зрения вычислительной эф-
фективности результщы, полученные при решении метоцом МОПГ
задач нелинейного программирования (особенно наиболее трудных
задач, относящихся к категории А), представляются весьма об-
надеживающими (заметим, что задача 20 была решена с помошью
невырожденного варианта программы МОПГ, относяшегося к
1970 г.). Попытки решить с помощью алгоритма МОПГ задачи
класса С (задачи 9, 11, 14 и 16) оказались безуспешными из-за
преждевременного останова; тем не менее задачи 11 и 14 были ре-
шены позднее Абади. Во всех случаях, когда оптимум был най-
ден, временнЫе затраты, связанные с решением каждой из ука-
занных выше задач, были значительно ниже соответствующих
временннкх затрат, имевших место при использовании других ме-
тодов; поэтому машинная программа МОПГ является одной из
самых популярных и получим широкое распространение.

2. Алгоритм скользящего допуска. Данный алгоритм охазал-
ся в состоянии обеспечить решение задач всех пяти классов (А,
В, С, 1) и Е); исключение составили лишь две задачи, решение
которых с помощью алгоритма скользящего допуска получить не
удалось. Задачи 6 и 18 обсуждались в подразд. 9.3.1. Следует под-
черкнуть, что при использовании алгоритМа скользящего до—
пуска было затрачено слишком много времени на поиск точки,
удовлетворяющей ограничениям—равенствам, так что при решении
этих задач нельзя было уложиться в приемлемое время. Поскольку
речь идет о методе прямого поиска, для реализации алгоритма на
ЭВМ находить производные (фигурирующих в задачах фунъщий)
в аналитическом виде не требуется, Поэтому временнЫе затраты
на выполнение подготовительных операций для всех задач ока—
зываются весьма незначительными. Более того, в процессе вы-
полнения подготовительных работ ошибки почти исключаются.
С другой стороны, затраты машинного времени при решении за-
дач большой размерности (например, задач 18, 19 и 20) оказыват-
ся более значительными, чем в случае, когда оптимизация осу-
ществляется с помощью алгоритмов МОПГ и НЛП.

3. Алгоритм НЛП. С помощью данного алгоритма удалось ре-
шить большинство тестовых задач классов В, С, В и Е; исключе—
ние составили задачи 6, 14 и 16. Однако следует отметить. что
после перехода в задаче 6 к новым переменным (в результате ко-
торого 16 линейных ограничений-равенств превратились в 16 ог-
раничений-равенств нелинейной структуры) ее все же удалось
решить. В этой связи следует заметить, что, строго говоря, за-
дачу 6 нужно рассматривать как задачу класса А. Работу алгсь
ритма НЛП в процессе решения задач класса А нельзя назвать
достаточно эффективной; сходимость в случае задачи 20 алгорит-
мом НЛП не была обеспечена. Как известно, при использовании
алгоритма НЛП требуется знать частные произведные первого
 pagebreak 
Задачи нелинейного программирования 441

 

порядка для ‚‘ (х), И,(х) и 3, (х) в аналитической записи. Это приво-
дит к тому, что временнБхе затраты на выполнение подготови-
тельных операций оказываются большими и повышается частота
возникновения ошибок при подготовке задачи к решению (когда
подготовительные операции выполнятся вручную). Временные за-
траты, связанные с реализацией самого вычислительного процес
са на ЭВМ, ниже по сравнению со случаем использования метода
скользящего допуска (хотя и Имеются некоторые исключения).

4. МПБМ (вариант, относящийся к 1968 г.). Результаты, по—
лученные с помощью МПБМ, вполне соответствуют структуре
математического аппарата. характерного для метода последова-
тельной безусловной МИНИМИЗации (см. гл. 7). С помощью МПБМ
удалось решить все тестовые задачи классов В, С, 1) и Е, за ис-
ключением тех задач, при подготовке которых к решению полу—
чаются ошибки при вычислении вторых частных производных
„х), и, (х) и 5, (х), и, таким образом, окончательное решение ока—
зывается неправильным. МПБМ не смог, одншю, отыскать оп—
тимальное решение ни одной из задач класса А, Более того, раз—
рывный характер первых производных в задаче 15 сделал вообще
невозможнъхм применить МПБМ для отыскания оптимального
решения. Но в этой связи следует напомнить, что МПБМ для за-
дач класса А не гарантирует сходимость к оптимальному решению
(см. гл. 7). Необходимость в вычислении первых и вторых частных
производных функций [ (х), и, (х) и 3, (х), возникающая в слу-
чае применени МПБМ, приводит к значительному колИчеству
ошибок, допускаемых в процессе выполнения вычиолтельных
операций вручную, и увеличИВает временные затраты на стадии
подготовки задачи к решению на ЭВМ. К счастью, целевые функ-
ции некоторых из тестовых задач симметричны по независимым
переменным (например, задачи 4, 6, 10, 18 и 19), так что пробле—
ма нахождения первых и вторых частных пронзводных оказывает—
ся существенно упрощенной. Затраты машинного времени при ре-
шении с помощью МПБМ задач, относящихся к классам В, С, В
и Е, вообще говоря, ниже затрат машинного времени при поиске
решения прямыми методами.

5. Алгоритм Розенброка. Данный алгоритм справился с реше-
нием лишь некоторых задач, принидлежзщш к классам С, 1) и Е.
Причина имевших место неудач объясняется прежде всего прежд
девременным прекращением вычислительного процесса из—за слиш-
ком медленной сходимости в ходе перемещений вдоль ограничений
задачи.

Зарегистрирован один случай, когда алгоритм Розенброка
смог` обеспечитнрешение задачи класса В (а именно задачи 1).
Однако тот факт, что даже при решении такой простой задачи
(число переменных задачи равняется двум) потребовалось СЛИШ-
ком много машинного времени, наводит на мысль о том, что
 pagebreak 
442 Г лава 9

 

попытки решать с помощью алгоритма Розенброка задачи клас-
са В бесполезны. Неудачная попытка применения метода Розен
брака при решении задачи 5, являющейся простейшей задачей
класса А, говорит о том, что алгоритм Розенброка вообще плохо
приспособлен для решения задач указанного класса.

6. ПОП ". Попытки применить ПОП 11 при решении тестовых
задач приложения А свидетельствуют о его незначительных воз-

Таблица 9.3, 7

Сравнение машинных программ, основанных на использовании различных
алгоритмов нелинейного программирования

 

Класс за ачи
Алгоритм (и соответствующая д

машинная программа)

А | в ] с | в \ Е
МОПГ (1970) Да Да Да Да Да
Скользящий допуск Да ') Да Да Да Да
НЛП ? Да Да Да Да
МПБМ (1968) Нет да Да Да да
Роаенброка Нет Нет Нет Нет Да
ПОП 112) Нет Нет Нет Нет Да
ОГМОП Нет ? Нет ? Да

 

]) За исклочением случаев, когда задачи содержит большое число ограничений в виде
равенств

2) Работу алгпритмя можно улучшить путем выбора соответствующих значений параметров.

 

можностях: ‹: помощью ПОП 11 удалось решить лишь четыре из
двенадцати задач. Эти результаты совершенно отличаются от ре—
зультатов, опубликованных Колаиллом. Поскольку ПОП 11 не
предназначался для решения задач, относящихся к классам В и А,
неспособность данной машинной программы обеспечить решение
задач указанных классов не была неожиданностью. Низкая же
эффективность ПОП 11 при решении задач классов [) и С вызы-
ла, однако, некоторое недоумение.

7. ОГМОП. Данный алгоритм, как правило, прекращал рабо—
ту прежлевременно; причины преждевременных остановов были
самыми различными (на подробном описании этих причин мы здесь
не останзвливаемся). Отметим лишь, что нередко составляжощие
вектора, задающего Направление поищи, или же составляющие
градиента оказывались равными нулю либо в силу случайного
стечения обстоятельств, либо в результате округления получае—
мых числовых значений.

Данные относительно возможностей семи машинных программ,
предназначенных для решения задач нелинейного программиро—
вания, приведены в табл. 9.3.7. Эта таблица может оказать не—
которую помощь тем, кто сталкивается с проблемой выбора типа
программы в связи с решением той или иной задачи нелинейного
 pagebreak 
Задачи нелинейного программирования 443

 

программирования. Если в ячейке табл. 9.3.7 стоит «да», то это
означает, что соответствующий алгоритм можно в принципе счи—
тать способным решать задачи нелинейного программировани
указанного (в соответствующем столбце) класса. Если же в той или
иной ячейке стоит «нет», то это означает, что соответствующий ал-
горитм не рекомендуется использовать при решении задач, от—
носящихся к тому классу, который указан в соответствующем
столбце. Знак вопроса означает, что относительно эффективности
соответствующего алгоритма (в связи с его применением при
решении задач соответствующего класса) нельзя пока сделать
определенного вывода.

ЛИТЕРАТУРА

1. 5іос1‹ег В. С., А Сотрагаііче Зіщі оі Мопііпеаг Ргоегаттіпе Соаез, М. $.
ТЬезіэ, ТЬе Ппіч. оі Техаз, Апзііп, ск., 1969.

2. Ноіитап А. Съ, Оотрагаііче Апа1у5і5 оі Мотіпеаг Ргодгаттіпа Соаез шт]
Ше \Уеізшап А1догіс11т, ЗНОС Верь 113, Цпіч. оі РіНэЬцгеЬ, РііізЬш-дн, Ра.,
№№. 1969.

З. СоічіНе А. К., 1ВМ М. У. Зсі. Сепіег Нері. 320—2949, .Уцпе 1968.

4. Зацег Н. М., Со1чі11е А. Е., в…лск С. Ш., Нусітсп/іюп Ргосевэ. Реііоі. Квіти,
43, 85 (1964).

5. ВгасКеп Л., МсСогтіск 6. Р., Зеіессеа АррНса’сіопз ог Мопппеаг Ргозгаттіпе,
Шііеу, 1пс.. М. У., 1968.

ДОПОЛНИТЕЛЬНАЯ ЛИТЕРАТУРА

Назігівіп 1… А., Сгііегіа Хот Сотрагіпе Меіпоаз оі' 5ее14іп3 ап ЕхігегпЦШ (Еп31і5и
Тгапзд, Хаит !.аіь, 32, 1248, 1529 (1966).

Козеп .1. В., ЗцшКі $., Сопзігисііоп оі' Ыоп11'пеаг Рговгашгпіпг Тезі РгоЫептз,
Соттцп. АСМ, 8, 113 (1965).
 pagebreak 
Приложение А
ЗАДАЧИ НЕЛИНЕИНОГО ПРОГРАММИРОВАНИЯ и их РЕШЕНИЯ‘)

Задача 1 ….
Число переменных равняется двум.
Задача содержит ограничение в виде равенства и одно ограни-
чение в виде неравенства.
Требуется
минимизировать [(х) == (›‹1 —— 2)2 + (х„— 1)“
при ограничениях
п,(х)=х1——2х„+ 1 =0,
1%
е1(Х)= —Т—х;+ 1 >О.
(0)

В качестве начальной выбирается точка х [2 211, лежащая

вне допустимой области. В этой точке [(х‘щ) = 1.
Решение:
і …) = 1393,
х? = 0,823,
х; = 0,911.
Задача 2 [2].

Число переменных равняется двум.

Ограничения отсутствуют.

Требуется

минимизировать [ (х) = 100 (х‚— дс?)2 + (1 — 39)“.
В качестве начальной выбирается точка х…) = [_ 1,2 111. В этой
точке Пхи”) = 24,20.

Решение:

х*=[1 117, і(х*)=0.

Задача 3 [3],

Число переменных равняется двум.

Задача содержит три нелинейных ограничения в виде нера-
венств и четыре предельных ограничения для значений, которые
могут принимать независимые переменные.

') ИСТОЧНИКИ, ИЗ КОТОРЫХ ЗЗИМСТВОВЗНЫ рассматриваемые ниже задачи, Ука-
ваны В КОНЦЕ ПРИЛОЖЕНИЯ.
 pagebreak 
Задачи нелинейного программирования 445

 

Требуется
максимизировать [ (х) = 75,196 — 3,81 121, + 0,12694хё—
_ 2,0567 . 10—31% + 1,0345 . 10—5х1 _ 6,8306х2 +
+ 0,0302з4х,х‚ — 1,28134 . 10`3х1ХЁ + 3,5256 - 10—5х,х°г _
_ 2,266 . 10'7х,хт + 0,25645хё _— 3,4604 - 10'3хЁ +

+ 1,3514- 10—5х‘_ 38410? —5,2з75_ 10—°хіхё=6‚з ><
8 3 ?

>< 10“ …? + 7 . 10`1°ХЁхЁ+ 3,4054 - 10—47…32— 1,6638 ><
>< 10`6х1хЁ _ 2.8673 ехр (0,0005х,х,)
при ограничениях

 

0 < 1:1 < 75,
0 < 9:3 < 65,
х,):2 —— 700 >О,
х, —5(—’2‘15—)2 >О,
(х2 — 50)2 —-— 5 (х, ——55) >О.

В качестве начальной выбирается точка ХФ) = [90 1011, лежащая
вне допустимой области. В этой точке [(хю’) = — 82,828.
Решение:

х*= [75 6517, і(х*)= 58,903.
Задача 4 ….
ЧИСЛО переменных равняется десяти.
Задача содержит три линейных ограничения в нише равенств
и десять предельных ограничений для значений, которые могут
принимать независимые переменные.
Требуется

10 ‚-

минимизировать [ (х) = 2 х, (с, + 111 +),
Ы

Й ”і

[=!
где с, = ——6‚089, с, = — 17,164, с, = _- 34,054‚ с, = _ 5,914,
„ = __24,721‚ с, = _ 14,986, в, = _ 24,100, с, = _ 10,708, в, =
= _ 26,662, с… = _ 22,179.
Ограничения имеют следующий вид:

”1(х)=х1+2х2+2хв+хв+х10"2=0‚

п,(х)=хд+2х5+хв+х‚—1=О‚

Из(х)=х3+х‚+хв+2х„+х…—1=0,
хд>0, і=1,.…,10.
 pagebreak 
446 Приложем из А

 

о 0 .
В качестве начальнои берется точка х? = 0,1 (1 = 1,. ..., 10),

лежащая вне допустммой области. В этой точке [ (х‘щ) = — 20,961.
Решение: см. задачу 421.

Задача 451.
Число независИМых перемеННых равняется десяти.
Задача содержт три нелинейных ограничения в виде равенств.
Требуется

10 Х, , 10 11
минимизировать {(х’) = 2 {в ’[сі + х,- —1п(2 г ‘Я}

5: =} ‚

при ограничениях
И1(х’) = е"1 —— Эг!” + 2ех3 + ехб + е”… — 2 = О,

 

щ (х') = в"4 … 2е"5 + е"6 + е‘7 — 1 = о,
на (х') = е‘з + е‘7 + е"8 + 2е"9 + е’ЧО _ 1 = 0,

 

 

 

 

 

 

 

В качестве НаЧальной берется точка х‚-= —2,3 (і : 1, ..., 10), ле—
жащая вне допустимой области.
Решение:
Метод {
НЛП скольэящего ОГМОП МОГ” МПБМ
шпуска
[ (х) —47,751 —47,736 —47‚656 —47‚761 ——47‚761
х, 0,0350 0.0128 0 0,0406 0,0407
::2 0.1142 0,1433 0.1695 0,1477 0.1477
›:3 0,8306 0,8078 0,7536 0,783? 0,783?
хд 0,001? 0, 0062 0 0,0014 0,0014
х, 0,4887 0,4790 0,5000 0,4853 0,4853
жд 0,0005 0,0033 0 0,0007 0,0007
х, 0,0209 0,0324 0 0,0274 0,0274
::8 0,0157 0,0281 0 0,0180 0,0180
х,) 0,0289 0,0250 0,0464 0,0375 00373
›:10 0,0751 0,0817 0,1536 0,0969 00969
и! (х) 3.Е _ 12 3.Е _ 05 о 1.5 _ 06 —8.Е _ 08
да (к) 3.Е — 12 2.Е — 05 0 1.15 — 06 —1.Е —07
п…) г.в _11 9115 __05 о 1,Е-—06 -—1.Е—07
Задача 5 [4].

Число переменных равняется трем.

Задача содержит одно нелинейное ограничение в виде равенст-
ва, одно линейное ограничение в виде равенства и три предельных
ограничения для значений, которые могут принимать независи-
мые переменные.
 pagebreak 
Задачи нелинейного программирования 447

 

Требуется

минимижровать ‚‘ (х) = 1000 — хдд — 2х; _ х“; —— лс,):я — 351153

при ограничению:
пд(х) = хЁ—і—хЁ—Ь—хЁ—25 = 0,
д.д(х) = 8х1 —[—141с2 + 7х3— 56 = 0,
х‚>0‚ [=], 2, 3.

В качестве начальной выбирается точка хЁ-Ш = 2; другой вариант:
х‘Р' = 10 (і = 1, 2, З). Обе точки лежат вне допустимой области.
В любой из этих точек ;“ (х‘о’) = 976.
Решение:
і(х*) = 961,715, х, = 3,512, ::2 = 0,217, х„ = 3,552,
И1(х*) = 0, 11261") = 0.

Задача 6 [5].
Число переменных равняется 45.
Задача содержит 16 линейных ограничений в виде равенств.
Требуется
7 ”11 х”;
минимизировать [ (х) = 2 хі1е(с,-;‚ + …
:!

_ "я

__| [ 2 26172

і=1

 

при ограничениях

7 ";;
п,“): )* (;ЕцьхіЬ)—ді=0‚ і= ], , 16,

й=1

хііс>0‚ і=194"7пьр Ё=1‚...,7.

(Примечание. Зинчения 1), и ад, указаны в приведенной ниже таб-
лице.) В качестве начальной выбирается точка хдд = 0,1, ]=

 

 

!, ..., пд, /г = 1, …, 7, лежащая вне допустимой области. В этой
точке ‚‘ (хю’) = — 30,958.
Решение:
НЛП МПБМ МПБМ (Джонса)
; (дд) _1909‚740 —-1910‚361 49, 108
х}, 7,854Е __ 07 6,599Е _- 06 6.440Е _ 01
да;. 8,078Е _ 02 2,51215 _— 01 2,59015 _ 01

мы 3,706Е _ оо 3,705Е _— 00 3,7о5в _ оо

___—___…“—
 pagebreak 
448

 

Продолжение табл.

 

НЛП МПБМ МПБМ (Джонса)
ХХ: 8,855Е _ 02 253513 _ 01 299715 _ 01
Хіг 6,894Е _— 01 0,52915 _ 01 561715 _ 05
№ 302013 _ 02 1,23513 _ 03 6,880Е _ 04
ХЗ: 1,398Е „ 04 3,00715 _- 04 20625 _ 04
252 1,02013 _— 04 270413 — 06 1,10113 _ ов
х.:‚2 0 5,441 Е _— 06 243315 _ 06
”02 27021: _ 02 7‚звзв _ 02 5,7151—3 _ 02
%;; 7,950Е _ 02 8,791Е _ 02 7,938Е _— 02
";2 3,42115 — 02 3.54% — 02 32315 _- 03
*$; 2,486Е + 01 4,458Е + 01 28395 _ 01
Йод 3,873Е __ 02 2,669Е — 02 1.388Е __ 02
01,2 1,50015 — 04 7,70915 — 00 3.2831; _ 00
ХЁи 1,170Е _ 05 3,70415 _ 05 1,738Е _ 05
"132 1,55015 _ 02 1,550Е — 02 1,15513 _ 02
ХЬ 0 29005 — 07 5,95015 - 05
"33 2,649Е _ 02 5,077Е _ оз 4,419Е — 04
1633 1,25113 _ 04 3,10713 _ 05 220513 _ 04
‚623 10041: _— 01 1,5405 _ 00 1,00513 — 06
"Ёз 0 3,102Е — 05 1,852]; __ ов
Хёз 525315 _ 02 041015 _ 03 229115 _ 02
>53 8,710Е _ 03 220215 _ 04 „515 _ 03
133 1,47115 _ 02 1,2В7Е _ 02 450615 _ 02
"33 4,73515 — 02 2,165Е -— 00 1,832Е _ 01
*Вы 9,208Е _ 02 2,07513 _ 00 0. 3961; _ 03
{11.3 3,119Е _ 04 3.4375 _ 06 2,855]; _ 06
”12.3 1,50015 _ 02 1,40015 _- 05 7,806Е — 06
ХЁзд 2,42113 __ 02 1,927Е _ 02 „135 _ 02
хдд 2,448Е _ 03 1,855Е _— 03 7,42913 — 06
 pagebreak 
Продолжение табл,

 

 

НЛП МПБМ МПБМ (Джонса)

”15.3 8,398Е _ 03 3,264Е _ 06 3.0175 _ 05
„163 5, 28513 _- 03 7.5705 _ 07 5,05013 _ 05
„:” 0 3.5105 _— 07 4,0715 — 05
„;и 1,6о1в—03 2,5131—3—07 2,1421—3—03
‚‚;4 4,968Е — 07 0 2,33713 — 06
„34 1,978Е — 02 4,20013 — 07 1,821Е — 04
„;4 6.271Е —03 706313 _ 06 8,583Е _ 05
„;5 5.328Е -— 02 0 735513 _ 05
‚625 о 0 1,25113 — 03
„;5 0 1,3055—06 7,57зв_0з
„;& 2,51015 _ 02 1,465Е — 05 3,038Е — 04
„36 1,22015 _ 00 1.313213 _ 05 3,902Е — 05
„1-7 0 2,872Е _ ое 2,879Е __ 02
„;7 0 2,476Е _ 06 1,49913 __ 03
„_ … 5.111313 _ 02 252913 _ 07 —4‚800Е __ 07
„2 (… 2‚407Е __ 03 226315 — 07 1,592Е _- 00
„а (… 2,55913 _ 05 1.511715 — 07 2,03113 _ 06
„‘ (… 4,49313 — 02 1,112Е —00 —4,024Е + 01
„6 … 2,389Е _ 02 _4,51зв _ 07 —4‚624Е _|- 01
„„ (‚‘—) 3.1005 — 04 —3.946Е — 07 1,340Е —01
„, (… 6,692Е — 06 15,7715 __ 07 1,3021:` —00
„в (‚д) 6.376Е — 04 5, 10113 _— 07 1,362Е _ 00
„” (‚… 0 —1,8695 _ 07 _з‚94зв — 03
11… 1х“) 2,082Е _— 02 _1.95013 _ 07 2,280Е _ 03
и„ (г) —2,27зв _ оз _2_27з1‹: _ 03 _2,2731-: _ 03
н„ (‚т) —1,ззо1-: — 02 —5,583Е _ 07 409913 _ 04
11,8 (К’) 15,9405 _ 04 6,001Е _ 07 415751: _ 03
1… № 5.3315 _ 02 1,10915 — 06 8,847Е _ 03
111,1… 7,789Е _ 06 2,180Е _— 07 —5‚529Е _ 07
п… (х’) 31521315 _ 09 11284Е _ 07 4033015 _ 07
 pagebreak 
450
Значения 0, и сд в задаче ‹;

 

 

 

 

 

 

: | "! ‚ ( й “`Ла , і 71 ’]!г
1 06529581 1 1 0,0 6 З о_о
2 0281941 2 1 ——7,69 7 3 2,2435
3 11705233 3 1 ——1 1,52 8 3 0,0
4 47, 00022 4 1 —36‚60 9 З —39‚ 39
5 47,02972 1 2 —1о‚94 10 3 _21‚49
6 0, 08005 2 2 0,0 1 1 З —32_84
7 008813 3 2 0,0 12 3 6,12
8 004829 4 2 0,0 13 а 0,0
9 0,0155 5 2 0,0 14 3 0,0
10 0,0211275 6 2 0,0 15 3 _],9028
11 0,0022725 7 2 0,0 16 З —2‚8889
12 0,0 8 2 2, 5966 17 3 4,362?
13 0,0 9 2 —39,39 18 3 —7‚4854
14 0,0 10 2 —21‚35 1 4 —15‚639
15 0,0 11 2 —з2‚84 2 4 0,0
16 0,0 12 2 6,26 3 4 21.81
13 2 0,0 1 5 —16‚79
1 3 10,45 2 5 0,0
2 3 0,0 3 5 18,9779
З 3 —0,50 1 6 0,0
4 3 0,0 2 6 11,959
5 3 0,0 1 7 0,0
2 7 12,899

 

данные для определения Е:” в задаче 6
 pagebreak 
Продолжение табл.

    

.!
“З

 

 

ц—шю—
!
|
о:
 pagebreak 
452 Приложение А

Задача 7 [6].

Число переменных равняется трем.

Задача содержит 14 нелинейных ограничений в виде неравенств
и шесть предельных ограничений для значений, которые могут
принимать независимые переменные.

Эго одна из типичных задач, при решении которых целевые
функции и функции, задающие ограничения, описываются ‹: помо-
щью автономной машинной подпрограммы.

Требуется

максимизировать [ (х) = 0,068у2у5 — 5,042:1 — 3,36% — 0,035х„ —
— 10›сз
при ограНИчеНИЯх
0 < 1:1 < 2000,
0 < х‚ < 16 000,
0 < х„ < 120,
0 < у, < 5000,
0 < ув < 2000‚
85 < 94 < 93,
90 <% < 95.
3 < ув < 121
0,01 < % < 4.
145 < ув < 162.

Описание процедуры вычисления ув, уз„ у,. уд, у‚‚ у, и у‘! на языке
ФОРТРАН выглядит следующим образом:

т) = мых…
10 Ш) = я.22*у<2) = ха)
УФ) = (ХО) + У(3))/Х(1)
У2САЬС = х‹1)‹=(112. + 13.167*У(6) _ 0.6667*У(6)**2)/100.
1Р(АВ5(У2САЬС _ т)) _ 0.001) 3030,20
20 т) = У2САЬС
со то 10
30 соытшив
№4) = 93.
100 т) = 8635 + поэзии) = о.оззж(6)‹=2 + 0.325*(у‹4) — 89.)
из) = 433. + з.*у‹5)
У(7) = 35.82 _ 022290103)
У4САЬС = 98000.жХ(3)/(У(2)*У(7) + х‹з)*1000.)
1Р(АВ5(У4САЬС _ ум» — 0.0001) 300300200
200 №) = теме
60 то 100
300 соытшив
 pagebreak 
Задачи нЕ/шнейного программирования 453

В качестве начальной выбирается допустимая точка х… = [1745
12000 1101Т. в этой точке ! (№) =868,6458.

Решение:
х*=[1728‚37 16000 98,131’‚
і(х*) = 1162,036.

Задача 8 [7].

Число переменных равняется четырем.

Задача содержит восемь предельных ограничений для значе-
ний, каторые могут принимать независимые переменные, и ха-
рактеризуется наличием неоптимальной стационарной точки при
{(х) а 8, обеспечивающей быструю сходимость.

По условию задачи требуется

минимизировать {(х) = 100 (;&—хг)? + (1 —х1)”+ 90 (хд—ХЁ)$+
+(1_хз)2+1071[‹х=—1)2+‹ха—1)21+19›8(хя_'1)(х4—1›
при ограничениях

_10<х,<10‚ і=1‚2,3, 4.

В качестве начальной берется допустимая точка
х‘°’= [_в __1 —з __11Т‚

в которой Мхи”) = 19 192.
Решение:

х*=[1 1 1 пт,
{(Х*)=0_

Задача 9 [8].

Число переменных равняется четырем.

Задача содержит одно нелинейное ограничеНИе в вила нера-
венства.

Требуется

19
минныизировать )* (х) = 2] (уда… — ушам)“,

‚, 1:3 ‘/я сд ";—1 ( _ сих, )
”35 ( 6,2832 ) (7,658) °” ”* В 7,658

 

 

 

 

 

 

уцвьш = _1"'_"_—_ +
[+ 12:02
В *. хд Ч. 0; "‘—1 срс,
+ (1.43%?) (6,283?) ( 7,658 ) “%*—Б 7,65%)
…. ;

ш.
 pagebreak 
454 Приложение А

 

где 0 == х„ + (1 —х„)х‚. (Примечание. Значения с, и имел ука-
заны в приведенной ниже таблгще.)
Ограничения задачи Имеют следующий вид:

х3+(1—х3)х4>0,
х4>0‚

<1.

і= 1, ..., 4.

$

В качестве начальной выбирается точка
х…) = [2 4 0,04 212
в которой Дх…) = 4,8024‘

 

 

 

Решение:
х" = [12,277 4,632 0,313 2,0291Т‚
[(х) = 0,0075.
Значения 1:1 и уд наб” в задаче 9

! \ а д . набл \ х' 0 [ Щ, набл
1 0,1 0,00189 11 10 0,702
2 1 0,1038 12 11 0,528

3 2 0,268 13 12 0,385
4 3 0,505 14 13 0,257
5 4 0,577 15 14 0.159
6 5 0,604 16 15 0,0869
7 6 0,725 17 16 00453
8 7 0,898 18 17 001509
9 8 0,947 19 18 0,00189
10 9 0,845

 

 

Задача 10 [9].

Число переменных равняется пяти.

Задача содержт десять линейных ограничений в виде нера-
венств и пять прецедьных условий для значений, которые могут
принимать независИМые переменные.

Требуется

5

5 5 &
минимизировать і (х) = ] е,х, + 2.12; с;]хдхі + 2‘ 11,163
„= = ‚=

‚':
 pagebreak 
Задачи нелинейного программирования 455

 

при огРЕНИчениях
5
Едііхі_ьі>0‚ і=1‚ 10,
‚:

х,>0‚ ]=1‚...‚5.
(ПриМечание. Значения е‚-‚ ад,. а„ щ, и Ь, указаны в приведенной
ниже таблице.)
В качестве начальной выбирается допустимая точка хю’ =
=[0000 ИТ, в которой Нх‘щ) = 20.
Решение:
х*= [0,3000 0,3335 0,4000 0,4285 0,2241т,

;(х* = _ 32,349.

Исходные данные для задач 10 и 18

 

 

 

\\ | 2 ' з 1 4 ‹ в
в, —15 —27 —36 —18 —12
… во —20 —10 32 —10
с„- 40 39 —6 —31 32
с,] —10 _в 10 —в —10
сд,- 32 _—31 _ 6 39 —20
с., —10 32 >10 —20 30
а, 4 в 10 6 2
а„ —16 2 о | о
а„, о —2 о 0.4 2
118] -— 3,5 0 2 о о
ад, 0 -—2 о —4 — 1
вы о —9 _2 1 —2‚8
а„ 2 о —4 о о
а,] —1 —1 —-—1 —1 ——1
из, —1 —2 —3 —2 —1
а„, 1 2 з 4 5
а…, 1 1 1 1 1
171 122 Ьз 17; да да да да 179 510
——40 —2 -—-0‚25 —4 —4 —— 1 ——40 —60 5 1

 

Задача 11 [10].

Число переменных равняется пяти.

Задача содержит шесть нелинейных ограничений в виде нера-
венств и десять предельных ограничений для значений, которые
мог т принимать независимые переменные.

аметим, что в структуру „х) переменные х, и ::4 не входят.
 pagebreak 
456 Приложение А

 

Требуется

минимизировать [(х) = 53578547165 + 0,8356891х1хь +
+ 37293239):1 —- 40792141
при ограничениях

0 < 85,334407 + 0,0056858х,х, + 0,0006262х1х, __
_ 0 ‚0022053х,х„ < 92,
90 < 80,51249 __ 0 ‚0071317х2х5 +0, 0025395515115, + 0, 0021813хё< <110,

20 < 9,300961 —— 0 ‚0047026х3х5 + 0 ,0012547х1х3 +
+ 0,0019085х3х4 < 25,

 

78 < х, < 102,
33 < хи < 45,
27 < х„ < 45,
27 < х, < 45,

27 <хд< 45.
В качестве начальной выбирается допустимая точка

=[78,62 33,44 31,07 44,18 35,221Т,

в которой их"”) = —зозв7.
Решенихе:
=пв‚ 000 33, 000 29,995 45,000 36,7761Т,
Нх’“) = — 30 665,5
В качестве начальной можно взять точкух “_) —-[78 33 27 27 271Т‚

лежащую вне допустимой области. В этой точке ‚‘ (К‘и ’) = 32 217
При этом также приходим к решению

х*=[78‚000 33,000 29,995 45,000 36,7761Т,
і(х*)=—-—30665,5.

Задача 12 [3].

Число переменных равняется пяти.

Задача содержит 4 линейных ограничения в виде неравенств, 34
нелинейных ограничений в вище неравенств (прИчем оказывается,
что некоторые из них можно исключить из условия задачи) и 10
ограНИчений, задающих нижний и верхний пределы изменения
независимых переменных.

Требуется

максимизировать } (х) = 0,000000Е'у843у17 —0,0001 Пу” — 0,1365—
«— 0900023581113 —— 0 ‚000001502уд, — 0,0321у12 — 0,004324у5 —-

——0,0001 —‘—'ь —з7, 48— "? .

010 с„
 pagebreak 
Задачи нелинейного программирования 457

Величины у, и С" определяются следующими соотношениями:
ш=д+д+мд
с, = 0,024х4 — 4,62,

12,5 + 12,0,

01

ед = 0,0003535х3 + 0,531 1х1 + 0,08705у„х„
св = 0,05%:1 + 78 + 0,002377у„х„

 

?:

ув : % ‚

уф : 19%:

с‘ = 0947820;1 __ ув) + №№ + 0,6376у‚ + 1,59%
с„ = 10019,

до = "1_!/з—У4‘

07 = 0,950 — 2—3,

% = 5607.

уе: х1—95_И_узя
дв : (95 + 1/4) 0395,

 

% _ ;.
['
уд : 3758 ’
09 = у, _- ШЁЁЁ —о‚з153‚
96,82
% = 59 "' 01321у1)

ую : 1,29% + 125894 + 2,29% + 1,71%,

уп = 1,71):[ = 0,45% + 0,58%,
__ 12,3
610 “ 752,3 ’

си = (1‚75у2) (0,995х1)‚
св = 0.995у10 + 1998,

уп : 010% + 1“—

сш '

у13 = сш _ 11751151
 pagebreak 
458 Приложение А

 

146.312
111; + "6 ,
ош = 0,995у10 + 60,8):% + 48% — 0,1 121511,1 —— 5095

913

уп» : _013 1

= 148 000 — 331 0005115 + 40у13 — 61уцу№
сы = 232451… — 28 740 000у2,

у„ = 14130000 —-1328уд‚—531у„ +—- ‘—1-4,

012

 

у„ = 3623 + 64,4х, + 58,413 +

с : Ию __ Ша
15 уп, 0,52 ’

= 1,104— 0,72%,

см

017 = 119 + хв—
Ограничения имеют следующий вид:
0, 28
И _ 0 _7_2 96 > 0
1 ‚Бас2 — хз > 0,

21,0—3496— >О.

12
62 212
017

 

—110‚6—у,>0,

213,1 < у, < 405,23,
17,505 < у, < 1053,6667,
11,275 < у, < 35,03,

214,228 < уд < 665,585,

7,458 < у, < 584,463,

0,961 < у„ < 265,916,

1,612 < % < 7,046,

0,146 < у, < 0,222,
107,99 < у„ < 273,366,

922, 693 < у… < 1286,105,
926 832< <у„ < 1444, 046,
18,766 < у„ < 537,141,
1072,163 < у„ < 3247,039,
8961,448 < у„ < 26 844,086,
 pagebreak 
Задачи нелинейного программирования 459

 

0,063 < уд, < 0,386,
71 084,33 < у… < 140 000,
2 802 713 < уп < 12146108,
704,4148 < х] < 9063855,
68,6 < х2 < 288,88,

0 < хз < 134,75,
193 < х‚ < 2870966,

25 < хБ < 84,1988.

В качестве начальной берется допустимая точка хю’ = [900 80

115 267 2711 в которой их“”) : 0,939.
Решение:

х*=[705,060 68,600 102,900 282,341 35,6271’,
{(г): 1,905.

Задача 13 [11].

Эту задачу можно рассматривать либо (3) как задачу, содер-
жащую 12 переменных, 7 ограничений в виде равенств и 16 огра-
ничений, задающих нижний и верхний пределы изменения неза-
висимых переменных, либо (что проще) (б) как задачу, содержа-
щую 5 переменных, З нелинейных ограничения в виде неравенств
и 10 ограничений, задающих нижний и верхний пределы изме
нения независимых переменных.

Задача 13 иллюстрирует тот случай, когда требуется опреде-
лять параметры в высокой степени нелинейных дифференЦИалы
ных уравнений, основываясь на экспериментальных данных. Це—
левая функция фактически представляет собой сумму квадратов
разностей между экспериментальными данными и решениями си-
стемы дифференпиальных уравнений, полученными методами чис-
ленного интегрированИя.

По условию задачи требуется

максимизировать/(х) = [50у1 + 9,583у2 + 20у3+ 15у4—852 960——
'_ 38 100 (хи + 0,01%) + ‚ды + ’дзвхг + 1333353 + ‚33854 + ’гзэхь] "1 _

24345+15х„. Значения у, (і = 1, 2, З, 4), х… х, и ::8 находятся
путем решения следующей системы уравнений:

”в = (‚31 " +32”; + Ёгхв + 12,254 + #5165) хр
у1 : "де + ,г7х2 + Ёвхз + ‚дехд + Ё…Хд,
1/11 : Ёп " ЁшХ-д + ‚дыхз + ‚314% + ‚9159551
 pagebreak 
460

Где

Приложение А

93 = ‚дм + "] 1152 + 1318353 + 4319354 + ‚320х151
% = ‚321 + ‚322% + #28358 + 4324354 + Ёяьхьг

"7 = (111+ % +%) хп

хз : (‚326 + 4327452 + 4328158 + 1629254 +
+ 4350115) х1 + ха + хп

#, = —145421‚402‚
[е, = 2931,1506,
16, = _ 40,427932,

@, = 5106,192,
ь, = 15711,36‚
[е, = —161622,577,

іг, = 4176,15328,
6, = 2,8260078,

&, = 9200,476,

6,0 = 13160295,

#„ = — 216869194,
Ь„ = 123,56928,

Ь„ = — 21,1188894,
Ь" = 706,834,

Ь„ = 2898,573,

Ь„ = 28298388,

1›„ = 60,81096,

Ь„ = 31,242116,

’с“, = 329,574,

1820 = — 2882,082,
1821 = 74095,3845,
1622 = —- 306,262544,
‚321.1 = 16243649,

ігд = — 3094,252,
1225 = — 55662628,
#26 = — 26 237,

‚327 = 991

ігдв = — 0,42,

1629 = 1300,

4330 = 2100,

ігы = 925548252,
‚ги = — 61968‚8432‚
‚гад = 23,3088196,
ігм = — „097,648,
#35 = »— 50843,766.

Ограничения имеют следующий вид:

0<х1<51

1,2 < яс2 < 2,4,
20 < ›‹в $ 60,
9 <”; <913‚

615 < ХБ < 7»
0 < х„ < 294 000.
0 < х, < 294 000.
0 < х„ < 277 200.
 pagebreak 
Задачи нелинейного программиравпния 461

В качестве начальной выбирается точка
х'°’=[2,52 2 37,5 9,25 6,817,

в которой [ (х…) = 2 351 243,5.
Решение:

х*=[4‚538 2,400 60,000 9,300 7,0001Т‚
„… = 5 280 254,

х; = 75 570,
х; = 198 157,
х; = 277 200.

Задача 14 [12].

Число переменных равняется шести.

Задача содержит четыре нелинейных ограничения в виде нера-
венств.

Задача 14 возникла в связи с реальной проблемой «централи-
ЗЗЦИИ теплоснабжения нефтеочистительных заводов» И характе—
ризуется наличием бОЛЬШОГО числа локальных ОПТИМУМОВ, каж-
дый из которых имеет свою интерпретацию.

По условию задачи требуется

4 &
минимизировать [(х) = 2 0 (х,) + 2 100 0 (х,)
:=] і=5
при ограничениях
із — 300 > 0,
{‘ — 300 > 0,
280 — Ть > 0,
250 _ т6 > 0.
Для вычисления с(х,)‚ !, и Т, используются следующие соотноше'
ния:
с (хі) = 2,7х, + 1300 (наименьшее целое число >_2ЁО_0) ,

Т, = __,ЁЁЁО’ЁОЁЁБЁ: ‚ тд = ————”'+1 (100—85350—0“ ‚
11 = 500 — т„ !, = 350 + (1, — Т,) го“,
«, = _ 0,0001вв5х,‚ Т,? = о‚зта + 0,273,

7; = № . осб = 0,000375х„‚

] —— 1,5е"°°'
 pagebreak 
462 П рилджениг А

1‚ = 300 + (200 — т.д) ещ, Т“ = 80 + @,2 _ 80) е—“д
0:3 = 0,085 . 9,36 . 104553, т,] = 0,7т1 + о,:щ,

Т _ 11+(29,75—ід)е_°"
“ 1—0,9\5е—“= ’

га = 350 + (:, _ тэ) ещ, т„ = 80 + (тд _ 80) Пн,
004 = 0,00025 ;с‘?
В качестве начальной выбирается точка
х“) = [8000 3000 14 000 2000 300 1011

в которой [ (х…) = 459 100.

Решение, полученное методом скользящего допуска, имеет
следующий вид:

х“ = [11 884 3288 20 000 4000 114,18 — 155,03]Т,
пт = 2507909.

Колвилл приводит следующие значения [(х) в оптимальной точ—
ке х:

ос, = 0,0003хд,

 

При старте из твики,

При старте ив допус' не являющейся

Ал итм, сложен" й не но-
тимий начальной гор н ы °

ву машинной программы

 

точки допустимой 1)
255303‚5 Алгоритм обобщенного 266754‚0
г Миента
389858,0 ПО ‹360 ——
1325 18,0 Оптим (название специаль- 125578‚0
ной; машинной праграм-
мы

” Имеется в виду точка кт) = [0000 3000 10 000 2000 200 1017.

Задача 15 [13].

Число переменных равняется шести, из которых только две
являются независимыми

Задача содержит 4 нелинейных ограНИчения в виде равенств,
2 ограничения на производные (в виде разрывных функпий) и 6
ограничений, задающих нижнюю и верхнюю гранииы изменения
переменных. (Задача оптимизации электрической цепи.)

Требуется
минимизировать [(х) = ‚; (151) + 10 (ха)
при ограничениях
30/01, 0 < х! < 300,
11071) =
31х1‚ 300 < 361 < 400,
 pagebreak 
Зпдачи нелинейного программирования 463
___—___—

! 28х„‚ 0 < х‚< 100,
& (%+) = 29х2, 100 < х? < 200,
[ 30:3, 200 < 22 < 1000,

0,9079812
›‹1 = 300 _ ттт сов (1,43577 _ х,) + _ЁГОТВЁ— с051‚47588,
000793112
::2 = — % соз (1,48477 + х,) + “1300—784— сов 1,47588,
№4 0,90798х47

х„ = — № 5111 (1,48477 + х,) + 5111 1,47588,

131,078

200 _ № зіп(1,48477 — хз) + №.— хЁ 5111 1.475313 = 0,

131,073
0 < ‚$1 < 400.
0 < х, < 1000,
340 < х„ < 420,
340 < 1:4 < 420,
_ 1000 < ›‹6 < 1000,
0 < х, < 0.5236.

В качестве начальной берется точка

х‘°’= [390 1000 419,5 340,5 193,175 0,517, вкотороймхю’) =
= 9074,14.

В зависимости от степени точности, с которой определяется точ-
ка Х, результаты оказываются различными. Наличие разрывов
производных ‚‘‚(хд и [2 (х!) приводит :( скачкообразному изме-
нению { (х) и х*. Это подтверждается данными, содержащимися в
приведенной ниже таблице.

№

 

Высокая ТОЧНОСТЬ Умеренная точность
х; 107,81 201,78
х; 196,32 100,00
;; 373,83 333,07
‚1; 420,00 420,00
1% 21,31 —1о‚907
„; 0,153 007314
і(х*) 8297.5888 8853,44 … 3953,40

 

___.—
 pagebreak 
464 Приложение А

Задача 16 [14].

Число переменных равняется девяти.

Задача содержит 13 нелинейных ограничений в виде неравенств
и одно ограничение, задающее верхний предел изменения одной
из переменных.

Данная задача связана с максимизацией площади шестиуголь-
ника, максимальный линейный размер которого (диаметр)
равен единице.

Задача сводится к

максимизации Дх) = 0,5 (хдд:4 — хихэ + хз):9 —— хдх. + хдхв — хех,)
при ограничениях

1—ХЁ—х3>0‚
1—х3>0‚
1—хЁ—ХЁ>0‚

1—хЁ— (х‚— х„)’ >О,
1 _ (хх _ хз)? — (хе _ хе? > 0,
1_ ("1 "‘?)2— ("2 _ хд)*>0‚
] _ (хз _ хб)2 " (х; _“ Хо.!)2 >О,
1 —— (хз — >61)“ — (х. — %)2 >О,
1…х3—(хв—х„›*>о‚
’Их: _ хвхз > 0:
х„х„ >О,
_“ хвхв >О,
265263 _ Хед >О,
‚»:9 > 0.
В качестве начальной выбирается точка ‚1:5… = 1, і = 1, …, 9,

в которой [ (х‘°’) = 0.
Решение:

х* = [09971 —О,0758 0,5530 0,8331 0,9981

—0,0623 0,5642 0,8256 0,000002417,
пт = 0,8660.

Задача 17 [4].

Число переменных равняется десяти.

Задача содержит ‘20 ограничений, задающих нижншю и верх—
нюю границы изменения переменных.

Вне допустимой области целевая функция не определена.
 pagebreak 
Задачи нвлинейнаго программирования 465

 

Требуется
10
минимизировать {(х) = 2 {Пн (х, _ 2)1и + [111 (10 — мж} _-

=!

10 0.2
—-<П х,)
!=]
при ограничениях
2,001<х‚<9‚999‚ і= 1, ..., 10.
В качестве начальной выбирается точка х?” = , і= 1, ..., 10.

Решение:
х*=[9‚351 9,351 9,351 9,351 9,351 9,351 9,351 9,351
9,351 9,35117,
і(х*) = — 45,778.
Задача 18 [9].

Число переменных равняется 15.

Задача содержит пять нелинейных ограничений в виде нера-
венств и 15 ограничений, определяющих границы изменения не-
зависимых переменных.

Данная задача является двойственной по отношению к задаче 10.

Т ребуется

5 5

10
максимизировать Дх) = 2 Ьдхд — 2 2 011х10+1х1в+1——
1:1 1:1 1:1

5
— 2 ‚21 411631»;

при ограНИчениях
5 10

2 21011х1о+1 + 341361044 + е‚› _ 121] “№1 >О, != 1, › . - ‚ 5,
1: :

х,>0, 1:1, 15.

(Примечание. Значения г;, с;], а„ а;, и Ь, содержатся в таблице,
приведенной в связи с рассмотрением задачи 10.)
В качестве начальной выбирается допустимая точка

хР=0‚0001‚ 1:1, 15, цы,
х‘у‘» = 60,
в которой
их)“) = _— 2400,01
 pagebreak 
456 Приложение А

Решение:
х*=[0,0000 0,0000 5,1740 0,0000 3,0611 11,8395 0,0000
0,0000 0,1039 0,0000 0,3000 0,3335 0,4000 0.4283
0324012
нг) : — 32,386.

К такому же решению можно прийти, начав оптимизационный
поиск в точке

х$°’=ЬЁ°’‚ і=1‚ 10,
х$°’=0, і=11,14‚
хі-°’= , і=15‚

которая не является допустимой и В которой
‚‘(х(0)) = 6829,06.

Задача 19 [15].
Число переменных равняется 16.
Задача содержит восемь линейных ограничений в виде равенств
и 32 ограНИчения, которые определяют нижнюю и верхнюю гра-
ницы изменения переменных.
Требуется
16 16
максимизировать дх) = — 21 21410 (953 + хі + 1) (х,? + х, + 1)
і: ]:
при ограничениях

16
2 170%; = сп і
і=1

0<х_‚<5, ;‘=1,...,16.

1, ...,8,

П

(Примечание. Значения ш,. дц и с‘ указаны в приведенной ниже
таблице.)

В качестве начальной выбирается точка х?” = 10, і: 1,

…, 16, лежащая вне допустимой области. В этой точке і (х‘о’) =
= 209,457.
Решение:

х*=[0‚040 0,792 0,203 0,844 1,270 0,935 1,682 0,155

1,568 0,000 0,000 0,000 0,660 0,000 0,674 0,0001Т,
год) = _ 244,900.
 pagebreak 
данные для задачи 19

 

7

 

В

9 10 11

12

13

14

 

15

 

16

 

 

0,22
—1,46
1,29

0, 20

——0,89

—1,10 —1,06

1.12

2,5

——1,72

0,45
1,1

0,19
—1,30

0,95
#033

0,26
——З,1

0,25
1,82

——0,54
—1.43

0,31
—1,10
—3.5

0,15
—1,15
—1,16

1,51
1,62

0,58
1,3

0.11

——0.96
›—1‚78

0,12
0,80

—-0,41

0,59 .—0,33

1,24

2,1

0,21

1,12
—-1,08

2,3

0, 1 З
—0. 49

_О, 43
——0‚ 26

0,10
—1‚5

1,00
1,00
1,00

-—0,36

1,00

1,00

 

1,00

1,00

1 ‚00
 pagebreak 
468

Приложение А

 

Задача 20 [4].
Число переменных равняется 24.
Задача содержит 12 нелинейных ограничений в виде равенств,
2 линейных ограничения в виде равенств, 6 нелинейных ограни-
чений в виде неравенств и 24 ограничения, задающих верхние

границы интервалов изменения НИЯВИСИМЫХ переменных.

Данная задача связана С минимизацией затрат на ПРИГОТОВ-
ление МНОГОКОМПОНСНТНЫХ ЖИДКИХ смесей.

Задача состоит в том, чтобы

минимизировать [ (х) = 21 (1,26,
1:

при ограничении

”**тг__———тг——=Ш =:
х ` Х
изд… 2 _— 4017,2, 7;—
‚4—13 =] ’

+; 2“ "—{ —1,671 =о‚

!=] і=|3

і= (0, 7302) (530) (№№)

-—[х‚-+хд ] .
—„—+і>о. 1: 1, 2, з,

БИ+“

‚'=1
№>0‚1=4,5‚6_

Е‘і‘і'еі

,0, і=1, ..., 24.

., 12,

(Примечание Значения а„ Ь„ с„ ‹1 и е, указаны ниже в таблицах )
В качестве началъной берется ’ючка хю’ = 0,04,

лежащая вне допустимой области. В этой точке ‚°(хш’)= = 0,14696

Решения, получаемые методом скользящего допуска, методом
НЛП и методом МПБМ, имеют следующий вид:

.., 24,
 pagebreak 
Метод скользящего
№пускя

0,05700
7,804Е —— 03

1,1215 —0|
1,136Е —01

1,914Е — 02
6.009Е —— 03
5,008Е _ 02
1,844Е — 0!
2,693Е — 01

0

0

0
1.704Е —- 01

0

0

0
8,453Е — 01
1,980Е -— 04

060009900

НЛП
0,09670

9.5371: _ 07

о
4,21БЕ _ 03
1,03915 _— 04

0

0
207213 — 01
5,91915 _ 01
1,298Е _ 01
3,350}; — 02
1.7115 — 02
8. 42713 — 03
4,657Е _ 10

0

0

0

0

0
2,868Е — 04
|,193Е _ 03
8,332Е _ 05
133913 — 04
2,070Е — 05
1,829Е — 07
4,908Е — 07

0

0

0

0

0
_2 209Е — 08
4152115 —— 08
--5.854Е — 09

МПБМ

0.07494
9.1095 — 03

3,73915 — 02
8,961 Е — 02
1.1375 _ 02
4,15515 — 03
4.153415 _ оз
5,980Е _ 02
1.5545 — 02
139913 — 02
8,780Е — 03
1,23113 — 02
1, 15315 — 02
7,57015 — 02
7,997Е _ 02
2,797Е _ 01
1,168Е _ 01
2.3475 _ 02
6,368Е _ 03
2,028Е _ 01
7,451Е — оз
4,547Е — оз
1,010Е _ 02
1,22013 — 03

!,810Е — оз
--1,182Е _ 03
4,32% __ 04

3,467Е _ оз

2,217Е _ 04
455015 7 04
—7‚368Е — 04

1,982Е _ оз
__2‚зз4в — 05

1,629Е _ оз
 pagebreak 
Продолжение табл.

 

 

 

 

 

м
етоддЁЁ$ЁЁящею Н Лп МПБМ
и… (х') 0 8,137Е — 08 ——4,397Е -— 04
И„ (х*) 0 —2,596Е — 08 9,431Е — 04
п„ (‚а) (› 5,766Е — 08 1,853Е _ 03
И„ (х*) 0 0 —1,741Е —-02
И„ (К') М 0 8,743Е — 03
Данные. относящиеся к задачам 10 и 18
1 ‘ ”и 177 01 \ дд ‘ г,-
1 0.0693 44,094 123,7 31 ‚244 0,1
2 0,0577 58,12 31,7 36,12 0,3
3 0,05 58,12 45,7 34,784 0,4
4 0, 20 137,4 14,7 92,7 0,3
5 0,26 120,9 84,7 82,7 0,6
6 0,55 170,9 27,7 91,6 0,3
7 0,06 62,501 49,7 56,708
8 0, 10 84,94 7,1 82,7
9 0, 12 133,425 2,1 80,8
10 0,18 82,507 17,7 64,517
1 1 0, 10 46,07 0,85 49,4
12 0,09 60,097 0,64 49,1
13 0,069?! 44,094
14 0,0577 58,12
15 0,05 58,12
16 0,20 137,4
17 0,26 120,9
18 0,55 170,9
19 0,06 62,501
20 0,10 84,94
21 0,12 133,425
22 0,18 82,507
23 0,10 46,07

24 0,09 60,097
 pagebreak 
Задачи нелинейного программирования 471

 

Задача 21 [16].

Число независимых переменных равняется трем,

Задача содержит 6 ограничений, задающих нижнюю и верхнюю
границы изменения незавпсимых переменных.

Требуется
99

. _ х! ,
минимизировать [(х) = 2 {ехр [_ Щ] _ 0,011} ‚ и,- =

і=1 х,

.= 25 + (_- 5011100101!"5
при ограничениях
0,1 < х, < 100,0, 0,0 < х, < 25,6, 0,0 <х3 < 5,0.

В качестве начальной выбирается допустимая точка х…) = [100,0
12,5 3,01Т.

Решение:

х* =150,0 25,0 1,51Т,
і(х* = 0,0.

Задача 22 [17].

Число независимых переменных равняется шести.

Задача содержит 4 нелинейных ограничения в виде неравенств
и 12 ограничений, задающих нижние и верхние границы изменения

независимых переменных.
Требуется

минимизировать [(х) = 4,3х1 + 31,81:«\ + 63,3):3 + 15,8х4 +
+ 68,5х5 + 4,7хв

при ограничениях
17.13:1 + 38,2х, + 204.2х, + 212,3х. + 623,425 + 1495,50, _
— 169х1х5 — 3580х3х5 — 3810хдх5 — 18 500364368 — 24 300х530,3 > 111,
17,9х1 + 36,83% + 113,90, + 109,7х4 + 337,8х, + 1385,2):6 _
— 139х1х3 — 2450хдх5 — 16 600хдхд — 17 200х5хд > 172,

— 273):2 — 701:4 —— 819):Б + 26 000154165 >!)…
159,9х1 — 311х2 + 5871г4 + 391х5 + 219830, -— 14000х1хв > 17…

0<х1<0‚31‚ 0<х4<0,042‚
0 < ›:2 < 0,046, 0 < х, < 0,028,
0<х3<0‚068, 0<х6<0,0134‹

Ниже приводится решение задачи для различных значений па—
раметров.
 pagebreak 
472 Прилжение А

 

4,97 —-1,88 —— 29.08 —— 78,02 0 0 0 0 0 0,00333 0,0156
4,97 ——1,88 —— 69,08 —118‚02 0 0 О 0 0 0,00332 0,0156
32,97 25,12 — 29,08 _ 78.02 О 0 0,0633 0 0 0,0134 4,070
32,97 25,12 ——124‚08 —17З,02 О 0 0,0633 0 0 0,0134 4,070 '

Задача 23 (распределение орудий по целям) [1].

Число независимых переменных равняется 100.

Задача содержит 12 линейньш ограничений и 100 ограниче-
ний, задающих нижние границы для значений, которые могут при-
нимать независимые переменные.

Требуется
20 Б _.
минимизировать і(х) = 2, и,(П “ЗЧ __ 1)
!=! :=\

при ограничениях "

5
(;да—1790, і= 1, 6, 10, 14, 15, 16, 20,

20
—(Ёіхсі)—0:>0‚ і=1‚ „… 5.
]:

Задача 24 [1].

Число независимых переменных равняется двум.

Задача солержит одно нелинейное ограничение в виде нера-
венства и ОДНО линеиное ограничение также в виде неравенства.

Требуется
минимизировать {(х) = (я:! — 2)“ + (дс2 — 1)2
при ограничениях
31(Х)= —х%+х2>0‚
3200 : ——Х1 —х2+2>0-
В качестве начальной выбирается точка х…) =[2 217, лежащая

Вне допустпмой области. В этой точке {(хю’) = 1.
Решение: '
? (дд) = 1,
х*=[1 11’.
Задача 25.
Число независимых переменных равняется двум.
Ограничения отсутствуют.

См_ таблицу на стр. 471.
 pagebreak 
данные для задачи 23
щі—вероятность того, что ]-е орудие ие поразит і-ю цель

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

, | с,-
\‘ 1 | 2 з 4 5 в 7 в | 9 10 ' п 12 13 и 15 16 п ' 13 19 го {"Ъ”:}?
] |двй типа 1)

1 1 0,95 1 1 1 0,85 0,90 0.85 0,80 1 1 1 1 1 1 1 1 0,95 1 1 200

2 0.84 0,83 0.85 0,84 0,85 0,81 0,81 0,82 0,80 0,86 1 0,98 1 0,88 0,87 0,88 0,85 0,84 0,85 0,85 100
3 0.96 0.95 0,96 0.96 0,96 0,90 0,92 0,91 0,92 0,95 0,99 0,98 0,99 0,98 0,97 0.98 0.95 0,92 0,93 0,92 300
4 1 1 1 1 1 1 1 1 1 0,96 0,91 0,92 0,91 0,92 0,98 0,93 1 1 1 1 150

5 0,92 0,94 0,92 0,95 0,95 0,98 0,98 1 1 0,90 0,95 0,96 0,91 0,98 0,99 0,99 1 1 1 1 250

___—№

{);—минимальное число орудий, выделяемых для поражения і-й цели

 

 

30 1 00 40 50 70 35 10

Щ

иі—степень важности (с военной точки зрения) і-й цели

60 50 50 75 40 60 35 30 25 150 30 45 125 200 200 130 100 100 100 150
 pagebreak 
Орудие

 

допустимые решения, получаемые при решении задачи распределения орудий по целям хи

 

 

 

 

 

 

Номер цели ‚'

 

 

 

 

 

 

 

 

 

 

 

 

 

 

"‘"“ 1 2 з 4 5 6 | 7 в 9 10 п 12 13 14 15 16 п 19 19 20
1 24 32 37 28 22 5 52
(16) (100) (38) (26) (20)
2 1 в 2 18 11 29 9 21
(23) (20) (25) (31) (1)
3 9 29 62 35 17 25 62 60
(45) (76) (56) (62) (61)
4 9 39 58 44
(39) (50) (57) (4)
5 47 5 36 12 6 50 42 51 1
(50) (46) (47) (50) (57)
Итого 48 46 38 30 40 100 37 28 22 50 51 39 51 58 70 53 38 77 62 60
(50) (62) (47) (23) (20) (100) (38) (26) (20) (50) (57) (39) (50) (57) (70) (35) (77) (56) (62) (61)

 

 

 

 

 

Итого

200

(200)

( 1 00)
299

(300)
150

(150)
250

(250)

 

Примечание: Числа без скобок взяты у Хольтцмана. числа в скобках заимствованы у Брэкена и Мак-Кормика.

Г (х*) = 1732.
 pagebreak 
Задачи нелинейного программирования 475

Требуется
минимизировать {(х) = 4 ():1 _ 5)2 + (›:я — 6)”.
В качестве начальной выбирается точка х(°›=[8 ИТ, в которой

1“ (х(°)) : 45.

Решение:

›‹* = [5 611,
Г(Х*) = 0.

Задача 26 [18].
Число незаВИсимых переменных равняется четырем

Ограничения отсутствуют.

Требуется

минимизировать і(х) = (х1 + 10х‚)* + 5 (хз — 1:4)” + (::2 — 2х3)“ +
+ 10051 _ ”4%
В качестве начальной выбирается либо точка хю’ = [3 —1 0 ИТ,
в которой і(х‘°))= 215, либо точка х…): [1 1 1 Пт, в которой

і(х(°)) : 125,
Решение:
х*=[0 о 0 шт,
і‹х*›=о.
Задача 27.

Число независимых переменных равняется двум.
Ограничения отсутствуют.

Требуется

минимизировать і(х) = (х1х2)2(1 —х1)°[1 —- х1——х‚(1 —х,)51”.

В качестве начальной выбирается точка х…) = [—1‚2 111, в ко-

торой их“”) = 26 656.

Решение:
точкой х* является либо точка П, неограниченное значениеР,

либо тожа [О, неограниченное значение”,
либо точка [неограниченное значение, 01Т,
г‹х*› = 0‘
Задача 28 (связана с решением системы уравнений).
Число независимых переменных равняется двум.
Ограничения отсутствуют.
Требуется
минимизировать [(х) = (х? + ::2 — 11)‚! + ():1 + хЁ — 7)*‚
“" — [1 ИТ, в которой

В качестве начальной берется точка х
і(х‘°’) = 106.
 pagebreak 
476 Приложение А

Решение:
а) х*= [3,58443— 1,848131’; @) ‚:== [3 217, Г(х')=0.

(Пр имечание. Все машинные программы при старте из точки

х‘°’= [1 117 приводят ко второму решению.)
Задача 29.
Число независимых переменных равняется двум.
Ограничения отсутствуют.
Требуется

минимизировать [(х) = (х? + 123:2 —— 1)я + (49:6? + 49:53 + 84х, +
+ 2324х.2 — 681)”.

В качестве начальной выбирается точка хю’ = [1 11’, в которой
[(хю’) = 33306 . 106.
Решение:

3) х* = ю 28581 0 279361Т, пи) = 5,9225;
6) х*= [= 21026653 =36,76600901’, і(х*) = 0,

Задача 30.
Число независимых переменных равняется трем.
Ограничения отсутствуют.

Требуется
минимизировать [(х) = 100 [хз -— (}}—РП“ + (1 — лс,)2 +
+ (1 —хя)’-

В качестве начальной выбирается 'ючка )(0 = [— 1,2 2 ШТ, в
которой і(х‘°’)= 8…40

Решение:

х" = и 1 пт,
г‹х*› = 0.

Задача 31 ….

Число независимых переменных равняется двум.

Ограничения отсутствуют.

Требуется

минимизировать [ (х) = (‚&—2)“ + (х2 — 1)“+ ТТХ) + —Ё—Ь(;0 ,

при ограничениях
„%
3100: _т—хё'і- 1:
п1(х) = х1—2х„+ 1.
 pagebreak 
Задачи нелинейндго программирования 477

 

В качестве начальной берется точка х‘"’ = 12 ШТ, в которой
их“”) = 5,99.

Решение:

х*=[1‚7954 1377917 (локальный минимум),
і(х*} = 0,16904.

(Примечание. Другие варианты выбора начальной точки приво—
дят к друшм решениям, При проверке не было получено ни реше-
ние, приведенное в указанном выше источнике, ни данное решение
при указанном начальном векторе. Представляется важным сле—
дуюшее обстоятельство: при достаточно больших начальных пе—
ремещениях (т. е. при начальных перемещениях с большой дли-
ной шага) локальный минимум „х) удается обойти, в результате
чего оптимизационный поиск сразу приводит к глобальному ми-
нимуму [(х) при 3, (х) = —— 0, когда і (х) —› — оо.)
Задача 32.

Данная задача возникает в связи с оцениванием эксперимен-
тальных данных методом наименьших квадратов,

Число незаВИсимых переменных равняется четырем.

Ограничения отсутствуют.

 

Требуется
*НХЁЩМЁЙ _„
7 1 + хЁа, ‘
минимизировать [(х) = 10‘ 2 ‚и .

1:1
В качестве начальной выбирается точка
х‘°>= [2,7 90 1500 юг,

в которой і(х‘°’) = 2,905 - 104.

Решение:

х*= [2,714 140,4 1707 31,511Т‚
і(х*) = 318,572.
Ниже указаны значения констант а, и д,:

 

[ 01 | И

1 0,0 7,391
2 0,000428 11,18
3 0,00100 16,44
4 0,00161 16,20
5 0,00209 22,20
6 000348 24,02
7 0,00525 31,32
 pagebreak 
478 Приложение А

Задача 33.
Число независимых переменных равняется двум.
Ограничения отсутствуют.
Требуется
максимизировать ‚“(х) = (‚›—“_" (212% + 3х2).

В качестве начальной выбирается точка х…) = [2,5 2,5]Т‚ в ко-
торой Нх‘ш) = 23299 . 104.

Решение:

х*= [0 Пт или х*= [О — НТ,
тд) = 1,10%.

Задача 34 [19].

Число независимых переменных разняется трем.

Ограничения отсутствуют.

Требуется

минимизировать і(х) = 100 {[хз— 10 9 (1:1, х,)Р—і- [(:Ё + мг%)”2 —

—- 112} + хг,

1 ::
—2—п— агс’ге—ХЁ— , х1>0‚

90:1, хи) = 1 1 ;и
—,_‚—+ 'ЯЗЩЁТ' х1<0.

В качестве начальной берется точка
х‘°’= 1—1 0 Ой.
Решение:
х*= 11 о 01’,
№) = 0.

Задача 35.
Число независимых переменных равняется двум.
Ограничения отсутствуют.
Требуется
минимизировать ПХ) = и? + и; + и;,
где

и, = с, — 1:1(1— 265), с] = 1,5, 02 = 2,25, 03 = 2,625.

Т
В качестве начаЛЬной выбирается точка х‘°’ = [2 0,2] ‚ в которой

і(х(°)) = 0,52978.
Решение:

х* = [3,0000 0,50001Т‚
і(Х*) = 0.
 pagebreak 
8553.5!9—‘9

__.
горе

зороячччнльэ

Задачи нелинейного программирования 479

ЛИТЕРАТУРА

ВгасЪкеп 11, МсСогтісК & Р., 5е1ес1е11 Арр1ісаііоп5 оі Моп1іпеат Ргавгат-
гите, чтеу, М. У.. 196$

КоэепЬтоск Н. Н„ Ап Апіотаііс Метод іог Ріпаіпв 111е Огеаіеэі апа Ъеаві
\’аШе 01 а Рипсііоп, Сотриіег !„ 3, 175 (1960).

Ватпез & К., М. 8, ТЬеэіэ Ппіч. 01 Техаз, Ацэііп, Тех., 1967.

Рачіапі Е). А., РЬ. 1). Віэзегтаііоп, Цпіч. оі Тегаз, Ацзііп, Тех., 1969.

Лопез А. Р., ТЬе СЬешіса! ЕчціііЬгіцт РгоЫет: Ап Арр1ісаііоп 01 $ПМТ,
Не5.Апа1 5і5 Согр., МсЬеап, \іа., НАС-ТР—272, 1967.

СоічШе Х Н., А Сотрагаііче Зішіу оп Моп1іпеаг Рговгатгпіпг Сойеэ, [ВМ
М. У. 5сі‹ Сепіег Кери 320-2949, .]цпе, 1968, р. 31.

Шойд С. Р., Шезііпдйоизе Кез. 1.211). (сііеа іп Сомне. 1ВМ М. У. Зсі. Сепіег
Берг. 320-2949, Зцпе. 1968).

Нітте1Ь1ап 1), М., Уаіеэ Ц. Ч., А Мет Ме1110г1 01 По… Кощіпв, Шаіег
Незацгсез Ё65.‚ 4, 1193 (1968).

$11е11 Вечеіортеп! Со. (сііеб іп СоМПе, 1ВМ М. У. 5сі. Сепіег Нері. 320-

2949,1цпе, 1968, . 21).
Ргосіог анд Сат |е Со. (сііеа іп Со1чі11е, |ВМ М. У., $сі. Сепіет Еері. 320-
2949. ‚Ише, 1968, р. 2411

, Вох М. ‚|., А Меш Метод 01 Сопэігаіпеа Оріітіиаііоп апа & Сотрагізоп

№111 Оіпег Мепокіэ. Сотриіег !., 8, 42 (1965),

Еігоутзоп М. А., Еззо №5. аппі Епгі'пеегіпз Со. (сііей іп Сомне, [ВМ
М. У. Зсі. Септег Верт. 320-2949, Дипе, 1968, р. 26).

Ниага Р„ Е1ес1гісі[ё‚ Це Ргапсе, Вігесііопз дез Ёішіез е! НесЬегсЬез (сііей
іп СоЫШе. [ВМ М У. Всі. Сепіег Нері. 320-2949, `Ише, 1968, р. 28).

. Реагзоп !. 0.‚Оп \]агіаЫе Ме1гіс Меіпоаз оі Міпітіиаііоп, Иез. Апа1узіз

Согр. Кері; ЦАС-ТР-ЗО2, МсЬеап, Ув., Маг, 1968.

Оаишіег .]. М., [ВМ Ргапсе (сііекі іп Со \ііПе, [ВМ М. У. $сі. Сепіег Кері.
320-2949, .Пте, 1968, р. 29).

Но12тап А, О., ЗКСС Верь 113, Ыпіш оі РШзЬигвЬ, Рі1‘15ЬцгеЬ, Ра., 1969.
Ц $. $[ее1 Со (Спек! Ьу Но11тап. ЗКСС Цері, 113, 1969).

Роше11М..1.1Э.‚ СатриГег 11, 5, 147 (1962).

пеш… К., Роше" М, .]. В., Сотриіег .1., 6, 33 (1963).
 pagebreak 
Приложение Б

ПРОГРАММЫ НА ЯЗЫКЕ ФОРТРАН, НЕПОСТАВЛЯЕМЫЕ
КОММЕРЧЕСКИ

Для решения задач нелинейного программирования при от—
сутствии ограничений представленные программы используют
следующие алгоритмы:

1) алгоритм Бройдена;

2) алгоритм Давидона — Флетчера —— Пауэлла;

3) алгоритм Пирсона 2;

4) алгоритм Пирсона 3;

5) алгоритм Флетчера — Ривса;

6) алгоритм Ньююна;

7) проективный алгоритм Ньютона;

8) алгоритм Голдштейна — Прайса;

9) алгоритм Пауэлла;

10) алгоритм Нелдера —- Мила.

При решенрт задач нелинейного программирования при нали—
чии ограничений используется алюритм. скользящего допуска.

Б.]. АЛГОРИТМЫ НЕЛИНЕИНОГО ПРОГРАММИРОВАНИЯ
ПРИ ОТСУТСТВИИ ОГРАНИЧЕНИЙ,
ОСНОВАННЫЕ НА ВЫЧИСЛЕНИИ ПРОИЗВОДНЫХ

Приведенные ниже инструкции являются руководством для
использовании программ”, основанных на применении в сочетании
с методом золотою сечения и методом ДСК—Пауэлла (Когги-
на) следующих алгоритмов:

1) алгоритма Дэвидона —— Флетчера _— Пауэлла;

2) алгоритма Пирсона 2;

3) алгоритма Пирсона З;

4) алгоритма Бройдена;

5) проективного алгоритма Ныотона;

6) алгоритма Флетчера — Ривса;

7) алгоритма Ньютона;

8) алгоритма Голдштейна — Прайса.

1. Структура программы
Вызывшощая программа ЕХЕС. Эта программа запускает
ШШС и ХРКШТ и измеряет время их исполнения, исключая

!) Автор приносит благодарность М. Апшенберг’у ва подютовку программ 1—8.
 pagebreak 
Программы на языке ФОРТРАН 481

время запуска программы. Следует задать 1РН1МТ= 1, чю
бы получить полную распечатку каждою шага. и [РКПЧТ = 2.
если необходимо распечатать только окончательные значения це-
левой функции и вектора х. Программа ЕХЕС вызывает подпро-
грамму МПП. (Правила использования 1ЫВ1С приводятся в опи—
сании подпрограммы ЗЕАКСН.)

1.2. Подпрограмма ММП. Эта подпрограмма управляет вы-
бором используемого алгоритма. Она вызывает ВЕК, РПМ, ЕТА
и СОМУКО. Имеются разные варианты МШ1 для следующих
групп алгоритмов:

а) Дэвидона — Флетчера — Пауэлла, Бройдена, Пирсона 2,
Пирсона 3, проективного Ньютона;

б) Ньютона;

в) Г Оддштейна — Прайса;

г) Флетчера — Ривса.

Подпрограмма МН\П также обеспечивает распечатку инфор—
мации на Каждом шаге при условии использования 1РК1МТ.

1.3. Подпрограмма ЕТА. Эта подпрограмма обеспечивает вы-
числение Матрицы выбора направлений для первых пяти из ука-
занных выше алгоритмов (т. е. имеется пять различных вариантов
подпрограммы ЕТА).

1.4. Подпрограмма СОПУКО. Эта подпрограмма обеспечивает
вычисление критерия сходимости, определяемого в конце каж-
дого шага, на основе значений Нх), х и производных от і(х).

1.5. Подпрограмма ЗЕАКСН. Эта подпрограмма включает
несколько взаимозаменяемых групп команд одномерного поиска.

1.6. Подпрограмма РПМ Данная подпрограММа содержит
функцию, подлежащую минимизации. Чтобы обеспечить мини-
мизацию функции НХ), необходимо ее представить как

РХ = . . . .

1.7, Подпрограмма ВЕК. Эта подпрограмма обеспечивает вы—

числение первых частных производных і(х) в следующей после-
довательносги:
СіХ(1)—частная производная по 1:1,
6Х(2)—частная производная по ::2 и т. д.

1.8. ВЬОСК ВАТА. Подпрограмма обеспечивает присвоение
начальных значений составляющим х и фиксирует число незави-
симых переменных [\] (№ принимает целочисленные значения).
2. данные, подготавливаемые пользователем

Параметры в программу не вводятся. Однако эт можно осу—
ществить, если добавить соответствуюшие подпрограммы.

2.1. Ч’юбы провести линейный поиск (методом ДСК -— Пауэл-
ла (Коггина) или методом золотого сечения), необходимо исполь-
зовать соответствующие подпрограммы ЗЕАЕСН и МПП, опре-
делив их при помощи комментариев за заголовком подпрограммы.
 pagebreak 
482 Приложение Б

 

2.2. Чтобы выбрать необходимую подпрограмму ЕТА, соот-
ветствующую группе алгоритмов 1—5, необходимо прочесть ком-
ментирующие перфокарты, следующие после заголовка. Когда
в колоду перфокарт вставляются карты ‹: кодирограммой ЕТА,
необходимо убедиться, что ранее используемый вариант этой ко.
дивограммы из колоды изъят.

2.3. В подпрограмме ВЬОСК ВАТА необходимо подготовить
исходные предполагаемые значения хі°> вектора х и указать раз-
мерность вектора х и число переменных. В соответствующей
строке после слова ВАТА нужно разместить вводимые значе-
ния х и размерности № (целое) так, как показано в приводимом

ниже примере Подпрограммы1).

 

РКООКАМ ЕХЕСПНРЦТ001ПРЦТ)
СОИМОМ [ХНЙЕЕ/ м.пгиисъшжу,пеъшшспрммт
МРНМС‘ЬО
МДЁЧ‘О
шшс-г
[РКМН ' 1
САШ- ЗЕСОМЫТХМЕ]
РКП“ 20007 'ПМЕ
(АЦ. МПП
(АЦ. БісопЩТШЕ)
РКП” 2000» ТЕМЕ
(АЦ. ЕХ1Т
8000 РОКМАТНОТШЕ 1$ МОНМПО-Зй БЕСОМ°$-*п/1
БМП

эиЕКЩЛШЕ СОМУКБЮУЦРАБЕ)

сонмом /0"Е/ ХЦСЛсУПО] |$41°НРХОР\’

СОММОП ”НЕБЕ! ПЩРЦНСТ'ММУОПЕЮШЩС'ХРКШТ
5124501530” 61‘101 `

ХТОЦО-ООООЛ.

 

" Рассмотренные программы для решения задач нелннейнаго программи-
рования написаны на языке ФОР’ГРАН [Ч. Здесь процедура присвоения тех или
иных значений переменным осуществляется в момент заг узки программы при по-
мощи предложения ВАТА и подпрограммы ВЬОСК БАТ . Эти методы присвоения
значений переменным являются отличительной чертой языкаФОР’ГРАН “1. Одна-
ко прнводимые программы можно реализовать и с использованием обычного
транслятора с ФОРТРАНа, изменив соответствующим образом процедуры присвое-
ния значений переМенным.-— Прим, перев.
 pagebreak 
РТОЬ'0.0000]
6Т0Ь=0о0001

‹ СНЕСК РЦНСПОМ \!АЦіЕЗ
ДЁЕАВ$|ГХЬЬЕ№ХШЦ 601010
!РіАВЗ‘!ГХ'ЁУИЁХЬСТ-Гіоьі 50 10 60
60 ТО 20

10 1Р1д5$(ГХ-ЁУ!-6Т.ЁТОЬ) 60 10 60

( СНЕСК 125? РОН"

20 00 1.0 К'“?!
]?!АВБКХНПОЪЕ-ХТОЪ.) 60 10 30
”(АВЭКіХ(1)-УПН/ХПН.БТ-ХТОЬ! 60 ТО 60
60 10 1.0

30 |Г(АБ$(ХП)*УПН—БТ-ХТОЬ) БО ТО 60

40 СОНТКМОЕ

С СНЕСК БПАОХЕНТ
00 50 1'1."

50 ”(АВБПБУПП-ОТКЛОЦ 60 10 50

С АЦ. СОМУЕКСЕМСЕ СЙПЕККА $АП$|ЧЕ°
\РА5511
ЙЕУЦЙ"

( СОМУЕКБЕМЕ МОТ АСМ]ЕУЕ°

60 |РА$$в2
КЕПЖМ
ено

ВЬОСК ВАТА
СОИИОМ [ОМЕ/ ХЦОНУ‘ХОНБПОНРХ.Р'
СОММОН [ТНКЕЕ/ М.НРЦМСЗ'ЩЖУЦТЕ
ИПА (ХП)91'1!4ЬМ/'3.0'1-"3
Е…?

   

.:В!

ЗЧВКЩЛПШ ОЕдііоБХ)

СОИМОН іінКЕЕ/ м.нгимст‚попу.!твк.1мв1с.|гиіпт

ВХМЕМЗПЖ {ПО!

ВПМЕМЫОМ "МЫ

ВБМЕМБХОМ БХЦО!

1М|П=2і21'2|1)*2(1\

ХМ12111-211Ь

ТМ!3"11М-1(3)*2(31

ТНИ‘ПХ'ЫЗ)

ТИ|51=2К2Р1

ТМ1Ы=21И)'1
6х‹х›--цоо.іипптмп1—2птмп2)
бхіг"200.'ТМ(11+20-2*ТМ!5!*19-8‘ТМ‘Ь'
6х(3)"360‘1|3)'1М(3)—2.'ТИ1Ь!
БХ(В)=150.‘ТМ(3)+20-2*ТМК6]+19›8*ТН(5)
НОВУ'МОКУ94

КЕТЧВМ

ЕМО

БиВКОЦТАМЕ Пт (25…

СОИМЦЙ /1НЁЕЕ/ НяМРЧйСТ!М0КУ!!ТЕК-ХПВХС11РК1ЙТ

[ПМЕПБНШ 2К10|
ВХМЕМЫОМ “Мб!
тмкхі-2421-1(1!*1‹1)
ТИК2!'1'2(1!
ТМ!З|Я2(д!-2(3]*213)
ПММ-Ъ'ХКЗ)
ПНЭ'ідігі'і.
тнпьі=2(ц1-1

РХдШОМЧ’Міпітмпід'Мі2\'ТМЦ]*90-"ТМ!3)*ТМ(3)01М(61'ТМ(580
Ахо."ПН!5Ь'ТМ(5]*1Н|6Э'ТМ46Л )#!9.Б*ТМ(5"ТМ(6)

мгимст-пгимстьд
КЕТЧКМ
БНП

МВХ(.1РК1МТ

483
 pagebreak 
484

зивпоитхмв мкм:
( ментом МЕтноо
: тнЕ ЕТА зивпоитяме ни$т сдъсиьлт! тн! Астидь МЕЗ$|АМ идтніх Амо
: квтикп ТНЕ пнчЕпзв !" тнЕ н АККАУ.
сонмом /омЕ/ хкіо›.укхоя.5‹1о›.гх‚гу
сонмом /тн0/ и‹10'10).оЕьхс101.оеьв‹10›.сх‹101
сонмом /тнКЕЕ/ п.мгипст.мвкч.[тепрімв1с‚|Ряхиі
1тЕК=0
: ЕчАЬиАтЕ !п1т1АЬ РОХМУ
САЬь гиміх.гх|
коимтзякоимтзо1
рахит гоооо хтек.гх.‹Х|1).1=1›и)
сдьь вЕН‹х‚ъх›
: ХтЕКАТЕ гоп зоьиткоп
10 11Ек=1тЕк+1
(Ады ЕТА
по за 1-1,”
5:11:0-
ио 20 4-1.М
20 $(!7=$(К1-Н11с4)ібхі11
зо “(Н):хннэкп
(Аьь гим1у.гг)
коцмтз-кпиптзо1
‹ тЕэт гоп сотнями—
сльь ьЕКцурвхя
САЬЬ сомукаіах.!РА$5›
]г‹!РА5$.ЕО.1› 60 то 50
‹ ‹опчЕКьЕпсЕ спітеаід пот $АТ|5Р1Е°
гх=г1
00 до 1-10"
во хк|1:уя!›
ПпРКШт-ЕО-П РКШТЗОЧОс ПЕШЕХЦХПНХ'ЬШ
60 то 10
с сопуіпьепсе спктепхд $Атквгівп
50 Рвхмт гиоо. 1тЕп.Р!.іг|1›.1-1.п1
2000 гокмятк1х'іь‚е1ь.е.|521ь.вз›
антики
Ем»

зиВКОЦПпЕ м…!

СОММОК /0МЕ/ КПО! ‚УНО! ‚ЗНОНРХгРУ

СОМИОМ /'|ЪЮ! ИПОФЪОЬПЕЪХЦЩ и\ЪЕЦ'эі 10) 'БХПОЪ

СОНМОК ГШКЕЕ/ МяМРЧМСТБМВШ/НТЕК'ППЛСНРВНП'

ОХИЕНЗХОП БУ410)
С ЕХЕСЦПУЬ РЕоБКАМ гоа МЕТРЮдЗ "НКП АРРКОХШАТЕ \“НЕ ШУЕКЗЕ ОГ ЛН!
С НЕЗЗДАМ МАТКПХ ХНСЦДПЖЗ
С ] ОАУХЩЖ'РЬЪТСНЕКрРОНЁЦь

С 2 ЕЙОУВЕМ
С 3 РЕАКЗОМ 2
С А РЕАКЗОН 3
!ТЕЙ=0
С ЕУАЦМТЕ ТНЕ ННТПН. РОН”

(АЦ. РЦМ(Х›РХ)
(АЦ. ВЕК(Х.6Х)
РНПЦ 2-00» ХТЕКШРЧНСТЦЮКУ'ГХЦХКПпі‘ід“
С ЗЕТ ЦР ТИЕ ХОЕЖПТУ МАППХ
5 00 20 1-1!“
00 М} лиц
10 Н(ЬЛ=0.О
20 НПвП’іоО
С ТАКЕ ОКАОКЕНТ ЗТЕР
!РНРКХПТ-Еаціі РКП” 2100
2100 ЕОКИАТ“ спмпепт $ТЕР“Б
ВО 30 П'Чгм
30 5|Н=-6Х|П
С РК…) КЕХТ "ОПП'
дд САЫ- ЗЕМЁСН
 pagebreak 
485

‹ снгси ыцгтндя зекксн нд: А зиссезз. хг Мот. везет и Аль ТАКЕ вдАахспт зтцг
1?!гг.оі.гх› 50 то 5
]!ЕК!!ТЕП&1
сдъь оЕк:т.6У:
сдьъ сопикоцеу.прд55г
1г11РА$$.Ео.іъ во 10 10
: СОМУЕНБЕМСЕ СК}ТЕЙ]А мот $Ат15г16в. гіно А мен вхвгстхоп Мдткхх
1гк1гк:мт‚ео.1› рпямт гооо‚ 1тея.пгимст.цову‚гг.‹т‹хг.х-1‚м:
во 50 |-х.м
оеьа‹1›-сч‹1л-ехк1›
05ьха!!=ук1›-х‹1!
БХ‹11=6У11)
эо х111-г‹хя
гххгг
‹Аьь ЕТА
С $Ет ир ман $ЕАасн вявестхоп
но во к-1.п
5411-е.
во 59 4-х‚м
ао 5х1):5‹|›-н‹ідцлйеу|47
60 то до
: сопуввевпке скітевкд $АТЗ$Р1Е0
70 ?якнт 2000. 115к.нгипст.нопу‚гу.(У!!)‚Х-ХоМУ
зочо гокидт‹1х.зі7.вде-8.(5516.8!)
петикн
емо

знакоитімв мхи:
: БьетснЕК—ВЕЕуез сомциодте скдвхепт метноо‚ БЕСТ10М :.:—:
компан іомв/ хоха)…укхоз›;‹1о›.гх.гу
соммим /тиои нч10›10››оЕьх‹1о›.веьв‹1о›.ах:1е›
сом=оп [ТНКЕЕ/ м.пгим:т‚мвку‚1твп‚ъпокс.1рп1мт
дтЕ =о
1пвэет:п+х
!МБЕх-ХИЕЗЕТ
‹ БудьиАтЕ'згдктхнв РОХМТ
сАьь гим‹х›гхл
сдьь 0Е81Х'6Х]
рв1мт гиио. 1тек.мгимст.моку‚гх.кхк1).1=\.п1
с САЬСоьАТЕ эпидкво мови ог екдвгепт
10 50мой1=0.
00 20 1-1."
:и зомопх-здмопх+ох‹1л*6Х(1)
пгсхмосх.мг.1кезетз со то 50
с згт зеАпсн охвестіом то МЕБАТПУЕ сКАОХЕМХ
зо 1?!1РР1МТ.Е0-12 РЕ1МТ 2100
2100 ЕОКМАТ(* вкяодвмт 515?!)
1пввх=о
во ао 1=1оМ
ьо 5‹1›--Бх‹11
аи то 70
С 551 ЗЕАЯСН ОХКЕСТХОМ 0$1М6 КАТПО 0? $ОНАКЕВ МОЁН$
50 во 50 х-х.м
во эктхя-ехпхъ+5‹хзгзопспдіэопокг
‹ гла» мехт‘рокнт
70 сдьь задксн
с снгск инвтнек задкси иАз А зиссвззп :Р пог тАКЕ А скдохемг этев.
дг‹гг.ов.гх› 60 то 30
сдьь вЕк‹ч‚сх›
кпъех=1пвех+1
:тек=хтвк+1
(Ань сопчкв‹6х.1РА55)
1?11РА5$.ЕО.1) со то 90
: сонувквгмфв скхтвпуд мот $Аті$Р1ЕВ. сомтхмив ЗЁАКСН-
1$!!РКтмт—Е0-жт Рвітт 2000, ітеп.пгчмст‚поку:гж.‹х‹1›.1-1-мъ
С вдув пигокмдтіоп ГОК МЕХ! $ТА6Е
00 во 1-1."
 pagebreak 
овьх115=у‹!|нх‹т)
во хкіувукі)
гхзгу
зопоигкзвмокх
60 10 10
С СОНУЕКОЕМСЕ СКП'ЕМА ЗАТЕБПЕВ
во яккпт гооо»:тек.игом‹т.покч.Ру›!У(17.1:1."!
гопи гокмдт‹1х.317.516.е.‹звъь.6»
антики
ема

ЗОВЁОЦПМЕ ЕТА

С ПМЦВШЪ Рі-ЕТСНЕК-РОНЕЦ. НЕ'ЕНФБО $ЕСП°М 3.5-2
СОКМОМ !"!0/ "(10:10)‚ЙЕЪХ(10)›ОЕЪ6(1О!‚“КИО!
СОММОМ /ТНКЕЕ/ М.МГОМСТ-НМУ’ПЕК'КШЭЦСОХППЙТ
017494510" НВБНОМОБНПО)
ЭХВС’Оц
”6…3650.
00 20 КБМ"
"%КП‘РБНПН0э
00 10 151."
”ПВНПНЭБН!‘НП'Л'РЕЪБЩ’

10 ММП)=ВБИ(ПФПЕЪБЬЛ'НК—іо]›
”Х06‘0Х05*0Е|_ХП]‘ВЕЪБСП

20 ВбНООПВОНОБОРЫ-Ц [ і'ОЕЪБ‘ …
00 30 хчт
00 30 «"К-М

50 …]пЛ-НПЫНОЕЬХП)‘0ЕЬХКЛ/ПХ064НВБП)‘ЬБНЫПЕ
КЕПЖМ
ЕМО

зивпоитімв в1д
: вкоуовм метиов. застхоп 3.0-1
сонмом /тио/ нк10›101.вгъхк10›.оЕьс‹1о›.ахкъол
сомиоп /тнкае; п‚мгимст.поку.1тек.1мохс'ЪРк1пт
охмемэпоп охновкдо)
пътепм=о.
по го 1:1‚п
охивс‹хл=пвьх‹т›
во 10 4-1.м
хо вхиве‹к›:вхноасхл—нк|.4›гвеьв‹4›
го ВБТЕКМБВБТЕКМФЭХН06(1)‘0ЕЬ6(1|
оо эо х=1.м
во 30 4-х‚п
эо нк1.4›=нка.х1-нцх.:›оохнов‹1›похнпвкаг/вътнпм
ветивм
Жив

зивкоитіпв ЕТА
с РЕАкзон : нетнов. ъвстяом г.в
сонмом /тнои нсдо.1о›‚оаьхкхо›‚веьецхол.вхкхо›
спином 11нкЕЕ/ м.нгоист.мвку.1тгк.хпо|с.хдн1их
оімвнзпоп Вхнобііо)
ОХОО-о.
Во 20 к=1.м
вхнвькъъ=оеьх‹1)
00 :о ц=1‚м
:о охнвьі1›-вхиопкх›—н‹1.4)!ввь6(4)
го охосіпхвсъвгьхкхъ'оіьъ‹х)
во 30 1-1.м
во зо 4=1›п
30 Н51'4!=Н(1р4›*ПхНРФ|Ъ]*РЕЬХ[4)/ВХ06
пвтикм
ЕГФ
 pagebreak 
487

ЗЦБКООТШЕ ЕТА
С РЕАКЗОМ Э МЕТНОЁ. ЗЕСПОМ Зоб
(ОМНОМ ітни/ Ні10о10).0ЕЬХ(\0).ОЕЬ6(10\'Бхііо)
суммам [ТНПЕЕ/ М.ПРЦМСТ.НОВУуПЕК‘КМИС-іРКП“
ОХМЕНЫОМ РХНБС‘ПОЬОБНПО'
ВБНПБ=0и
00 20 [“-Н
ВХНОБП !‘РЕЦЦН
ВЕН” ]‘0-
00 10 )=1›Н
вхнпбп›:вхнип1-н‹ь.1ноы_ы.п
10 ББН”)ЗВБНПХФОЕЪБЪЛЧНЗЦ)
20 ПБМіХпОБНШБ-ФРБНЦХЙВЕЪБП)
00 30 яч…
00 30 )*}‚П
30 НПМРНЦг.ПФРХНВБ!П‘Обт-Л/ООНВБ
КЕТЧКМ
БМВ

зивкоц1хме ЕТА
( РКО.!ЕСХЕЦ НЕЪПОМ МЕТНОВ. ЗЕСПОМ 3-11 ($АНЕ А5 10018’3'3 рколстюп
С МЕНЮ!» БЕСПОМ ЗоЭ-Ь!
‹ [НЕ и мдткхх мизт кЕзЕт то тнЕ КВЕМТ|ТУ млтктх ЕКЕКЗ М ЗТЕРЗ
сонмом /Тн01 НК10!10);05ЪХ(10)'ВЕЪ5(10'16Х1101
СОММОМ /ТНКЕЕ/ М.МРЦМСТЖГЖУ-ПЕКЦМШС'П’ПМТ
оямвмыом нобпоповнпт
ванос-о.
во 20 |=Ъ0М
ИОБНРО-
06Н(1)= .
00 ХО 4-1'"
и0611›=ноъі!›он:х.4›іоёьсіц›
10 ОБНП)*06НП)'05|_6()ПНЩ'П
20 ВБНВ6=ОБНООФОЕЬБК \ ["'-106! И
во 30 1=1ум
во 30 4=1‚М
30 НПЦРНПЫРШЪН!!!“!НОЫЛ/Вбнвб
НЕтикм
БМВ

 

зивпоитіпв мпмх
воьпзтьхм—Рк1сг мЕтноо. эестіоп в.а
УЕК$10М 2. тнг ЭЕАКСН вхвьстпом при]! 15 вет то тнЕ вадвпемт опьт ок
тнг гікьт втЕР Амо нием о 15 ьгмсиьдп
сомюим [ОМЕ/ х:1о›.г‹1о›‚Рн|‹1оі‚гх›гч
(иммим 1тн0/ 0|10п101.оЕьх(10).ПЕЬБ!!О!-6Х|!0)
сонмом [ТнКЕЕ/ м.пгимст‚моку.1твк.іпвісціРпямт
вгмамэіоп бусіо)
к=0.0001
тнетА-п
ЛТЕК-о
: ЕудьиАтЕ зтдктхмс Рохнт
сАьь гим‹х‚гхз
сдьь 05к‹х›6х›
: Ряінт Рохмт
рахит геоо‚ хтЕк.Мгипст.мвку'гх.‹хк!).1=1ппі
60 Ю М
: ОЕМЕКАТЕ тив о мдткях
10 по 30 4:1‚п
хзАУЕ-хіщі
х‹4›-х«ц›+тнвтд
сдкь ОЕК‹Х'67›
во 20 1=1.п
го оа!.ц›=квуі|)—6хк1›1/ТНЕ!А
зо Х|4)-ХБАУЕ
‹ хпувпт а

ппп
 pagebreak 
САН. ЗГМШПОпМ-ХОЦБГ!
1г115г.мв.1› 60 то до
16119к1пт.50.1› рн1мт 2200
2200 гоппдт11Хв°0 1; $|Мъиьдк*›
00 то 70
с гавн тив рн] уесток и51н6 0
40 00 50 1-1."
РНЦ“- .
во 50 а=1.п
90 Ри1‹11-Ри!‹11+н‹1›4›!6х141
60 то 110
10 :Р \]Рдіпт.ЕО.]] ркімт 2100
2100 ГОКМАУ|1ХпіаКА01ЕМТ $ТЕР'!
: ЗЕТ Рн1 10 тнь овдпъгпг
00 60 1310"
во ›н111д-0х111
110 сомт1ниЕ
сдъь зеАксн
|гіГУ.вЕ.РХ) 00 то 70
с сАьсиЬАтЕ тнЕтА гоа нЕхт 1ТЕКА1|0М
рипдкм=б.
00 120 1-1."
120 гнпикиігнмокм+рн1111'Рн111›
димопм-заитіРипокм)
тиетА=кгрнмокм
: тезт Рок сонуьквімсв
115к-11Ея+1
(Ань 0ЕК(Уо6Х1
:Аььсомукв10х.1рдзз›
1г‹1РА$5.Еа.1› 50 то 140
: сомувкеемсв СКЦТЕКХА пот ЗАТХБРХЕВ
1гіёР81пт.Ео.11 явки? 2000» 1ТЕя.мгинст'м0пчяггокуі!)»!ніапі
РХ= У
00 130 №1…
вььхд11-1‹1›-х‹1!
130 х‹11-1111
00 то 10
: сопуькоіись СК1тЕК1А 5Ат|5г1еп
140 ркънт 2000; 1тЕа.пгипст.пвку.гу‚(гсі|.1е1,ц1
2000 гикмдтк1х.э11‚21ь.в.1>вхь.ві1
ветивп
Ено
зиьаоитхмв $Ум|МУіА›МС›пВ›15Р!
01МЕМ510и А1мосн0›.т‹201.0120).К120›
1$к0-0.и : омЕ-1.о › 1зг=о $ 00 21 м=1пмс
21 !!!…-ОМЕ
во 38 м=1‚нс : вдсзііко
во гц ь=1янс $ АВ=АБ$(А(Ъ,Ъ1) $ |г‹Ав-51с›2д'24.22
22 1гпвпь!!23.2а.2з
23 в10-Ав $ к=ь
24 соптлмиь 5 171810125‚25.2ь
25 ги1мт 13 5 1$г=1 & квтиям
13 РОКМАт11ох‚2эинА1я1х 1муЕп510п гдяьгоі
гв кш-хвко › щкномымкжи › пкъ=омв & мк.к›=пко : км::к-1
|Р:км1.Ео.о›31-27
27 по 30 ь=19км1 › т‹ь›-Акъ.к1 5 ]РЦК!Ь!›29‚28у29
гв 0:ь::д‹ь.к›и0|к› $ 60 10 30
29 01ь›—-А‹Ьькуіокк1
30 А!Ь.К)-2ЕКО
31 с0н11пив ь кР1-к41 ь 1гцкр1-от.мсизч.32
32 во зд ь=кР1.нс $ 161к1ь1133я34.зз
эз ткьх-Аік.ъ1 › сд то 35
зи т‹ь›--А‹к:ъ›
35 ось:--А‹к.ь›і0|к›
36 А1к‚ъ1-1Ек0
:? (оЩШиЕ
00 вв ь=1.пс 5 00 за к:н‚мс
3$ МН‘РМЦКМПЩ'ЩЮ ) М=МС+1 $ Ъ=МС
 pagebreak 
39

С .
; г
‹ .

“ поддал

102

489

во 39 К=2.мс $ м=М-1 : ъ-ъ—1 ! 00 39 ц=1‚ъ
А(Н‚4)=А(4‚М)
ЯЕТЦКМ ! Емо

ЗОБКОЦТХМЕ ЗЕАКСН
СОББПЖ МЬТНОО ОР ЦННЛМЕПЗХШМАЪ БЕАНСН

сонным іомЕ/ х|10›.1‹хо›.5‹1о›.гх'гу
сонным /тии/ нк1о-х0›‚вЕьх‹1и).ввь6‹10).бхк10!
сонмом [ТНЙЕЕ/ №.МРиМСТ›НВКУ-[ТЕЕяХМ01<.1РК[МТ
" тнг Апітъдь удкгдвьв УАКЧЕБ Ане им х. дуо тнг сокпЕзРопвімв
** гопстхон уАьиЕ 15 гх.
** [НЕ ЬЬАКСН ОХКЕСТ\0М ЧЕСТОК !$ 5. АМВ 1НЕ !МітіАК $1ЕР 512Е БТЕР-
15х1т=о
МТоь=О
гтоь:. их
гтоь' ТОЬ/[ООо

 

зтЕР=х.о
0=$ТЕР
изв тнг РАКАМЕТЕК хмпхс то 1М01САТЕ нои ТнЕ звАксн частой ьЕМвтн
5н0иьо нь зсдьвв.
1п01с-2 по пот всАьЕ. таке нвмстн віуем ву мхмх (Аьсиьдтхом
хмохь-х зсдье омьу 17 тие ьеМотн ог тнв ьАзт зтег иАз зноктвк тнАм
тнь ььмети ог тнь задксн увсток. зсдьв то ькмвтн ог ьАзт $ТЕР
хпвхс=д“утняпе вот 1 ок 2 квзиьтз нм зсдьлмв то ЬЕМБТН ог ьдзт БТЕР.
хг.лмвіс.ь0.2.ок.1твк.іо.ои 60 то 1
гхмо пики ог $ АМВ мики ог оЕьх
ЮХМКМ-ч.
змпкм-о.
по 102 1=ъям
охмиКМ-ВХНОКМФПЕЬХ11"ОЕЪХ(|›
зпокм-змопм+5‹1»5‹1›
1г‹1поъс.ь0.д.дыв.рхпокм.ев.5миямъ сп то ;
кдтхо-вхнОНМ/змопм
зтьг=5ивт‹кдт|о›
В=ЗТЕР
** $ТАк1 тнь ььдкси тнг воина тн: мхмхмин
1 во : \:1.м
2 укхя=х‹1иооезкп
сдьь гип‹ч.г›
к=ко1
1Р(г-РА) 5›Зс6
" м0 СНАМБЕ лн гимстяом удьиг. кЕтикм н1тн угсток сопявэронохпв то
гимстхоп уАьиЕ ог РА. ввсдиэв нг тив гипстлон УАьиЕ 15 ]МОЕРЕМРЕМТ
ог тнхз зедксн охпест1оп. тнЕм (ндмъвз ім тнг чАкгАвьЕ удьиез МАУ
ЦРБЕТ тив мАхм РКОБЙАИ сомуЕКсЕмсе тгзтхмв.
3 во ь 1=х.м
& уц!›-х‹1›+ода5‹1л
гу-гд
1г‹дРккмт.Ео.х1 вкпмт 2100

Зіии РОЙИАЧ!‘ ЭЕАКСН РАКЬЕВ. гимстіом УАЪОЕ !МВЕРЕМВЕМ' 07 БЕАКСН ВКК:

С .

Астяонпи
во то 325
чб тн; гинстхоп 1$ зтіьь онсведзгма. нпсяалзе тнЕ этЕР $115 ву
ооивкь тие ркеутопз ‹мскедзг !М'ЗтЕР 511$.
5 гСкгв : РВ=РА і гл=г
о<=ов $ онкод $ вд-в
и=2.и—о»5тьр
вы 10 \
*' минимим 1$ воимвви хм Ат ьёдзт ома Влпгстъом.
ь 1г‹к› т.н.э
мійімцм 15 нюимвви !" ома вхкестхом ФМЬУ. аечскзе ТНЕ $ЕАКСН
В!КЬСТ!0М Анд КБСУС\Ь`
 pagebreak 
490

7 РБ=Р
03:0 8 0=—0 ! $ТЕРБ-51ЕР
60 ТО 1
С МПНМОМ 1$ НОЧНОЕ!) 1" ВОТН ВійЕСУХОПЗ АР'ЕЙ От.? ТПО РЦПСТ'ОМ
С ЕУАЦ‘АТПОПЗ 'ОНЕ ЕПНЕК $105 0? ТНЕ 0К161М2о РЯОСЕЕП ТО ТНЕ
С РАКАВОЪХС [МТЕКРОЬАПОН-
. ЁС=ЁВ \ РВ-РА 5 ГА'Р
0С=ВВ $ ПВПЬА 5 ВАПБ
60 10 21
С ТНЕ МПННЦМ 15 ВОШЧПЕО АРТЕК АТ КЕА$Т ТПО РОМСПОМ ЕУАЦМПОМЗ 1"
С ТНЕ ЗА!: ШКЕСПОМ- ЕУАЬЦАТЕ ТНЕ ПШСТПЖ АТ ЗТЕР $!!Е'ЮАФВВНЁО
С ППЭ БПЦ. ПТИЦ) & ЕЩМЦЛ ЗРАСЕВ Р01МТ$ ВОЦМОХМБ [НЕ МППМЦМ-
9 ВС=ОВ $ ВЕ-Оь 5 пА-о
ГС'РВ $ ГВ‘РА , РА*Р
10 ПНО-Э'ЕЩРЁБ)
00 11 іііом
Н ПП-ХПМВОЗП)
САЦ- тмин
( ." МОИ “АУБ ]НАТ РА‘РВОРС МВ ‘ИА? ЁА'РОРС А5$Ш|М6 ТНАТ "НЕ
С ПШСТПЛ‘ 1$ ШНМОПМц ЕЕМОУЕ ЕХТИЕК РОХМТ А ОК РОНЦ“ В КМ ЗОСН А
С НАУ ““Т "Е ЁНМС'ПОМ 1$ НЩЖВЕ° АМО РА‘РБОГС 'ТНЕ СОККЕЗРОМРЖПЁ
С 51$? ЕЦЕЬ АВЕ ВА'ОБ'ФС ОК ВАОЭВОВС 1.
\: ]ПШС'ВИШ—ОВП [ЭЦЗЦВ
С ". ЪОСА'ПОП ОР МШШИМ !$ ЦИПЕО ВУ кОиМВШЁ ЕКНОВ$с КЕТОКМ ИПМ Вс

13 во и пьм
::. пп-хпновпып
гу-гв
!ГПЕХП-ЕО-Х) ‹.о то 32
хгпэкттлош гипп 2:00
221… ниями" замки гмьво. ьосАпом ог мшкмчм 'цмпво' и копмокмъп
со то 325_
‹: …» тнЕ Ропп в хз … тнЕ мыса и то ав.
1$ япг-гад 15.13.17
и гс=гв $ гв-і
:):-вв 5 овяг
во то 21
п РА=Р
мю
во то 21
с "и те рошт (› !$ … тн: „№5 вв то 17°
и шг-гш 19.13.20
19 гд=гв & гв-Р
„Адоб \ 08'0
‹‚о то 21
20 гс-г
вс-о
‹. ть пин РЕКРОЕН тн: ммвоцс тт:»рцпоп.
п А=гм шь—ос нгвиоым пгс! (»А-вы
хг… ггшмг
:: о=о.50‹ юв—вв—осюсигмпмбвс-оАчоАнпчомм-овіовпгспд
с смеси тип тнг Ропп 1$ сово. " зо, идиштг тна гимном.
ткщ—вшв-всп 13.13.23
23 ьо и т.п
и уш-хпнмэт
:Ац гонтп
: ст снвск гоа сошеквнпсв. хг нот Асиешвв. пепси.
пиныгвл-гтоьы 25.25.26
15 А=Ьо › ео то 21
26 А-ытв
27 !гнАвыгв-гпм-гтоы 28.20.12

с "* СОМУЕПБЕМСЕ АСНЕШЕВ. КЕШКМ ШТН ТМЕ ЗМАЬЬЕК О! Р АМВ РБ.
2! іЕХП‘і
“’“-78! 29.13.19
29 РРР
60 ТО 32
С "" ТнЕ РАКАБОЦС ШТЕКРЧСАТШМ НА; РЯЕУЕМТЕП ВУ ТИЕ ЫИБОК БЕШБ
Ё гЕКОс !? ""$ !$ \’НЕ ЁПіЗТ ПМЕ ХНА! ]Т НА$ НАРРЕМЕР. ТЙ' АМ

"ПЕКМ'ЕИАТЕ $159 $185 АМ) КЁСУСЪП ОТНЁЙШЁБ “УЕ НР А5 " |.00К5
 pagebreak 
4.9ь

СККЕ А 105? САЦ$ЕО
30 !РН“ 31131013
51 М-НОА
60 ТО 10
32 ПО 99 !=1‘М
ХРППЬМЕ-ХПП 60 ТО 329
99 (ОКП…)Е
60 ТО 33

325 |Р|МТОЬцМЕс0чАЮпХРЕПГЬЕавП Рдін'Г'ЗОООо "10|—
3000 Рокнлт‹1х.*тоьсвдмс: КЕвиСЕВ 'оііп' УХМЕ(5!'Э
326 КРКРУ-Ъ'НРХЪ “ЕПЛ"

1Р(5! “ “&.-ФСНП .ОЙАГУ-Ъ'ЪРХП ЙЕТШЁ"
РКП‘ПЭШБО

5000 РОКНАТі' ЕЕАКСН РАХЕЕВ 0“ А ввюшмт $157. 405 ТЕКИПМАТЁП`ч

РПЦ“ $100- [ТЕХ.МРЦМТч'іі-ЖУ1ЁУНУС 1 ! ”“М"

5100 ЕОКМАіі1х»317.Е1Ь-8г(5516у8)|

34

ЗТОР
33 !РНПОЪоЕО—Б) 60 Ю 34
ХЕХПЗО
мтоь-мт0ь+1
РТОЪ-РТОЪ/ПЪ
60 10 12
!РНРМН'ЬЕО-Хі РКП” 2000

2000 ГОКНАТ(' А РОЕНТ ЭЕтТЕК ТМА" ХнЕ ентепхпв РОЛ"! САМКОТ ВЕ РОЦКП."

на пол

п пппппп

\: › п п ‹:

ПЕТЧКП
БМП

вивяошшв задвсн
шішигмыимь эпики из…в сомони звеном. чнкыом :. нео ‘"
сонмом ‚оны хпомпюнзпоммгу
сиимим тт н…ъюэ.оеьхцомогьъцо!.схпол
сонмом пняЕЕ/ м.пгомст.мпку‚пккпмшсцркшт
шмепзюп икоты10|.рцоэ‚кцоъшгпюнззпы
пАтА пююхеоззэеэ/
Р-ошезт ог |.А51 1НКЕЕ Роштз
:внюоьв Рахит
и-сокквпт ротт
птпц$=о
мтоь-о
хомязшдквв пони ог УЕстов гном ›! тп : никн №51 в: Аснщеь гов
сомувкьвпсе
тоь-ошооощ
мпмвз-с
05$ унанкдмпев шок то ямисцв нон тнг зывсн чества ьвмстн
зноиш нь зсцво. .
ток:: сш пот зсдъе. тже ьемвтн впіп ву шп] сцсицпоп
шис-ъ зсдьн оны хг тие ъвмвтн ог тнЕ нэт 515» нм знамен тнт
тн: ьемвтн ог тнг зыксн честв- зсмн 10 шт… ог цзт $тЕР-
…они-шутить вит : ок : кезиьтв … всдцпв то с.:петп ог цэт $159.
тшръс.ео.2.оп.1т_5я.ео.о› со то ‹
повинні тнЕ зеАксн читов то тие !.ЕМБтН 0520 он тне ркшоиз $159-
окислами.
зпоямю.
\ш 2 1:1…
ихпияиахмиптовьщ ! ивы.)“ :)
знаниязмояты : мы ”
хгкшис.ео.1. Апофхпонншецпоань 60 то 4
охпикмчокт кохпокш
змонм-зокт ‹ змопм]
мпикохпокМ/зцопм
по 3 1:1…
55(Х’-$!|]*КА110
во то 10
ммптдп тнг плевы" ог тн: $ЕАКСМ уестоя ву сопз'тостше Ап типсы.
уЕстак Ами иаемтшс он и.
во 5 1=нп
ззш-зш
 pagebreak 
сдпівКАскьт тив мвмхмим хп тив & піпістхоп
‹ тАк: 5159 гном 0п|61МАЬ Рокмт
10 во 20 1=1‚м
:(:з-хкхл
го н‹»-хк1и+$5‹хл
г1=гх
нукмвэ-мтхмезо1
сдьь гиппч‚ги›
|г‹ги-ггъ Зи.7о.50
: соптлмив БЕАКСН хп 5АМЕ вхявстхоп
30 он во 1=1.п
р‹хи=1‹1›
:сяв:н‹|\
$$1!’=2-*$$(1›
«о нп1»-ик!›+$$‹1›
РР=Р2
г::гн
мтнмвэвитхм55+1
сАьь гим‹н.гн›
!РіРн-гі) эч.7о.120
с :н.вт.гг. веское нивінвя то ввуекзі відксн ояпв
50 хг‹мткмез.мв.х› ап то 120
: ЙЕУЕКБЕ БЕАКсн виде<1кон
во 50 1-1.м
55|1'--$$|Ь›
ьо Р1|)=Н(|)
Едягн
60 то 10
с Ранги. снвск мявР01мт
70 во во 1-1.н
во ки1›-‹1‹1\+и‹хвя/2е
птпм55=нтямез+1
сдьь РОМКК:РП)
нкпях
лг‹Рп-ггъ 1600300590
90 {г.мтлмьз.м5.:ь во то 110
с печень: згАксн вхністяоп
по 100 1:1."
551111-55к11
зоо Р(1›=кккя
гэнгк
во 10 10
с & АМО Р вддскет : Амо тнЕ Мъмімин
110 по 115 1:1‚п
и‹і›-ккк\
к‹1›=1‹х›
115 2‹х›=г‹|л
няни:
ги-гк
гп=г2
г1-гр
60 то цао
: Р дно и ВКАСКЕТ : АМО тнЕ млнхном
129 по 130 1=х.п
в‹х›=1‹|›
130 ;‹к\-Рцк›
мхм-х
гк-г;
г;:гр
Сціібоърім ьсАпснъ : АМВ н ВВАск51 тне мдмямин
14.0 нтокмщ.
оо хьь 1:1."
ихгг11›-ипЬ›—2‹1\
1ц5 ндмикм-намокм.пігг‹хвчоъггк1|
хг‹и1покм.ьт.тоъ› 60 то 290
на 00150 вник
$Ест-г1*0ігг|1\
Рк1›-2‹:›эзест
 pagebreak 
150 МП-ЩП-ЗЕСТ
сдьь гимнр›гРл
Сдьь гип‹к.гин
160 АГ(ГК—ЕР] х7о‚гзо.гоо
‹ кврьдс: н вт 9 АМВ › ву к
170 ниповнно.
оо 100 1-1."
н‹1›-Р‹х›
Р(|›=к‹|!
окгг‹къ=и||1—1‹1›.
удпокм=н1мокн‹п1гг‹х»о|6г‹1!
100 кц:)-н‹К!-гъ*вігг‹1і
гихгв
гр=гк
1гки:попм.ът.тоья 60 то 320
сАьь гипкв‚гкъ
во то 160
: КЕРЬАСЕ : ну и дно к Б! Р
200 н:покм=о.
со 210 1-1!"
1‹11-к11›
в‹к›=рклв
плгг‹1›-и‹яв—2‹1л
и:мокм-н2мокмовягг‹1›іоіггкхі
219 Р‹1!-2к1›4г1*в1гг|11
г1-гк
гв=гр
1г‹н1мокн.ът.7оьл 60 то 300
сдьь гом.р.гг›
60 то 160
с ггягв. снЕск Мхорохмт
гаи вп 240 х=1.п
240 у‹11-1Р11›+К|1))/і-
сАьъ гип‹у.гуъ
хг‹гу-гг› 250.3ьо‚:1о

: › дни я впдскві тие иппхмии ‹115 впдсквіео:

250 00 260 №17"
ЪЦИПП)
ЩН-РП)

260 МНЦ”!
ЕБРК
РНЯРР
ГВ'Г?

И…“
60 то ПО

493

‹: типе Анг. тью иш… ветнЕЕк : АМП и. Апшмкяц иск тн: ттт.

‘ ВЕТНЕЕМ ' АМВ Н (ННХСН [МСЦШЕБ Р’
270 ВО 200 1-1…
280 {”)-“П

Р2‘РУ

мм::

60 ТО 1%0

с ВКАскьт ом тнЕ млм 1$ зцгг1<45мтъч знАЪЪ

29ч во 10 (300.320). мкм
с к 15 іне родит ямзіиё тнг ВВАСКЕТ
зоо по 310 1-1,"
210 укп-К‹Н
РУНЕК
во то зьо
с Р 15 тив водит |М$КЬЕ ТНЕ ВВАСКЕТ
3:0 по 330 1.1."
330 ук13-9‹|ж
гк-гг
8100 СОМ'ПРШЕ
во эаэ 1-1›п
энэ |г‹х‹х|.п:.у(1)р во то 306
во то 350
396 !ППобЕоРМ 60 ТО 370
 pagebreak 
494

!РКХРВХМт-МЕ-Ъ] КЕТЦКМ
кг 1мтоь.мь.08 гкіпт зооо.мтоъ
1:1п1къ:$.м5. › раки! 3100
3000 гоямдтц1х‚*тоьвкдпсв кврисвп і,]і.і тхМЕізіі!
зъои гокндткхх.д55<0но ТПУ.“!
кетипМ'
сспіАк: САвЕ 06 РАтнАъ061САь сиппхтопз
‹ А1 тив рввзвнт тоьаяъпсе ьЕуЕь мо Рохит САп ве говно нихсн
( 1$ ВЕТТЕК ТИА“ ТНЕ ЕПТЕК1Н6 РОХПТ. ЕЕВНСЕ ТОБ В? А РАСТОК ОР 1004
350 |г1МТОЬ-ЕЦ-5) 60 то 360
мтоь=птоь‹1
тоь:тоь1100.
60 то хвь
с пкхмт мезэАвЕ Ако квіикп
360 згікРк|п1.пЕ.1› 60 то 316
|Р|МТК1Е$.МЕ.О) 60 10 375
РВК"! аиООоТОЬ
2000 РОПИАТСАХ-‘ТНЕ !ОЪЕКАМСЕ НАЗ БЕЕМ БЕВМСЕО $ 11НЕ$ ТО А СЦПКЕМТ ПАВ
АиБ 056.Ех5.в.і.п./.
вхх. 'А Ролик еЕтгкп тнАм тн: :птвкяме 901пт САмпит в! гонке Ат тп
сиз ЬЕУЕЪ ОР тоъввАпсЕ. тнг вптекяпе РОЦМТ 1$ ввпма кЕ1икпЕо.і1
60 то 376
с.. гу.6т.гх‚ гяпо А вкдскет ЕХСЬивінв тн: чАъъЕу срмтАкпхма ?—
370 |Р|МТКЪЕ$оЕО.0) 60 то 380
|г‹мтоь.ьт.5› 60 19 350
315 РПКМ1 2100
ранит :ооо.птоь
2100 РОКИА‘(1х-.А РОХМТ КАЗ РОЦЙО ЭПСН 'ИА! 5! МАЗ БКЕАТЕК ТИА“ РХ. ^
взгсопа АттвиРт то гіно А родит н|тм А гипсткок уАьиЕ №558 тнАи :»
:РА!ЬЕВ.')
315 171$(11.м:.—6х‹1\ .ок.кгу.ьт.гх1) кечикп
рякмт 2200
2200 гопмдт‹* $ЕАвсн гАхьЕв он А БКАОХЕМТ зтЕР. 405 тскнхмАтЕВ*і
рипы! 2300. :т:к.мгирст.м0ку.гч.(1к1›‚1-х‚пі
2300 гоз:дт‹1х›зхт‚въь.ву|5515.о››
эт
с коек гоп А впАсквт пЕАя х ок тн: 5105 ОРРозхтЕ ГНОМ !!
зао птяіЕЗ-ъ
по 390 1-1.н
1(Х›:Х11)
$$‹|›-‹хк1›—у‹1›|/20о
390 н:х›‹х‹х›+55к1л
гізгх
сдьь гонцногнл
хгігн-ггз эч.ьоо.дэо
С Рі-РН: СНЕСК НКОРОКМТ
доп 00 «хо 1-хцн
.10 ркихвк1‹х›*и‹1ля/2-
сАьь гопцР.гР1
!РіЕР-Ё1! бгО'ЭЕОоВЭО
с г:.от.гр Амо гн.6т.гР. н Амо : гопи А ввАскЕ1
ьго н1п=2
ев то хьо
‹ гр.ят.г;. Р 15 А вкдскет НіТн тнг иямхмим ВЕТНЕЕМ Р Амо '
дач ио цьо 1-1.п
ции н‹|›=911›
РН=РР
с ги.вт.г1. и 15 А еаАскЕт нятн тНЕ мінімии ветнеев и Ано ?
‹ снаск мьвРокмт 06 ' Ани и
450 по 650 1-1."

2(11='!11
Ь60 Р(|)-(1|БП+Н(ХУ!/2'
ГХ'РУ

410 сАьь гим:р.гр›
дгкгР.ьь‚г1› 60 то «90
: тку Абдіп
по два 1-1."
;сів-Рпъъ
 pagebreak 
Программы на языке ФОРТРАН 495

 

діи ННЧНПНЦППЁ-
гихгг
60 то «10
с Р хз кн А УАьЪЕУ вяггЕдЕмт гном 1НЕ ОМЕ сомтАіпяме 1.
с сикск нньтньк Р АМВ н Роки А ввАскЕт
аэс 00 500 1-1."
500 я‹|!-‹Р|к›9н‹1\112.
сдьь гим‹я.:к› ‚
1г1гя.ьь.гн› во то 550
1г1гп.ъь.гР› во то 520
с Р АМП и гопи А вддскет
505 он 510 1-1.“
510 2:1):Рі1)
Р2=РР
ихп-1
60 то 150
‹ гв.ь1.гн- гк.65.гя. ненсЕ ьоок год А ввдсквтхме уАьиЕ ветигвм р Амв !.
#20 по 530 х-1.к
П(1)-Р(1)
$30 РПЛЦРЦНЦПНЕ.
ПЬЕР
зао (Ань гчм‹Р.гР1
1?|ГР.ЬЬ.$1› 60 то 590
С гиены. АРРАКЕМ'П.‘ 1 15 … тнЕ $АНЕ УАЦЕУ НПН '.
но 550 1-1›п

211)-Р(1)

550 Р:х›=кк‹1ъ‹2‹1ъ›/г.
ггпгв
ао то вао

с РКоБЕ-Рн

$60 !ПРКоЬЪРР) 60 ТО 505
С ГЁ-БЕ-ГРс К АМВ и РОКМ А ВКАСКЕТ
00 570 1-10"
570 2П1-ііп
Р2=РВ
60 "О 156
ЕМВ

 

Б2.ПР0ГРАММА ОПТИМИЗАЦИОННОГО МЕТОДА
ПАУЭЛЛА

Отдельная подпрограмма МШ] была подюгювлена для реа—
лизации оптимизационного алгоритма Пауэлла, предназначен-
ного для решения задач нелинейного программирования при огг-
сутствии ограничений (без использования производных). Следует
отметить, что здесь ВЕК не используется, 3 ПЧШС присваивается
значение 2. Специальные инструкции относительно“ сходимости
содержатся в комментирующих картах в подпрограмме М1М1.
Следует положить 1СО№16 = 1, если один проход по алгоритму
Пауэлла будет достаточным, или 1С0№16 = 2, если окончатель-
ное решение должно быть изменено и найдено новое и если необ-
ходимо выполнить экстраполяцию между ними. Подпрограмму
МТМ должна сопровождать специальная псдпрограмма ТЕЗТ.

Помимо указанных выше отличий подпрограмма МШ! для
метода Пауэлла полностью совместима с программой ЕХЕС и
должна использоваться вместе с нею. Программа ЕХЕС была рае-
смотрена выше.
 pagebreak 
496

5иНЕ0011МЕ МКМ!

С РОНЕЦ. МЕТНОВ ОР ШЁЁСТ ЗЁАЁСН
‹ зивяштте тез: низт' ве рвоушеп гон сомчвмексг тента

оппппппоппп

:

*
:
.

сонмом іопп хпомупомзноьгмп
сомон/тнО/ икестпоцимвимпоъ.вггокгпо!.гхкзтцо)
сонмом ПНКЕЕ/ Мспгипст.ММЧяПЕКэШМС-[РНШ1
окметзшм нцомзесмишэ
Бошумвмсе (н.вгсмш
“ . тнг иимвгк ог умными.
кома - тнЕ ПММ. шпикашцЕ твзт ВЕЫКЕЬ.
- 1. твкмхпдтв А5 зоом А5 тсзпме 1$ зАтізгдво.
. 2. А5 зови А5 тнг тнзпмв скинам Акг злпзпгп тсянзе
дц. тнг. удкывцэ ву хоцсс АМВ зоше пковьгм дамп.
тнвм Рікгопи А !.…Е- звАксн Ватикан тнг эоштшпз нг ыгггквнт
зоштюмз АКЕ ВЕЕМЕВ то ВЕ гоимв.
зтЕР . ТНЕ тп…. БТЕР 5115.
АСС : 'не КЕОЩКЕЬ Акима … тн: гипстіом АМО чгстов \!АШЕЭ.
ШЗЕН" ХРППП- ]. Род СОМРЬЕТЕ РММТ Щл ОК [РМАТ ' 2 ПММ-
]АМЗИЕК они
АССБОЩООМ
ЗТЕР=ЬО

[МЛС ‚ПБ? ВЕ ЗЕТ Т0 3

1М01С=2
1С…“Бд1
!ТЕКЧ]
нтК1-1
"!дн—і
51ЕРА=5ТЕР

: !О& 551 ОР ТнЕ 1нхт1Аь ПХКЕСіХОМ "дійіх (051М6 "МХТ УРСТОКБУ.

во : х-мм
во 1 апт
: ответными.
: шпестптп.

С "' ЕУАЬЦАТЬВ ТНЕ РНМСУХОМ‘АТ ТНЕ !МітіАЪ УАКХАБЪЕ уАьиЕ5.

100 САН. ТЦ…ХОЁХ)

РПН‘П' 2000г |ТЕП‚МЁН"СТ›РХя (Х”НТ‘1'М’

2000 РОКМА1(ЗХ’2111Е16с61(5516.8)]

60 ТО 301

: пц зна тие ппц гипстюм умин (РН АМВ тив РН…. УАПАМР УАШЕз

п а п п

“О

_кввгоды гном тн: рквуюив сусп.
: хтЕд-пвкп
1$!1Рн1МТ-Е0-1) РКХМТ 2000; ]ТЕКоМРОМСт.ГХвКХ(Хія1=1‚п}

301 гхпгх

00 6 1'1-М
& ВЕРОКЕК]!;Х(1У
ЗШКО.
АТ ТНЕ ЕП0_0Р ТНЕ СУСЪЕ- зим НКЬЪ СОМТАХП ТНЕ МАХХНЦМ СНАМБЕ 1"
'не ПШГПОП УАЪЦЕ РОК АМ‘і ЗЕАЙСН ОБКЕСПОМ. АМ) 1$АУЕ ТМПХСАТЕ$
1:5 \)ПЁЕС'ПОП УЕСТОК ГО ИНКСН ХТ СОККіЗРОМВЗ.
В 9 '11П
$ СОМТАХМз ТНЕ ХМХТКАЬ $ТЕР 511Е$ ХМ ТНЕ 1-ти РХКЕСТіодч
00'5 д'ійд‘
# 5(4)=01ПЕС`П4—П‘5ТЕР
РХЁВЕТНЕ НКМХМММ ХМ ТИЕ 1-ТН 01КЕСТ10М' АМО ТНЕ СНАМБЕ 1" ГОМСТТОМ
\… О .
САН. БЕАКСН
АгРх-РУ
]Р‘А'ЭШ” 707'6
6 [ЗАЧЕПХ
ЗОН'А
тядмзгек ТНЕ "ЕН ГЦМСЖПОМ АМО УАдіАБСЕ УАЪНЕ$ ТО РХ АМВ Хо.
7 00 В Ц=1'М
В ХН)_"‘4!
9 РХ'Г'

‘ оп МОН ШУЕЕТЙМЁ ИНЕТНЁВ А ПВН ЗЕАВБН ИКЕЯПОН ЭНОЧЪР ЁЁ шсокгон—
 pagebreak 
10

11
с %!.

12
13

и.

по

15

16

26

С «1!

27

га
29
30

с из
С

497

АТЕВ ШЫЕАО ОР …! ХЗАУЕ ЩКЕСПОпо

Р2=ГК

00 10 Ник

“(”=2с0‘Х1П-ВЕРЩЁЕКП

САЦ. РШ‘НЧ'РЗУ

А.РЗ'П.

1ПА‘ 11.19“?

А=2-0.(Ё1'2‹0‘52+73)'((Г]-Р2-$0Мі/АУ“2

[“А-$0… 12.19г19

А МЕН $ЕАКСН ВШЕС'ПОН 1$ ПЕОЦПКЕВ. ПЁЗТ КЕНОУЕ КОИ {ЗАЧЕ-
ЦРЦ5А‘1Е'Ю 13015-15

00 15 ХЦЗАЧЕ'Щ.

11,151

130 110 4810"

ОШЕСТЧЩ'П-ПККЕСТН'П)

ЗЕТ ТНЕ М-ТН ВЛКЕС'ПОМ УЕСТОК ЕСЦ“. ТО ТНЕ МОКМАЦЗЕВ БПРЕЙЕМСЕ
ВЕТНЕЕ‘Ч ТНЕ “ЧП]АЬ АМ) ЁПМЪ УАЮАЕЪЕ уАЦіЕ5 РОЙ |.А5Т СУСЬЕ-
А=0.

00 16 4'19"

оівЕС'ПдіППХЬП—ВЕГОКЕЬП

А'ВКЙЕС1‘4'М!'*2+А

А'1-0/50К1(А)

во 17 4-1.м‚

шкеспцтгвщпвсгштпд

$ПНОШЕСТ(-НЮ*$ТЕР

САН. $ЕАКСН

РХ=ГУ

00 \В "Ь"

Х|П=УКП

ТЕ6Т РОЙ СОМУЕМЕМСЕ-

САН- ТЕ$Т(Ё1!гдпвЕГОЙЕ'Х-РЪАБяПоАССУ

"’!РЪАБ) 22.22'20

СОМУЕКБЕМСЕ МОТ УЕТ АСНЕХУЕВ. СОМРЦТЕ А ЦЕН 5159 $115 АМВ
БО ЕАСКТО Э-

!дігі—ГХПЁіЦЕОЦЕО

ЗТЕРн-ОсВ'ЗОП'|АВ$[Р\'ЁХ1]

60 ТО 123

$ТЕР=0вдд50КТ(Рі-РХ1

”(ЗТЕРА-ЗТЕР) 2193,3

$ТЕР-51ЕРА

60 ТО 3

С…УЕПБЕНСЕ АСНЕП/ЕР. ХР 1С0МУ6=2в КМСКЕАЗЕ АЦ- УАПХАВЪЕЗ ВУ
10*АСС АМВ 60 БАСК ТВ З.

60 "О (ЕЗОЗ'МНСОМУБ

$5105?“

60 ТО (25:27) ‚МТК?

ПТКУ=2

00 26 КРЦ."

ЁШЗТП ‚ПХП!

ХКП'ХЕЪ)+ЛСС.10-

751Й51=7Х

60 'О 100

СОПУЕКБЕМСЕ АТТАХМЕП ОЗП“: ГНО ВП’ГЕКЕМТ ЗТАКПМС РОПП'З. СОМЗТ'ШС
ипхт честод ввтнеен заьитяоМз Амо згдксн вживстком гск А мхмкмим.

РЗЕСМ0=РХ

А=0.

00 25 1-11М

ЭЕСМПП ПХП)

ЗКП=Г1К$`ПИ-ЗЕСМВП)

А=АО$П 3..2

!Рід‘ 23.23г29

А'З'ЕР/Э‘Ж'ПА)

ПО 30 ННП

5|1)=5”).А

САН. ЗЕАЙСН

ТЕЗТ |Р "ЕН РО…Т 15 ЗЦГРПСЦЕМТЬУ {ЦВЕ 10 ЕПНЕК ОР '!НЕ ТПО
$0ЦЛ'|0"$- |? 50 ПЕТШЧМ-

(АЦ. тЕБт(ГРХКЗ'!‚РНПЁЫИУН—Абтцсі)
 pagebreak 
498 Приложение Б

 

[Рігъдбі 32.32.31
’! САЪЪ 1551!РзЕСМП.РУ‹5ЕСМП:У'РЪАбуиідссУ

[РЦРЪАФЭ 32.32.3ц
32 00 33 1-1.“
33 Хііі=1117
ГХ'ГУ
ПЕТОК"
С "' РЪМАЬ ЗОЬЧТХОМ НОТ АССЦКАТЕ ЕМООБН. ПЕРЬАСЕ ТНЕ Р|Я$Т ОТПЕСТХОП
С УЕСТОК ВУ ХМТЕд-ЗОЬНТЪОН УЕСТОК (МОПМАЬПЗЕВ! АМВ КЕС'СЬЕ
Эд А=Аі$1ЕР
00 35 1:1'М
ВКРЕсті|р1)=|Г1К5Т!1’°5ЕСМВ(17)*А
35 РХРЗТКЦП=ЗЕСМВККП
60 10 З
Е…)

ЗПБЕОЦХЪНЕ ТЕЗТЦРКвЁРгК1удР-РЪАБуПядссі
С 1Н|$ $0$КОЦТ|МЕ 1$ РЕСПЪЪАЙ ТО ТНЕ РОНЕЪЪ НЁ1НОП ОР ВХКЕСТ $ЕАКСН
П|НЕ"$10М К1110)1Е71101
РЕАБПФ20
!Р!А6$|ГК|-АСС| 2,291

: |Г(АВ$|!РХ°РРі/Р1)-АСС! 3.3.7
: кгкАвзкгя-гг›—Асс› 3.3.1
3 во 6 1:1.м
|Р(АВ$|П1(|1)-АСС) 5.5.ь
" [ЁКА85((ЙНХ‚'КРПП/КХПП'АССі 60507
5 хгкдвзідіпіь-кг‹х»-Ассп ь.ь›7
ь сомтвмие
П.АБ=—2о
7 кгтивм
ЕМО

 

В.З. МЕТОД ОПТИМИЗАЦИИ НЕЛДЕРА И МИДА.
ИНСТРУКЦИИ ПО БВОДУ ДАННЫХ В ПРОГРАММУ

Функцией, представленной в холоде перфократ в данной про-
грамме, является функция Вуда. Карта (ЗИМ (ПЧ) = [ (х)) (третья
последняя карта в колоде) должна заменяться при каждом новом
выборе функции. Максимальная размерность задачи может бЫть
50, т. е. от Х (1) до Х (50).

Пользователь должен подготовить следующие перфокартысдан—
ными:

Карта 1. Перфорируется МХ —— число переменных целевой функ-
ции в формате 15 в колонках 1—5, а также ЗТЕР—
размер шага в формате Р10.5 в колонках 6—16. При
отсутствии другой информации выбирается ЗТЕР ==

. 0,2 "
=…… {—і;1а,‚ 41,42, …а…}

где п—число независимых переменных, ад—область
возможного поиска по переменной хд.

Карта 2. Перфорируется исходное предполагаемое значение каж—
дой переменной в формате Р10.5. Карты 2 и 3 могут
быть повторены с измененными размером шага и исход‹
 pagebreak 
Программы на языке ФОРТРАН 499

 

ными переменными в зависимости от задачи, но после
последней карты типа 2 должна следовать:

Карта т. Пустая карта.

дпппппппппопо

РКОСКШ ЗХМРЬЕХНЙРНТсОЦТРиТ’

ПХ !$ ТНЕ ПЦНБЕК 07 [МВЕРЕМВЕМТ УАКЦАБЬЕ5'
ЗТЕР 1$ ТНЕ КМХПАЪ БТЕР $12Е-

ХП) 15 .ТНЬ АЮ?!” ОР ”ППМ. ЕЦЕЗЗЕЗо
”АТА (АППБ АКЕ А5 РОЦЛНЗ-

САП) М). РАВАМЕТЕПЗ РВКММ' (ОЦШОБ
! МХ 15 ). ТНКЦ 5
]. $гЕР под 6 чиво 15
2 ХЦ) 710.5 1 ТНКЦ 10

(Апр 3 !$ вьАпк.
ТЦ ОРПМЦЪЬ ТНЬ Он.!ЕСТП/Е РЦМС'ПОМ РОЙ дМОТНЕП ЗЕТ ОР РАКАИЕТЕЙЭ
ПЕРЕАТ САЙОЗ 1 МШ 2 Од‘ьУв
РОК РКОРЕП РШН'ЮЦТ ОГ ВЕБЦПЕР Х(П АККАУ; РОПМАТ $ТАТЕМЕН1$ 103
АМВ 101 МЦБТ ВЕ КЕЩЗЕБ АССОЙВШВЬУ.
ВКНЕИЗХОМ Х1і50;50|п Х|501в ЗШМБОУ
соммоп/1/ х.х1.мх-515Р.кх.зиисхм
! РОКМА1([5›РЦО.5)

100 ПЕМЛ ‹ мХ-ЗТЕР

”(ЮИ ЧЭВ›.999›99В

990 КЕМ) 2. |Х1Н|1=11ПХ|
2 РШ…АТЦОГЪФ.5)

АЬГА-Ьч
ВЕТА‘О-Э
бАМАгг-О

ОЪГЕК ! 0.

ХМХ '- ”Х

“О ' !

САН. $0.43

РКП” 1027$ЦНЦ|ЦХПИХ=1рМХі
РКП” 1002-5ТЕР
САН. ЗЕСОМВП'ПМЕ’
РИП" Ъчбп'ПМЕ

105 РОКМАП/БОХ-ПНТЦИЕ 15 М0Ы›Г10о3`БН ЗЕСОМПЗП

РПП” 103

103 ЁОКНА11‘6Х’1ИНРЦМСТК0М \!МиЕЦБХгЗНХ1=.20Х93НХ2-ц20Х-3МХ3=›2ОХ-ЭНХЬ

11-16Х ЦЗНПШС. СНМЮЕ)

1Ч2 ГЮЁМАП1н1912Х’23НГЦМСПОМ ЗТЁКПМБ УАЪЧЕуГ10051/йтНЕ )( АКЕАУ 15'

1.1‚5х‚1щЕп.м2хп

1002 РОРМАП12ХМЗТЕР=*-Ё602’

к1-іих41
КЕ'ПХ92
КЗ'МХОЗ
КЬ=М<9Ц
САЬЬЗТАКТ

250031‘11!“

110%! .1 ' 1- их
# ХБ” = ХЦ! п”
… Х |
(АЦ. ЗЦНЁ
3 СОМПМЦЕ

С ЗЕЬЕСТ ЪАПБЕЗТ УАЬЦЕ ОГ $ЦМП) ]" ЗПМРЪЕХ

25 5001“ = 500411]

!мввх = 1
ню 7 1 я 2. Кі
1?(50М||)-ЬЕ-$имН) 60 то 1
зимн = вини!)
!МОЕх : !

7 СОМП'ШБ
 pagebreak 
500

по

за.:ст мхшмим иш: ОР $014… ХМ ЫМРЪЕХ
зим. - зимми
копит . 1
00 в 1 - :. к1
:пзшмцьэинпн 60 то 5
$)…. = 50…“
коимт : :
в сомттие
Пио сьмткош ог 90…15 шт 1 шггіпвмт тнАи |мои
00 9 .] ' И МХ
$ЦМ2 : Ос
00 10 1 ' 1' К!
10 зим: = 50042 # ППМ!
хиппи цихмхчэинг — Х1ПНВЕХ94П
пни вггьестшп 05 июн ропп тнпшвн свитке…
хикзм) - п. 4 Аьгміхпкгнз - мгмхпшоЕх-Л
9 хи] - хпкзмл
… - кз
сш. зима
піэиткзшлвииы 60 то и
зёъьст зісоми ываізт умме … ымпвх
Пинкаю.“ 60 10 за
“№ . зимы
60 то 39
28 50И$ ' 50…27
ээропк-пк:
ігптоах - 11.504» 50 ш 12
1г|5им‹1›.ьЕ.5имз› 60 то 12
5111$ : эш…)
1.2 спмтшив
хпзиткпютдимы 60 то 13
60 то и.
РСПМ ЕХРАМБШН ОР НЕМ МШП‘ШМ !? КЕРЪЕСПОМ НАЗ РКОПЦСЕВ ОМЕ ИХ…ИЧН
и по :> 4 . :. мх
химии = 11 - БАМАЛ'ХНКЪЛ * бАМА'тНКЗЫ)
ль хм) : ХНК‘п-Л
… = кц
еды. зона
1г150м‹ки-\.т.5имы 60 то хь
со то и.
13 кпзпткзьст.эимн› 60 то и
во 19 „А . 1. их
18 хп…ввх-л = хпкзыг
ппопц-ьмх
хню…н : ввтмхнШоЕх'л + и. — еЕтм'хпкгнъ
19 ХШ) : КНК‘пЦ’
… = кв
‹.Аъь зима
пциинщтвимцкьп 60 то 16
кЕшсЕ минах ву им.? 15 КЕгьЕспоп нАРРем5 то РКОШСЕ А !.АКБЕК чм.
шЕ тндп те мдхпши
во гв .| = 1, их
00 20 1 - 1. кх
20 хип.” - о.…хшш + хпкоцптнп

00 29 ! : 1; К!
00 30 4 ' 1! "Х
30 ХК—П. ' хппл
… - :
сш. зима
29 СОМТПШЕ
60 То 26
1600214=1удХ
житии… - шт.…
21 х… - хижинах…
ям : хмовх
САН. $…“
60 10 26
и 90 гг 4 г ;. мд
 pagebreak 
Программм на языке ФОРТРАН 50|

 

х:‹1пввх.ця . х1ккз.4ъ
:: х‹4| . ххкімоех.4)
хм : хпвех
сАьь зима
26 00 23 .} = 1; “Х
23 х‹ля : х1‹к2.4п
хм : кг
сАьь зима
вхггк - о.
по ад 1 . :. къ
гц шгвк - шгев . ‹зимпх - зимккаииг
вхгЕк =1./хпх0$0нтг01гвк1
рккмт івх' зимь. ‹х1къоимт.цл. 4- 1.мх1‚ вігвн
101 Ропмдтк212Х.Еіь.ьіяЗ(7Х’Е16-6!.12х-Е16061
1г| ихгьн.ае.о.ооооооъ› во то га
:Аьь эесоппкткмвл
рпхмт 105.т1мв
ао то хоп
999 сомтлмив
емо
зивкоитімв зтдат
охмьмзяом А150›5оъ‚ ххсьо.воп. х‹50›. 5им‹50›
соммоп/х/ х‚хх.мх‚515г.К1.зим.хм
уп - мх
зтгрщ - зтЕР/‹умгзЁвЕк2.›!*‹$онткчм + 1.) + чм - 1.)
этап:: 51ЕР/(УП'89 т 2-1›*150ктсчм + 1.) . 1.1
00 1 4 - 1- их
: мил . Оь
во 2 1 - 2. 31
по г а . ;. мх
А‹1.ц1 . зтагг
ь - 1 — :
Акк.ь› - зтвг:
: сомтхмие
во 3 х в 1. к;
по з 4 = 1› их
› кхкхяцъ : хсця + Акхдці
ватник
смо
зивкоитхмв зима
Соммип/х/ х‚х1.пх.$твг.к ‚зом.!п
вхмаизхом х1гзо.50)с х‹5 ;. зим‹501
зиМкХМЗ-схк1!+хо.&хсгі:'іг+5-*‹х‹3›—х‹4)!‘*2+іх12)-2‹!х‹3)іідьф
110.плх‹1)-хяьуліпв

 

КЕПЖН
Ёко
4 0.5
3.0 -1-0 0.0 1.0
5.4. ПРОГРАММА ФЛЕКСИПЛЕКС (МЕТОД СКОЛЬЗЯЩЕГО

ДОПУСКА)
]. Назначение.
Программа Флексиплеко решает общую задачу нелинейного
программирования:
минимизировать у: [(х), хе Е",
при ограничениях
ні(х)=0‚і=1‚...,т‚ 541
Е;(Х)>0‚і=т+1‚…‚р‚ (”>
где і(х) является целевой функцией, подлежащей минимизации
(или максимизации); х = (х„ х„ ..., х,.)т—вектор-столбец,
элементы которого представляют собой п переменных рассмат—
 pagebreak 
502 Приложение 5

 

риваемой задачи в п›мерном пространстве; ‚!,-(Х) = 0, і= 1,
…, т, — ограничения в виде равенств; 31(х) > 0, і = т + 1,
…, р‚— ограничения в виде неравенств. Функции [(х), и (х),
@, (х) могут быть линейными и (или) нелинейными; ти (или) р—т
могут быть равны нулю. Таким образом, для т = 0 и р —— т = 0
оптимизация осуществляется при отсутствии ограничений“ .
2. Ввод задачи в программу Флексиплекс

Целевая функция и ограничения задачи (5.4.1) вводятся в
вычислительную машину посредством подпрограммы ЗШВКОППМЕ
РКОВЬЕМ (ЩО). Параметр ШС) идентифицирует целевую функ-
цию и служит характеристикой фигурирующей в задаче совокуп—
ности ограничений. НЧО = 1 соответствует ограничениям в виде
равенств; то = 2 соответствует ограничениям в виде неравенств.
На протяжении всей программы каждое из ограничений в виде
равенств и неравенств, а также целевая функция идентифицируются
присоединенной переменной

МЦ1=Ъ……т‚т+ъ…„мр+Ь

Подпрограмма ЗОВНОНПМЕ РКОВЬЕМ (НЧО) организуется
следующим образом:

1. После содержащей комментарий карты ‹Ечцаіііу Сопзігаіпіз»
(ограничения в виде равенств) и оператора 1 вводятся ограниче-
ния в виде равенств (если таковые имеются) в следующей форме:

К (1) = 1110$
К (”О = И… (Х)—
2. После содержащей комментарий карты ‹1печпа1ііу Оопзігаіптз»
(ограничения в виде неравенств) и оператора 2 необходимо пред—
ставить ограничения в виде неравенств как

К(т + 1) = Ет+1 (Х),
К№=ЬЩ
3. После содержащей комментарий карты «ОЫесііче Рцпсііоп»
(целевая функция) и оператора 3 необходимо представить целе-
вую функцию как К(р + 1) = {(х).
Если в формулировке задачи равенства отсутствуют (т = 0),

то не нужно вводить никаких данных после оператора 1 и !? (т + 1)
обратится в К (1). Аналогично если имеются только равенства и

нет неравенств, то следует опустить все данные после оператора 2
и 1? (р + 1) обратится в К (т + 1). В случае задачи без ограни-
чений И (р + 1) = И (1).

” Более подробно рассматриваемая здесь Методика решения задачи (5.4.1)
описана Павиани (Рачіапі в. А., А Меч! Метод іог Ыте Зоіцііоп оі [Ье Скепеха1 Моп—
ііпеаг Ргоегаттіпд РгоЫет, рп. В. Віззегіаііоп, ТЬе Цпіч. оі Техаз. Аизііп.

Тех., Мяу 1969).
 pagebreak 
Программы на языке ФОРТРАН 503

 

Например, задача
МИНИМ143ирова'гь ‚‘ (х) = 1000 — х? _ 2х; _ ХЗ _- 161163
при ограничениях
п1(х):х%+х3+хЁ—25 =0,

И2(х):8х1 + 14:2:2 + 7х8— 56 = 0,

8;(Х)іХ‚->0‚ і=1,...‚з,

должна быть представлена ‹: использованием подпрограммы
РЦОВЬЕМ (ЩО) следующим образом:

С ЕООАЫТУ СОЫЗТКАПП'З

1 СОЪГПЪЮЕ
30) = Х(1)и2 + Х(2)п2 + Х(3)и2 - 25.
К(2) = 8.жХ(|) + |4.я‹Х(2) + 7 ‚«Х(3) — 56.
Сю юз

С ХЫЕОПАЫТУ СОЫЗТКАШТЗ

2 СОЫ'ПЪШБ
К(З) = Х_(1)
К(4) : Х(2)
36) = Х(3)
60 10 5

С ОШЕС'ПУЕ РОЫСПОН

3 СОЫТШЦЕ
К(б) : 1000. -— Х(1)м2 - 2.8Х(2)и2 — Х(3)п2 — Х(1)вХ(2)

5 Книги

3. Представление данных
Первая карта с данными
Эга карта является ключевой и должна содержать данные,
идентифицирующие решаемую задачу. Любые алфавитно-цифро-
вые операторы могут располагаться в колонках 1—80.
Вторая карта с данными
Эта карта содержит параметры задачи, такие, как
МХ — общее число переменных (зависимые + независимые)
в формате 15 слева направо;
МС — общее число ограничений в виде равенств (т) в формате
15 слева направо;
МС — общее число ограничений в виде неравенств (р = т) в
формате 15 слева направо. Следует заметить, что Верхний и ниж
 pagebreak 
504 Приложение Б

 

ний пределы для вектора х представляют также ограничения в
виде неравенств;

$12Е = :, величина, определяющая размер деформируемого мно-
гогранника в исходной фазе поиска (используется формат Р10.5).
Объяснение того, как следует выбирать значения $12Е, приводит-
ся ниже.

(ЮМУЕК = &, произвольно выбранное положительное малое
число, используемое для окончания поиска; число & рассматри-
вается в качестве индикатора сходимости и обычно выбирается
равным 10“5 или 10—е.

Рекомендуемыми значениями $1215 являются следующие. Ког-
да верхний и нижний пределы вектора х известны, то выбирается:

]. $12Е @ 20% разности между верхним и нижним пределами
х, если ожидаемые интервалы изменения х; вдоль каждой оси коор-
динат приблизительно равны.

2. Если ожидаемые интервалы измененияхвдоль каждой оси ко-
ординат различны, то $12Е присваивают значение, равное наи-
меньшей разности между соответствующими верхним и нижним
пределами любого т.

Примеры
(1) ‹2)
—11 <х1<98,7 0<х1<400
—10 <хя<100‚1 0<хд<1000
—9,5 <хз<101 340<х8<420
-— 10,2 < х, < 99,5 340 < х4 < 420
—9‚8 <х5<100 —1000<х„<1000
0 < хо < 0,5236

$12Ег0,2* 110 = 22 $12Еш1

РНОбКАИ РЪЕХК ! ХМРиТу ОПТРЩ'я ТАРЕ10 ' ШР!" '

‘. 60
С 70
: .***'*РВОБКА.ИРЬЕХХРЪЕХ******

С 80
С 90
С 100
С "Х ТОТИ. МЦМБЕЁ ОР ХМВЕРЕМОЕМ'Г УАЕ1АВЪЕ$ 0110
С "С "“М. МЧНБЕК ОР ЕОЧАЪП'У СО'БТЁАПП'Б 0120
С "ХС ТОТМ. МЦМВЕК ОР "‹ЕЦЦАЪПУ СОМ$ТКА1МТ5 0130
С 512$ ЕВБЕ \.ЕМБНТ ОР ТНЕ ПЦ'ПМ. РОЬУНЕОКОМ 0100
С СОМ/ЕК СОНУЕКБЕКСЕ СПП’Е‘ЧОЦ БОЯ ТЕКМХМАПОМ ОР '!НЕ ЗЕАКСН 0150
С АЪРА ТНВ КЕРЪЕС'ПО" С°ЕЁР|С|ЕМТ 0150
С ВЕТА ТНЕ (ОМ'КАСТПЭМ соьгпсхемт 0170
С 6”… тт: ЕХРАМ5Х0М СОЬРЁПСЕЕМТ 0180
‘ ХП! ТНЕ А550НЕВ \!ЕСТОК ТО ПН'ПдТЕ ТНЕ $ЕАКСН 0190
С ГВП'ЬЕ ТНЕ ТОЪЕКАНСЕ СК-іТЕВХОМ ГОК С0М$ТКАПП уюьпюп 0200
С кот Д СОЦМТЕК 10 ЁЕСОПВ ЭТАБЕ СОМЁЧТАТ10М$ 0210
С "(ОМТ А СОЦМТЕВ 10 РКП“ ХМЁЦКМАТХОИ ЕУЕКУ ("ХОМ 5ТА6Е 0220
: БОИ Ап ХМПЕХ ТО [ВЕП'ПГУ '"?!)КМАПОМ НЕЦПЕВ ТО ТНЕ \.ОНЕЗТ 0230
С ЧМ-ПЕ ОР ОБЩ- РШК'ПО“ 1" МОЗТ КЕСЕМТ РОЦ‘НЕОКОМ 0250
С ЦПО“ АМ ШОЕХ '… ХПЕП'ПРУ ШГОКМА‘ПОМ ЁЕЦТЕО ТО ЬЖБЕЭТ \!АЦУЕ 0290
С 0? ОБ). БПМ‘ПОМ … 04051 КЕСЕМТ РОЦ'НЕВКБМ " 0260
С і-ЗЕС АМ ПЮЕХ '1'0 ХВЕМТЛГУ ХМРОВМАТЛОМ КЕЬАТЕ!) 10 ТНЕ $Ес°№ 0270
С КАЙФЕЗ‘ УАЪЧЕ ОР ово. гимном … №51 дЕСЕМ‘ РОЦ’НЕОКОМ 0288
С 9
 pagebreak 
ХО

&пммипнпцц

0ХМЕК$10М К(БО!:х1450о50!'Х2(50я$01‚Е(1007'50Н‘50)0Р(501‚$К(50›о
! К°ЦЖ1°0Н "(50|

СОМ…“1/МХ-НС0П1С-5ТЕР:АЦ’А-БЕтдрбАНАЦМв ХМЁ-РЫРЕКпЭЕОдгкі'Кг ,
\КЗ-Кдуйі.КбуКТ:КВ|К9.ХпхігхгрдіЗЧИвгвЕНЪКОЪРуЗСМ-ЕвЁОі-В

С№°н121ЪЁЕА$вЬ5д-Ьо\7п|.8‚ЪЁчРПАоПгАпЁЗА

ЁЁОВЪЕИ 10ЕМТХГКСАПОМ НЕАВЕП !$ КЕАВ !" АРТЕК ТНХЗ САК!)

А0 59

РАЁАИЕтЕКЭ ТОЦ 'КНЕ РЙОВЪЕИ АКЕ КЕАО [" АРТЕЁ ТНПЗ САКВ

КЕАВ !. НХ."С›МХС.$12!.СОМУЕК

АЪГА ' ]-

ВЕТА ' 0.5

БАМА ' 2-

РЕЙНАМЕМТ ВАТА РОК 7НЕ РКОЕЬЕМ 5Н00ЪВ ВЕ КЕАЬ ЕМ АРТЕК ТНПЭ САКП
САЪЬ ЗЕС0М0(Т!НЕ)

ТЕИРОВАК? ВАТА РОК ТН! РйОвЪЕн; $001 А5 \!АЁЧАВЪЕ СОЕРЁЦСКЕ'ПЗ ОЕ
ЛЕН РАЁАМЕТЕКЗ БМОЦЬО БЕ ВЕАП ХМ АРГЕК 7Н|5 САПР

ЪТЕР . 5122

ТН! А$$иНЕВ |МКТХАЪ УЕС70П 1$ КЕАВ ХМ АРТЕК ТНХЗ САКВ

КЕАП 2 ' (Хіііп ! ' Хи МХ!
!РКЕОРі1019999'11

]! РВХМ7 106

50 на

РЕН“ 759
рк1пт 1569 МхоМС'ПХСрзідбпСЧМЧЕКяТХИЕ
К) ‘ НХ *

К2 ' МС
КЗ = МХ
&& - МХ
КЭ ' ”Х
Кб ‘ МС

«

”5"=°’шм”
&

++оо+0о0

:
|
2
х
\
2
п

м-п+1
1гкп1.ьь'вл 60 то 50
м—э

мн:

МЭ
ме
МЭ
нь
“7
кв
ХМ
хмх - их

хпі = и!

въд = 0.5“!50я1к5.’ !.
над . Н1А*К1А

:эА . ягдіяъх

ЬЬ ' "Х
16 - мх
\? = мх
ьв - их
19 - их
|<опт :
псом -
гкънт 115

Радик 116. [хдд]. 4 . \. мх)
501РЕК : 2..1МС + Жі'БТЕР
гоьп : годгЕп

ім = м1

слъь эпик

$ккнхъ = Бокткзгоьэ

РКНП 763: ЁИРЕК! $8…“

гггггггг
000++++
очошеып

РЬ‘Ф + + 4 +
отче…

505

0300

310
0320
0530
0350
0350
0360

0310

ВОО
0010
01020
0530

ЬАО
0‘ч50
0,060
0510

0520
0530

540
0550
0960
0570
0 500
0590
0600
0610
0620
0630
0650
0650
0660
0570
0680
0690
0700
0710
0720
07 30
0700
0760
0760
0770
0780
0800
0610
0520
0830
0000
0950
0860
0970
0080
0690
0900
0910
0920
“950
091.0
0950
0960
0970
0980
0990
1000
1010
1030
1030
 pagebreak 
506

3101

237

5
1000

(. ЗЕЪЕСТ ЪАЁЁЁЗУ \!АЦЛЕ ОР 05.'ЕСТП/Е ГЦМС'ПОМ РВОМ РОЪУНЁВКОМ УЕК'ПСЁЗ

16

: ЗЕьЕст мхнлмим УАЬЧЕ ОР 054ЕСТХУЕ гиМсТХОМ ЕКОМ РОЬУНЕОВОМ УЕКТХСЕЗ

А1

17
86

!гкзпкмх›.ьт.гсігея) 00 То зд!
(АЪЬ икхтех

РК1М1 757

хп? : №1

зтьв : и.озіг01гея

САьь РЕАЭВЪ

рахит 7ьь

РКХАТ 116. (ХЗСЪМЁ14)|4 ; 1. их]
ввшт 765» зпктгл
!РкРоьВ-ьТ-Ъ-ОЕ—ОЧЖ во то 80
рахит 35

РКШТ 758. КОМП ГИРЕК

сдьь нпітіх

гтЕп : К(к9э

СОМРЦТЕ СЕНТК010 ОР АЪЬ УЕК11СЕ5 ОР 1М111АЬ РОЪУНЕОКОМ
$1ЕР1 = 57ЕР*[50КПХМХ * 1.) # ХМХ " 1-і/КХМХ'50ЙТ12ЬП
БТЕРг ‘ $ТЕР‘130КТКХИХ ‹ 1-1 ' 1:1!(ХНХ‘БОКПЗП)

ЕТА : ($ТЕР1 * іхдх ' 1.1“51ЕР211(ХМх + 1-1

00 0 .| = 10 "Х
ХК.“ ' Х(.Л ' Етд
СОМТКМНЕ

(АЦ. ЗТАКТ-

00 9 Х ' 1. "1

00 9 ., ' 10 НК
ХПИ.” ' Х1ПЬ”
СОМТПШЕ

00 5 1 ‘ 10 "1

1” ' 1

00 6 .] ' 101!

%(4) ° хгк1.а›
САЦ. ЗЦНЕ

ЗКП’ ' ЗОЁ'ПЗЕОД!
1?!$К|Х!.ЬТ.РОХРЕК1 60 ТО в
(АЦ. ЁЕАЗВЬ
1Р(50Ь0-\.Т‹1п0Е-091 60 ТК) 80
САН. РЙОБЬЕМКЗ]
РЦ!) = КіКЭ]
СОМПГ‘ШЕ

ЗУБР : 0.05іЕОХЁЕК
100?" * 160!" # 1

РН = РКП

|.Н16Н = 1

00 16 1 ' 29 М!
[РКРКП-ЪУ-ЕИ] БО ТО 16
РН ‘ ГКП

ЪНХБН = 1

СОППМЦЕ

Рь = г!!)

ьои = 1

00 17 1 = 2. №1
[?(гь.ьт.гіі)) 60 то 17

П. = ПН

ьои : 1

сопт1пцЕ

00 66 а = Хи МХ

хкц) = хгкьпира)

1н ‘ мои

сдьь зима

зкъьоиъ : зоптвзіоъі
ігізккьии›.ьт.гвкгвп› 00 то 81
хпг ‘ мии

сАьь гЕАьвъ
ігігоъо.ьт-1.оЕ-09› 60 то во
сдьь ркивькм131

ікьии| = акк?)

901041

1040
1041
1050
1060
1061
1070
1090
1090
1100
1110
1120
1130
111.0
1150
1160
1170

1150
1190
1200
1210
1220
1230
1240
125.0
1260
1270
1200
1290
1300
1310
1320
1330
1350
1350
1360
1370
1580
1590
11.00
1А10
1620
1430
1540
1Ь50
1060
1470
11.50
1490
1500
1510
1520
1530
1550
1550
1560
1510
1590
1590
1600
1610
1620
1630
16160
1650
1660“
1610
1680
1590
 pagebreak 
С

07 С0М11ниЕ

гхмв свмтпохо ог Рахит: ихтн : ЬХРРЕ&Емт тнАМ ънхвн
во 19 а - 1. их

зииг . в.

во 20 х - 1. №1

10 зима = вине. # Хдіяд)
19 хг…гщш = !../ХЙ‘ЧБЮМЗ’ХЗЦНШНЫН

зинг : 0.

00361511"!

00 36 4 - 1. их

зима = зимгк+ |х2‹1.4) - х21м2.435*'2

36 СОНПГ‘ШЕ

ГОХРЕК = [МС + Н/ХМ1050дТ150М2
!РН’ОХРЕК-ЬіЧРОЦЛ 50 То 98
ГОХГЕК ' ГОЬП

60 Т“ 198

98 РОЪО = РЩГЕК
19$ с0№1180Е

РТЦ? = 5 (\.ОЬП

137 ЪСОЫТ = исопі + 1

ХГШСОНТлЛйаіпп 60 ТО 31
!ГПСОН .1500! 60 Т“ 331
РОМ) ' . ‘РОЪП

 

 

3.37 "(ОМТ =_ О

РККНТ 35
РКШТ 758. !С0М'. Р01ЁЕК
(АЦ. НКПЕХ

37 ”(РПХРЕВодТ-СОНУЕЯ’ 60 ТО 51

( згьест весомо ьцквезт УАЪЦЕ ОР семестхче гимстхоп

пп

”'[ЬЩЫ'ЬЕЧ‘Н 60 10 ‘03
ГЗ = РКЦ
ЪЗЕС = 1
5:0 ТО то

да гз = г‹2›

ЪБЕС : 2

## 00 1& 1 = 1. Н!

1Ё(\.Н16Н.ЕОоН 60 10 18
1РКПКЬЬТ0Г5)60 ТО 18
РЗ = "'!“
ЬБЕС ' 1

18 сотпшь

КЕЁЬЕСУ ГЦБИ РОН" ТНЕОЦБМ СЕНТЁО‘Р
\… 61 ‘) 6 19 "Х

хгамэ.ц› = хг:мг‚4› + Аъгд*дхгімгр4) « хг‹ьнхсн.4дв

ьх х14о : хгкпз.ц›

ім ' МЗ
САЦ. ЗШ‘К
503…“ = ЗНКТКЗЕОЫ

ВЭ [Ріьвіп3)-ЬТ.РП|РЕКЭ 60 ТО 82

”№ : "3
(АЦ. ГЕАЗВЬ
|Р(Р0Ц›.|_Т-1-ОЕ-09’ 60 "О 80

82 САЦ- РПОВЪЕМКЗ)

г‹ьзі : в‹кт
1г1г|н31.ът.гідои›) 50 то 64
|г|Р|п3!.ът.Г1ь5Е(10 Бо ТО 92
60 то ьи

92 00 93 ‘) ' 1,11)‘
93 Х2ЦН16Ну—Н .' ХЗКМЪЛ

ЗККЦ'ПСМ) =_5ЙШ3!
ГН-Н16Н) ' НМЗ)
60 10 1ч00 '

ЕХРАЬО УЕСТОК ЧР ЗЕАКСН АЪОМБ ОККЕСТХОМ ТНКОЦБИ СЕМТКОХО АМО

‚КЕЕЪЕСТЕО УЕС'ЮК

вц ио4гэ ; . х. мх

хмм… : шыш] + ФАМАЦХН №№ - хана,…

33 Х(4) ' хгсмввдъ

1” ' Мб

507

1700
1710
1720
3130
Атцо
1750
1760
1170
1180
1790
’]800
1.310
1520
1830
Хвьо
1350
1660
1870
1880
1890
1900
1901
1902
1910
1920
1930
19ь0
1=950
1960
1970
1980
1990
2000
2010
2020
2030
20ц0
2050
2060
2076
2080
2090
2100
2110
2120
2130
21А0
2150
2160
2170
21яо
2190
2200
2210
2220
2230
221.0
2250
2260
2270
2200
2290
2300
2310
2320
2330
гзьо
2350
 pagebreak 
25

26

60

65
610

66

61

69

71

72
70

68
73

81

во

35
106
115
115
72$

 

 

САЦ 50ия . 2260
зим: - зовпзеоы 2370
хпзщмььнжшгею 60 то 25 2300
мг - № 2390
сш. гызы. 21.00
\г‹гош.\.т.1.ое-09› 00 то 00 2010
см!. вкивьвтз) 24.20
гп… - мкэі изо
хнншшцъгшьп 00 то 92 2ьц0
00 26 о : 1. их 2450
хг‹\.н16н.4г ‹ хитам) 21.60
пшик) : ПМ) 2570
зщшшнл = зять! 21.00
00 то 1000 2490
хпгшзі. т ньншнп 60 то $:. 2500
00 ьв .: - 1. их 2510
химии..» : хгкмзьл 2520
00 ьь .: - 1. их 2530
хгтюл = ветнхмьнхенщ) + (1. — ввтмихгтгш 251.0
хк.» : хгтмл 2550
… = № 2500
см!. зимп 2570
зап… - зокпзіоы 2500
1гкзк‹мь›.ьт.г01гня› 00 то ь7 2590
шг = № 2ь00
сш. гызы. 2610
ігкгоььцт-ъоЕ-оэъ 00 то 00 2020
‹Аы. гковьімсзр 2030
пм“ = кика» 2650
1нгцн1аю.0т.пм» 00 то 60 2650
00 09 .) = 1. № 2660
00 69 1 = 01 2070
11211141 . . чкхгіьл + хгкьошцп 2000
00 70 1 - Ь м1 2590
00 71 .1 . ь мх 2700
т.п : хан..» 2710
хм : 1 2720
САН. эпик 2730
за… = зоппэіоы 271.0
хпэпкпдяашгвк) 60 то 72 2750
мг › 1 2700
САЦ. гены. 2170
хпгошцъьоі—ои 00 70 00 2700
см.:. рковььты 2790
гп) : Кккз) 2000
60 то 1000 2020
00 13 .1 = 1. их газо
хацншнм» . каши.») 2000
звцмктъ- экшн 2050
пинаю : гп… 2860
00 70 1000 2070
эмм 700.1сомъ РЩРЕК геяо
сдц имтЕх 2890
мы. экопыпмы 2900
тнт 755. пмв 2010
Рим 701 2910
00 то 10 2920
Ркмт 700. кот. гыгы 2930
мы. икпех 2931
ватт 762 291.0
во то 10 291.1
гокмдпэшахоааша! 2950
гокмдт‹вг10.51 2950
гон…пдцщдвдчьіцісъпіііъяіда-іфичьівцеіии) 2970
гокмАтпнЬ/п 2900
гоямдпп. ин тн: зтжпмв частой звьястів ву 052?! 15 1 2990
гокмдтквыыы 3000
гипатит эьн тив симвитшом име … эесомвз - 512.51 ‚3010
 pagebreak 
156 ЕОВМАТ(//|ХОХ›$0Н МЦМВЕЯ ОР ХМВЕРЕМОЕМТ УАКХАВЪЕЗ 15\/010Х
1‚ььн "ЦНБЕЙ ОГ ЕООАЪ17У СОПБУКАХНТЗ ХЕу/сЁОХодОН ПЦМВЕЙ 0
25 !МЕЧЦАЬЛТУ СОМЗТКА|МТ$ ХЭг/рЪОХ-ЬОН 511Е ОР 1н1т11ъ РОД!
ЗНЕОЙОЬ Е12-5'1'101›ВОН ТНЕ 05$|КЕВ СОМУЕКОЕМСЕ 15
;& 2 5, ЕЪЗ-Бу/ПЮХоММ ТНЕ СОМРЦТА'ПОН ііМЕ ХЛ 5ЕС0МВ$

1 .

757 РОКМАТК/7о7ін ЖНЕ 1М111АЪ Х УЕСТОН 005$ МОТ БАТХЗР! ТНЕ |Н|Т|АЬ ТО
ЪЪЕПАНСЕ свічвкіом |

756 РОКИАТ‹ /!10Х›27Н ЗТАБЕ САЬСОЪАТЦОМ МЦНБЕЯ ' 15| 20Хс 27Н ТНЕ ТОЬЕ
ЗВАМСЕ {ККТЕКХОМ : 514-61

759 РОКМА1130НЙ

1 !

760 ЕОКМАТ‘//с З9Н ТОТАЪ МНМВЕК ОР $ТА6Е5 САЬСОЪАТ10Н$ = 15, 10Х0 25"
\тНЕ ССНУЕКБЕНСЕ ЬХМХТ ' ЕХБ-Б‘ .

761 ЁОПНАті/і'ЗОХпЗБИ ТНЕЗЕ АКБ РПМАЬ АНЗПЕКЗ !

732 ЕОВМАТ‘і/гбйхр29н ХНЕБЕ АКБ №01 РХМАЬ АМ$НЕК$ )

763 РОЕИАТ(//о10Х'ВОН ТНЕ [МітХАЪ ТОЪЕКАМСЕ склтгп|ом !$ 512.50/1
110Хэд0Н тнг›$им 9? УХОЪАТіо СОМЗТЙАХМТЭ 15 Е12-5)

766 РОПМА111/170Н ТНЕ ЧЕСТОК ГОНМП ВУ РРОСКАМ ИНЦСН $АТ1$Г1Е5 ТНЕ 1п1т
!ЖАЬ ТОЬЕКАМСЕ 1$ )

765 РОВИ^Т(/п ЭЪН ЗиМ ОР УХОЪАТЕВ СОМЭТКАЕМТЭ = Еі797)

Л999 БТОР

емо
зиьксит1пв гЕАзвъ

"‘“‘5ивКООТХНЕ РЕАЗВЪ ИХП1М11Е$ ТНЕ ЗиМ ОР ТНЕ $ОЦАКЕ ЧАЬЦЕЗ ОР ТНЕ
”!ОЪАТЕд СОПЗТЙАЪМТЗо [Т 15 САЪЪЕО ЕУЕЁУ ТіМЕ ТНЕ соивтмев УАЬОЕ
ОР ТНЕ ЧХОЬАТЕВ СОПЗТКАХМ'Ь ЕХСЕЕО$ ТНЕ тМЕ ЧАЬЦЕ ОР 1НЕ 10ЬЕКАНСЕ
спітькіим РОК ТНЕ СЧПКЕЙТ $ТАБЕ

01м5н51им х‹50›.х1‹ьо.50)ях2‹ьо.эол.011001.50М1501‚71501‚:К1501я
1воьо‹1оо›я я1|10°1; в211001‚в311001о гъъкъоі. "150!
100 гокмдткавъь.ь›
соммоп/Х/пх.пс‚мкс.5тЕ?.виМ1›00м2‚вимз.1п.кмг.гохгея.550Ь.К1‚кгг
1к3.кь.к5.кь.ктъквък9›х-х1.х2.К.$0н.Р.5к.воь015САЪЕоР0ъ0
(отмоп/гіьгьдз.ъ5‚ъ5›ь1‚ъВ:Ь9.ВЪА›82АпВ3А
Аьгл : 1.
БЕТА : ч.5
БАМА - :.
хмх : мх
хсимт : о
ьснак : о
:сивк « о
{5 :Аьь зтдпт
00 3 1 = \. К1
во ц 4 г 1. их
А х‹4› : Х111 ‚41
1м = 1
:Аьь зима
; сомт1пие
‹ веьвст ьмкььзт УАЪЦЕ ог зим‹1› хп згмрьгх
ав зимы = зим…
японх = 1
00 7 1 я 29 к1
1г150м11|.ь5.зимн) 00 то 7
зимы : зиккхл
хмогх = 1 .
т сомтхми:
‹ ііььст М1м1мим УАЬЧЕ ог эпикхл 1м зтмвьвх
вину. : зим…
коимт = 1
00 б 1 ' 21 К!
1гцзиыь.ЬЕ.5ин1311 ни то в
Бима - $0м(11
копит - 1
В СОНП‘ШЁ
! г1ми свдткияо ог Роимтз нхтн 1 охггепспт тнАм :пиех
по 9 4 - 1. их

000000

509

3030
3030
3050
3050
3060
3070
3080
3090
3100
3110
3120
3130
3100
3150
3150
3110
3150
3190
3200
3110
3220
3230
3260
3250
3250
3270
3280
5290
3300
3310
3320
3330
ззьо
3350
3360
3370
3300
3390
3500
ваха
зцго
3430
303!
зььо
3550
Зььо
3070
Звво
3590
3500
3510
3520
3550
ЗБАО
$550
3560
3570
3586
3590
3600
3610
3ь20
1630
звцо

650

вес
3670
5680
 pagebreak 
510

С

50"? = &.
00 10 | = 19 К!
10 зимг = 5ин2 + Х||104›
к1!К2-4› =1ц/хмхчіьимг “ ХХ(ХМЬЕХ41$!
Гіии КЕР;ЕСТ10М ОР Н16" РОЛНТ ТНКОЦБН СЕМТЁ010
ХііКЗ-ц) = 2.“Х1|К2рді ' Х1Е1Н0ЕХ›Ц)
9 Хіі) = Х1|К3›4)
ім = кз
САЬЬ ЗЦИП
1?(ЗЦМ(К3)-ЬТ-5ЦМЪ’ 00 ТО 11
ЗЕЬЕСУ ЬЕСОМО ЪАКОЕБТ ЧАЬЦЕ КМ 51МРЬЕХ
!РК100ЕХ-Ецп11 00 ТО 35
$0М$ = $0м11л
60 то 39
38 Бить = зимкгэ
39 00 12 ! = 1, К]
[Е((ХЬОЕХ _ ХізЕО-Сі 60 ТО 12
|Р($ШМ|1)-ЪЕ‹$ПМ$1 00 ТО 12
зимь = ьимкхв
12 сонтімие
1Р($0Н|К3)-6Т.$ЦМ$) 60 ТО 13
60 то 15

пики ЕХРАМБЕОП ОР “ЕН Мімімин ХР КЕРЪЕСТіОМ НАЗ РЕООНСЕО ОМЕ‘МХМХНПН

11 00 15 4 = 1. МХ

ХЪККЬ‚Ц) = Х11К2с3) # 2-*|Х1!К3'4! ' Х1(К294))

15 К‘!) = ххккь‚ц›
ім = кв
САЬЬ зимк
1Р(5ЮМ(Кч)пЬТ.5НМЬЪ 60 ТО 16
60 то 14
13 ігсьимккзл.от.5имн› ьо ти 17
ни 13 4 = \. их
18 х1‹1нвЕх.ц› = х1кк3‚цл
17 во 19 а : 1. их
Хіікдуді = 0-5*Х111М0ЕХ04! + 0.5“Х1(К2и4’
19 ХКЦ) = Х1(КЬ|41
хм - кц
САЬЬ зимп
[РКЗЦМН-бісЭЧМККді) 60 ТВ 6

КЕОЦСЬ >|МР№ЕХ БУ НАЪР ХР ВЬЁЬЕСТХОМ НАРРЕНЗ ТО РКФРЦСЕ А ЬАКБЕЙ УАЪ

ьиЕ УцАМ ТНЬ МАХЦНЦН
00 20 1 = 11 "Х
00 29 | 1. к1

20 Х1|1.4) ч.5*(х1(114> + Х1!К00Мт‚4’1
00 29 ! & 1; Кі
во 30 а = ;. мх

30 х‹ц| = хъцх-цл
ЛН = ]
САЬЬ БЦМК

29 сопт1цив

5 вить : 50м‹1|
КОЦНТ = 1
во 23 | = 2. к1
!гкьимь.ът-5иМ11›) 60 10 23
зимь = $им(х|
коим! : 1

23 сомгімие
5К(|МР’ = $0КТ(50М(КОЫНТ)1
00 27 4 = 1\ ”Х

27 х‹а› = хъккпипт.ц)
60 То 26

6 00 31 4 в 1, их

31 ххіхпвЕх.а› ‘ ххіКьоф)
випііпиЕХ) = $иМ1кц)
60 то >

16 во аж 4 = 1. их
х1|1нвЕХ.аи - ххккц.4)

31 ХЦ!) = ХХК1ЫРЕХ04!

3590
3100
’3110
$720
3730
з7ьо
3750
3760
3170
3750
3790
3800
3810
3520
3930
3850
3850
3360
3870
3880
3690
3900
ЗЭХО
3920
3930
З9ьо
3950
3950
3970
3980
эээп
#000
ьо1о
ного
возд
дово
цово
ц0ьо
«070
6080
6090
вжоо
въхп
ьіго
ьъзо
діьп
«150
5160
6170
5150
5190
Агоо
40210
#220
5230
#200
Агап
Агьо
ь27о
#280
#290
ьзоо
#310
0320
вазе
АЗФО
#350
АЗЬО
 pagebreak 
п п п а

16
22

26
36

219

57

5\

52

56

54

55

97

5иИ|1П0ЕХ1 = $0М1Кд1
$п‹1пгъ - зов1|$иМ‹Кдіі
60 то га

00 22 4 = 1' "Х
ХАНПОЕХр-Л : ХНКЗЬ”
хкцл . ХііАМОЕХ.41
ЗиМПпОЬхі ' $Ш1К3!
5К‹1мг) : 50п1|$ии(к3)1
[СИП = конт * 1

00 36 4 : А.МХ
х211м5.41 = х(4
ХРНСОМТ-ЬТ.2!КН 50 то 50
ХСОНТ ! О

00 2’0 _! * 1; МХ

х!ц› : х\[к2.4)

ХМ ' КЕ

САЪЬ ЭЦИЕ

“"СК ' О-

00 57 1 = [: К1

ОігЕК = ВХРЕК # |$ЦМН| ' $ЦМ(К2Н*'2

01658 : 1-11‘1'хМхР59КТКИРЕК)
1Р|°|РЕП.6Т.1сОЕ-іді 60 ТО 51!

|Р РЬЕХХБЬЕ $|ИРКЕХ МЕ'НОВ РАНьЕО Т0 $АП$РУ ТНЕ (ОМЗТЙАППЗ ИКТНХМ
ТнЕ ТОЬЕКАПСЕ СКЦЖЕКЮМ РОК ТИЕ СЦПКЕПТ ЗіАбЕр
РЕКТОЙВЕВ РЯОМ ТНЕ РОБП'КЛ‘ ННЕКЕ ТНЕ ›‹ УЕСТОЁ 15 5ТЦСК АМВ ТНЕМ
РЕА$ВЬ 15 КЕРЕМ'ЕВ ОМСЕ МОКЕ РКОН ТНЕ ВЕБ…МЖЪ

хп : к1

зтьр : ао.›гв1гея

сдьь зима

эккімг› - ьокт($воь›

во 52 4 - ). мх

х11к1.л› : хп41

по 53 4 : 1. их

гдсток : 1.

х(4і : х1|К1›4› + гд;топй$тер
х1|ь9.ці : х‹4›

хм - ь9

сдьь зимв

хци» = х1‹кх‚д) - РАСТОП'5ТЕР
хдкь5‚ц› : хццв

1м : ь5

сдьь зима
лгізимкьеэ-ьт.5им‹к1ъ) 60 то БА
ъгжзомкь5›.ьт.5иМ|к1|› 50 то 55
60 то 97

х1‹ь5.41 : х1кк1‚4!

5им‹ь5› - $иМ|К1Ъ

хх‹кх.ц› : хъкь9.41

5имкк1! - ьимкьзт

гдстоп : гдсток ' 1.

хпал = х1‹К1‚ц› + РАСТОП'5ТЕР
хп : ьэ

:Аьь зимд

ьо ти :ь

хіцьэ-а» - х1‹к1.4›

5им‹ь91 : $0М‘к1)

х1|к1.4› - х1къ5.ці

$ЦН|К1) : $ом‹ъ5|

РАстоп : гдстоп . 1.

хцц) = х1‹к1.ц› - ?Астокчэтвр
:» : ьь

Сдьь зима

60 то ьь

ИШ шмызюмм. ЗЕАКСН &' 601—0511 ЭЕСПСМ М.ОМО ЕАСН СООКОХКАТЕ

ниц) = х]‹ъ9.д› - х1‹ь5‚4ъ
х1‹ьь.ц› . х11ь5‚4л + и(илдддд
х‹4) = х1‹ъ6.4)

“\'ЬЕ

\’НЕ ЗЕАЙСН 15

511

#310
4380
6390
5000
цвхо
цьго
ььзо
5,050
6650
ццьо
4.670
0550
ьв9о
«500
10510
А520
“530
«вьо
“$50
10560
авто
1.580
19590
5500
ць1о
5620
ььзо
4600
#650
10650
40670
10680
5690
6700
4710
6720
ьтэо
ь1ьо
#750
10760
0770
«тво
“790
10800
#810
#820
4330
#850
“850
5560
‘оЕ70
#880
40590
#900
6910
ьчго
“930
1.950
“950
19960
4970
49ЕП
«990
5000
5010
5020
5030
5000
 pagebreak 
512

(АБК ЗЦМЙ 5050
хпЦ-л : хины! + НЦНМА Ьоьо
хп) : хип.“ 5010
ХМ = #7 501.0
см.:. зима 5090
хг‹$ют\.ы.‹зт.5имц7п 60 то 65 5100
хпьвнэ - хпььрп ‹ п- - ЮАР….” 5110
хины! - хины! пго
хыу = х….вмл $130
… = ьн 511.0
нц зимк 5150
|г|5им‹ъау.с‚т.5имцьп во 10 76 51ьо
хина.“ = хпьеы! 5170
зимин) : зимы) 5180
60 ТО 75 5190
7ь хины) = хпьам) 5200
5имц9) з вымыв) 5210
(Ю ТЧ 75 5220
ед ›…ъэщл : хньыл 5230
хпьв'л : х1‹ь5.л+ КВМ…” 524.0
пл : химии: 5250
… : ь.» 5260
(М.и ЗЧИК 5270
ЗТЕР ' 512Е 550
$иМН-‘Н ! ЬЧНЦЬ) 5280
[ПЗЧМ(Ъ7Ь61›$ЦН(Ц’Н БО 10 71 5290
ХНЬЭЫЭ ' ХНЬВН) 5300
$ЦИ(|.5! ‘ ЗОНЦВ] 5310
(50 10 '!5 БДО
П. ХЦЩЫ) ' ПНЛ'Л 5330!
ЗШКШ! : ьитьп 531.0
75 АПАБЫХНЪЮЛ - ХПН..”!обНКмОі'РЩРЕК) 60 10 91 5350
хим.“ - хип… 5360
ХП) ' Х1Ц7М) 9310
зимин . ними.… 5350
$ЁП^Г) ' $°ЁУ|$0МСКП| _ 5390
ХПЬННЬТНЪТчРРХГЕК) 69 ТО 760 5’000
» помыть 5А1о
КНЦ - [сны + ; Бдго
510 - гыгы: 5ьзо
АРПСНЕК-ЪЬ-г) 60 10 25 Бььо
РОЪФ * ЬОЕ'ХЗ 51450
РПМ 853 5Аьо
УКП“ 850 5570
РКМН ВНО [›‹(лнчтх) 55.60
РММ 6552. РИГЕК: ЗКП“?! 5Ь90
ьч 10 «. 5500
760 Ш) 761 Н ' 1. "Х 5510
ханты: = хиты» 5520
751 хин : хиппи 5530
50 Агцзмшн-ы.гшпк1 60 10 28 5550
: МОшпьи ьдсяднсі …твкроытшп Рок тхбнт ШЕОЦАЦПН: 555о
1г|$кппгьъъод (‚0 то 35 5560
сын ркиьььмкэл 5570
нм › Юки 5550
09 »У и - :. № 5590
на хим: хгпигы) 560
(дц. »кошстг» 561
ии до .: : кика 5620
:…- ппл : нкл' 5630
во и .) = :. мх Ььис
51 ›‹(Л ' ХНКОШПЪП 5659
(мы РВшвььтгп Бььа
{›0 м2 4 = м.кв 561а
Аг пыл = кн) 5580
во #3 .: = 1. № 559Ц
ны: : Апатиты) - хиты:: 5700

103 )Ч—П ‘ хіННРп-П + Одёініді 5710
 pagebreak 
(АЦ, РКЮБКЪМЦЗ!
гьок1) * @.
гьа‹4› . и.
51.6(3) = 0.
00 45 4 : к7‚кв
ХР…З!.П.6!.ОЦ 60 10 Ш.
гье‹1› : Рьв‹1› + к1‹41*к1141
РЪСЦ] ' РЬБі2) + КПИ….”
Рьб‘з! = ГЬБЦЗ) + КЭ!Ц\'К3|4)
105 СЧЙТП‘АЧЕ
ЗКНИЕ) : ЗОКТН’ЬЁПН
ХП5ППЙРЬЪТ-РВПЕН] 60 ТО 35
АЬРА1 ' РМ:”) — г.“РЦБП! + РЦНЗ)
віТдд - 3.'гь611› _ в-*РЬ6‹2) + гьбізі
пАТхи = вЕтд1/‹Ь.*АЬРА1›
во да а - 1, их
45 ХЦ) ! Хгііміуі) + "(.Лд'ЕАПО
[ш : [МР
САН. ЗЧИВ
$П|1М51 ' ЗОЁПБЕОЬі
К(ЗЙННП-КТйВПЕП! 50 ТО 465
00 М! | = 1. 20
00 да а : \. их
«& х‹ц› - хкцл — 0.05-н(41
САьъ зимк
$к|іпг> : ьцкткэвоьл
!ПЗКНПРЛ-ГКоПЛРЫЮ 60 П) 669
мч сомтдпиь
дез САЬЬ рковьЕИ[3›
ХР!Р!‚МТ.61-К|К9НОО ТО &&
экцхмгі : и.
во 10 35
&& во м? 4 = 1, их
47 хгкхпгяцл = хкці
35 симтхпиь
ии 33: м . 1, их
335 ХК.“ : химии
вэи Ритчдтп/ьин ” 1$ МОТ Р05$|ВЬЕ 70 ЗАПЭРУ 'тЕ \!ЮЬАТЕБ СОМёТПАПд
”' >61 Рішн ТНХЬ \]ЕСтОВс ТНЕ ЗЕАЕСН ЪЛЬь ВЕ тЕЕИіНАТЕОо /6!н РъЕАзЕ
2 (нииэь А пни ьтдктхмь чьсток дми КЕРЕАТ эоьитхом дздім )
85] ЁПКМАП1/063Н ТНЕ УЕС'ШК РОК ИНХСН 1НЕ СОМБТКАХМТЗ соиьв НОТ ВЕ ЗА
1тъьг1ьо 1$ 1.1вьхь.ьіл
В>2 ЁОКМАН/іоЕТН ТНЕ тоьскмсе СКГ'ЕКТОМ : 518-6120)“ ЬЧН ТНЕ ЗОЦдЙЕ
1Коит‘иг тнь сомзтпд1мтз зоиАпев 15 - :1ь.ь›
853 РОКИАП/іраін ' * ' ' ' * ЗЦБКОНТЦМЕ РЕАЗВЬ РАЦЭ ТО РХМВ А РЕАЗ
„ьцьрохмтццчичиізъх
ЁЕТШ‘п
Ето
БЦЬНОЦПМЕ $ТАЕТ
0|ИЬП$АОМ А(50›50!
шмьпэшм Х(Э°НХ1(Э°-5Ч›0Х2(50'501.К‘100,|$ШМ50Н5150Н$КК501'
1 КОЦЦЬАО)
СиММОМ/і.!МХ›ПС'МХС›ЗТЕР‚АКРА-ЬЕТАсБАМ‘|П:ХМР-РШРЕК‚ЭЕОЬ9КХ;К2в
1Кэ.кь›к5.кь‚к7‚ке‚к9.х.хх‚ха‚д‚$им.г.зк.кеьв.5сдьіэгоьо
СиимиМ/З/ЬЁЕАЗрЬБ‚&&-Ъ7'Ь8169удідчкгдгкзд
\!М ' МХ
ьТЕРх = зтЕР/‹УМ‹50НТ(2.››°1$ОКТ|чм + 1.) # ун - 1.)
5ТЁР2‘ БТЕР/шмьчкпг-›)ЧьнКпх/м 4' 1.) ' Ь]

0014 = 1: МК
1 АК1-1)= 0.

00 2 1 ‘ 2. к1

00 5 \1 ‘ 15 “Х
и АН..” ' $ТЕР2

Ь =1’ 1

АПН.) . 5ТЕР1
: сомтхпие

во 3 1 = 1. к1
00 3 4 - 1о МХ

513

5720

9730

57А°
5750
5760
5710`
Этно
5790
5500
5510
5820
5330
$650
5850
5560
5570
5880,
5590
5900
5910
5920
5930
ьэьв
5950
5960
5970
5980
5990
6000
5010
6020
6030
6050
6050
6060
6070
6080
6090
6100
6110
6120
6130
61190
6150
6160

6170

6180

6190

6200

6210
6220
6230
6260
6250
6260
6270
6280
6290
6300

6310
6320

6330

631.0

6350

6360

6370

6380

6390
 pagebreak 
514

П ршюжение Б

 

С

а х1!1.ц) - х‹ц› + Аіірд)
кьтикм
Епв
ьиькоитімь ЬК|1ЕХ
рхмкмзъим х‹>и).х1|ЭО.5Ц).Х2(ЬО:50›‚кі100).5им(50)›Р(50)›5п1501‚
1 комокхиоъ
СиИМЦМ/Х/МХ.ЫК-М]С›572РгАЬРАпНЕТА:БАМАвХМ.!МР›Р01ГЕЁо$ЕОЬ‚К1‚К2|
:кз.кц‚къ.кь.к1.кв.к9.х.х1›х2.н‚зпн‚г.эк.п0ьо›$САьЕ.Роьв
симмип/г/ьгідэ‚ка.ь6‚ь7‚ь8‚ь90Р11.Е2А‚кзА
сдъь рноеъЕм‹3›
Ріінт 1' к‹к9›
1 гокмА1‹/‚ квн овцестлув Римстхсп УАЬНЕ = Е17ь7)
РММ ъ [хим а = 1, мхи
2 гоямдт1/. дэн тнг хнввріновпт уссіовз АкЕ /(6617.7›
хгкмс.ви.о: ао то 6 '
:Аьь Рковььм‹1›
Рклмт э. АР(Ц]› 4 = 1. МС)
а РиКМАТ(/› зьн Тне Ечидьхтч с0М5тКА|МТ УАьивз АКЕ /|6517.7›
6 |Р‹мдс.ьо.и) со то 5
сдьь ркивьЕм‹21
РК1ЫТ @ . (під). : = К7|К6’
# РЧНМА711. эьн тнг |пЕицяь1ТУ ‹омзтддхнт удъигз /(6Е1?.1)
5 патоки
впо
зивпоитхмв зима

Е‘*"*ТН16 ЬЦЬКиЧТіМЬ СЬМРОТЕЭ ТНЕ ЗОМ ОР ТНЕ ЗОЦАКЕ УАЪЦЕЗ ОР ТНЕ

С
С

С

ТО

УХЧЪАТЕО СЧМ$7Й81П7$ 1" 0305“ ТО БЕ СОМРАКЕО И‘ТН ТНЕ ТОЬЕКАМСЕ
СКЪ1ЬКАЦМ

ОХНЕМЗЛШМ Х(50)іХ1(50150)‚Х2(50'501›П!100?›50М(50)6Р(50›'ЗЁКБО’О
; киьи‹1но›

сомМин/і/МХ.МС‚М]С.51ЕР‚АЪРАуЕЕТАубАМАиХМ'ХмгугВХРЕд'5Е0Ь1К19К29
1к3.кд›к5‚кь‚к7.кв‚кч‚х›хъ‚хг‚и‚зимьгцэк.каъп‚5САЪЕ‚РОЬР

симмип/2/ЬРЕА5'Ъ57Ь61Ъ71Ь81Ь9181А1Р2Аідзд

5им‹хпи : о.

(Ань риивьімк2›

зьшь = и.

кг‹пхс.ьо.и› со то «

по 1 а = к7. ке

1Р|К(43-65-0-) 60 то 1

звць . заем + к:д›*п141
1 сомтлпие
А 1Р(КС.ЕО.0) со то 3

сАьь РковьЕм‹хл

он 2 4 = 1- мс

2 $Е0Ь ' ЕЕОЪ + ЙСЦ›*К!Ц)
3 Зиміімі = ЗЕОЪ
5 ВЁТОКЫ

ЕМО

Т ретья и последующие карты

6400
6610
6А20
евзо
бьЬО
6650
6560
6ц7о
6880
6690
6500
6510
6520
6530
6560
6550
6560
6570
6550
6590
6600
6610
6620
6630
6650
6650
6660
6670
6680
6690
6706
6710
6720
6730
6760
6750
6760
6770
6780
6796
6800
6810
6820
6820
68Ь0
6850
6660
6870
6880
6890

Если исходные данные задачи, такие, как константы, коэф-
фициенты, значения і (х) и т. п. должны бы'ть введены в про-
грамму, их следует перфорировать на третьей и последующих кар-
тах. При этом можно использовать любое необходимое количество
перфокарт в любом удобном формате. Эти данные считываются в
основную программу Флекси и переносятся в полпрограмму‚ ко-

рая вычисляет функции и сопутствующие выражения задачи

{ЗПВКОПТШЕ РНОВЬЕМ (ШОП с помощью соответствующих
общих операторов.
Операторы РОКМАТ, СОММОМ и НЕАВ для специфических
данных должны обеспечиваться пользователем.
 pagebreak 
Программы на языке ФОРТРАН 515

 

 

Оператор КЕАВ необходимо использовать для данных (кон-
стант. коэффициентов и т, п.), которые сохраняются для всех по-
следующих вычислений. Этот оператор располагается в начале
основной программы после содержащей комментарий карты
«Регшапепі Ваш іог Ше РгоЫеш...» (неизменяющиеся данные за-
дачи...). Если таких данных нет, то пользователь должен изъять
все операторы считывания и распечатки, следующие после ком-
ментирующей карты до оператора 10. Тоша с карт, следующих

сразу после второй карты данных, будут считываться исх0дные

предполагаемые значения переменных ЗЗДЗЧИ,Т. е. ХЁШ, != 1,

МХ. Исходные значения для х‘О) располагаются после послед-
ней карты данных, описанной выше, т е. после второй карты,
если нет коэффициентов или констант, которые должны считывать-
ся. Исходные предполагаемые значения х(°’ должны перфориро-
ваться в формате 8Р`10.5.

Рассматриваемая программа может управлять более чем ОД-
ним набором исходных предполагаемых значений переменных.
Этоозначает, что после отыскания решения для первых исходных
предполагаемых значений переменных основная программа осу—
ществляет считывание дополнительного набора исходных предпо—
лагаемых значений переменных и задача решается еще раз. После
завершения решения управление в программе передается оператору
10 для считывания следующего х…) и сошветствующего решения
задачи. Если нужно изменить данные в задаче (новые коэффициенты
или новые константы), то операторы считывания с сооггветствую
щими операторами по размещениюиформату общих данных должны
быть расположены после оператора 10. Программа заканчивается
картой «Епё оі Рі1е» (конец файли).
 pagebreak 
Приложение В

МАТРИЦЫ

Алгебра матриц широко используется всякий раз, когда при—
ходится иметь дело с большим числом переменных, связанных
линейными соотношениями. Знание некоторых условных обозна-
чений и технических приемов матричного исчисления, а также
представление о прикладных возможностях и границах примени-
мости теории матриц необходимы как для освоения методики реше-
ния важного класса линейных задач, так и для понимания спосо—
бов упрощения громоздких математических записей. Следует
также отметить, что операции над матрицами могут с большой
скоростью выполняться на любой цифровой вычислительной
машине. Главное преимущество использования аппарата теории
матриц заключается в том, что при этом удается избежать боль-
шого числа утомительных, хотя и имеюших стереотипным
характер, элементов вычислительных пропедур. Ниже прив0дят-
ся некоторые наиболее существенные свойства матриц и рассма—
триваются основные операции над матрицами.

В‘1. ОПРЕДЕЛЕНИЯ И ОБОЗНАЧЕНИЯ

Таблицу
“11 012 › . ам
а а. . ‘ а
&= “1.35.37.
а…; дт? - - - ати

содержащую определенным образом упорядоченные элементы аш,
называют матрицей. Первый из индексов, которыми снабжен
каждый элемент матрицы, обозначает номер строки, второй—
номер столбца.

Квадратной называется матрица, в которой число строк рав-
няется числу столбцов. Так, например,

123
а=234
345
 pagebreak 
Матрицы 517

 

представляет собой частный случай матрицы размерности 71 Х гг
при и = 8.

Матрица, имеющая т строк и п столбцов, называется прямо-
угольной. Матрипа размерности 1 Х 1 есть скаляр.

Две матрицы считаются равными друг другу, когда каждый
элемент первой матрицы равен занимающему соответствующее
положение (которое определяется номером строки и номером столб-
ца) элементу второй матрицы.

Матрица, состоящая из единственного столбца, называется
вектор-столбцом (или просто етолбцом), а матрииа, состоящая
из единственной строки, называется вектор-строкой (или просто
строкой). В качестве иллюстрации приведем

]

2
З и вектор‘строку [1 2 3 4].
4

Диагональной называется квадратная матрица, в которой от-
личными от нуля могут быть только элементы, расположенные
на главной диагонали.

Под единичной матрицей (обозначаемой, как правило, через
!) понимается диагональная матрица ‹: диагональными элемента-
ми, равными 1 (остальные элементы равны 0). Так, например,

вектор-столбец

100
1:010
001

есть единичная матрица размерности 8 Х 3.

Матрица, все элементы которой равны нулю, называется ну—
левой матрицей, обозначаемой через 0.

Определитель (детерминант) матрицы & будем обозначать че—
рез сіеі (а). Если (іеі (а) ;& 0, матрица & называется невыроэюден—
ной; если ‹іеі (а) = 0, то говорят, что матрица & является вырож-
денной.

Если в матрице а поменять местами строки и столбцы, то по-
лучится матрица, транспонированная по отношению к а:

ап ад а…
ат : “и “22 а…; _
діп дэн - - - дтп
Так, например, если
{2 0 —1
а =
\ 1 1 4 ’
 pagebreak 
518 Приложение В

 

то
2 1'
ат: О 1 .
—1 4

Симметрической матрицей называется матрица, удовлетворяю-
щая условию & = ат. Например для матрицы

012
а=123
234
012

аТ=123,
234

т. е. а = ат, и, следовательно, мы имеем дело с симметрической
матрицей.

В.2. ОПЕРАЦИИ НАД МАТРИЦАМИ

Сложение матриц. Сумма двух матриц & + Ь = с, где в., Ь
и с—матрицы размерности т >< п, находится путем попарного
сложения всех одинаково расположении элементов а и Ь. Отметим,
что сумма матриц разных размерностей не имеег смысла. Проил-
люстрируем приведенное выше определение на конкретном при—

мере:
ь 20 1—2 [3—2
°=°+=6з+з 2:9 5'

Умножение матрицы на скаляр. При умножении матрицы на
скаляр получается матрица, в которой каждый элемент равен
соответствующему элементу исходной матрицы, умноженному на
данный скаляр. Пусть, например, ос = 8, а

341
а=262
101

Тогда
3х3 3х4 8х1 912 3

«&= 3х2 З><6 З><2 : 618 б .
3><13><03><1 3 0 3

ИЗ ПРИНЯТЫХ выше определений следует, ЧТО
а+(Ъ+С)= (а+Ь)+с‚
а+Ь=Ь+щ
 pagebreak 
Матрицы 5 [9

 

а+0=а‚
ц(а+Ь)=оъа+осЬ.

Произведение двух матриц. Умножение (слева) матрицы а на
матрицу Ь возможно только в том случае, когда эти матрицы
удовлетворяют следующему требованию: число столбцов матрицы &
должно равняться числу строк матрицы Ь (& Называется левым
множителем, а Ь — правым множителем). Заметим, что аЬ, в0‹
обще говоря, не равняется Ьа, хотя в некоторых частных случаях
равенство аЬ = Ьа может иметь место. Для того чтобы умножить
матрицу а на матрицу Ь, необходимо пределать следуюшее: взять
первый слева элемент первой строки матрицы & и умножить его
на первый сверху элемент первого столбца матрицы Ь, затем взять
второй слева элемент первой строки матрицы и и умножить его
на второй сверху элемент первого столбца матрицы Ь и т. д., пока
не будут попарно перемножены все элементы первой строки мат-
рицы а на соответствующие элементы первого столбца матрицы Ь;
после уюго все найденные произведения суммируются, в результате
чего определяется элемент с11 матрицы с = аЬ! Таким образом,

”,
Сп = 2 “іідд'

!=!

Аналогично определятся остальные элементы матрицы с,
т. е. элемент, расположенный в № строке и іе-м столбце матрицы
с = аЬ, определяется следующим сошношнием:

П.
от = 2] анд,»а

‚:

 

Проиллюстрируем сформулированное выше правило на при—
мере умножения матрицы

102
21:21]
012

на матрицу
0 1 3
Ь= 2 1 о .
3 2 1
Произведение равно
(0+0+6) (1+0+4) (3+0+2) 6 5 5
аЬ= (0——2+8) (2+1+2) (6+0+1) = 5 5 7 .

(0—-2+6)(0+1+4) (о+о+2) 8 5 2

Определив произведение двух матриц, можно рассмотреть ряд
дополнительных свойств, которыми обладают матрицы.
 pagebreak 
5 20 Приложение Б

 

Матрица, транспонированная по отношению к произведению
двух матриц. Матрица, транспонированная по отношению и про‹
наведению двух матриц, равняется произведению матриц, транс—
понированных по отношению к исходным матрицам, взятому в
обратном порядке, т. е.

(аЬ)Т = ьТаТ.

34 Ь 02
3:15! —43'
Тогда

Ь__[1618 Т 1620 0431 16 20
а“2017“(“"’)=1з 17=2з4з=1з 17°

Обратная матрица. По аналогии с обратной величиной по от
ношению к некоторому скаляру для невырохщенной квадратной
матрицы & существуег единственная матрица г‘, обладающая тем
свойством, что

Пусть, например,

;да—` : а_‘а = !.

Существуют различные способы, позволяющие выразить элементы
матрицы г‘ через элементы матрицы &; желающие познакомиться
с этими способами могут обратиться к сошветствукицим учебным
пособиям".
Если ат = г', то матрица & называется ортогональной.
Матрица, получающаяся в результате умножения а на ат,
является симметрической. Действительно, пусть

Ь = аа,.
Тогда _
ЬТ = (авт = (ат)таТ = ааТ.

Для матрипьъ транспонированной по отношенпю к невырожден`
ной квадратной матрице &, обратная матрица равняется матри-
це, транспонированной по отношению к г‘, т. е.

(аТ)—і : (2—1 Т.

” Читателю, знакомому с теорией определителей, напомним, что для нахожде-
ния обратной матрицы можно воспользоваться следующей (универсальной) форму-
дой:

А
_] .— _] __ ігі
& = [“Не] =[_—_(іе[ (а) ] ‚

где А ‹ _- алгеб аическое дополнение элемента а в определителе ёеі (в . Ясно,
и Р м

что условие невырожденности :: является существенным: при (іеі (а)= 0 приве-
денная выще формула теряет смысл.— Прим. перга
 pagebreak 
Матрицы 521

 

Нормировка. Длина действительного вектора, т. е. вектора,
все составляющие которого представляют собой действительные
числа, определяется следующим образом:

” '/я
длина вектора )( : (хтх)`/’ = (121%) .

Процедура нормировки вектора х сводится к делению каждой со-
ставляющей х на длину этого вектора (с тем, чтобы получить в
результате единичный вектор). Пусть, например,

х=[1, 2, —3‚ 0].

 

Тогда
Длинах=1/1”+23+(—3)“+0‘==1/П
и
" 1 2 —3 Т
"‘[уП' тя Ё'ОЪ

Виз, ПОЛОЖИТЕЛЬНО ОПРЕДЕЛЕННЫЕ МАТРИЦЫ

Каждой квадратичной форме

,!

і 00 = 2 ацхдхі
ЕЦ].
=,

СООТВЕ’ГСТВУЗТ действительная” симметрическая квадратная МЗТ-
рипа В., ИЛИ, ИСПОЛЬЗУЯ матричные обозначения, МОЖНО написать

і(х) = хТах.

Матрицу а называют положительно полуопределенной (или
неотрицательно определенной), если і(х)>0‚ и положительно
определенной, если і(х)> 0 для любого хаво. Квадратичной
форме [(х) соответствует также бесконечное число других квад-
ратных матриц Ь… не являющихся симметрическими:

} (х) : хТах = ТЬ„х.

Хорошо известно, что необходимые и достаточные условия,
при выполнении которых имеет место положительная определен-
ность, сводятся к следующему: все главные миноры и определи-
тель матрицы а должны быть положительными (или, что эквива-
лентно сформулированному выше требованию, должны быть по-
ложительными все собственные значения данной матрицы). Эти
утверждения справедливы лишь в том случае, если иметь в виду

‘) Матрица называется действительной, если все ее элементы представляю:`
собой действительные числа. — Прим. перев.
 pagebreak 
522 Приложение В

именно матрицу а, а не какую-либо из матриц Ьд. Действитель-
ная несимметрическая матрица может удовлетворять приведен-
ным выше требованиям и все же не быть положительно опреде-
ленной.

Рассмотрим, например,

і(х)=хг+3х+2=п „[2 3Н1]=хтьХ,
О 1 х

‚…… ичз г].

Собственными значениями Ь являются 2 и 1, ‹іеі (Ь) : 2 и глав-
ный минор Ъ равен 2; тем не менее [’ (х) принимает отрицательные
значения в интервале — 2< х< —— 1. С другой стороны, і(х)
может быть представлена в виде

где

3
2 Т

і(х)=хд+3х+2=[1 х] [1]=хтах,
& 1 Х

где & —— симметрическая матрица. Собственными значениями & являю—
тся % = 3/2 + 1/ 10/2 и ?…, = 3/2— 1/10/2 (отрицательное число) и
аеі(а)<0, что полностью согласуется с приведенными ВЫШе кри-
териЯМи положительной определенности при записи {(х) с помощью
симметрической матрицы.
 pagebreak 
7П
75

чб

!ЧП

Приложение Г

СТА НДАРТНАЯ ТАЙМЕР-ПРОГРАММА

РРППЁАМ $ТПЙ [ПЦТРНТУ
тчгмцоммлтьт‚гцэмымлтмчпип
№011 = 40

Н = ЬП

№ . 10

т : А.иьопзщ

пп чп (_ = 1. №

по 25 1 = 1. и

по 25 .! = 1. м

дп… = 1.

тт-л гчтига

мл… = 1 + .:

ткпкпг

& 1,1. .тдтшщммл‚чимшпшт
см…мпа

РПМТ 100; ((Аіьіпі : 1: “1.1
готмткіяпогшзп

Б'МП

‚‹,пвпп'лшг ‚МАпш/М.яком'‚хсоылтимявщзп
тчгмзшм Апшппт'пысаып

№1 - м +'1
00 б 1 = 1,
пт.… = 1
№№… : 1
т 75 пгп =1. "
ММ” = ПГ”

1ч “!)

М

3:10
301

м;
тт
…

ЗОИ
3%
15

20

‚‹
чп

15

да
да

чт

55

дп

д.г—

""

75

Мьуп : 1

три» = щими
171тгмртзпо‚зсхрзо\
тгмв = —тЕмр
СОМПМ'Е

[1М110 : м9! › !гги
по 15 1 = |тгп.м

по 15 и = ». ъіихто
|.) = [.’—1)*‘№В|Ч+ !
^°5^ = АПЛ
1гкддчА11Рг.тазрэоз
Апкд : — дязл
і'іТг'йР-АР'ЛПОЦ'Н'КБ

 

ЧАкч : !

МАК!) _]

тгчп = А:…)
|Р|ТЁМР330ді3059105
п.№ = чвмг
СОМПМЧЕ

спмптпЕ

”(тЕМР-змьзп 20.20.25
1й0ы‹М°1› : ттЕй
ягшпм
|Р…дХГг—1ТГР1
По 15 д = 1. М
мхи = пчпмшцд …на
11.1 =і-1—!П^:П|№ # 1ТГ°
ТЁЧР = А|ИАХ°.П

мины) : мпл

мпл = ТПМР

”гыг: тощим…
дв…цидхщ - \Рпщпсю
|Бп'*'(ПЕ°] = ПГ…”
!г|чдхп — !! Ьз'ч6‚ч5
пп’дп ! = \, М

)Мдуп = (тдхп—13кытім + !
ТЕМР ; МП

МП = АПУАХП!

Ацз-мхп) : 7594г!

ПР'ЧР ! КПЬЩАКП)
КОНЧЁХ’)! 4 КСП,”!
|тип : ПЕМР

ПМР - АПТЕ”)

17гмр : !Счькіі

пп м ) = 7; М

пдщ : н—гпмти + 1169
П.! ; |.1—)›'^ч’\1`д + |ТГ°
А11Т1М1] : Акітці/УРМР
[(ты—н : кт.…)

1Т№ = (Ы—ННЩШ + ПЕ?
МП'Н ‘! .пгмп

!ГОЫШ _ ПЕУ°

по 75 ! = 1. М

”(!—”[Р] !:517‘1'65

ТЕМ” : АН)

”П 7›’\ 4 = 2. "

|л”| = (4-2)*чпги + 1

|.: = ы—пвнтих

п.№ : ‹.ьгнмщчптт
АПАУН = АП.” ›— ЛПТЦ'ЧПУЁ
спчпш-г

ім = ‹м-\›!ппіи « !

ПМ = (&'—ХПШЧЧ $11".
АПМ) ' ЧТЕУР‘ЩПТМН
СОМТНШЕ

по ио ] : 1. м

по эп .; я \. М

хгпчошл - :; всеамо

ЭО №0134"
 pagebreak 
524

 

00
85
90

\?д

105
1.25

‘СОМТНЧОЕ'
хт-лоотом

00 95 |. ' \: М
|.1хн-11хышм +1‚
Ы = (.'—ПЦН)!“ + Ь
ТРМР : АЦП

АЦП : АЦ…Л

А“…” = ТЕМР

\поиш) = Нюши
СОМПМЦЕ'

00125 1 = 1' ^!
п0105м= 1, м
]РПСОДШЪ-Н 1054101105
1511-Л11‘ч1257115
…) 120 |- * 1‘ М

и, - П- —1›щтм +!
_11. = “. ' ““МДМ * .!
ТЕМР ; МН.)

АПК.] = дні.)

мл.) = тгчр

Шац.” =1соЦЦ

бп ТО 125

спмпмж

СОМПМНЕ'

!ЧПИЩРП : °

Огни…

гиг)
 pagebreak 
Приложение д
ОБОЗНАЧЕНИЯ

а — константы или постоянные коэффициенты (раз-
личаются индексами);

аи— элементы матрицы а (или А);

а —— матрица коэффициентов;

а, — вектор-столбец матрицы;

‹ДЫ—числовое значение, определяемое по формуле
(8.3.7);

А — матрица, состоящая из постоянных элементов а„;

А,- —— векторы, ассоциированные с методом Розенбро-
ка;

А… — матрица, ассоциированная с соотношением
(3.4.5);

А, —— матрица, состоящая из коэффициентов, фигури-
рующих в совокупности ! ограничений;

!) —— константы или`посгоянные коэффициенты (раз-

„ личаюгся индексами);

Ь—собственное значение матрицы (каждому соб-
с’гвенному зничению присваивается свой индекс);

Ь — вектор—столбец, составленный из коэффициентов
при сответствующщ переменных;

Ьі —— 1-я строка матрицы В,„;

В, —— матрицы, определение которых дано в связи с
рассмотреНИем соотношения (4.3.2);

В… _— матрица, ассоциированная с соотношением
(3.4.5);

Вт—матрица, состоящая из коэффиииентов‚ фигу—
рирующих в сиотеме ограничений, имеющих
вид неравенстъз;

с— константы или постоянные коэффициенты (раз—
личаются индексами);

сд —- константа;

сд — диагональный элемент матрицы С;

с — вектор-столбец матрицы 0;
С — диагональная машина, определение которой

дано В СВЯЗИ С рассмотрением соотношения
(3.2.8);
 pagebreak 
526 Приложение Д

 

а—символ полной производной;_ элемент матри-
цы 0;
ад— случайная величина, характеризующаяся нор-
мальным распределением;
дій — величина, определение которой дано в связи с
рассмотрением соогношения (6.5.10);
В,. —— направляющий: косинус;
!) — матрица, с помощью которой строится правиль-
ный многогранник в Е“;
1), — вектор-столбец матрицы 1);
е,- — собственный вектор, соответствующий щ;
Е —— эффективность при одномерном поиске;
В (!г) —— относительное улучшение целевой функции на
16—м этапе оптимизационного поиска;
Е“ —— п-мерное евклидово пространство;
ЕМ — погрешность за счет линеаризации в методе

ПОП;
Е (х,п‚ш)—функция, двойственная по отношению и Р-
функции;
і (х)—целевая функция; значение целевой функции
в точке х;

;“ (х*) _— оптимальное значение ‚‘(х);
Е(х) _- аргумент і (х);
Рд — число Фибоначчи;
Е(х“), а) —- параметр в алгоритме Голдштейна — Прайса;
В (х) —— функция, задающая ограничение в виде нера-
венства (каждой функции присваивается свой
индекс);
Ае“) = № (Х…, — И (хип;
@ (3, (х)) — функционал над множеством ограничений в виде
неравенств;

6… = №8…) Ад… 520%]…

Щ,— (Ъ…) — диагональный элемент матрицы Н (х) (Н (х));
11 — вектор, составляющими кторого являются
функции, задающие ограничения в виде равенств;
Р:, (Х) — функция, задающая і—е ограничение в виде ра—
венства;
Н, Н (х) _ матрица Гессе целевой функции;

Н, Н (х), Н°“ (х) — приближенная (или усредненная) матрИЦа
Гессе;
Н (И; (х)) —— функиионал над множеством ограничений в виде
равенств;
! — единичная матрица;
|,- —— 1-й столбец матрины !;
.! — матрИЦа Якоби;
 pagebreak 
Обозначения 527

 

К —- бОЛЬЩое (фиксированное) число;
К' —- совокупность индексов, дополняющщ множество
индексов, асюциированных с базисом;
!, — функция Лагранжа;
[„ — нижняя граница для х,;
т — число ограничений в виде равенств;
т;,” — величины, определение которых дано в связи с
рассмотрением $6. 1. 3);
М?" — оценка (Ат… А, на іг мзгапе вычислительного
процесса;
м — линейное многообразие;
п —— суммарное число переменных;
№ -— норма;
р — полное число ограничений (как в виде равенств,
так и в виде неравенств);

;—

р—число ограничений в виде неравенств, оказав-
шихся нарушенными во внешней точке;
р*— полное число ограничений в виде неравенств;
р$”’——величины‚ определение кагорых дано в связи
с рассмотрением (6.3.1);
Р (кид, р…) — штрафная функция (обобщенная присоединен-
ная функция) с весом р… на іг-м Шаге;
Р (х…, г…) — штрафная функция (обобщенная присоеднненная
функция) с весом 702) на іг-м шаге;
Р (х) — обобщенная присоединенная функция; штраф-
ния функция;
РБ!” _- проектирующая матрица на іе—м шаге (индекс !
обозначает число связанных с нею ограничений);

137” —проектирующая матрипа (индекс ! обозначает
число связанных ‹: нею ограничений);
‹; — константа;
4$!” — величины, определение которых дано в связи с
рассмотрением (6.3.1);
‹; (х) —- кмдратнчная целевая функцм или ее прибли-
жение;
0 — положительно определенная квадратная матри—
ЦЗ;
=(п ——- т) — число степеней свободы; весовой
коэффициент в методе штрафных функций;
г (хдд) — вектор возврата‚ определяемый соотношением
(6.3.17);
г, _ диагональная машина, элементами которой яв-
ляются случайные числа;

!? — множество допустимых точек в Е”;
 pagebreak 
Приложение Д

 

Р
1
К(х) _“ ‚ёё: (›0'

К—симметрическая матрица, используеМая в алго-
ритме Пирсона;

$ — расстояние;

5 — вектор-столбец, задаюший направленИе ОПТИМИ-
зационного поиска;

„
5 _ единичный вектор-столбец, указывающий на-
правление оптимизационного поиска;
8* —- множество допустимых точек;

5… —— вектор, составляющими которого являются
масштабные коэффициенты;

!——расстояние между двумя вершинами; параметр
размера исходного многогранника в методе сколь-
зящего допуска;

Т(х) »функционал Над множеством всех ограничений,
т. е. нид множеством функций Ид (х) и 3, (х);
и,——ослабляющая переменная для і-го неравенст-
ва;
и, „множитель Лагранжа, ассоциированный с і-м
ограничением в виде неравенства;
и;———множитель Лагранжи в экстремальной точке;

ц —— вектор, сосшвляющими кагорого являются мно-
жители Лагранжа;

ці” — полученный на !е-м шаге вектор, составляющими
которого являются множители Лагранжа в !
активных ограничениях;
[) — унишрная матрицз;
и! — оператор Хевисайда (принимает значения 0 или
1):
П, — верхняя граница для х,;
и, ——- ослабляющая переменная для 1—го неравенства;
\! —- любой вектор-столбец общего вида;
ші — искусственная переменная для і-го равенства;
ш,- —— множитель Лагранжа, ассоциированный с огра-
ничением в виде равенства;
ш} _ множитель Лагранжа в экстремальной точке;
“! — положительно определенная симметрическая
матрищж;
х _— произвольная Независимая переменная;
х, —— составляющие вектора х;
х’. —— составляющие вектора х*;
х„- —- і-я составляющая і—го вектора в Б”;

: .
х; — аппроксимация 361;
 pagebreak 
Обозначены я 529

х — вектор-столбец, составляющими которого явля-
ютоя независимые переменные;

х* -— значение х, соответствующее оптимальному ре—
шению задачи нелинейного программирования;

х„ — вершина, соответствующая наиболъшему значе-
нию целевой фунхЩИИ;

х‚‹ —- і-й вектор (или і-я вершина), ассоциированный
(или ассоциированная) с минимизацией [(х);

х,——вершина, соответствующая наименьшему зна-
чению целевой функции;

„

х,—і-й векюр, ассоцшфованный с минимизацией
ТОК);

х“ _— приближенное значение х, при котором достига-
ется минимум [ (х);

Х,——произвольный скаляр; произвольный полином;
произвольный вектор;

! __ Т.
Х“ = [Ах<°’Ах<1) Ах“ "] ,
—- пе еменная величина; в яде сл чаев—целе—
у Р У

вая функция;
(’в)

у,- ——значение независимой переменной, полученное
в результате одномерного оптимизационного
поиска;

у — произвольный вектор-столбец;
г, — составляющая приведенного градиента;
: — вектор-столбец произвольного вида; приъаеден—

ный градиент; вектор ретроспективных данных,
используемый в (4.5.1);

0
2 (Х) = 12235 (Х) —- сумма квадратов функций, ассоци-

ированных с теми ограничениями, каторые ока—
зываются нарушенными (для внешней точки).

ГРЕЧЕСКИЕ БУКВЫ И СИМВОЛЫ

а_— коэффициент растяжения в методе Розенброка;
обычная константа; коэффициент отражения в ме—
тоде Нелдера и Мида;

ад —— собственное значение матрицы;

и,: — коэффшиент;

р _ коэффициент сжгтия в методе Нелдера и Мида;
 pagebreak 
Приложение Д

 

константа в соотношении (3.2.11); коэффициент
редукции в методе Розенброка;

у— коэффициент растяжения в методе Нелдера и
Мида; малая постоянная величина; обычная

константа;
? — Белшина, определяемая с помощью соотношения
(6.3.8);
Г —ЁеЁ1ичина‚ определение которой дано в подразд.
. ‚4;

б —— параметр в алгоритме Голдштейна — Прайса;
6, —- единичный вектор вдоль і-й оси координат;
6$,“ — константа; параметр;
б (х)—аргумент‚ для которого функция {(х) при не—
которых ›‹ в Б” не определени;
д —— символ частной производной;
А «символ приращения переменной величины Или
вектора (например, Ах);
А“” —— ограничивающий интервал при одномерном
поиске;
7х — градиент, включающий частные производные
‚ЛИШЬ ПО СОСТЗВЛЯЮЩИМ вектора Х;
Уф (х) — вектор—градиент фунхщии ф (х);
72ф(х) — матрица Гессе для ф (х);
в — произвольно малое положительное число;
11 — весовой коэффициент при лаграНЖИане;

пт, Ц (Х…) —- матрица, вещающая направление поиска на іг-м
этап‘е вычислительного процесса;

… матрица, задаЮЩая направление поиска На іг-м
этапе вычислительного процесса при наличии ]
ограничивающих условий;

9 — константа, значения которой лежат в интервале
от 0 до 1; в ряде случаев обозначает также угол;
Б“” —— параметр в алгоритме Голдштейна _— Прайса;
см. соотношение (8.1.2);
7», № ‹— параметр, задающий длину шага в направлении
ОПТИМИЗЗЦИОННОГО ПОИСКЗ;

А…, ?:… — длина шага, обеспечивающего минимизирующую
поправку для [’ (х) при перемещении в направле-
нии поиска (в ряде случаев Имеет нижний индекс);

7», — содержимое счетчика в методе НЛП;

Ад — направление поиска, определение которого дано
в связи с рассмотрением (4.3.1);

р.,- —— Масштабный множитель;

№ —— коэффициент 5 (3.3.4);

!?
пі’
 pagebreak 
Обизначгния 531

 

% — двойственное верхнее предельное значение в
МПБМ;
ё— выбираемая константа, используемая в ПОП,
а также малая величина;
пд _ плоскость, касательная к линии уровня целевой
функции в точке х…;
П _ масштабированная приближеннзя матрица Гессе;

П — аппроксимация П, но с положительными собст-
венными значениями;
р — весовой множитель в структуре штрафной функ-
ЦИИ;
р; —— параметр, учитывающий число осцилляций в
процессе применения метода НЛП;
т— единичный координатный вектор по отношению
к базису А;
т,- _- составляющие вектора т;
7… — аппроксимация матрицы Гессе целевой функции;
ф—случайный угол (при равномерном распределе-
нии);
ф (х) — выпуклая функция; иногда функция произволь-
ного вида;
ф _ вектор—столбец, введенный в (6.3.17);
Фш— критерий допуска для нарушений ограничений
в методе скользящего допуска;
ср (х…) — направление в алгоритме Голдштейнв — Прай-
са;
чз (х) — функция вектора х;
ш,. — весовой коэффициент;

9, _ г—я строкз матрицы (дЬ/дхі)“

ВЕРХНИЕ ИНДЕКСЫ

5, с, т —- обозначают точки при одномерном поиске;
іг — номер этапа (или шага) в процессе минимизации
НХ):
в—номер этапа (шага) в процессе минимизации
Т (Х);
Т— обозначает операцшо транспонирования.

НИЖНИЕ ИНДЕКСЫ

п— і-я вершини в Е“, соответствующая наибольше-
му значению [ (х);
1 — множество ограничений рассматриваемой задачи;
м —— проекты вектора на многообразие м.
 pagebreak 
Приложение Д

 

ЗНАЧКИ НАД БУКВАМИ И СИМВОЛАМИ

… — знак приближения или преобразования;
/\ —— знак, применяемый для обозначения единИчного
вектора;
’ — используется для того, чтобы отличить одну
константу (или переменную величину) от другой
константы (или переменной величины).

ДОПОЛНИТЕЛЬНЫЕ ОБОЗНАЧЕНИЯ

\… — показывает, что имеется в виду длипа вектора;
норма, т. е. квадратный корень из суммы квад-
ратов составляющих вектора;

| —- символ абсолютного значения скаляра;

( —-—символ множества;

|— означает «при условии, если»;
6 — знак принадлежиости (элемента множвству);
Ц —— оператор умножения.
 pagebreak 
СОДЕРЖАНИЕ 1)

Предисловие.. ......

Глава1.Введение. ..........

Глава 2. Задача НеЛИНЕйНОГО программирования И ее оптимальное решение

2.1. Задача линейного программирования . . . ........ .
2.2. Общая задача нелинейного программирования . ......
2.3. Связь задачи нелинейного программирования с реальным про-

цессом ............... . . . . . ......
2.4 Обозначенняитерминология . . . . . . . ......
2. 5. Необходимые и достаточные условия оптимальности решения

26. Эффективные методы одномерного поиска . . . . . . . , . .
2.7. Классификация методов нелинейного программирования . . .
Литература

Часть 11. Методы нелинейного программирования без ограничений

Глава 3. Методы минимизации без ограничений, исполъзующие производ-

ные

З…[Градиентные методы

З. 2. Метод вторых производных (метод Ньютона) и связанные с ним
алгоритмы. ............. .........

3..3 Сопряженностъисопряженные направления . . , . . . . . .

3.4. Методы переменной метрики . . . . . . . . . . .

З. 5. Краткий обзор алгоритмов программирования без ограничений

Лнтература

Глава 4. Методы минимизацни без ограничений. не использующие производ-

ные(методыпоиска)‚... .......
4.1.Прямойпонск
4.2. Поиск по деформируемому многограннику . . . . . . . . .
43. Ме'шды Роаенброкаидэвиса, Свенна, Кемпи . ‚ _ . . . _ .
4.4. МетодПауэлла . . . . ‘ . . . . . . ...........
4.5. Методы случайного поиска . ....... . . .

 

Литература.............'......:::..:.

Главаб. Сравнение алгоритмов нелинейного программирования при тсуг-
ствинограничений......................

 

14

14
18

30
39

58

98
117
142
153

210

!) Перевод предисловня и глав 1—5 выполнен И. М. Быховской, главы 6—9,
приложения А—д переведены Б_ Т, Вавиловым.
 pagebreak 
534 С одержимые

 

5..1 Круперииоценки
5.2. Тестовыезадачи . . . .. ....... .… ..
53. Оценивание алгоритмов нелинейного программирования при
ОТСУТСТВИИ ограничений ‚ . . . ‚ . . . . . . . ‚ . . . . .
Литература .

Часть !!!-Методы нелинейного программирования при наличии ограничений

Глава 6. Процедуры минимизации при наличии ограничений: методы ли-
нейнойаппроксимации

6.1. Аппроксимирующее линейное программирование .
6.2. Алгоритм нелинейного программирования . . . . .
6.3. Проективные методы . . .....

б 4. Метод допустимых направлений (метод Заутендайка)
6.5. Метод обобщенного приведенного градиента (МОПГ)
Литература

Глава 7. Процедуры минимизации при наличии ограничений: методы штраф-
ныхфункций .

7. 1. Методы штрафных функций специальной структуры .
7. 2. Метол последовательной безусловной минимизации (комбиниро-
ванный метод штрафных функций) . . . . . . . . . . . . .

Литература....:.... .....
Глава 8. Процедуры минимизации при наличии ограничений: метод сколь-
зящегодопуска

8.1. Определение Ф, Т(х) Ипочти допустимых точек . . . . . . .

8.2 Стратегия алгоритма скользящего допуска . . . . . . . . .

8.3. Процедура о‘гыскания допустимых и почти допустимых точек

8..4 Началоиокончаниепоиска

85. Методы решения задач нелинейного программирования с зо-

нальной неопределенностью . . . . . . . . . › . . . . . .

Литература

Главаэ. Оценка эффективное… методов нелинейного программирования
приналичииограннчении

9.1 Критерии, используемые при оценке эффективности ал-
горитмов нелинейного программирования . . . . . . .

9. 2 Сравнение некоторых алгорит_мов нелинейного программирова-
ния при наличии ограничений: двумерные задачи . . ‚ . .

9.3. Сравнение некоторых алгоритмов оптимизации при наличии
ограниченийвслучае более сложных задач . . . . . . . .

Литература

Приложение А. Задачи нелинейного программирования и их решения . . .

Приложение Б. Программы на языке ФОРТРАН, иепос'гавляемые коммер-

чеСКИ.........................‚......

ПриложениеВ.Матрицьх . . . . . . . . ‚ . . . . . . ........
Приложение Г.Стандартнаятаймер-программа . . . . . . . . . . ... .

ПриложениеД.Обозначения ‚ . . ... . . . . . . . . ‚ . ‚ . . . .

210
214

220
237

242

246
266
269
300
303
329

387

345
378

381

382
385
392
400

407
410

411

411
416

424
443

444

480
516

523
525
 pagebreak 
УВАЖАЕМЫЙ ЧИТАТЕЛЫ

Ваши замечания о содержании книги, ее оформлении, качестве
перевода и другие просим присылать по адресу: 129820, Москва,
И-110, ГСП, 1-й Рижский пер., 2, издательство «Мир):
 pagebreak 
Д. ХИММШЪБЛАУ

ПРИКЛАДНОЕ НЕЛИНЕИНОЕ
ПРОГРАММИРОВ АНИЕ

Редактор л. П, Якименко
Художник С. А. Бьппюв
Хутжест'венный редактор В. К. Бисенгалиев
ехнический редактор Т. А. Максимова

Слава и набор 22/1 1975 г. Подписано к печати 25…1111 1975 ?-
Буиага М 2 ВОХВОЧи - 16,75 буи. и. 38,50 печ. л. Уч.—иад. л, вип.
Над. М 20/7553. Цена 2 \ъ 35 к‚ Зак, ЗМ.

ИЗДАТЕЛЬСТВО «МИР»
Масква. і-й Рижский пер., 2

Отпечатано :: ордена Трхідового Краснею Знамени
Ленинградской типографии и 2 имени Евгении Соколовой
Союзпелиграфпрома при Государственном комитете
Совета Министров СССР
по делам издательств, полиграфии и книжной торговли.
198052. Ленинград 31-52, Измайловский проспект, 29, с матриц
Головною пре приятии республиканского производственном
объединении « олиграфкнига» Госкрмиэдата УССР, !, Киев,

ул. Довженко, з.